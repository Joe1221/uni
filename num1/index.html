Bernhard Haasdonk

haasdonk@mathematik.uni-stuttgart.de

Frederik Kisssling

kissling@mathematik.uni-stuttgart.de

Abgabe Mittwochs übung


<h1>Approximation und Interpolation</h1>

<p>
Sei $V= \{\Phi(x;a_0,\dotsc, a_n) | a_0,\dotsc,a_n\in \R\}$ eine Menge stetiger Funktionen für $x\in \R$, deren Elemente durch Parameter $a_0,\dotsc,a_n$ parametrisiert sind.
Seien Stützstellen $\{x_i\}_{i=0}^n\subset \R$ und Zielwerte $\{t_i\}_{i=0}^n$ gegeben (z.B. Messungen oder Funktionwerte einer komplizierten Funktion $f_i=f(x_i)$, oder Ergebnis eines Computerprogramms).
</p>
<p>
Finde Parameter $a_0,\dotsc, a_n$, so dass
\[
	\Phi(x;a_0,\dotsc, a_n) = f_i \qquad i= 0,\dotsc,n
\]
(„Interpolation“) oder allgemeiner:
\[
\sum_{i=0}^n(\Phi(x_i; a_0,\dotsc a_m) -f_i)^2 \qquad \text{minimal}
\]
(„Least-squares-Approximation“)
</p>

<section class="exp">
	<ul>
		<li>
			Polynominterpolation:
			\[
				\Phi(x; a_0,\dotsc, a_n) = \sum_{k=0}^na_kx^k \in \P_n
			\]
		</li>
		<li>
			Trigonometrische Interpolation:
			\[
				\Phi(x;a_0,\dotsc,a_m,b_1,\dotsc, b_m) = \f {a_0}2 + \sum_{k=1}^m (a_k\cos kx + b_k \sin kx)
			\]
		</li>
		<li>
			Spline-Interpolation:
			Sei $a=x_0\lt x_1 \lt \dotsb \lt x_n = b$, $q,r\in \N_0$, $q\le r$
			\[
			V := \{f\in \C^q([a,b]) | f_{[x_i,x_{ibm}]}\in \P_r, i=0,\dotsc,n-1\}
			\]
			(global $q$-mal stetig differenzierbare Fuktionen, stückweise polynomial vom Grad $r$)
		</li>
		<li>
			Exponentielle Interpolation (nichtlinear)
			\[
			\Phi(x;a_0,\dotsc, a_m,\lambda_0,\dotsc, \lambda_m) = \sum_{k=0}^m a_ke^{\lambda_k x}
			\]
		</li>
		<li>
			Rationale Interpolation
			\[
				\Phi(x; a_0,\dotsc, a_m, b_0,\dotsc, b_{\_m}) = \f {a_0 + a_1x + \dotscb + a_m x^m}{b_0 + b_1x + \dotsb + b_{\_m}x^{\_m}}
			\]
		</li>
	</ul>
</section>

<ul>
	<li>Ist die Approximations/Interpolationsaufgabe zu gegebenem $V$ und Daten ($x_i,f_i$) lösbar? eindeutig?</li>
	<li>Wie finden wir algorithmisch die Koeffizienten?</li>
	<li>Können wir Fehleraussagen treffen?</li>
	<li>Was ist die optimale Stützstellenwahl?</li>
	<li>…</li>
</ul>


<h2>Polynominterpolation</h2>

Sei $\{x_i\}_{i=0}^n, ${f_i}_{i=0}^n$ gegeben mit $x_i\neq x_j$ für $i\neq j$.

<article class="st" id="st-1.1">
	<h1>Existenz und Eindeutigkeit</h1>
	Es existiert genau ein Polynom $p\in \P$ mit $p(x_i)=f_i$ für $i=0,\dotsc,n$.
	<section class="proof">
		$p(x) = \sum_{k=0}^n a_k x^k$ löst das Interpolationsproblem $p(x_i)=f_i$ genau dann, wenn $a=(a_k)_{k=0}^n \in \R^{n+1}$ löst $a_0 +a_1x_i^1 + \dotsb a_nx_i^n = f_i$ für $i=0,\dotsc,n$.
		Das ist äquivalent zu $Aa=f$ mit
		\[
		A= \begin{pmatrix} 1 & x_0 & x_0^2 & \hdots & x_0^n \\
		\vdots  \\
		1 & x_n & x_n^2 & \hdots & x_n^n\end{pmatrix}, f= \begin{pmatrix}f_0 \\ \vdots \\ f_n\end{pmatrix}
		\]
		Wir zeigen, dass $A$ regulär ist, bzw. $\ker(A) = \{0\}$.<br />
		Sei $\_a \in \R^{n+1}, A\_a=0$, dann erfüllt
		$\_p(x) := \sum_{k=0}^n\_a_k x^k$ die Gleichung $\_p(x_i)=0$.
		$\_p$ ist Polynom von Grad $n$ und hat $n+1$ Nullstellen. Also $\_p=0 \implies \_a_k=0 \implies \_a=0$
	</section>
	<section class="note">
		<ol>
			<li>Darstellung in Monombasis $p(x)= \sum a_kx^k$ heißt Normalform des Interpolationspolynoms</li>			
			<li>Die Matrix $A$ aus dem Beweis ist die <em>Vandermondematrix</em>, typischerweise schlecht konditioniert, voll besetzt, daher das LGS $Aa=f$ recht aufwändig zu lösen</li>
			<li>Bei Verwendung anderer Basen ist das Interpolationsproblem leichter zu lösen.</li>
			<li>Allgemeine lineare Interpolation:
			Sei $\{\phi_k\}_{k=0}^n$ linear unabhängig. Dann gilt
			\[\ba
			p(x) = \sum_{k=0}^n a_k \phi_k(x) \text{löst die Interpolationsaufgabe}
			\iff a\in \R^{n+1} \text{löst} Aa=f \text{mit} f=(f_i)_{i=0}^n \text{und} A= \begin{pmatrix}\phi_0(x_0) & \hdots & \phi_n(x_0)\\
			\ea\]
			</li>
		</ol>
	</section>
</article>

<article class="st" id="st-1.2">
	<h1>Lagrange-Form</h1>
	Die <em>Lagrange-Polynome</em>
	\[
	L_k^n(x) = \prod_{i=0, i\neq k}^n \f {x-x_i}{x_k-x_i} \qquad k=0,\dotsc,n
	\]
	erfüllen
	\[
	L_k^n(x_i) = \delta_{ik} \qquad i,k=0,\dotsc, n
	\]
	und bilden eine Basis für $\P_n$ und das Interpolationspolynom hat sogenannte <em>Lagrange-Form</em>
	\[
	p(x) = \sum_{k=0}^n f_k L_k^n(x)
	\]
	<section class="proof">
		Siehe NLA
	</section>
	<section class="note">
		<ul>
			<li>Wegen $L_k^n(x_i)=\delta_{ik}$ nennt man die $\{L_k}_{k=0}^n$ eine nodale Basis</li>
			<li>Lösen eines LGS entfällt, da zugehörige Matrix $A=I$.</li>
			<li>$L_k^n(x)$ recht aufwändig auszuwerten</li>
			<li>Die Basen sind nicht hierarchisch, d.h. ${L_k^n} \not\subset \{L_k^{n'}\}$ für $n'\gt n$.</li>
		</ul>
	</section>
</article>

<article class="df" id="df-1.3">
	<h1>Newton-Polynome, Newton-Form</h1>
	Wir nennen
	\[
	N_k^n(x) := \prod_{j=0}^{k-1}(x-x_j) \qquad k=0,\dotsc,n
	\]
	<em>Newton-Polynome</em> und die Darstellung des Interpolationspolynoms
	\[
	p(x) = \sum_{k=0}^n a_k N_k^n(x)
	\]
	<em>Newton-Form</em> der Interpolierenden.
</article>

<article class="lem" id="lem-1.4">
	<h1>Eigenschaften</h1>
	<ol>
		<li>$N_k^n(x_j) = 0$ für $0\le j \le k$ </li>
		<li>${N_k^n}_{k=0}^n$ bilden Basis für $\P_n$</li>
		<li>Die Basen sind hierarchisch: $\{N_k^n\}\subset \{N_k^n'\}$ für $n'\gt n$</li>
	</ol>
	<section class="proof">
		1. und 3. sind klar.

		$N_k^n \in \P_n$ ist klar, zeige lineare Unabhängigkeit.
		Sei $a\in \R^{n+1}$ mit $0=\sum_{k=0}^n a_k N_k^n(x)$.
		Angenommen $a\neq 0, wähle $k_0 := \max\{k | a_k \neq 0\}$.
		Also
		\[
		0 \neq N_{k_0}^n = - \f 1{a_{k_0}} \sum_{k=0}^{k_0-1}a_k N_k^n(x)
		\]
		Also hat $N_{k_0}$ Grad $k_0$ und ist Summe von Polynomen niedrigeren Grades, ein Widerspruch.
		Damit ist $a=0$ und $\{N_k^n\}$ linear unabhängig.
	</section>
	<section class="note">
		<ul>
			<li>Die Interpolationsmatrix ist eine untere Dreiecksmatrix</li>
			<li>LGS ist durch Vorwärtseinsetzen in $\mathcal O(n^2)$ lösbar</li>
			<li>Alternative Berechnung: Dividierte Differenzen (später)</li>
		</ul>
	</section>
</article>

<article class="ex">
	Sei $n=2$.
		<table border="0">
			1 2 3
			2 3 6
		</table>
	$N_0^2(x) = 1, N_1^2(x) = (x-1), N_2^2(x) = (x-1)(x-2)$
	Das zugehörige LGS ist
	\[
	\begin{pmatrix}1&0&0\\1&1&0\\1&2&2\end{pmatrix}\begin{pmatrix}a_0\\a_1\\a_2\end{pmatrix} = \begin{pmatrix}2\\3\\6\end{pmatrix}
	\]
	Es ergibt sich $a_0=2,a_1=1, a_2=1$ und damit das Interpolationspolynom
	\[
		p(x) = 2 + 1\cdot(x-1) + 1(x-1)(x-2) = x^2 - 2x+3
	\]
	
</article>
	

<h1>Numerische Integration</h1>

<h1>Nichtlineare Gleichungsysteme</h1>

<h1>Optimierung</h1>


