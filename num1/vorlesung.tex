\documentclass[a4paper,10pt]{scrartcl}
\usepackage{mathe-vorlesung}

\title{Analysis 3}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Approximation und Interpolation}

Sei $V= \{\Phi(x;a_0,\dotsc, a_n) | a_0,\dotsc,a_n\in \R\}$ eine Menge stetiger Funktionen für $x\in \R$, deren Elemente durch Parameter $a_0,\dotsc,a_n$ parametrisiert sind.
Seien Stützstellen $\{x_i\}_{i=0}^n\subset \R$ und Zielwerte $\{t_i\}_{i=0}^n$ gegeben (z.B. Messungen oder Funktionwerte einer komplizierten Funktion $f_i=f(x_i)$, oder Ergebnis eines Computerprogramms).

Finde Parameter $a_0,\dotsc, a_n$, so dass
\[
	\Phi(x;a_0,\dotsc, a_n) = f_i \qquad i= 0,\dotsc,n
\]
(„Interpolation“) oder allgemeiner:
\[
\sum_{i=0}^n(\Phi(x_i; a_0,\dotsc a_m) -f_i)^2 \qquad \text{minimal}
\]
(„Least-squares-Approximation“)

\begin{ex}
	\begin{enumerate}
		\item 
			Polynominterpolation:
			\[
				\Phi(x; a_0,\dotsc, a_n) = \sum_{k=0}^na_kx^k \in \P_n
			\]
		\item
			Trigonometrische Interpolation:
			\[
				\Phi(x;a_0,\dotsc,a_m,b_1,\dotsc, b_m) = \f {a_0}2 + \sum_{k=1}^m (a_k\cos kx + b_k \sin kx)
			\]
		\item
			Spline-Interpolation:
			Sei $a=x_0\lt x_1 \lt \dotsb \lt x_n = b$, $q,r\in \N_0$, $q\le r$
			\[
			V := \{f\in \C^q([a,b]) | f_{[x_i,x_{ibm}]}\in \P_r, i=0,\dotsc,n-1\}
			\]
			(global $q$-mal stetig differenzierbare Fuktionen, stückweise polynomial vom Grad $r$)
		\item
			Exponentielle Interpolation (nichtlinear)
			\[
			\Phi(x;a_0,\dotsc, a_m,\lambda_0,\dotsc, \lambda_m) = \sum_{k=0}^m a_ke^{\lambda_k x}
			\]
		\item
			Rationale Interpolation
			\[
				\Phi(x; a_0,\dotsc, a_m, b_0,\dotsc, b_{\_m}) = \f {a_0 + a_1x + \dotsb + a_m x^m}{b_0 + b_1x + \dotsb + b_{\_m}x^{\_m}}
			\]
	\end{enumerate}
\end{ex}

Potentielle Fragestellungen:
\begin{itemize}
	\item 
		Ist die Approximations-/Interpolationsaufgabe zu gegebenem $V$ und Daten $(x_i,f_i)$ lösbar? eindeutig?
	\item
		Wie finden wir algorithmisch die Koeffizienten?
	\item
		Können wir Fehleraussagen treffen?
	\item
		Was ist die optimale Stützstellenwahl?
	\item
		\dots
\end{itemize}


\subsection{Polynominterpolation}

Sei $\{x_i\}_{i=0}^n$, ${f_i}_{i=0}^n$ gegeben mit $x_i\neq x_j$ für $i\neq j$.

\begin{st}[Existenz und Eindeutigkeit]
	\label{st:1.1}
	Es existiert genau ein Polynom $p\in \P$ mit $p(x_i)=f_i$ für $i=0,\dotsc,n$.
	\begin{proof}
		$p(x) = \sum_{k=0}^n a_k x^k$ löst das Interpolationsproblem $p(x_i)=f_i$ genau dann, wenn $a=(a_k)_{k=0}^n \in \R^{n+1}$ löst $a_0 +a_1x_i^1 + \dotsb a_nx_i^n = f_i$ für $i=0,\dotsc,n$.
		Das ist äquivalent zu $Aa=f$ mit
		\[
		A= \begin{pmatrix} 1 & x_0 & x_0^2 & \hdots & x_0^n \\
		\vdots  \\
		1 & x_n & x_n^2 & \hdots & x_n^n\end{pmatrix}, f= \begin{pmatrix}f_0 \\ \vdots \\ f_n\end{pmatrix}
		\]
		Wir zeigen, dass $A$ regulär ist, bzw. $\ker(A) = \{0\}$.<br />
		Sei $\_a \in \R^{n+1}, A\_a=0$, dann erfüllt
		$\_p(x) := \sum_{k=0}^n\_a_k x^k$ die Gleichung $\_p(x_i)=0$.
		$\_p$ ist Polynom von Grad $n$ und hat $n+1$ Nullstellen. Also $\_p=0 \implies \_a_k=0 \implies \_a=0$
	\end{proof}
	\begin{note}
		\begin{enumerate}
			\item 
				Darstellung in Monombasis $p(x)= \sum_{k=0}^n a_kx^k$ heißt \emph{Normalform} des Interpolationsproblems.
			\item
				Die Matrix $A$ aus dem Beweis ist die \emph{Vandermondematrix}, typischerweis schlecht konditionirt und voll besetzt.
				Daher ist das zugehörige LGS $Aa=f$ recht aufwändig zu lösen.
			\item
				Bei Verwendung anderer Basen ist das Interpolationsproblem leichter zu lösen.
			\item
				Allgemeine lineare Interpolation:
				Sei $\{\phi_k\}_{k=0}^n$ linear unabhängig. Dann gilt
				\begin{align*}
					p(x) = \sum_{k=0}^n a_k \phi_k(x) \text{löst die Interpolationsaufgabe}
					\iff a\in \R^{n+1} \text{löst} Aa=f \text{mit} f=(f_i)_{i=0}^n \text{und} A= \begin{pmatrix}\phi_0(x_0) & \hdots & \phi_n(x_0)\\
					\end{pmatrix}
				\end{align*}
		\end{enumerate}
		
	\end{note}
\end{st}

\begin{st}[Lagrange-Form]
	\label{1.2}
	Die \emph{Lagrange-Polynome}
	\[
	L_k^n(x) = \prod_{i=0, i\neq k}^n \f {x-x_i}{x_k-x_i} \qquad k=0,\dotsc,n
	\]
	erfüllen
	\[
	L_k^n(x_i) = \delta_{ik} \qquad i,k=0,\dotsc, n
	\]
	und bilden eine Basis für $\P_n$ und das Interpolationspolynom hat sogenannte <em>Lagrange-Form</em>
	\[
	p(x) = \sum_{k=0}^n f_k L_k^n(x)
	\]
	\begin{proof}
		siehe NLA.		
	\end{proof}
	\begin{note}
		\begin{enumerate}
			\item Wegen $L_k^n(x_i)=\delta_{ik}$ nennt man die $\{L_k\}_{k=0}^n$ eine nodale Basis
			\item Lösen eines LGS entfällt, da zugehörige Matrix $A=I$.
			\item $L_k^n(x)$ recht aufwändig auszuwerten
			\item Die Basen sind nicht hierarchisch, d.h. ${L_k^n} \not\subset \{L_k^{n'}\}$ für $n'\gt n$.
		\end{enumerate}
	\end{note}
\end{st}

\begin{df}[Newton-Polynome, Newton-Form]
	\label{df:1.3}
	Wir nennen
	\[
	N_k^n(x) := \prod_{j=0}^{k-1}(x-x_j) \qquad k=0,\dotsc,n
	\]
	\emph{Newton-Polynome} und die Darstellung des Interpolationspolynoms
	\[
	p(x) = \sum_{k=0}^n a_k N_k^n(x)
	\]
	\emph{Newton-Form} der Interpolierenden
\end{df}

\begin{lem}[Eigenschaften der Newton-Polynome]
	\label{lem:1.4}
	\begin{enumerate}
		\item $N_k^n(x_j) = 0$ für $0\le j \le k$ 
		\item ${N_k^n}_{k=0}^n$ bilden Basis für $\P_n$
		\item Die Basen sind hierarchisch: $\{N_k^n\}\subset \{N_k^{n'}\}$ für $n'\gt n$
	\end{enumerate}
	\begin{proof}
		1. und 3. sind klar.

		$N_k^n \in \P_n$ ist klar, zeige lineare Unabhängigkeit.
		Sei $a\in \R^{n+1}$ mit $0=\sum_{k=0}^n a_k N_k^n(x)$.
		Angenommen $a\neq 0$, wähle $k_0 := \max\{k | a_k \neq 0\}$.
		Also
		\[
			0 \neq N_{k_0}^n = - \f 1{a_{k_0}} \sum_{k=0}^{k_0-1}a_k N_k^n(x)
		\]
		Also hat $N_{k_0}$ Grad $k_0$ und ist Summe von Polynomen niedrigeren Grades, ein Widerspruch.
		Damit ist $a=0$ und $\{N_k^n\}$ linear unabhängig.
	\end{proof}
	\begin{note}
		\begin{itemize}
			\item Die Interpolationsmatrix ist eine untere Dreiecksmatrix
			\item LGS ist durch Vorwärtseinsetzen in $\mathcal O(n^2)$ lösbar
			\item Alternative Berechnung: Dividierte Differenzen (später)
		\end{itemize}
	\end{note}
\end{lem}

\begin{ex*}
	Sei $n=2$.	
	\begin{tabular}{l|rrr}
		$x_i$ & 1 & 2 & 3  \\ \hline
		$f_i$ & 2 & 3 & 6 
	\end{tabular}
	\\
	$N_0^2(x) = 1, N_1^2(x) = (x-1), N_2^2(x) = (x-1)(x-2)$
	Das zugehörige LGS ist
	\[
	\begin{pmatrix}1&0&0\\1&1&0\\1&2&2\end{pmatrix}\begin{pmatrix}a_0\\a_1\\a_2\end{pmatrix} = \begin{pmatrix}2\\3\\6\end{pmatrix}
	\]
	Es ergibt sich $a_0=2,a_1=1, a_2=1$ und damit das Interpolationspolynom
	\[
		p(x) = 2 + 1\cdot(x-1) + 1(x-1)(x-2) = x^2 - 2x+3
	\]
\end{ex*}

\section{Numerische Integration}	

\section{Nichtlineare Gleichungsysteme}

\section{Optimierung}



\end{document}
