\documentclass{mycourse}

\title{Analysis 2}

\begin{document}

\maketitle
\tableofcontents

\setcounter{chapter}{10}
\chapter{Elementare Differenzialgleichungen}

\section{Einleitung}

Sei $v(t)$ die Geschwindigeit eines fallenden Balls mit Luftwiderstand, dann gilt mit der Annahme, dass die die Bremsung durch den Luftwiderstand linear von der Geschindigkeit des Balls abhängt:
\[
	\dot v = g - \lambda v \qquad g=9,81\f m{s^2}, \lambda > 0
\]
Wir suchen $v(t)$ für alle $t\ge 0$.
Man sieht leicht, dass die Lösung von einer Anfangsbedingung abhängen muss, z.B. 
\[
	v(0)=0
\]
Die Lösung für diese beiden Gleichungen ist
\[
	v(t) = \f g\lambda (1-e^{-\lambda t})
\]
\begin{seg}{Kontrolle:}
	\[
		\dot v(t) = \f g\lambda e^{-\lambda t} = g - g(1-e^{-\lambda t}) = g - \lambda \f {g}\lambda (1-e^{-\lambda t}) = g - \lambda v(t)
	\]
\end{seg}


\section{Grundbegriffe}

Sei $D\subset \R^2$ und $f: D \to \R$.
Man nennt dann
\[
	y' = f(x,y)
\]
eine \emph{gewöhnliche Differenzialgleichung} erster Ordnung.
Als Lösungen der Differenzialgleichung akzeptieren wir jede differenzierbare Funktion $\phi : I \to \R$, die auf einem Intervall $I\subset \R$ definiert ist, sodass
\begin{enumerate}[(i)]
	\item
		$\Gamma(\phi) = \{\big(x,\phi(x)\big) \big| x\in I\} \subset D$
	\item
		$\phi'(x) = f(x,\phi(x))$
\end{enumerate}

\begin{ex*}
	Sei $a \in \R$ und $n\in \N$.
	\begin{enumerate}[1)]
		\item
			\begin{alignat*}{3}
				y' &= ay\\ 
  \phi(x) &= c \cdot e^{ax} &&\qquad c\in \R
			\end{alignat*}
		\item
			\begin{align*}
				y' &= \f nx y \\
  \phi(x) &= c \cdot x^n \qquad c\in \R
			\end{align*}
		\item
			\begin{align*}
				y' &= xy \\
		   \phi(x) &= c \cdot e^{\f {x^2}2}  \qquad c\in \R
			\end{align*}
		\item
			Die Differenzialgleichung
			\[
				y' = y^2
			\]
			hat folgende Lösungen:
			\[
				\phi_0(x) = 0 \quad \text{und} \quad \phi(x)= \f 1{c-x} \qquad (c\in \R \;\land\; x\neq c)
			\]
		\item
			\begin{align*}
				y' &= g(x) \\
		   \phi(x) &= \int g(x) dx =  G(x) + c
			\end{align*}
	\end{enumerate}
\end{ex*}

\subsection{Richtungsfelder}

Eine differenzierbare Funktion $\phi:I\to \R$ ist genau dann Lösung von $y'=f(x,y)$, wenn die Tangente in jedem Punkt $(x,y)\in \Gamma(\phi)$ die Steigung $f(x,y)$ hat.
Zeichnet man in vielen Punkten $(x,y)\in D$ ein Geradenstück der Steigung $f(x,y)$ ein, so kann man die Lösung manchmal erraten oder einen qualitativen Eindruck erhalten

\begin{ex*}
	Betrachte die Differenzialgleichung
	\[
		y' = -\f xy
	\]
	Die Lösung ist gegeben durch
	\[
		\phi_\pi = \pm\sqrt{c-x^2}
	\]
	Anhand des Richtungsfeldes (\fixme[Graphik]) konnte man sich einen Eindruck der Lösung verschaffen. 
\end{ex*}

\subsection{Anfangswertproblem}

Ein Anfangswertproblem zur Differenzialgleichung $y'=f(x,y)$ ist ein System von Gleichungen
\begin{align*}
	y' &= f(x,y)\\
y(x_0) &= y_0
\end{align*}
wobei $(x_0,y_0)\in D$ gegeben sind.
$y(x_0) = y_0$ heißt \emph{Anfangsbedingung}.
Eine Lösung dieses Gleichungssystems ist eine Lösung der Differenzialgleichung, die $\phi(x_0)=y_0$ mit $x_0\in I$ erfüllt.

Das Anfangswertproblem heißt \emph{lokal eindeutig lösbar}, wenn jedes Paar $\phi_1 : I_1 \to \R$, $\phi_2 : I_2 \to \R$ von Lösungen auf $I_1\cap I_2$ übereinstimmt.

\begin{thm}[Peano]
	Ist $D\subset \R^2$ offen und $f:D\to \R$ stetig, dann hat jedes Anfangswertproblem
	\begin{align*}
		y' &= f(x,y)\\
	y(x_0) &= y_0
	\end{align*}
	eine lokale Lösung.
	\begin{proof}
		Siehe Vorlesung Funktionalanalysis
	\end{proof}
	\begin{note}
		\begin{enumerate}[1)]
			\item
				Man darf also bei der Suche nach einer Lösung von ihrer Existenz ausgehen.
			\item
				Unter einer schwachen Zusatzannahme an $f$ ist die Lösung lokal eindeutig
			\item
				Häufig muss man mit der Kenntnis einer impliziten Lösung zufrieden sein, d.h. mit einer Gleichung $U(x,y) = 0$, welche von den Lösungen erfüllt wird.

				Beispielsweise hat die Differenzialgleichunge $y'= - \f xy$ die implizite Lösung:
				\[
					U(x,y) = x^2 + y^2 - c = 0
				\]
		\end{enumerate}
	\end{note}
\end{thm}


\section{Lineare Differenzialgleichungen}

\begin{df*}
	Eine Differenzialgleichung $y' = f(x,y)$ heißt linear, wenn
	\[
		f(x,y) = a(x)\cdot y + b(x)
	\]
	wobei $a,b: I \to \R$ stetige Funktionen auf einem Intervall $I$ sind.
\end{df*}

\subsection{Homogene Lineare Differenzialgleichungen}

Zuerst betrachten wir den \emph{homogenen} Fall (für $b(x) = 0$) und das zugehörige Anfangswertproblem
\begin{align*}
	y' = a(x)y \qquad\land\qquad
y(x_0) = y_0
\end{align*}

\begin{st} \label{11.2}
	Sei $a:I \to \R$ stetig und $A:I\to \R$ eine Stammfunktion von $a$.
	Dann ist die allgemeine Lösung der homogenen linearen Differenzialgleichung $y' = a(x) y$ gegeben durch
	\[
		\phi_c (x) = c e^{A(x)}
	\]
	und das zugehörige Anfangswertproblem $y(x_0) = y_0$ hat die eindeutige Lösung
	\[
		\phi(x) = y_0 e^{\int_{x_0}^xa(t)dt}
	\]
	\begin{proof}
		Sei $\phi: I' \to \R$ eine Lösung von $y' = a(x) y$, dann gilt
		\[
			\f d{dx} (e^{-A(x)}\phi) = -A'e^{-A}\phi + e^{-A}\phi' = e^{-A}\underbrace{(-a\phi + \phi')}_{=0} = 0
		\]
		Weil $I'\subset I$, gilt $e^{-A(x)}\phi(x) = c$, d.h. $\phi(x) = c e^{A(x)}$.
	\end{proof}
\end{st}

\begin{ex*}
	Die Differenzialgleichung
	\[
		y' = (\sin x)y
	\]
	hat die allgemeine Lösung
	\[
		\phi(x) = ce^{\cos x}
	\]
\end{ex*}

\subsection{Inhomogene Lineare Differenzialgleichungen}

Die inhomogen Differenzialgleichung $y' = a(x)y + b(x)$ lösen wir mit dem Ansatz
\[
	\phi(x) = u(x) \phi_0(x)
\]
wobei $\phi_0' = a(x) \phi_0$ ($\phi_0 = c e^{A(x)}\neq 0$).
Sei $\phi$ ein Lösung.
Wir versuchen jetzt $u(x) := \f {\phi(x)}{\phi_0(x)}$ zu berechnen.
Setzen wir in die DGL ein, erhalten wir
\[
	a(x)\phi(x) + b(x) = \phi' = (u\phi_0)' = u'\phi_0 + u\phi_0' = u'\phi_0 + a(x)\phi_0
\]
Also ergibt sich
\[
	u' = \f b{\phi_0}
\]

\begin{st}
	Sei $a,b:I \to \R$ stetig und sei $\phi_0 : I \to \R$ eine Lösung der homogenen Differenzialgleichung $y' = a(x) y$.
	Dann ist die Menge der Lösungen von $y' = a(x)y + b(x)$ gegeben durch
	\[
		\phi_c (x) = \phi_0(x) \left(c + \int_{x_0}^x \f {b(t)}{\phi_0(t)} dx\right) \qquad c\in \R
	\]
	Dabei kann $x_0$ beliebig gewählt werden (verschwindet in dem $c$).
	Die Lösung des zugehörigen Anfangswertproblems mit Anfangsbedingung $y(x_0) = y_0$ erhält man mit der Wahl $c := y_0$.
	\begin{proof}
		Siehe oben \fixme[unvollständig]
	\end{proof}
	\begin{note}
		Der Ansatz $\phi(x) = u(x) \phi_0(x)$ heißt \emph{Variation der Konstanten}, da man $c$ in der allgemeinen Lösung $\phi_0(x)$ der homogenen DGL durch eine Funktion ersetzt hat.

		Ist $y_p$ eine \emph{partikuläre Lösung} der inhomogenen Differenzialgleichung und $y_0$ eine Lösung der zugehörigen homogenen Differenzialgleichung, dann ist
		\[
			\phi(x) = y_p(x) + cy_0(x) \qquad c\in \R
		\]
		die allgemeine Lösung der inhomogenen Differenzialgleichung
	\end{note}
\end{st}

\begin{ex*}
	\begin{enumerate}[1)]
		\item
			Die DGL
			\[
				y' = \f yx + \sin(x)
			\]
			hat die homogene Lösung $\phi_0(x) = x$ und daher als inhomogene Lösung
			\[
				\phi(x) = x(c + \int_1^x dt)
			\]
		\item	
			Die Lösung der Newtonschen Gleichung $\dot y = g - \lambda y$ hat die partikuläre Lösung $y_p(t) = \f g\lambda$.
			Eine Lösung der homogenen Gleichung ist $v_0(t) = e^{-\lambda t}$.
			Also ist die allgemeine Lösung gegeben durch
			\[
				\phi(t) = c\cdot e^{-\lambda t} + \f g\lambda
			\]
	\end{enumerate}
\end{ex*}



\section{Separierbare Differenzialgleichungen}
Eine Differenzialgleichung der Form 
\[
y'=f(x)g(y)
\]
heißt separierbar.

Seien $f:I\to \mathbb R, g: J\to \mathbb{R}$ stetig.
Jede Nullstelle $y_0$ von $g$ liefert eine konstante Lösung $\phi(x):=y_0$, $x\in I$.
Sie zerlegen $D=I\times J$ in „horizontale Streifen“.

\begin{st}
	Sei $f,g$ stetig und $g$ habe keine Nullstelle in $J$. Seien $F$ und $G$ Stammfunktionen von
	$f$ und $\frac{1}{g}$ und $I_0\subset I$ ein Intervall mit $f(I_0)\subset J$. Dann ist
	\[
	\phi(x)=G^{-1}(F(x)) \qquad x\in I_0
	\]
	eine Lösung von $y'=f(x)g(x)$. Jede Lösung ist von dieser Form.\\
	Die Wahl 
	\begin{align*}
		F(x)&=\int_{x_0}^xf(u)du\\
	 G(y)&=\int_{y_0}^y\frac{1}{g(v)}dv
	\end{align*}
	liefern die Lösungen für das AWP $y'=f(x)g(x), y(x_0)=y_0 \in \mathring J$.
	\begin{proof}
		Sei $\phi : I_0 \to \R$ eine Lösung und $G(x)$ Stammfunktion von $\f 1{g(x)}$, dann ist
		\[
			\phi'(x) = f(x)g(\phi(x)) \implies f(x) = \f {\phi'(x)}{g(\phi(x))} = \f d{dx} G(\phi(x))
		\]
		Also ist $F(x) := G(\phi(x))$ Stammfunktion von $f$ auf $I_0$.
		Da $G' = \f 1g \neq 0$, ist $G$ streng monoton und somit ist $G: J\to G(J)$ bijektiv.
		Also
		\[
			\phi(x) = G^{-1}(F(x))
		\]
		Sei umgekehrt $\phi(x) = G^{-1}(F(x))$, dann gilt
		\[
			\phi'(x) = (G^{-1})'(F(x))\cdot F'(x) = \f 1{G'(G^{-1}(F(x)))} \cdot f(x) = \f 1 {G'(\phi(x))} \cdot f(x) = g(\phi(x))f(x)
		\]

		Wir haben die Lösung $\phi(x) = G^{-1}(F(x))$ auf $I_0 = \{x\big| F(x)\in G(J)\}$ gegeben.
		Es gilt $x_0\in I_0$.
		Wir zeigen, dass $x_0$ nicht der einzige Punkt in $I_0$ ist.
		Wegen $G'(y_0) = \f 1 {g(y_0)}\neq 0$ und $G(y_0) = 0$ existiert ein $\epsilon > 0$, sodass $B_\epsilon(0) \subset G(J)$.
		Da $F(x_0) = 0$ und $F$ stetig gilt
		\[
			\exists \delta > 0 : F(B_\delta(x_0)) \subset B_\epsilon(0) \subset G(J)
		\]
		Also $B_\delta(x_0) \subset I_0$  und
		\[
			\phi(x_0) = G^{-1}(F(x_0)) = G^{-1}(0) = y_0
		\]
	\end{proof}
\end{st}

\subsection{Autonome Differenzialgleichungen}

\begin{df*}
	Eine Differenzialgleichung von der Form
	\[
		y'=g(y)
	\]
	nennt man \emph{autonome Differenzialgleichung} oder \emph{$x$-frei}.
	Sie sind insbesondere separierbar.
	Die Nullstellen von $g$ führen zu konstanten Lösungen.
	Die nicht-konstanten Lösungen in den Streifen sind implizit bestimmt durch
	\[
		\int \f 1{g(y)}dy = x + c
	\]
	Sie unterscheiden sich nur um eine Verschiebung in $x$-Richtung.
\end{df*}

\begin{ex*}[Logistisches Wachstum]
	Gegeben ist eine DGL der Form
	\[
		\dot p = (a-bp)p
	\]
	Die Nullstellen ergeben die konstanten Lösungen der Gleichung:
	\[
		p = 0 \quad \text{oder} \quad p = \f ab
	\]
	Die nicht-konstanten sind implizit gegeben durch
	\[
		\int \f 1{a-bp}dp = t +c
	\]
	Man rechnet
	\begin{align*}
		\int \f {dp}{(a-bp)p} &= \int \f {\f 1a}{p} - \f {\f 1a}{(p-\f ab)}dp\\
							  &= \f 1a \ln \left| \f p{p-\f ab}\right| = t +c
	\end{align*}
	Setze $c=0$.
	Für $0<p<\f ab$ ergibt sich
	\[
		\phi(t) = \f ab \f 1{1+e^{-ta}} \to \begin{cases} \f ab & t\to \infty \\ 0 & t\to -\infty\end{cases}
	\]
	und für $p> \f ab$
	\[
		\phi(t) = \f ab \f 1{1-e^{-ta}} \to \begin{cases}\f ab & t \to \infty\\0 & t\to -\infty\end{cases}
	\]
\end{ex*}

\begin{ex*}[Newtonsche Gleichung]

Ein Teilchen der Masse $m$ in einer Dimension, $I\to \R$ stetig, $I\subset \R$:
\[
m\ddot x=f(x)
\]
Sei $V$ Stammfunktion von $-f$.
\begin{align*}
m\ddot x &= -V'(x) \\
m\ddot x \dot x + V'(x)\dot x &= 0 \\
\frac d{dx} \int m \ddot x\dot x + V'(x)\dot xdx &= 0\\
\frac d{dx} \frac m2 \dot x^2 + V(x) &= 0\\
\end{align*}
Die Ableitung ist gleich $0$, also folgt für den Funktionswert:
\begin{align*}
\frac m2 \dot x^2 + V(x) = E = \text{konst.}
\end{align*}
auflösen nach $\dot x$ liefert:
\[
\dot x = \pm\sqrt{\frac 2m (E-V(x))}
\]
Dies ist eine autonome Differenzialgleichung für $x(t)$.\\
Lösung:\\
\[
t+c = \pm \int \frac{1}{\sqrt{\frac{2}{m}(E-V(x))}}dx
\]
\end{ex*}


\subsection{Homogene Differenzialgleichungen (nicht-linear)}

Eine Differenzialgleichung der Form
\begin{equation}
\label{eq:homdgl}
y'=f(\f yx)
\end{equation}
heißt homogen. Solche Gleichungen lassen sich durch die Substitution
$u=\f yv$ auf separierbare transformieren:

Ist $\phi$ ein Lösung von \eqref{eq:homdgl} und $u(x) = \f{\phi (x)}x$, dann gilt:
\begin{align}
	f(u) &= f(\f{\phi(x)}x) = \phi'(x) = (xu(x))'=u(x) + xu'(x)\\
\label{eq:homsep}\\
u'(x) &= \frac{f(u)-u}{x}
\end{align}
Damit ist eine separierbare Differenzialgleichung für $u$ gegeben.
Umgekehrt, wenn $u$ eine Lösung von \eqref{eq:homsep} ist und $\phi(x):=xu(x)$, dann
ist $\phi$ eine Lösung von \eqref{eq:homdgl}.

\begin{ex*}
\[
y'=\frac{y^2+x^2e^{-\f yx}}{xy} \qquad \text{ist eine homogene DGL}
\]
\end{ex*}

\section{Eindeutigkeit der Lösung}

Eine Funktion $f:D\subset R^2\to R, (x,y)\mapsto f(x,y)$ heißt lokal Lipschitz-stetig
bezüglich $y$, wenn zu jedem Punkt $(x_0,y_0)\in D$ ein $\varepsilon > 0$ und ein $L\in R$ existiert.
D.h. so dass:
\[
|f(x,y_1)-f(x,y_2)| \le L|y_1-y_2| \qquad 
(x,y_1),(x,y_2) \in B_\varepsilon (x_0,x_y) \cap D.
\]
Beispiel:
\begin{itemize}
\item
Sei $a,b:I\to\R$ stetig, dann ist
\[
f(x,y)=a(x)y + b(x)
\]
lokal Lipschitz-stetig bezüglich y.
\item
Sei $f$ stetig und $g$ differenzierbar, dann ist
\[
f(x,y) = n(x)g(y)
\]
auch lokal Lipschitz-stetig bezüglich y.
\item
\[
f(x,y)={|y|}^{\frac 12} \qquad, D=R^2 \qquad
\]
ist nicht lokal Lipschitzstetig bezüglich y, denn $y\mapsto y^{\frac 12}$ ist nicht differenzierbar bei $y=0$.
\end{itemize}

\begin{thm}
Sei $ D \subset \R^2$ offen, $f:D\to \R$ stetig und lokal Lipschitzstetig bezüglich $D$. Dann ist jedes
AWP
\[
y'=f(x,y) \qquad\land\qquad y(x_0)=y_0
\]
lokal eindeutig lösbar. 
\begin{proof}
Existenz einer lokalen Lösung folgt aus dem Satz von Peano.
Seinn $\phi, \psi: [x_0,x_1] \to \R$ zwei Lösungen von des AWPs. Wir zeigen, dass $\phi=\psi$.
Sei $\tilde x = \inf{x\in [x_0,x_1]: \phi(x)\ne\psi(x)} \ge x_0$.
Wir zeigen, dass $\tilde x<x_1$ unmöglich ist. $\phi(\tilde x) = \psi(\tilde x)$ wegen der Stetigkeit dieser
Funktion:
Ist $\tilde x > x_0$
dann ist:
\[
phi(\tilde x)= \lim_{h\to\alpha}\phi\left(\tilde x - \f 1h\right)=\lim_{h\to\alpha}\psi\left(\tilde x - \f 1h\right) = \psi(\tilde x)
\]
Aus dem Hauptsatz der DI-Rechnung folgt für $x\ge\tilde x$:
\[
\phi(x)= \phi(\tilde x)+\int_{\tilde x}^x\phi'(t)dt
=\phi(\tilde x) + \int_{\tilde x}^xf(t,\phi(t))dt
\]
Ebenso für $\psi(x)$
Subtrahiere $B$ von $A$:
\[
\phi(x)-\psi(x)=\int_{\tilde x}^xf(t,\phi(t))-f(t,\psi(t))dt
\]
Somit:
\[
|\phi(x)-\psi(x)| \le \int_{\tilde x}^x|f(t,\phi(t)) - f(t,\psi(t))|dt
\]
Nach Annahme existieren $\varepsilon > 0, L\in R$ so dass:
\begin{equation}
\label{eq:lipschitzbed}
|f(t,\phi(t)) -(t,\psi(t))| \le L|\phi(t)-\psi(t)|
\end{equation}
für $t\in[\tilde x, \tilde x +\delta]$ wenn $\delta >0$ klein genug ist. Denn, wegen der Stetigkeit von $\phi,\psi$ sind
\[
	\big(t,\phi(t)\big),\big(t,\psi(t)\big)\in B_\varepsilon\big(\tilde x, \phi(\tilde x)\big)
\]
wo die lokale Lipschitz-Bedingung \eqref{eq:lipschitzbed} erfüllt ist.
Sei 
\[
M=\sup_{\tilde x \le x \le \tilde x + \varepsilon}|\phi(x)-\psi(x)|
\]
Aus ?? folgt:
\[
|\phi(x)-\psi(x)|\le L\int_{\tilde x}^x|\phi(t)-\psi(t)|dt \le L\delta M \qquad \text{für } \tilde x \le x \le \tilde x+\delta
\]
Insbesondere also: 
\[
M\le L\delta M
\]
Wählen wir $\delta >0$ so klein, dass $L\delta <1$, dann folgt $M=0$;
ein Widerspruch zur Definition von $\tilde x$ und der Annahme $\tilde x<x_1$.
\end{proof}
\end{thm}

\begin{ex*}
Das AWP
\[
y'=|y|^{\frac 12} \qquad y(0)=0
\]
ist nicht lokal eindeutig lösbar. Neben der Nulllösung $\phi(x)=0 \forall x\in\R$ gibt es z.B. noch die Lösung:
\[
\phi_1(x)=
\begin{cases}
\frac 14 x^2 &x\ge 0\\
0 &x<0
\end{cases}
\]
In der Tat gilt $\phi_1(0)=0$, $\phi_1'(x)=0=|\phi|^{\frac 12}$ fur $x<0$ und $\phi'(x)=\frac 12 x = |\phi_1(x)|^{\frac 12}$ für $x\ge0$.
\end{ex*}

\begin{note}
\[
y'=|y|^{\frac 12} \qquad y(2)=1
\]
ist lokal eindeutig lösbar! $\phi_1$ ist eine der lokal eindeutigen Lösungen!
Denn die Funktion $f(x,y)$ ist in $D=\{(x,y):y>0\}$ lokal Lipschitzstetig bezüglich $y$.
\end{note}

\subsection{Fortsetzen von Lösungen}

$f:D\to \R$ stetig, $D$ offen. Die lokale Lösung kann bis zum Rand von $D$ fortgesetzt werden.
\begin{ex*}
Sei $D=\R^2$ für das AWP:
\begin{align*}
y'=y^2 \qquad& y(0)=1 \\
\implies\phi(x)=\frac 1{1-x}
\end{align*}
\end{ex*}


\chapter{Funktionenfolgen}
\section{Gleichmäßige Konvergenz}

Motivation:\
\begin{align*}
 f_n:[a,b]\to \C, n\in \N\\
\forall x: f_n(x)\to f(x) \qquad (n\to\infty)\\
\end{align*}
Frage: Gilt $f_n'(x)\to f'(x)$? Darf man Ableitung und Limes miteinander vertauschen?
\begin{align*}
	\lim_n\frac d{dx}f_n&=\frac d{dx}\lim_{n\to\infty}f_n\\
\lim_{n\to\infty}\int_a^bf_ndx&=\int_b^b\lim_{n\to\infty}f_n(x)dx
\end{align*}
Eine Folge von Funktionen $f_n:D\to\C$, $D$ eine beliebige Menge, konvergiert punktweise gegen $f:D\to\C$, wenn gilt $\lim_{n\to\infty}f_n(x)=f(x)$ für ale $x\in D$.
Sie konvergiert \emph{gleichmäßig} gegen $f$ wenn:
\[
\sup_{x\in 0}|f_n(x)-f(x)|\to 0\qquad (n\to\infty)
\]
Mit andere Worten zu jedem $\varepsilon>0 \exists N_\varepsilon \in \N$, so dass:
\[
n\ge N_\varepsilon, x\in D \implies |f_n(x)-f(x)|<\varepsilon
\]
\begin{note}
\[
f_n\to f \text{ gleichmäßig} \implies f_n\to f \text{ punktweise}
\]
\end{note}
\begin{ex*}
\begin{enumerate}
\item
\begin{align*}
f_n(x)&=x^n, x\in[0,1]\\
f_n(x)&\to f(x) \text{ punktweise}
	\intertext{mit}
	f(x)&:=\begin{cases}
0 & 0\le x<1\\
1 & x=1
\end{cases}
\end{align*}
\item
\begin{align*}
f_n(x)=x^n(1-x) \qquad x\in[0,1]\\
f_n\to 0 \text{ gleichmäßig}
\end{align*}
\begin{proof}
$f_n(0)=0=f_n(1)$ und $f_n\ge0$ ist stetig, sogar differenzierbar, hat also ein Maximum in $(0,1)$.
\begin{align*}
f_n'&=\frac d{dx}(x^n-x^(n+1)=nx^(n-1)-(n+1)x^n\\
&=x^{n-1}(n-(n+1)x)=0
\end{align*}
$f_n$ hat das Maxmum bei $\frac n{n+1}$. Also:
\[
0\le f_n(x)\le f_n(\frac n{n+1})\le(1-\frac n{n+})=\frac 1{n+1}
\]
D.h.:
\[
\sup_{x\in[0,1]}|f_n(x)-0|<\frac 1{n+1}\to 0
\]
\end{proof}
\item
\[ f_n(x)=\sqrt{x^2+\frac 1n}, x\in \R \]
\[ f_n\to f \text{gleichmaßig, wenn } f(x):=|x|\]
\begin{proof}
\[ |x| \le \sqrt{x^2+\frac 1n}\le\sqrt{x^2}+\sqrt{\frac 1n}=|x|+\frac 1{\sqrt n}\]
Also:
\[ \sup_x|f_n(x)-f(x)|\le \frac 1{\sqrt n}\to 0\qquad (n\to\infty) \]
\[ f_n'(x)=\frac x{\sqrt{x^2+\frac 1n}} \]
$f_n'\to g$ konvergiert punktweise, nicht gleichmäßig mit:
\[
g(x)=\begin{cases}
1 &x>0\\
0 &x=0\\
-1&x<0
\end{cases}
\]
\end{proof}
\end{enumerate}
\end{ex*}

\begin{st}[Cauchy-Kriterium]
Eine Folge $f_n:D\to\C$ ist genau dann gleichmaßig konvergent, wenn zu jedem $\varepsilon>0$ ein $N_\varepsilon\in \N$ exisitiert, so dass
\[
n,m\ge N_\varepsilon \implies \sup_{x\in D}|f_n(x)-f_m(x)|<\varepsilon
\]
\begin{proof}
Falls $f_n\to f$ gleichmäßig und $\varepsilon>0$, dann existiert $N_\varepsilon\in \N$, so dass:
\[
n\ge N_\varepsilon \implies \sup_x|f_n(x)-f(x)|<\frac \varepsilon2
\]
Also:
\begin{align*}
n,m\ge N_\varepsilon \implies |f_n(x)-f_m(x)| \le |f_n(x)-f(x)|+|f_n(x)-f_m(x)|
&\le \sup_x|f_n(x)-f(x)|+\sup_x|f(x)-f_m(x)|<\frac \varepsilon2 +\frac \varepsilon2 =\varepsilon
\end{align*}
Also:
\[
n,m\ge N_\varepsilon \implies \sup_x|f_n(x)-f_m(x)| \le \sup_x|f_n(x)-f(x)| +\sup_x|f(x)-f_m(x)| <\varepsilon.
\]
D.h. die Cauchy-Bedingung ist erfüllt. Umgekehrt sei die Cauchy-Bedingung erfüllt, dann ist $(f_n(x))_{n\in\N}$ für jedes $x\in D$ eine Cauchy-Folge.
Also existiert:
\[
f(x):= \lim{n\to\infty}f_n(x)\in\C
\]
Behauptung: $f_n\to f$ gleichmäßig. Sei $\varepsilon>0$. Dann gilt:
\[
|f_n(x)-f_m(x)|<\frac \varepsilon2 \qquad \text{ für } n,m\ge N_{\frac \varepsilon2}
\]
für alle $x\in D$.
Aus der vorigen Gleichung folgt:
\[
|f_n(x)-f(x)|=\lim{x\to\infty}\underbrace{|f_n(x)-f_m(x)|}_{\frac \varepsilon 2}
\le \frac \varepsilon 2 <\varepsilon
\]
für alle $x\in D$ und $n\ge N_{\frac\varepsilon 2}$. D.h. $f_n\to f$ gleichmäßig.
\end{proof}
\end{st}


\begin{thm}[Stetigkeit der Grenzfunktion]
\label{stet_grenzf}
Sei $D\subset\R^\alpha$ und $f_n:D\to\C$ eine Folge stetiger Funktionen. 
Falls $f_n\to f$ gleichmäßig, $f:D\to\C$, dann ist auch $f$ stetig.

\begin{proof}
Sei $x_0\in D$ und $\varepsilon>0$. Wir nehmen $n\in\N$ so groß, dass
\[
\sup_x|f_n(x)-f(x)|<\frac \varepsilon 3
\]
Halte dieses $n$ fest!
Da $f$ stetig ist, existiert $\delta>0$, so dass
\[
x\in B_\delta(x_0) \implies |f_n(x)-f_n(x_0)|<\frac\varepsilon 3
\]
Aus beiden Gleichungen folgt:
\begin{align*}
x\in B_\delta(x_0)\\
\implies |f(x)-f(x_0)| &\le |f(x)-f_n(x)|+|f_n(x)-f_n(x_0)|+|f_n(x_0-f(x_0)|
&<\frac\varepsilon 3+\frac\varepsilon 3+\frac\varepsilon 3=\varepsilon
\end{align*}
Somit ist $f$ stetig in $x_0$.
\end{proof}

\end{thm}

\begin{thm}[Differenzierbarkeit der Grenzfunktion] \label{12.3}
Sei $V\subset\R$ ein Intervall und sei $f_n:I\to\C$ eine folge differenzierbarer Funktionen.
Falls $f_n\to f$ punktweise und $f_n'\to g$ gleichmäßig, dann ist $f$ differenzierbar und $f'=g$.
\begin{note}
Punktweise Konvergenz der Ableitungen $f_n'$ genügt nicht. Siehe früheres Beispiel.
\end{note}

\begin{proof}
Sei $x_0\in I$. Wir zeigen, dass $f'(x_0)=g(x_0)$.
Sei
\[
\phi_n(x)=\begin{cases}
\frac{f_n(x)-f_n(x_0)}{x-x_0}&x\neq x_0\\
f_n'(x_0)&x=x_0
\end{cases}\\
\phi(x)=\begin{cases}
\frac{f(x)-f(x_0)}{x-x_0}&x\neq x_0\\
g(x_0)&x=x_0
\end{cases}
\]
Da $f_n$ differenzierbar ist, ust $\phi_n$ stetig und wenn $\phi$ in $x_0$ stetig ist, dann ist $f'(x_0)=g(x_0)$.
Nach \ref{stet_grenzf} genügt es zu zeigen, dass $\phi_n\to\phi$ gleichmäßig.
Aus den Vorraussetzungen folgt $\phi_n\to\phi$ punktweise.
Es genügt also zu zeigen, dass $\phi_n$ die Cauchy-Bedingung aus Satz?? erfüllt.
Dazu definieren wir $f_{nm}=f_n-f_m$.
Dann:
\[
\phi_n(x)-\phi_m(x)=\begin{cases}
\frac{f_{nm}(x)-f_{nm}(x_0)}{x-x_0}& x\neq x_0\\
f_{nm}'(x_0) & x=x_0
\end{cases}
\]
Nach dem Mittelwertsatz der Differenzialrechnung existiert $\xi_x$ zwischen $x_0$ und $x$:
\[
\phi_n(x)-\phi_m(x)= f_{nm}'(\xi_x)=f_n'(\xi_x)-f_m'(\xi_x)
\]
Da $f_n'\to g$ gleichmäßig, erfüllt $(f_n')$ die Cauchy-Bedingung. 
Zu $\varepsilon>0$ existiert somit $N_\varepsilon\in Un$ so dass:
\begin{align*}
\varepsilon&>\sup_x|f_n'(\xi_x)-f_m'(\xi_x)|\\
&=\sup_x|\phi_n(x)-\phi_m(x)|
\end{align*}
für $n,m\ge N_\varepsilon$.
\end{proof}
\end{thm}

\begin{thm}
Sei $f_n:[a,b]\to\C$ eine Folge von Regelfunktionen, welche gleichmäßig gegen $f:[a,b]\to\C$ konvergieren. Dann ist $f$ eine Regelfunktion und
\[
\int_a^bfdx=\lim_{n\to\infty}\int_a^bf_n(x)dx
\]
\begin{note}
Die Aussage gilt nicht, wenn $f_n\to f$ nur punktweise.
\end{note}
\begin{ex*}
Sei
\[
f_n(x)=\begin{cases}
\min\{n^2x,2n-n^2x\}&x\in[0,\frac 2n]\\
0&x\in (\frac 2n, 1)
\end{cases}
\]
Fläche unter dem Graphen gleich 1. $f_n\to 0$ punktweise, aber
\[
\int_0^1f_n(x)dx=1\not\to \int_0^10dx \qquad (n\to\infty)
\]
\end{ex*}
\begin{proof}
Sei $\varepsilon>0$ und sei $n\in\N$ so groß, dass
\[
\sup_{x\in[a,b]}|f_n(x)-f(x)|<\frac{\varepsilon}2
\]
Sei $\phi:[a,b]\to\C$ eine Treppenfunktion mit
\[
\sup_{x\in[a,b}]|\phi(x)-f_n(x)|<\frac{\varepsilon}2
\]
Aus beiden Gleichungen folgt, dass
\[
\sup_{x\in[a,b]}|\phi(x)-f(x)|<\varepsilon
\]
Also ist $f$ eine Regelfunktion.
Aus ?? folgt, dass
\begin{align*}
|\int_a^bf(x)dx-\int_a^bf_n(x)dx|\\
&=|\int_a^b(f_n-f)dx|\\
&\le\int_a^b|f_n-f|dx\\
&\le(b-a)\sup_x|f_n(x)-f(x)|\to 0\qquad (n\to\infty)
\end{align*}
\end{proof}
\end{thm}

\section{Funktionenreihen}

Eine Reihe $\sum_ku_k(x)$ von Funktionen $u_k:D\to\C$ heißt punktweise (gleichmäßig) konvergent auf $D$, wenn die Folge der Partialsummen
\[
f_n(x)=\sum_{k=0}^nu_k(x)
\]
auf $D$ punktweise (gleichmäßig) konvergent ist.

\begin{thm}[Weierstraßscher M-Test]
Sei $D$ ein beliebige Menge und $u_k:D\to\C$, $k\in\N$ ein Folge von Funktionen auf D.
Falls $\sup_{x\in D}|u_k(x)|\le M_k$, wobei
\[
\sum_{k=0}^\infty M_k<\infty
\]
dann ist 
\[
\sum_{k=0}^\infty u_k
\]
absolut und \emph{gleichmäßig} konvergent auf $D$.
\begin{ex*}
Die Reihe
\[
\sum_{n=1}^\infty \frac{\cos(nx)}{n^2}
\]
ist gleichmäßig konvergent auf $\R$, denn
\[
\sup_x\left|\frac{\cos(nx)}{n^2}\right|=\frac 1{n^2}\qquad (=M_n)
\]
und
\[
\sum_{n=1}^\infty\frac 1{n^2}<\infty
\]
\end{ex*}
\begin{proof}
Für jedes feste $x \in D$ gilt
\[
\sum_{k\ge 0} |u_k(x)|\le \sum_{k\ge 0}M_k <\infty
\]
also ist $\sum u_k(x)$ absolut konvergent.
Da $\sum M_k$ konvergent ist, bilden die Partialsummen eine Cauchy-Folge, d.h. für $\varepsilon>0$ existiert $N_\varepsilon\in \N$, so dass
\[
n>m\ge N_\varepsilon \implies \sum_{k=m+1}^n M_k <\varepsilon
\]
Für die Partialsummen
\[
f_n(x)=\sum{k=0}^n u_k(x)
\]
folgt daraus
\begin{align*}
n>m\ge N_\varepsilon \implies |f_n(x)-f_m(x)| &= |\sum_{k=m+1}^n u_k(x)|\\
&\le \sum_{k=m+1}^n |u_k(x)|\\
&\le \sum_{k=m+1}^n M_k
\end{align*}
Also:
\[
n>m\ge N_\varepsilon \implies \sup_x|f_n(x)-f_m(x)| \le \sum_{k=m+1}^n M_k < \varepsilon
\]
Nach ?? ist die Folge $(f_n)$ und somit die Reihe $\sum u_k$ gleichmäßig konvergent auf $D$.
\end{proof}
\end{thm}

\begin{st}
Die Summe einer auf $[a,b]$ gleichmäßig konvergenten Reihe
$\sum_k u_k(x)$ stetiger Funktionen $u_k:[a,b]\to\C$ ist eine stetige Funktion und
\[
\int_a^b\sum_{k=0}^\infty u_k(x)dx = \sum_{k=0}^\infty\int_a^b u_k(x)dx
\]
\begin{proof}
$f_n =\sum_{k=0}^n u_k$ ist stetig und konvergiert gleichmäßig gegen $f=\sum_[k=0]^\infty u_k$.
Also ist $f$ stetig nach \fixme[thm??] und nach \fixme[thm??] gilt.
\begin{align*}
\int_a^b fdx
&=\lim_{n\to\infty}\int_a^b f_ndx\\
&=\lim_{n\to\infty} \underbrace{\int_a^b \sum_{k=0}^n u_k(x)dx}_{\sum_{k=0}^n\int_a^b u_k(x)dx}\\
&=\sum_{k=0}^\infty\int_a^b u_k(x)dx
\end{align*}
\end{proof}
\end{st}

\setcounter{thm}{6}
\begin{st}
\label{12.7}
Die Funktionenreihe $\sum u_k$ sei auf $[a,b]$ punktweise konvergent, wobei
$u_k:[a,b]\to\C$ differenzierbar seien, und $\sum u_k'$ sei auf $[a,b]$ gleichmäßig konvergent.
Dann ist auch $\sum u_k$ auf $[a,b]$ differenzierbar und
\[
\frac d{dx}\sum u_k(x)=\sum u_k'(x)
\]
\begin{proof}
Es folgt aus \ref{12.3}:
\[
f_n=\sum_{k=1}^n u_k\longrightarrow \sum_{k=1}^\infty u_k=f \qquad \text{punktweise}
\]
und $(f_n')$ ist gleichmäßig konvergent.
Nach \ref{12.3} ist $f$ differenzierbar und
\begin{align*}
f'&=\lim_{n\to\infty} f_n' \\
&=\lim_{n\to\infty}\sum_{k=0}^n u_k'(x)\\
&=U\sum_{k=0}^\infty u_k'(x)
\end{align*}
\end{proof}
\end{st}

\section{Potenzreihen}

\begin{thm}
\label{12.9}
Eiene Potenzreihe $\sum a_kz^k$, $a_k\in\C$, mit Konvergenzradius $R>0$
konvergiert auf jeder abgeschlossenen Kreisscheibe $\{z\in\C:|z|\le r\}$ mit $r<R$ gleichmäßig.
Für $|z|>R$ divergent, für $|z|<R$ konvergent.
\begin{note}
Im Allgemeinen ist die Konvergenz in $\{z:|z|<R\}$ nicht gleichmäßig.
\end{note}
\begin{proof}
Nach 6.20 ist die Reihe $\sum a_kz^k$ für $|z|<R$ absolut konvergent.
Also gilt für $r<R$ 
\[
\sum_{k=0}^\infty |a_k|r^k < \infty
\]
und
\[
\sup_{|z|\le r}|a_kz^k| = |a_k|r^k =: M_k
\]
Das Theorem folgt somit aus dem M-Test von Weierstraß.
\end{proof}
\end{thm}

\begin{thm}
\label{12.10?}
Die Summe einer Potenzreihe
\[
	f(x):=\sum_{k=0}^\infty a_kx^k \qquad a_k\in\C
\]
mit Konvergenzradius $R>0$ ist auf $(-R,R)$ stetig und es gilt
\[
\int_0^xf(t)dt=\sum_{k=0}^\infty a_k \frac{x^{k+1}}{k+1}
\]
Der Konvergenzradius der Reihe rechts ist ebenfalls R.
\begin{proof}
Nach \ref{12.9} und \ref{12.7} ist $\sum_{k=0}^\infty a_kx^k$ in jedem Intervall $[-r,r]$ mit $r<R$ stetig.
Also ist $f$ in jedem Punkt $x\in (-R,R)$ stetig.
Sei $x\in (-R,R)$ fest, dann ist die Reihe
$\sum a_kt^k$ auf $[0,x]$, beziehungsweise $[x,0]$ gleichmäßig konvergent.
Also gilt:
\begin{align*}
\int_0^x f(t)dt &= \lim_{n\to\infty}\int_0^x\sum_{k=0}^n a_kt^kdt\\
&= \lim \sum_{k=0}^n a_k \int_0^x t^k dt \\
&= \sum_{k=0}^\infty a_k \frac{x^{k+1}}{k+1}
\end{align*}
Die Reihe $\sum a_k\frac{x^{k+1}}{k+1}$ hat den selben Konvergenzradius $\tilde R$ wie $\sum a_k\frac{x^k}{k+1}$, also
\begin{align*}
\tilde R^{-1}
&=\limsup_{k\to\infty}\sqrt[k]{\frac{|a_k|}{k+1}}\\
&=\limsup_{k\to\infty}\sqrt[k]{|a_k|}\\
&=R^{-1}
\end{align*}
denn $\sqrt[k]{k+1}\to 1$ für $k\to\infty$
\end{proof}
\begin{ex*}
\begin{itemize}
\item
Stammfunktion von $e^{-x^2}$. Für alle $x\in\R$ ist
\[
e^{-t^2}=\sum_{k=0}^\infty \frac 1{k!}(-1)^kt^{2k}
\]
(Konvergenzradius $= \infty$) Also gilt für alle $x\in\R$
\[
\int_0^x e^{-t^2}dt = \sum_{k=0}^\infty \frac{(-1)^k}{k!}\frac {x^{2k+1}}{1}
\]
\item
Für $|x|<1$ gilt
\[
\frac 1{1+x}=\sum_{k=0}^\infty (-1)^kx^k
\]
also
\begin{align*}
\ln(1+x)
&=\int_0^x \frac 1{1+t}dt\\
&=\sum_{k=0}^\infty (-1)^k\frac {x^{k+1}}{k+1}\\
&= x-\frac{x^2}2+\frac{x^3}3-\dotsb
\end{align*}
\end{itemize}
\end{ex*}
\end{thm}

\begin{thm}
\label{12.10}
Die Summe einer Potenzreihe
\[
f(x)=\sum_{k=0}^\infty a_kx^k \qquad a_k\in\C
\]
imt Konvergenzradius $R>0$ ist auf $(-R,R)$ beliebig oft differenzierbar.
Es gilt
\[
f'(x)=\sum_{k=1}^\infty a_kkx^{k-1}
\]
und allgemein für $n\ge 1$,
\[
f^{(n)}(x)=\sum_{k=n}^\infty a_k k(k-1)\dotsb (k-n+1)x^{k-n}
\]
wobei die Reihe rechts auch den Konvergenzradius $R$ hat.
\begin{proof}
Die Reihe $\sum_{k=1}^\infty a_kkx^{k-1}$ hat den selben Konvergenzradius wie $\sum a_kkx^k$, also Konvergenzradius $R$, denn $\sqrt[k]{k}\to 1$ für $k\to\infty$.
Also ist $\sum_{k=1}^\infty a_kkx^{k-1}$ auf jedem Intervall $[-r,r]$, $v<R$, gleichmäßig konvergent
.
Es folgt aus \ref{12.10}, dass $\sum a_kx^k$ differenzierbar ist in $[-r,r]$ und
\[
\frac d{dx}\sum_{k=0}^\infty a_kx^k=\sum_{k=1}^\infty a_k k x^{k-1} \qquad |\dotsc|\le r
\]
Das gilt somit auch für alle $x\in (-R,R)$.
Die Behauptung über $n\ge 1$ bekommt man induktiv.
\end{proof}
\begin{ex*}
\[
\sum_{k=0}^\infty (-1)^k\frac{x^{2k+1}}{2k+1}=x-\frac{x^3}3 +\frac{x^5}5-\dotsb
\]
hat $R=1$. Also ist ihre Summe in $(-1,1)$ gliedweise differenzierbar.
\begin{align*}
\frac d{dx} \sum (-1)^k \frac{x^{2k+1}}{2k+1} \\
&= \sum_{k-0}^\infty (-1)^k\frac d{dx} \frac {x^{2k+1}}{2k+1}\\
&= \frac 1{1+x^2} = \frac d{dx} \arctan(x)
\end{align*}
Also
\[
\sum (-1)^k\frac{x^{2k+1}}{2k+1}+C=\arctan(x) \qquad x\in (-1,1)
\]
Und für $x=0$
\[
0+C = 0 \implies C=0
\]
\end{ex*}
\end{thm}

\begin{note}[Anwendungen der DGL]
Die Bohrinsel Sleipner-A.
Berechnung der Betonkonstruktionen (Elastizitätsgleichungen).
Approximation der Lösung mit der Finite Elemente Methode.
Die erste Verosion von Sleipner-A sank, wegen ungenauer Approximation der Elastizitätsgleichungen (Unterschätzung der Scherkräfte um $47\%$.
Entstandene Kosten: $700$ Milliarden Dollar.
\end{note}
\begin{note}[Karl Weierstraß (1815-1897]
\end{note}

\begin{kor}
\label{12.12}
Ist die Funktion $f:(a-R,a+R)\to \C$ gegeben durch eine konvergente Potenzreihe,
\[
f(x)=\sum_{k=0}^\infty a_k(x-a)^k \qquad a_k\in\C
\]
dann gilt $a_k=\frac{f^{(k)}(a)}{k!}$.
Das heißt: $\sum_{k=0}^\infty a_k(x-a)^k$ ist die Taylorreihe von $f$ mit Entwicklungspunkt a.
\begin{proof}
Es gilt $f(x)=g(x-a)$ mit $g(t)=\sum_{k=0}^\infty a_kt^k$, wobei $|t|<R$.
Nach Annahme ist der Konvergenzradius gleich $R$ oder größer.
Aus \ref{12.10} folgt:
\begin{align*}
g^{(k)}(t)&=\sum_{k=n}^\infty a_kk(k-1)\dotsb(k-n+1)t^{k-n}\\
&=a_nn!+a_{n+1}(n+1)n\dotsb t + \dotsb\\
\implies g^{(n)}(0)&=a_nn!
\end{align*}
wegen $f^{(n)}(x)=g^{(n)}(x-a)$ folgt $f^{(n)}(a)=g^{(n)}(0)=a_nn!$.
\end{proof}
\begin{ex*}
\begin{enumerate}
\item Bestimme die Taylorreihe von $f(x)=\frac 1x$ mit Entwicklungspunkt $a=3$:
\begin{align*}
\frac 1x&=\frac 1{(x-3)+3}=\frac 13 \frac 1{1+\left(\frac {x-3}3\right)}\\
&=\frac 13 \sum_{k=0}^\infty\left(\frac {x-3}3\right)^k(-1)^k\\
&=\sum_{k=0}^\infty(-1)^k\frac 1{3^{k+1}}(x-3)^k
\end{align*}
\item Berechne Konvergenzradius und Summe von
\[
\sum_{k=0}^\infty k^2x^k
\]
Lösung:
\begin{align*}
kx^k &= x\frac d{dx}x^k\\
k^2x^k &= x \frac d{dx}\left(x\frac d{dx}x^k\right)\\
\implies \sum_{k=0}^\infty k^2x^k &= \sum_{k=0}\infty x\frac d{dx}\left(x\frac d{dx}x^k\right)\\
&= x\frac d{dx}\left(x\frac d{dx}\sum_{k=0}^\infty x^k\right)\\
&= x\frac d{dx}\left(x\frac d{dx}\frac 1{1-x}\right)\\
&= \dotsc\\
&= \frac {x+x^2}{(1-x)^3} \qquad \text{für } |x|<1
\end{align*}
Der Konvergenzradius ist $R=1$ das $\sqrt[k]{k^2}\to 1$ ($k\to \infty$).
\end{enumerate}
\end{ex*}
\end{kor}

Letzte Woche:
\begin{align*}
\log(1+x) &=x-\frac {x^2}2+\frac {x^3}3 - \dotsb\\
\arctan(x) &= x - \frac {x^3}3 + \frac {x^5}5 - \dotsb
\end{align*}
für $|x|<1$.
Es stellt sich die Frage, ob diese Gleichungen auch für $x=1$ richtig sind.

\begin{st}[Satz von Abel]
\label{12.13}
Ist $\sum_{k=0}^\infty a_k, a_k\in \C$ konvergent, dann ist
\[
\sum_{k=0}^\infty a_kx^k
\]
gleichmäßig konvergent auf $[0,1]$ und insbesondere
\[
\sum_{k=0}^\infty a_k = \lim_{x\to 1-}\sum_{k=0}^\infty a_kx^k
\]
\begin{proof}
Aus der gleichmäßigen Konvergenz folgt, dass $x\mapsto\sum_{k\ge 0}a_kx^k$ auf $[0,1]$ stetig ist und somit dass $\sum a_k=\lim_{x\to 1-}\sum a_kx^k$.
Die gleichmäßige Konvergenz zeigen wir mit dem Cauchy-Kriterium:
Sei $\varepsilon>0$ und
\[
A=\sum_{k=0}^\infty a_k ,\qquad A_n =\left(\sum_{k=0}^n a_k\right)-A
\]
Wegen $A_n\to 0$, gibt es ein $N_\varepsilon$ so, dass
\[
|A_n|<\frac \varepsilon3
\]
für $n\ge N_\varepsilon$.
Für $n>m\ge N_\varepsilon$ gilt (diskrete partielle Summation Integration):
\begin{align*}
\sum_{k=m+1}^n a_kx^k &= \sum_{k=m+1}^n (A_k-A_{k-1})x^k\\
&=\sum_{k=m+1}^n A_kx^k - \sum_{k=m}^{n-1} A_kx^{k+1}\\
&=\sum_{k=m}^{n-1} A_k(x^k-x^{k+1}) + A_nx^n -A_mx^m
\end{align*}
Es folgt:
\begin{align*}
\left|\sum_{k=m+1}^n a_kx^k\right| 
&\le \sum_{k=1}^{n-1}|A_k|(x^k-x^{k+1}) + |A_n|x^n+|A_m|x^m\\
&\le \frac \varepsilon3 \sum_{k=m}^{n-1}(x^k-x^{k+1})+\frac \varepsilon3x^n +\frac \varepsilon3x^m\\
&=\frac \varepsilon3 (x^m-x^n)+\frac \varepsilon3 x^n +\frac \varepsilon3 x^m\\
&=\frac {2\varepsilon}3 x^m \le \frac 23 \varepsilon < \varepsilon
\end{align*}
D.h.:
\[
\sup_{x\in[0,1]}\left|\sum_{m+1}^n a_kx^k\right| < \varepsilon
\]
für $n>m\ge N_\varepsilon$.
\end{proof}
\end{st}
\begin{note}[Folgerung]
\begin{align*}
\ln(R) &= 1-\frac 12 + \frac 13 -\frac 14 +\dotsb\\
\frac \pi 4 = \arctan(1) &= 1 -\frac 13 +\frac 15 -\frac 17 + \dotsb
\end{align*}
\end{note}

\begin{lem}
\label{12.14}
Auf jedem Intervall $[\delta,2\pi-\delta]$ mit $\delta >\infty$ ist die Reihe
\[
\sum_{k=1}^\infty \frac{e^{ikx}}k
\]
gleichmäßig konvergent.
\begin{proof}
Sei $s_n(x)=\sum_{k=0}^ne^{ikx}$ 
\[
= \sum_{k=0}^n(e^{ix})^k
= \frac {1-e^{ix(k+1)}}{1-e^{ix}}
\]
Also
\begin{align*}
|s_n(x)|
&\le \frac 2{|1-e^{ix}|}\\
&= \frac 2{|e^{-i\frac x2}-e^{i\frac x2}}\\
&= \frac 1{i\left|\sin \left(\frac x2\right)\right|}\\
&\le \frac 1{\sin\left(\frac\delta 2\right)}
\end{align*}
für $x\in [\delta, 2\pi-\delta]$.
Mit partieller Summation:
\begin{align*}
\sum_{k=m+1}^n \frac {e^vkx}k
&= \sum_{k=m+m}^n(s_k(x)-s_{k-1}(x))\frac 1k \\
&= \sum_{k=1}^{n-1}s_k(x)\left(\frac 1k -\frac 1{k+1}\right) + \frac 1n s_n(x) -\frac 1m s_m(x)
\end{align*}
Somit gilt für $x\in[\delta,2\pi-\delta]$
\begin{align*}
\left |\sum_{k=m+1}^n \frac {e^{ikx}}k\right|
&\le \frac 1{\sin\left(\frac \delta 2\right)} \sum_{k=m}^{n-1}\left( \frac 1k - \frac 1{k+1}\right) + \frac 1{\sin\left(\frac\delta 2\right)} \left( \frac 1n + \frac 1m \right)\\
&= \frac 1{\sin\left(\frac\delta 2\right)} \frac 2m\\
&< \varepsilon
\end{align*}
für $n>m$ und $m$ groß genug.
\end{proof}
\end{lem}

\begin{st}
\label{12.15}
Für alle $x\in(0,2\pi)$ gilt
\[
\sum_{k=1}^\infty \frac{\sin(kx)}k = \frac 12 (\pi-x)
\]
und auf jedem Intervall $[\delta,2\pi-\delta]$ mit $\delta>0$ ist die Konvergenz gleichmäßig.

\begin{proof}
Nach \ref{12.14} ist
\[
\sum_{k=1}^\infty \frac {e^{ikx}}k
\]
gleichmäßig konvergent auf $[\delta, 2\pi-\delta]$ also auch
\begin{align*}
\sum_{k=1}^\infty \frac{\sin(kx)}k
= \sum_{k=1}^\infty \frac {\Im(e^{ikx})}k
=\Im \sum_{k=1}^\infty \frac{e^{ikx}}k
\end{align*}
Sei $f(t) = \sum_{k=1}^\infty \frac{e^{ikx}}k t^k$ für $\in[0,1]$.
Wir suchen $\Im f(1)$.
Nach dem Satz von Abel gilt:
\[
f(1)=\lim_{t\to 1-}f(t)
\]
und nach \ref{12.10} ist $f$ auf $(-1,1)$ (beliebig oft) differenzierbar und
\begin{align*}
f'(t) 
&= \sum_{k=1}^\infty e^{ikx}t^{k-1}\\
&= e^{ix}\sum_{k=0}^\infty (e^{ix}t)^k\\
&= \frac {e^{ix}}{1-e^{ix}t}\\
&= \frac 1{e^{-ix}-t}\\
&= \frac 1{\cos x -i\sin x -t}
\end{align*}
Es folgt:
\begin{align*}
(\Im f)'(t)=\frac {\sin x}{(t-\cos x)^2 +\sin x}
\end{align*}
Es folgt also:
\begin{align*}
\Im f(t)
&= \arctan \left(\frac {t-\cos x}{\sin x}\right) + c
\end{align*}
Wegen $f(0)=0$ bekommen wir:
\begin{align*}
\Im f(1)
&= \int_0^1(\Im f(t))'dt\\
&= \left.\arctan\left( \frac {t-\cos x}{\sin x}\right)\right|_{t=0}^{t=1}\\
&= \arctan \left(\frac {1-\cos x}{\sin x}\right) +\arctan\left(\frac {\cos x}{\sin x}\right)
\end{align*}
Mit Hilfe von
\begin{align*}
\sin x &= 2\sin\left(\frac x2\right)\cos\left(\frac x2\right)\\
1-\cos x &= 2\sin^2\left(\frac x2\right)
\end{align*}
bekommen wir
\begin{align*}
\arctan\left(\frac {1-\cos x}{\sin x}\right)
&= \arctan\left(\tan\left(\frac x2\right)\right)
= \frac x2 \qquad \text{für } x\in (0,\pi)
\end{align*}
und
\begin{align*}
\arctan\left(\frac{\cos x}{\sin x}\right)
&= \arctan\left(\frac{\sin(\frac \pi2-x)}{\cos(\frac \pi2-x)}\right) \\
&= \arctan\left(\tan\left(\frac \pi 2-x\right)\right)\\
&= \frac \pi 2 -x
\end{align*}
Also:
\[
\Im f(1) = \frac x2 +\frac \pi 2- x= \frac 12 (\pi -x)
\]
für $x\in (0,\pi)$.
\end{proof}
\end{st}

\section{Die Binomialreihe}

Für $\alpha\in\R$, $k\in\N$ definiert man den \emph{Binomialkoeffizienten} $\binom{\alpha}{k}$ durch
\begin{align*}
\binom{\alpha}{0}:= 1 \qquad
\binom{\alpha}{k}:= \frac {\alpha(\alpha-1)\dotsb(\alpha-k+1)}{k!}
\end{align*}
Die Reihe
\[
\sum_{k=0}^\alpha\binom{\alpha}{k}x^k
\]
heißt \emph{Binomialreihe}.
Ist $\alpha\in \N$, dann gilt
$\binom{\alpha}k = 0$ für $k\ge \alpha +1$ und somit
\[
\alpha\in\N \implies \sum_{k=0}^\infty\binom\alpha kx^k=\sum_{k=0}^\alpha\binom \alpha kx^k=(1+x)^\alpha
\]
\setcounter{thm}{14}
\begin{thm}
\label{12.15}
	Ist $\alpha\in\R$ dann gilt
\[
(1+x)^\alpha=\sum_{k=0}^\infty\binom\alpha kx^k \qquad \text{für }|x|<1
\]
\begin{proof}
Für alle $k\in\N_0$ gilt:
\begin{align*}
\binom{\alpha}{k+1}(k+1)&=\frac{\alpha(\alpha-1)\dotsb(\alpha-k)}{(k+1)!}(k+1)\\
&=\frac {\alpha(\alpha-1)\dotsb(\alpha-k+1)}{k!}(\alpha-k)\\
&=\binom{\alpha}k(\alpha-k)
\end{align*}
Quotientenkriterium:
\begin{align*}
\lim_{k\to\infty}\left|\frac{\binom\alpha {k+1}x^{k+1}}{\binom{\alpha}kx^k}\right|&=
\lim_{k\to\infty}|x|\left|\frac{\alpha-k}{k+1}\right|=|x|
\end{align*}
Die Reihe ist absolute konvergent für $|x|<1$ und divergent für $|x|>1$.
Somit ist der Konvergenzradius $R=1$.
Nach \ref{12.10} ist die Funktion
\[
b_\alpha(x)=\sum_{k=0}^\infty\binom\alpha k x^a
\]
auf $(-1,1)$ differenzierbar und
\begin{align*}
b_\alpha'(x)&=\sum_{k=1}^\infty\binom\alpha kkx^{k-1}\\
&=\sum_{k=0}^\infty\binom\alpha{k+1}(k+1)x^k\\
&=\alpha\sum_{k=0}^\infty\binom\alpha kx^k-\sum_{k=0}\infty\binom\alpha kkx^k\\
&= \alpha b_\alpha(x) - x\sum_{k=0}^\infty\binom \alpha k\frac d{dx}x^k\\
&= \alpha b_\alpha(x)-xb_\alpha'(x)
\end{align*}
Also
\begin{align*}
(1+x)b_\alpha'(x)=\alpha b_\alpha(x)
\end{align*}
Es ergibt sich eine lineare (homogene) DGL für $b_\alpha$:
\[
b_\alpha'=\frac \alpha{1+k}b_\alpha
\]
Wegen $b_\alpha(0)=1$ gilt nach \ref{11.2}:
\begin{align*}
b_\alpha(x)&=\exp\left(\int_0^x\frac\alpha{1+t}dt\right)\\
&=\exp(\alpha\ln(1+x))\\
&=(1+x)^\alpha
\end{align*}
\end{proof}

\begin{ex*}
Für $|x|<1$  ist
\[
(1+x)^{-\frac 12} = \sum_{k=0}^\infty\binom{-\frac 12}kx^k
\]
Es ergibt sich:
\begin{align*}
\arcsin(x)&=\int_0^x\frac 1{\sqrt{1-t^2}}dt\\
&=\int_0^x\sum_{k=0}^\infty\binom{-\frac 12}k(-t^2)^kdt\\
&=\sum_{k=0}^\infty\binom{-\frac 12}k(-1)^k\frac{x^{2k+1}}{2k+1}\\
&=x+\frac 16x^3+\frac 3{40}x^5+ \dotsb
\end{align*}
\end{ex*}
\end{thm}

\section{Fourierreihen}

Eine Funktion $f:\R\to\C$ heißt $2\pi$-periodisch, wenn $f(x+2\pi)=f(x)$ für alle $x\in\R$.

Für jedes $n\in\N$ sind $\cos(nx), \sin(nx)$ und $e^{\pm inx}$ $2\pi$-periodisch.\\
Frage: Unter welchen Annahmen an $f$ gilt
\[
\label{eq:four1}
f(x)=\sum_{n=-\infty}^\infty c_ne^{inx}=\lim_{N\to\infty}\sum_{n=-N}^Nc_ne^{inx}
\]
für geeignete $c_n\in\C$.
Das ist wegen $e^{inx}=\cos(nx) +i\sin(nx)$ äquivalent zu
\[
f(x)=\frac{a_0}2+\sum_{n=1}^\infty a_n\cos(nx)+b_n\sin(nx)
\]
wobei
\begin{align*}
a_n&=c_n+c_{-n} \qquad n\in\N_0\\
 b_n&=i(c_n-c_{-n}) \qquad n\in\N
\end{align*}
Wenn \eqref{eq:four1} gilt und die Konvergenz gleichmäßig in $x\in[0,2\pi]$ ist, dann folgt:
\[
\label{eq:four2}
c_n=\frac 1{2\pi}\int_0^{2\pi}e^{-inx}f(x)dx
\]
Die Reihe \eqref{eq:four1} mit $c_n$ definiert durch \eqref{eq:four2} heißt \emph{Fourierreihe} von $f$ und die Zahlen $c_n$ heißen \emph{Fourierkoeffizienten} von $f$.

\subsection*{Berechnung der Partialsummen $S_N$}

Sei $f:\R\to\C$ eine $2\pi$-periodische Regelfunktion.
Dann gilt:
\begin{align*}
s_N(x):=\sum_{n=-N}^Nc_ne^{inx}
&=\sum_{n=-N}^N\left(\frac 1{2\pi}\int_0^{2\pi}e^{-int}f(t)dt\right)e^{inx}\\
&=\frac 1{2\pi}\int_0^{2\pi}\underbrace{\left(\sum_{k=-N}^ne^{in(x-t)}\right)}_{D_N(x-t)}f(t)dt\\
&=\frac 1{2\pi}\int_0^{2\pi}D_N(x-t)f(t)dt
\end{align*}
wobei
\[
D_N(t):=\sum_{n=-N}^Ne^{int}=\begin{cases}
\frac{\sin\left(\left(N+\frac 12\right)t\right)}{\sin\left(\frac t2\right)} & t\not\in 2\pi\Z\\
2N+1 & t\in 2\pi\Z
\end{cases}
\]
FIXME: Beweise!

$D_N$ heißt \emph{Dirichkletscher Kern}.

\begin{note}
Eigenschaften des Dirichkletschen Kerns:
\begin{enumerate}
\item $D_N$ ist $2\pi$-periodisch
\item $D_N(-t)=D_N(t)$
\item $\frac 1{2\pi}\int_0^{2\pi}D_N(t)dt=1$
\end{enumerate}
\end{note}

\begin{df*}
Eine Funktion $f:[a,b]\to\C$ heißt stückweise stetig, wenn eine Partition $a=t_0<t_1<\dots$ mit $t_n=b$ existiert, so dass $f$ auf jedem Intervall $(t_{k-1},t_k)$ stetig ist und die Grenzwerte $f(t_{k-1}+), f(t_k-))$ existieren.
\end{df*}

\setcounter{thm}{15}
\begin{st}[Riemannsches Lemma]
\label{12.16}
Ist $g:[a,b]\to\C$ stückweise stetig, dann gilt
\[
\lim_{\lambda\to\infty}\int_a^bg(t)\sin(\lambda t)dt=0
\]
\begin{proof}
Es genügt den Fall zu betrachten wo $g$ stetig ist.
Im allgemeinen Fall, wo $g$ auf Teilintervallen stetig ist, betrachtet man das die Summe der Integrale auf den Teilintervallen.

Sei also $g$ stetig und
\[
J_\lambda = \int_a^bg(t)\sin(\lambda t)dt
\]
Sei $h=\frac \pi \lambda$.
Dann gilt dass
\begin{align*}
J_\lambda=\int_{a-h}^{b-h}g(t+h)\underbrace{\sin(\lambda(t+h))}_{=-\sin(\lambda t)}dt
\end{align*}
Also:
\begin{align*}
2J_\lambda=\int_{a}^{b-h}g(t)\sin(\lambda t)-g(t+h)\sin(\lambda t)dt +\int_b^{b+h}g(t)\sin(xt)dt -\int_{a-h}^hg(t+h)\sin(\lambda t)dt
\end{align*}
Es folgt dass:
\begin{align*}
|2J_\lambda|&\le |b-a|\sup_{a\le t\le b-h}|g(t)-g(t+h)|+2|h|\sup_t|g(t)|
\to 0 \qquad (\lambda\to\infty \iff h\to 0)
\end{align*}
da eine stetige Funktion auf einer kompakten Menge beschränkt und gleichmäßig stetig ist.

Ist $g$ sogar stetig differenzierbar, dann
\begin{align*}
\int_a^bg(t)\sin(\lambda t)dt 
&= \left.-g(t)\cos(\lambda t)\frac 1\lambda \right|_a^b + \int_a^bg'(t)\frac{\cos(\lambda t)}\lambda dt\\
&\le \frac 1a(|g(b)|+|g(a)|)+\frac 1\lambda (b-a)\sup_{a\le t\le b}|g'(t)|
&= \frac c\lambda
\end{align*}

\end{proof}

\end{st}

Für eine Regelfunktion $f:\R\to\C$ definieren wir einseitige Ableitungen
$f'(x+)$ und $f'(x-)$ durch 
\begin{align*}
f'(x+)=\lim_{h\to0+}\frac {f(x+h)-f(x+)}{h}\\
f'(x-)=\lim_{h\to0+}\frac {f(x-h)-f(x-)}{-h}\\
\end{align*}

\setcounter{thm}{17}

\begin{thm}
\label{12.18}
ist $f:\R\to\C$ eine $2\pi$-periodische stückweise stetige Funktion
und $x\in\R$ ein Punkt wo die einseitige Ableitung $f'(x\pm)$ existieren, dann gilt:
\begin{align*}
\sum_{n=-\infty}^\infty c_ne^{inx}&=\frac 12(f(x+)+f(x-))\
\end{align*}

\begin{proof}
\begin{align*}
s_N(x)&=\frac 1{2\pi}\int_0^{2\pi}D_N(x-t)f(t)dt \begin{gathered} u=x-t\\t=x-u\\du=-dt\end{gathered}\\
&=-\frac 1{2\pi}\int_x^{x-2\pi} D_N(u)f(x-u)du\\
&=\frac 1{2\pi}\int_{x-2\pi}^xf(x-t)D_N(t)dt\\
&=\frac 1{2\pi}\int_{-\pi}^\pi f(x-t)D_N(t)dt
\end{align*}
da $t\to f(x-t)D_N(t)$ $2\pi$-periodisch ist.
Also:
\begin{align*}
s_N(x) &= \underbrace{\frac 1{2\pi}\int_0^\pi f(x-t)D_N(t)dt}_{\to \frac {f(x-)}2 (N\to\infty)}
+ \underbrace{\frac 1{2\pi}\int_0^\pi f(x+t)D_N(t)dt}_{\to \frac {f(x+)}2 (N\to\infty)}
\end{align*}
Wir zeigen, dass diese Behauptung der Konvergenz stimmt.
\begin{align*}
\frac 1{2\pi}\int_0\pi f(x+t)D_N(t)dt - \frac {f(x+)}2
&= \frac 1{2\pi}\int_0^\pi\left(f(x+t)-f(x+)\right)D_N(t)dt\\
&= \frac 1{\pi}\int_0^\pi g(t)\sin\left(\left(N+\frac 12\right)t\right)dt
\end{align*}
wobei
\begin{align*}
g(t)&:= \frac {f(x+t)-f(x+)}{2\sin\left(\frac t2\right)} \qquad t\in(0,\pi]\\
g(0)&:= f'(x+)
\end{align*}
$g$ ist auf $[0,\pi]$ stückweise stetig, denn
\begin{align*}
\lim_{t\to0+}g(t)&=\lim_{t\to 0+} \frac{f(x+t)-f(x+)}t \underbrace{\frac {\frac t2}{\sin\left(\frac t2\right)}}_{\to 1}\\
&=f'(x+)
\end{align*}
Aus dem Riemannschen Lemma folgt:
\begin{align*}
\frac 1\pi \int_0^\pi g(t)\sin\left(\left(N+\frac 12\right)t\right)dt \to 0
\end{align*}
und gilt die obige Behauptung der Konvergenz.
\end{proof}
\end{thm}

\begin{lem}[Besselsche Ungleichung]
Sei $f:[0,2\pi]\to\C$ eine Regelfunktion und $c_n=c_n(f)=\frac 1{2\pi}\int_0^{2\pi}e^{-inx}f(x)dx$.
Dann gilt:
\[
\sum_{n=-\infty}^\infty|c_n|^2 \le \frac 1{2\pi}\int_0^{2\pi}|f(x)|^2dx
\]
\begin{proof}
Sei $s_N(x)=\sum_{n=-N}^Nc_ne^{inx}$.
Dann
\begin{align*}
\int_0^{2\pi}|f(x)-s_4(x)|^2dx
&= \int_0^{2\pi}|f(x)|^2dx + \int_0^{2\pi}|s_N(x)|^2dx - 2\Re \left( \int_0^{2\pi}f(x) \overline{s_N(x)}dx\right)\\
&= \int_0^{2\pi}|f(x)|^2dx    -2\pi \sum_{n=-\infty}^\infty|c_n|^2
\end{align*}
denn
\begin{align*}
\int_0^{2\pi}f(x)\overline{s_4(x)}dx &= 2\pi\sum |c_n|^2\\
\int_0^{2\pi}|s_N(x)|^2 &= 2\pi \sum |c_n|^2
\end{align*}
Also ist
\begin{align*}
\int_0^{2\pi}|f(x)|^2dx \ge 2\pi \sum_{n=-\infty}^infty|c_n|^2
\end{align*}
\end{proof}
\end{lem}

Eine $2\pi$-periodische Funktion $f:\R\to\C$ heißt \emph{stückweise glatt}, wenn es eine Zerlegung
$0=x_0<x_1<\dotsb<x_n=2\pi$ und stetig-differenzierbare Funktionen $f_k:[x_{k-1},x_k]$ gibt, mit $f(x)=f_k(x)$ für $x\in[x_{k-1},x_k]$.

\begin{thm}
\label{12.20}
Sei $f:\R\to\C$ $2\pi$-periodisch und stückweise glatt.
Dann gilt
\begin{enumerate}[(a)]
\item Auf jedem kompakten Intervall $[a,b]$ weg von den Unstetigkeitsstellen konvergiert die Fourierreihe von $f$ gleichmäßig gegen $f$.

\item Ist $f$ überall stetig, dann konvergiert die Fourierreihe von $f$ absolut und gleichmäßig auf ganz $\R$.
\end{enumerate}

\begin{proof}
Zeige zunächst den zweiten Teil:\\
Nach \ref{12.18} konvergiert die Fourierreihe von $f$  in jedem Punkt $x\in\R$ gegen $f(x)$.
Nach Vorraussetzung an $f$ gilt:
\begin{align*}
c_n(f') &:= \frac 1{2\pi}\int_0^{2\pi}e^{-inx}f'(x)dx \\
&= \underbrace{\left.\frac 1{2\pi}e^{-inx}f(x)\right|_0^{2\pi}}_{=0} -\frac {in}{2\pi}\int_0^{2\pi}e^{-inx}f(x)dx\\
&=inc_n(f)
\end{align*}
Mit Hilfe der Besselschen Ungleichung folgt:
\begin{align*}
\sum_{n=-\infty}^\infty n^2|c_n|^2
&= \sum_{n}|inc_n(f)|^2\\
&= \sum_{n=-\infty}^\infty o |c_n(f')|^2\\
&\le \frac 1{2\pi}\int_0^{2\pi}|f'(x)|^2dx 
< \infty
\end{align*}
Somit gilt
\begin{align*}
\sum_{n=-\infty}^\infty|c_n|&=|c_0|\sum_{n\neq 0}|c_n|\\
&= |c_0| +\underbrace{\sum_{n\neq 0}\frac 12 (n|c_n|)}_{\frac 12\left(\frac 1{n^2}+n^2|c_n|^2\right)}\\
&\le |c_0|+\frac 12 \underbrace{\sum_{n\neq 0} \frac 1{n^2}}_{<\infty}+\frac 12 \underbrace{\sum_{n\neq 0}n^2|c_n|^2}_{<\infty}\\
&< \infty
\end{align*}
Somit ist dier Reihe
\[
	\sum_{-\infty}^\infty c_ne^{inx}
\]
absolut und (nach dem M-Test) auch gleichmäßig konvergent.

Zeige nun den ersten Teil:\\
Der Beweis beruht auf den Beweis vom zweiten Teil und der Tatsache, dass
\[
\sigma(x)=\frac 12(\pi-x) \qquad x\in[0,2\pi]
\]
$2\pi$-periodisch fortgesetzt nach \ref{12.15} die Aussage vom ersten Teil erfüllt.

Sei $ 0=x_0<x_1<\dotsb < x_4=2\pi$ wobei $x_k$ die Unstetigkeitsstellen von $f$ in $[0,2\pi]$ sind.
Sei die „Sprunghöhe“:
\[
\delta_k:=f(x_k+)-f(x_k-)
\]
und
\[
h(x):=\sum_{k=1}^m\frac {\delta_k}\pi \sigma(x-x_k)
\]
Die Funktion $h$ hat dieselben Unstetigkeiten und Sprunghöhen wie $f$, also ist $f-h$ stückweise glatt und stetig.
Nach dem zweiten Teil gilt:
\[
\underbrace{s_N(f-h,x)}_{=s_N(f,x)-s_N(h,x)}\to f(x)-h(x) \qquad \text{gleichmäßig}
\]
Also
\[
s_N(f,x)-f(x) = S_N(f-h,x)-(f-h)(x) + S_N(h,x)-h(x)
\]
Nach \ref{12.15} gilt
\begin{align*}
\sup_{x\in[a,b]}|s_N(h,x)-h(x)|\to 0 \qquad (N\to \infty)\\
\sup_{x\in[a,b]}|s_N(f-h,x)-(f-h)(x)| \to 0 \qquad (N\to \infty)
\end{align*}
Also
\[
\sup_{x\in[a,b]}|s_N(f,x)-f(x)|\to 0\qquad (N\to \infty)
\]
\end{proof}
\end{thm}

\subsection{Gibbssches Phänomen}

\begin{st}
Sei $f:\R\to \C$ $2\pi$-periodisch und stückweise glatt mit einer Sprungstelle bei
$x=a$ der Höhe $\delta:=f(a+)-f(a-)$.
Sei $x_4=a+\frac {\pi}{N+\frac 12}$.
Dann gilt:
\[
s_N(f(x_N)) \ge f(a+)+0.1789\frac {\delta}2 + o(1) \qquad (N\to \infty)
\]
\begin{proof}
Sei der Sprung bei $a=0$ und $g(x):=f(x)-\frac \delta \pi \sigma(x)$,
wobei $\sigma$ die $2\pi$-periodische Fortsetzung von $\frac {\pi-x}2$ auf $[0,2\pi)$ ist.
$g$ lässt sich zu einer $2\pi$-periodischen stückweisen glatten Funktion fortsetzen, die in Punkten $2\pi\Z$ stetig ist und sonst mit $f-\frac \delta\pi \sigma$ übereinstimmt.

Also gilt:
\[
s_N(g)\to g \qquad \text{gleichmäßig}
\]
auf einem Intervall $[-\varepsilon,\varepsilon]$.
Daraus folgt:
\begin{align*}
s_N(f)-f&=s_N(g)-g + \frac \delta\pi(s_N(\sigma)-\sigma)\\
&=\frac \delta\pi(s_N(\sigma)-\sigma) + o(1) \qquad (N\to\infty)
\end{align*}
gleichmäßig auf $[-\varepsilon,\varepsilon]$.
Es bleibt die Behauptung für $\frac \delta\pi\sigma$ zu beweisen.

Es gilt:
\begin{align*}
s_N(\sigma(x))&=\sum_{k=1}^N\frac{\sin(kx)}k\\
&=\sum_{k=1}^N\int_0^x\cos(kt)dt\\
&=\sum_{k=1}^N\frac 12\int_0^x(e^{ikt}+e^{-ikt})dt\\
&=\frac 12\int_0^x(D_N(t)-1)dt\\
&=\frac 12\int_0^x(D_N(t)dt - \frac x2
\end{align*}
Für $x=x_N=\frac \pi{N+\frac 12}$  folgt daraus, dass
\begin{align*}
s_N(\sigma(x_N)-\sigma(x_N)
&= \frac 12\int_0^{x_4}D_N(t)dt - \frac \pi 2 \\
&\ge \frac 12 \int_0^{x_N}\frac {\sin(N+\frac 12)t}{\frac t2}dt -\frac\pi2 \qquad (u=\left(N+\frac 12\right)-\pi2)\\
&=\int_0^\pi\frac {\sin(u)}udu -\frac\pi2
\end{align*}
Also ist
\begin{align*}
	s_N(f(x_N))-f(x_N)&=\frac \delta\pi(s_N\sigma(x_N)-\sigma(x_N))+o(1)\\
&\ge 0.1789 \frac \delta 2 + o(1)
\end{align*}
wegen $f(x_N)\to f(a+)$ für $n\to\infty$ folgt die Behauptung.
\end{proof}
\end{st}

\begin{note}[Schlussbemerkungen]
Die Fourierreihe einer $L$-periodischen Regelfunktion $f:\R\to\C$, d.h. $f(x+L)=f(x)$,
lautet:
\[
\sum_{n=-\infty}^\infty c_ne^{in2\frac\pi Lx}
\]
wobei
\[
c_n:= \frac 1L \int_{a}^Le^{-in\frac{2\pi}Lt}f(t)dt
\]
Ist $F$ nur auf einem Intervall $[0,L]$ definiert, dann kann eine $L$-periodische Fortsetzung
$f:\R\to\C$ definiert werden durch:
\[
f(x+nL)=F(x) \qquad x\in[0,L), n\in\Z
\]
Die bewiesenen Sätze können auf $f$ angewandt werden.
Die Konvergenz der Fourierreihe hängt dann unter anderem von der Regularität von $f$ bei $x=0$, bzw. $x=L$ ab.
\end{note}

\chapter{Differentialrechnung im $\R^n$}

\section{Lineare Abbildungen}
Eine Abbildung $A:\R^n\to\R^m$ heißt linear, wenn
\[
A(\alpha x+\beta y)=\alpha A(x)+\beta A(x)
\]
für alle $x,y \in \R^n$ und $\alpha,\beta\in\R$.
Man schreibt dann $Ax$ statt $A(x)$.
Bezüglich der Standardbasen $(e_1,\dotsc,e_n)$ bzw. $(e_1,\dotsc,e_m)$ von $\R^n$ und $\R^m$ wird
$A$ durch die $m\times n$-Matrix $A_{ik}=\<e_{i},Ae_k\>$ repräsentiert.
Der Bildvektor $Ax$ ergibt sich also durch
\[
(Ax)_i=\sum_{k=1}^nA_{ik}x_k.
\]
Umgekehrt wird durch diese Gleichung zu jeder $m\times n$ Matrix $A_{ik}$ eine lineare Abbildung definiert.

Wir können also den Raum $\Hom(\R^n,\R^m)$ der linearen Abbildungen mit $\Mat(m\times n),\R)$ identifizieren.

Wir schreiben nun die Elemente der Vektorräume $\R^n, \R^m$ als Spaltenvektoren, so dass $y=Ax$ zu einem Matrixprodukt wird von $A$ und $x$ wird.
Die Verknüpfung $BA = B\circ A$ von lineare Abbildungen $A:\R^n\to\R^m$, $B:\R^m\to\R^l$ ist wieder eine lineare Abbildung:
\[
BA: \R^n\to\R^l
\]
mit zugehöriger Matrix
\[
(BA)_{ik}=\sum_{j=1}^m B_{ij}A_{jk}
\]
Nach 7.16 gilt:
\begin{align*}
\|BA\|&\le \|B\|\cdot \|A\|, \\
|Ax|&\le \|A\|\cdot |x|,
\end{align*}
wobei
\[
\|A\|=\Big(\sum_{i,k}A_{ik}^2\Big)^{\f 12}
\]
Die Menge der lineare Abbildungen von $\R^n$ nach $\R$ heißt Dualraum von $\R^n$ und wird mit $L(\R^n)$ oder $(\R^n)^*$ bezeichnet.
Jede Linearform $f\in(\R^n)^*$ entspricht einem Vektor $v\in \R^n$ mit
\[
f(x)=\<v,x\>
\]
und umgekehrt.
Der Zeilenvektor $v^T$ ist die Matrix von $f$.

\section{Die Ableitung}

Eine Abbildung $f:[a,b]\to\R^n$ ist im Punkt $t\in[a,b]$ differenzierbar, wenn
\[
f'(t)=\lim_{h\to 0}\frac 1h \big((f(t+h)-f(t)\big) \in \R^n
\]
existiert.
Das ist äquivalent dazu, dass ein $v\in\R^n$ existiert mit
\[
\frac{|f(t+h)-f(t)-vh|}{|h|}\to 0 \qquad (h\to 0),
\]
oder mit Landau-Symbolik
\[
f(t+h)=f(t)+vh+o(h) \qquad (h\to 0).
\]
Mit anderen Worten wird der Zuwachs $f(t+h)-f(t)$ für kleine $|h|$ gut approximiert durch die lineare Abbildung
\[
	\mathrm d f(t): h\mapsto f'(t)h
\]

\begin{df}
Sei $D\subset \R^n$ offen.
Eine Abbildung $f:D\to \R^m$ heißt differenzierbar im Punkt $x\in D$, wenn eine lineare Abbildung $A:\R^n\to\R^m$ existiert, so dass 
\[
\lim_{\substack{h\in \R^n \\ h\to 0}}\frac {|f(x+h)-f(x)-Ah|}{|h|}=0.
\]
Wir nennen die lineare Abbildung $A$ \emph{Ableitung}, oder \emph{Differential} von $f$ an der Stelle $x$ und bezeichnen sie mit $\mathrm d f(x)$ (in der Literatur wird auch $\mathrm D f(x)$ und $f'(x)$ verwendet).
Die zugehörige $m \times n$-Matrix heißt \emph{Jacobi-Matrix}.
\begin{note}
	Für $f: \R \supset D \to \R$ ist die Jacobi-Matrix an einer Stelle $x \in D$ eine $1\times 1$-Matrix, also eine reelle Zahl, bekannt als $f'(x)$.
\end{note}
\end{df}

\begin{note}
\begin{enumerate}
\item Im Fall einer Kurve
\[
f:(a,b)\to \R^n \qquad \text{stetig}
\]
reduziert sich die obige Definition auf die Existenz des „Geschwindigkeitsvektors“:
\[
f'(t)=\lim_{h\to 0}\frac 1h (f(t+h)-f(t))
\]
\item Eine affine Abbildung $f:\R^n\to \R^m$
\[
f(x)=Ax+b \qquad A\in\Mat(m\times n), b\in \R^m
\]
ist in jedem Punkt $x\in R^n$ differenzierbar und $f'(x)=A$ für alle $x\in R^n$.
\[
df(x)h=Ax
\]
$df: D \to \Hom(\R^n,\R^m):x\mapsto df(x)$ heißt \emph{Differential} oder \emph{Ableitung} von $f$
\begin{proof}
\begin{align*}
f(x+h)-f(x)&=A(x+h)-Ax\\
&=Ah
\end{align*}
Also
\begin{align*}
\frac{|f(x+h)-f(x)-Ah|}{|h|}=0
\end{align*}
für alle $h\in \R^n\setminus \{0\}$.
\end{proof}

\item
Sei $A$ eine symmetrische $n\times n$-Matrix und
sei $f$ die quadratische Form:
\[
f(x)=\<x,Ax\>=\sum_{i,j=1}^nA_{ij}x_ix_j
\]
Dann ist $f$ differenzierbar und die Ableitung ist
\[
df(x)h = \<2Ax,h\>
\]
\begin{proof}
\begin{align*}
f(x+h) &= \<x+h,A(x+h)\>\\
&=\<x,Ax\>+\<x,Ax\>+\<x,Ah\>+\<h,Ah\>\\
&=f(x)+2\<Ax,h\>+\<h,Ah\>\\
\implies \frac{|f(x+h)-f(x)-2\<Ax,h\>|}{|h|}&=\frac {|\<h,Ah\>|}{|h|}\\
&\le \frac {|h||Ah|}{|h|} = |Ah|\\
&\le \|A\|\cdot |h| \to 0 \qquad (h\to 0)
\end{align*}
\end{proof}

\item
Ist $f:D\subset R^n\to R^m$ differenzierbar in $x$, dann ist $f$ stetig in $x$.

\begin{proof}
\begin{align*}
f(x+h)-f(x)=df(x)h+o(h) \to 0 \qquad (h\to 0)
\end{align*}
\end{proof}

\item Bei Abbildungen einer Variablen $f:(a,b)\to \R^m$ ist es üblich auch den Vektor
$f'(t) = df(t)$ als Ableitung von $f$ im Punkt $t$ zu bezeichnen.

Bei Abbildungen/Funktionen mehrerer Variablen verstehen wir unter der Ableitung \emph{immer} die \emph{lineare Abbildung} $df(x)$.
\end{enumerate}
\end{note}

\setcounter{thm}{0}
\begin{st}
\label{13.1}
Eine Abbildung $f:D\subset \R^n\to \R^m$ mit
\[
f(x)=\begin{pmatrix}f_1(x)\\f_2(x)\\\vdots\\f_m(x)\end{pmatrix}
\]
ist genau dann differenzierbar im Punkt $a\in D$, wenn alle Funktionen
$f_k$  ($k=1,\dotsc,m$) im Punkt $a$ differenzierbar sind.
Dann gilt
\[
f'(a)=\begin{pmatrix}f_1'(a)\\f_2'(a)\\\vdots\\f_m'(a)\end{pmatrix}\in \Mat(m\times n, \R)
\]
mit $f_k'(a)\in \Mat(1\times n, \R)$.
\begin{proof}
Folgt aus 8.16, wonach 
\begin{align*}
\frac 1{|h|}(f(a+h)-f(h)-f'(a)h) &\to 0 \qquad h\to 0\\
\end{align*}
genau dann, wenn für $k=1,\dotsc, m$
\[
\frac 1{|h|}(f_k(a+h)-f_k(a)-\sum_{i=1}^nf'(a)_{ki}h_i) \to 0 \qquad h\to 0
\]
\end{proof}
\end{st}

\section*{Richtungsableitungen}

Die Richtungsableitung $\d_hf(x)$ einer Abbildung $f:D\subset \R^m \to \R^n$ im Punkt $x\in D$ in 
Richtung des Vektors $h\in \R^n$ ist (im Fall der Existenz) definiert als
\[
\d_hf(x) := \frac d{dt}\left.f(x+th)\right|_{t=0}
\]
Die Richtungsableitungen $\d_{e_k}f(x)$ in Richtung der Basisvektoren
$e_k$ Standardbasis, heißen \emph{partielle Ableitungen} von $f$ im Punkt $x$ und werden mit
\[
\d_kf(x) \text{ oder } \frac {\d f}{\d x_k}(x)
\]
bezeichnet.
Es gilt
\[
		\d_kf(x)=\lim_{t\to 0}\frac {f(x_1,\dotsc,x_{k-1},x_k+t,x_{k+1},\dotsc,x_n)-f(x)}t
\]
Im Falle einer Funktion $f:D\subset \R^n\to \R$ und $|h|=1$ ist $\d_kf(x)$ die Steigung des Graphen von
$t\to f(x+th)$ im Punkt $t=0$ (Steigung des Graphen von $f$ über der Geraden $t\to x+th$ bei $t=0$).

\begin{ex*}
\begin{enumerate}
\item
$f(x,y)=\sqrt{1-x^2-y^2}$ für $x^2+y^2\le 1$.
\begin{align*}
\d_xf(x,y)&=\frac 12 \frac 1{\sqrt{1-x^2-y^2}}(-2x)\\
&=\frac {-x}{\sqrt{1-x^2-x^2}}\\
\d_yf(x,y)&=\frac{-y}{\sqrt{1-x^2-y^2}}
\end{align*}

\item
Sei $f:D\subset \R^2\to \R^2$, $D=\R\times \R$ und
\[
f(r,\phi)=\begin{pmatrix}r\cos\phi\\r\sin\phi\end{pmatrix}
\]
\begin{align*}
\d_rf(r,\phi)&=\begin{pmatrix}\cos\phi\\\sin\phi\end{pmatrix}\\
\d_\phi f(r,\phi)&=\begin{pmatrix}-r\sin\phi\\ r\cos\phi\end{pmatrix}
\end{align*}
\begin{note}
Konzentrische Kreise!
\end{note}
\end{enumerate}
\end{ex*}

\begin{st}
\label{13.2}
Ist $f:D\subset \R^n\to \R^m$ im Punkt $x\in D$ differenzierbar, dann existieren alle Richtungsableitungen
$\d_hf(x), h\in \R^n$ und insbesondere alle partiellen Ableitungen $\d_kf(x)$ mit $k=1,\dotsc,n$.

Es gilt:
\begin{enumerate}[(i)]
		\item ${\displaystyle \d_hf(x)=df(x)h=\sum_{k=1}^n\d_kf(x)h_k}$
		\item Die Jacobi-Matrix von $f$ ist dann folgendermaßen bestimmt:
				\begin{align*}
						f'(x)&=\begin{pmatrix}
								| & |&\cdots & |\\
						\d_1f(x) & \d_2f(x)& \cdots&\d_nf(x)\\
						  |&|&\cdots&|\end{pmatrix}\\
       f'(x)&=\begin{pmatrix}\d_1f_1(x) & \cdots & \d_nf_1(x)\\ \vdots & &\vdots \\ \d_1f_m(x) &\cdots&\d_nf_m(x)\end{pmatrix}\\
		f'(x)_{ik}&=\d_kf_i(x) =: f_{i,k}(x)
\end{align*}
\end{enumerate}
\begin{proof}
		\begin{enumerate}
				\item[(ii)]
				

Existenz von $\d_kf(x)$ und $\d_hf(x)=df(x)h$ folgen aus
\begin{align*}
\frac {|f(x+th)-f(x)-df(x)ht|}{|t|}
&= \underbrace{\frac {|f(x+th)-f(x)-df(x)th}{|th|}}_{\to 0 (t\to 0)}|h|
\to 0 \qquad (t\to 0)
\end{align*}
nach der Definition der Differenzierbarkeit in $x$.
Also
\begin{align*}
\frac {f(x+th)-f(x)}t - df(x)h \to 0 \qquad (t\to 0)
\end{align*}
Aus $df(x)h=\d_hf(x)$ folgt insbesondere, dass $\d_kf(x)=\d_{e_k}f(x)$
\begin{align*}
=df(x)e_k &=f'(x)e_k
\end{align*}
was gerade die $k$-te Spalte von $f'(x)$ ist.
\item[(i)]
Für $h=\sum_{k=1}^nh_ke_k$ gilt
\begin{align*}
\d_hf(x) &= df(x)h \\
&= \sum_{k=1}^nh_kdf(x)e_k\\
&= \sum_{k=1}^nh_k\d_kf(x)
\end{align*}
\end{enumerate}
\end{proof}
\end{st}

\begin{ex*}
Sei 
\begin{align*}
	f(r,\phi)&=\begin{pmatrix}r\cos\phi\\r\sin\phi\end{pmatrix}\\
\d_rf(r,\phi)&=\begin{pmatrix}\cos \phi \\ \sin \phi \end{pmatrix}\\
\d_\phi f(r,\phi)&=\begin{pmatrix}-r\sin\phi \\ r\cos\phi\end{pmatrix}
\end{align*}

Falls $f$ differenzierbar ist, dann gilt
\[
f'(x)=\begin{pmatrix}\cos\phi & r\sin\phi\\ \sin\phi & r\cos \phi\end{pmatrix}
\]
\begin{note}
Rechteck wird abgebildet auf ein Rechteck im Kreissektor.
\end{note}
\end{ex*}
\begin{note}
Bei der Abbildung $df(x):\R^n\to \R^m$ stellen wir uns das Urbild $h\in \R^n$ im Punkt $x$
und das Bild $df(x)h$ im Punkt $f(x)$ angeheftet vor.
\end{note}

\begin{ex*}
Sei $f:D\subset \R^2\to \R^3$, $D=(0,\pi)\times(0,2\pi)$
\[
f(\theta,\phi)=\begin{pmatrix}\sin\theta \cos\phi\\ \sin\theta \sin\phi\\ \cos\theta\end{pmatrix}
\]
\begin{note}
Einheitskugel mit Längen- und Breitengrad.
\end{note}
\begin{align*}
d_\phi f(\theta, \phi) &= \begin{pmatrix}-\sin \theta \sin\phi\\ \sin\theta\cos\phi\\ 0\end{pmatrix}\\
d_\theta f(\theta,\phi) &= \begin{pmatrix}\cos \theta \cos\phi\\ \cos\theta \sin\phi\\ -\sin\theta\end{pmatrix}
\end{align*}

$df(p)$ bildet $\R^2$ auf die Tangentialebene an der Kugeloberfläche im Punkt $p$ ab.

\end{ex*}

\begin{note}
\[
f'(x)_{ik}=\frac {\d f_i}{\d x_k}(x)=\d_kf_i(x) =\lim_{h\to 0}\frac{f_i(x+he_i)-f(x)}h
\]
mit $e_i=(0,\dotsc,1,\dotsc,0)^T$.
\end{note}

\begin{ex*}
\begin{align*}
\frac\d{\d y}e^{\sin(xy)} &= e^{\sin(xy)}\frac\d{\d y}\sin(xy) = e^{\sin(xy)}\cos(xy)x
\end{align*}
\end{ex*}

\underline{Ist eine Funktion differenzierbar, wenn sie partiell differenzierbar ist?}\\
Nein! Gegebeispiele:
\begin{enumerate}
\item
Existenz der partiellen Ableitungen garantiert nicht einmal die 	

\end{enumerate}

FIXME: VORLESUNG FEHLT



\begin{note}
Sei $f:D\subset \R^n\to R$ differenzierbar, dann ist
\[
df(x)h = f'(x)h = \sum_{k=1}^n\d_kf(x)h_k = \<\nabla f(x),h\>
\]
mit
\[
\nabla f(x) = \begin{pmatrix}\d_1f(x)\\ \vdots \\ \d_n f(x)\end{pmatrix}
\]
\end{note}
\begin{ex*}

\begin{enumerate}
\item $f(x)=ax+b$, $a,x\in \R^n$, $b\in \R$ ist differenzierbar und
$df(x)h=ah$.
Also
\[
\nabla f(x) = a
\]
\item Sei $f(x)=\<x,Ax\>$, $x\in \R^n$ und $A$ eine symmetrische $n\times n$-Matrix.
Dann $df(x)h=\<2Ax,h\>$
Also
\[
\nabla f(x)=2Ax
\]
\end{enumerate}
\end{ex*}

\section*{Geometrische Interpratation von $\nabla f(x)$}
Aus obigem folgt für jeden Vektor $h\in\R^n$, $|h|=1$, dass
\begin{align*}
		\frac \d{\d x} \left|f(x+th)\right|t=:\d_hf(x)&=df(x)h\\&=\<\nabla f(x),h\>\\
												&\le |\nabla f(x)||h|\\&=|\nabla f(x)|
\end{align*}
mit Gleichheit nur für $h=\frac{\nabla f(x)}{|\nabla f(x)|}$.
Das heißt der Gradient $\nabla f(x)$ zeigt in die Richtung des größten Anstiegs von $f$ und $|\nabla f(x)|$ ist die Steigung von $f$ in diese Richtung.

Für jede differenzierbare Kurve $\gamma:I\subset \R\to \R^n$ in $D$ ($\gamma(I)\subset D$) folgt aus der Kettenregel, dass:
\begin{align*}
\frac d{dx}f(\gamma(t))&=f'(\gamma(t))\dot\gamma(t)\\
&=\nabla f(\gamma(t))\cdot \dot\gamma(t)\\
&=\sum_{k=1}^n\d_kf(\gamma(t))\frac{d\gamma_k}{dt}(t)
\end{align*}

Wenn die Spur von $\gamma y$, d.h. $\gamma(I)$ auf einer Niveau-Fläche(Kurve) von $f$ liegt, d.h.
$\gamma(I)\subset\{x|f(x)=\const\}$, dann ist $f(\gamma(t))$ konstant, also folgt aus obigem, das
\[
0=\nabla f(\gamma(t))\cdot \dot\gamma(t)
\]
Da $\dot\gamma(t)$ „tangential“ an die Niveaufläche ist, schließen wir:

Der Gradient $\nabla f(a)$ steht senrecht auf der Niveaufläche $\{x\in D|f(x)=f(a)\}$.

\begin{ex*}
Sei $f(x,y)=\frac{x^2}{a^2}+\frac{x^2}{b^2}$.
Die Niveaukurven 
\[
\frac{x^2}{a^2}+\frac{y^2}{b^2}=c
\]
sind Ellipsen.
\[
	\nabla f(x,y)=\begin{pmatrix}\frac{2x}{a^2} \\[0.3em] \frac{2y}{b^2}\end{pmatrix}
\]
steht im Punkt $(x_0,y_0)$ senkrecht auf der Ellipse:
\[
\{(x,y)|f(x,y)=f(x_0,y_0)\}
\]
\end{ex*}

\subsection*{Physikalische Anwendung}

Ein \emph{Vektorfeld} $F:D\subset \R^n\to \R^n$ ($m=n$) heißt konservativ, wenn es eine differenzierbare Funktion
$V:D\to \R$ gibt mit
\[
F=-\nabla V
\]
($V$ heißt Potenzial)
Für jede Lösung $t\to x(t)$ der Newtonschen Gleichung
\[
m\ddot x=F(x)=-\nabla V(x)
\]
ist die Energie
\[
E=\frac m2 \dot x^2+V(x)
\]
\begin{proof}
\begin{align*}
\frac{d}{dt}\left(\frac m2 \dot x(t)^2+V(x(t))\right) &= m\dot x(t)\ddot x(t) + \nabla V(x(t))\dot x(t)\\
&=\left<\underbrace{m\ddot x(t)+\nabla V(x(t))}_{=0}, \dot x(t)\right> = 0
\end{align*}
\end{proof}

\section{Mittelwertsätze}

Zu $a,b\in \R^n$ sei $[a,b]$ die \emph{Strecke} von $a$ nach $b$, d.h.
\[
[a,b]=\{a+t(b-a)|t\in [0,1]\}
\]

\begin{st}
Sei $f:D\subset \R^n\to \R$ eine differenzierbare Funktion und $[a,b]\subset D$.
Dann exisitiert $x\in [a,b]$, so dass
\[
f(b)-f(a)=\nabla f(x)\cdot (b-a)
\]

\begin{proof}
Sei $g:[0,1]\to \R$ die Funktion $g(t)=f(a+t(b-a))$.
Dann ist $g$ differenzierbar und nach dem bekannten Mittelwertsatz gilt
\begin{align*}
f(b)-f(a)&=g(1)-g(0)\\
&=g'(\tau)\cdot1\\
&=\nabla f(\underbrace{a+\tau(b-a)}_{=:x})\cdot (b-a)
\end{align*}
\end{proof}
\end{st}

\begin{st}
Sei $f:D\subset \R^n\to \R^m$ differenzierbar und $[a,b]\subset D$.
Dann existiert $x\in [a,b]$ mit
\[
|f(b)-f(a)|\le \|f'(x)\|\cdot |b-a|
\]

\begin{proof}
Für $f(b)=f(a)$ ist die Aussage trivial.
Wir nehmen an $f(b)\neq f(a)$ und definieren
\[
e:=\frac{f(b)-f(a)}{|f(b)-f(a)|}
\]
Sei $g:[0,1]\to \R$ definiert durch
\[
	g(t)=\<e,f(a+t(b-a))\>\in \R
	\]
Dann ist $g$ differenzierbar und somit folgt aus dem bekannten Mittelwertsatz, dass
\begin{align*}
g(1)-g(0)&=g'(\tau)\cdot 1\\
&=\<e,f'(\underbrace{a+\tau(b-a)}_{=:x})(b-a)\>\\
&\le |e|\cdot|f'(x)(b-a)|\\
&\le \|f'(x)\|\cdot |b-a|
\end{align*}
Wobei 
\begin{align*}
g(1)-g(0)&=\<e,f(b)\>-\<e,f(a)\>\\
&=\<e,f(b)-f(a)\>\\
&=\<e,e\>|f(b)-f(a)|= |f(b)-f(a)|
\end{align*}
\end{proof}
\end{st}

\begin{df}\label{13.5}
Eine Menge $D\subset \R^n$ heißt \emph{wegzusammenhängend}, wenn es zu jedem Paar
$a,b\in D$ einen Streckenzug $[a,x_1,x_2,\dotsc,x_{n-1},b]$ in $D$ gibt.
Das heißt, es gibt Punkte $x_k\in D, k=0,\dotsc,N$ mit $x_0=0, x_n=b$ und
\[
[a,x_1,\dotsc,x_{n-1},b] := \bigcup_{k=1}^k[x_{k-1},x_k]\subset D
\]
\end{df}

\begin{kor}
Sei $D\subset \R^n$ offen und zusammenhängend.
Ist $f$ differenzierbar und $f'(x)=0$ für alle $x\in D$, dann ist $f$ konstant in $D$.
\begin{proof}
Wähle $a\in D$ fest, dann gilt für jeden Punkt $p\in D$, dass
\[
f(b)=f(x_n)=f(x_{n-1})=\dotsb=f(a)
\]
wenn $[a,x_1,\dotsc,x_n=b]$ ein Streckenzug in $D$ ist.
$f(x_k)=f(x_{k-1})$ folgt aus obigem Satz.
\end{proof}
\end{kor}

\begin{note}
Eine Menge kann zusammenhängend und trotzdem nicht wegzusammenhängend sein:
\[
	\R^2 \supset D=\left\{(x,y)\in \R^2:y=\sin\left(\frac 1x\right)\right\}\cup\left\{(x,y)\in \R^2:x=0,|y|\le 1\right\}
\]
\end{note}


\section{Höhere partielle Ableitungen}


Sei $f:\R^2\to \R$ partiell differenzierbar mit existierenden
$\d_1\d_2f$ und $\d_2\d_1f$.
Gilt dann
\[
\d_1\d_2f(x,y)\stackrel ?=\d_2\d_1f(x,y)
\]
Nein, betrachte dazu folgendes
Gegenbeispiel: Sei $f: \R^2 \to \R$ gegeben durch $f(0,0)=0$ und durch
\[
f(x,y)=\frac{x^3y-xy^3}{x^2+y^2}
\]
für $(x,y) \neq (0,0)$.
Dann gilt für $(x,y)\neq (0,0)$
\begin{align*}
\d_1f(x,y) &= \frac{x^4y+4x^2y^3-y^5}{(x^2+y^2)^2}\\
\d_2f(x,y) &= \frac{x^5-4x^3y^2-xy^4}{(x^2+y^2)^2}
\end{align*}
und $\d_1f(0,0) = 0=\d_2f(0,0)$
\begin{align*}
\d_2\d_1f(0,0)&=\lim_{h\to 0}\frac 1h(\d_1f(0,h)-\underbrace{\d_1f(0,0)}_{0})\\
&=-1\\
\d_1\d_2f(0,0)&=\lim_{h\to 0}\frac 1h(\d_2f(h,0)-\underbrace{\d_2f(0,0)}_{0})\\
&=1
\end{align*}

\begin{st}
Sei $D\subset \R^n$ offen und $f:D\to \R$ wobei $\d_1f$, $\d_2f$ und $\d_2\d_1 f$ in $D$ existieren.
Falls $\d_2\d_1 f$ im Punkt $(0,0)$ stetig ist, dann existiert auch $\d_1\d_2f(0,0)$ und es gilt
\[
\d_1\d_2f(0,0)=\d_2\d_1f(0,0)
\]
\begin{note}
Der Satz gilt an jeder Stelle $(x,y)$, wenn man die Funktion nur entsprechend verschiebt.
\end{note}

\begin{proof}
Wir nehmen zuerst an, dass $\d_2\d_1f(0,0)=0$ und wir zeigen, dass
\[
\d_1\d_2f(0,0):=\lim_{x\to 0}\frac 1x (\d_2f(x,0)-\d_2f(0,0))=0
\]
Sei $\phi(x,y)=f(x,y)-f(x,0)$.
Der obige Quotient ist der Grenzwert für $y\to 0$ von
\begin{align*}
\frac 1{xy}(f(x,y)-f(x,0)-f(0,y)+f(0,0)) &= \frac 1{xy}(\phi(x,y)-\phi(0,y))\\
&\stackrel {\text{MWS}}= \frac 1{xy} (\d_1\phi(\theta x, y)x) \qquad \theta\in (0,1)\\ 
&= \frac 1y \d_1\phi(\theta x,y)\\
&= \frac 1y \d_1f(\theta x,y)-\d_1f(\theta x,0)\\
&\stackrel {\text{MWS}}= \d_2\d_1f(\theta x, \theta' y) \qquad \theta,\theta'\in (0,1)
\end{align*}
Da $\d_2\d_1f$ in $(0,0)$ stetig, gibt es zu $\varepsilon > 0$ ein $\delta >0$ so, dass
\begin{align*}
|x|,|y|<\delta \\
\implies \frac 1{|xy|}\left| f(x,y)-f(x,0) -f(0,y)+f(0,0)\right|
&=|\d_2\d_1f(\theta x,\theta' y)| \le \varepsilon
\end{align*}
Im Limes $y\to 0$ folgt daraus, dass
\begin{align*}
|x|<\delta \implies \frac 1{|x|}\left| \d_2f(x,0)-\d_2f(0,0)\right| \le \varepsilon
\end{align*}
Damit ist gilt die Gleichung zu Beginn.

Zum Beweisen der Behauptung im Fall $\alpha := \d_2\d_1f(0,0)\neq 0$ wenden wir das eben bewiesen Resultat an auf die Funktion
\[
g(x,y)=f(x,y)-\alpha xy
\]
Da
\[
d_2d_1g(0,0)=\d_2\d_1f(0,0)-\alpha = 0
\]
folgt, dass 
\[
d_1d_2g(0,0)=\d_2\d_1g(0,0)=0
\]
und somit
\[
\d_1\d_2f(0,0) = \d_2\d_1f(0,0)
\]
\end{proof}
\end{st}

\begin{ex*}
$f(x,y)=\sin (x^2,y)$. Dann ist
\begin{align*}
\d_1f(x,y) &= \cos(x^2y)2xy\\
\d_2d_1f(x,y) &= -\sin(x^2y)2x^3y + \cos(x^2y)2x\\
\d_2f(x,y) &= \cos(x^2y)x^2\\
\d_1\d_2f(x,y) &= -\sin(x^2y)2x^3y + \cos(x^2y)2x\\
\end{align*}
\end{ex*}

\begin{df}
	Eine Abbildung $f:D\to \R$ heißt \emph{$C^k$-Abbildung}, falls
	\[
		f \in C^k(D) = \{f:D\to \R|f \text{ ist $k$ Mal stetig partiell differenzierbar}\}
	\]
\end{df}

\begin{thm}[Satz von Schwarz]
\label{st:schwarz}
Sei $D\subset \R^n$ offen und $f\in C^k(D)$. 
Dann ist $\d_{i_1}\dotsc\d_{i_k}f$ unabhängig von der Reihenfolge der $i_1,\dotsc,i_k\in\{1,2,\dotsc,n\}$.

\begin{proof}
Führe eine Induktion auf $k$ aus.
\end{proof}
\end{thm}

\setcounter{section}{13}
\setcounter{subsection}{5}
\section{Hessesche Matrix und lokale Extrema}

Aus Analysis 1 wissen wir, dass für lokale Extrema $f'(x)=0$ gilt, können wir das verallgemeinern?

Sei $D\subset \R^n$ offen und $f\in C^2(D)$. 
Sei $a\in D$.
Dann ist auch die Strecke $[0,a+x]$ in $D$ für $|x|$ klein genugt.
Wir halten $x$ fest und definieren
\[
g(t) = f(a+tx) \qquad f\in [0,1]
\]
Aus \ref{13.5} folgt
\begin{align*}
g'(t) &= \sum_{k=1}^n\d_kf(a+tx)x_k\\
g''(t) &= \sum_{i=1}^n\sum_{k=1}^n\d_i\d_kf(a+tx)x_ix_k
\end{align*}
Insbesondere ist $g$ zwei Mal stetig differenzierbar.

Die  $n\times n$-Matrix $(\d_i\d_kf(x)_{i,k=1,\dotsc,n}$ heißt \emph{Hessesche Matrix} von $f$ an der Stelle $y$.
Sie wird mit $f''(x)$ oder $H_f(x)$ bezeichnet.

Da wir $f\in C^2(D)$ annehmen, ist $f''(x)$ eine symmetrische Matrix (wegen der Vertauschbarkeit der partiellen Ableitungen \ref{st:schwarz}).
Also:
\begin{align*}
g'(t) &= \nabla f(a+tx)\cdot x\\
g''(t) &= \<x,f''(a+tx)x\>
\end{align*}

\begin{thm} \label{13.11}
Sei $f\in C^2(D)$, $D\subset \R^n$ offen und $a\in D$.
Dann gilt
\[
f(a+x)=f(a)+\<\nabla f(a), x\> + \frac 12 \<x,f''(a) x\> + o(|x|^2) \qquad (x\to 0)
\]
\begin{note}
Das ist die Verallgemeinerung von der Taylor-Formel:
\[
f(a+x) = f(a) + f'(a)x + \frac 12 f''(a)x^2 + o(x^2) \qquad (x\to 0)
\]
\end{note}

\begin{proof}
Sei $g(t):= f(a+tx)$. 
Dann ist $g \in C^2([0,1])$ und nach der Taylorschen Formel 9.28 gilt
\begin{align*}
g(1) &= g(0) + g'(0)\cdot 1 + \frac 12 g''(\tau_x) \qquad \text{ für ein } \tau_x\in (0,1)
\end{align*}
Für $f$ bedeutet das, nach den Ableitungen von $g$, dass
\begin{align*}
f(a+x) &= f(a) + \nabla f(a)\cdot x + \frac 12 \<x,f''(x+\tau_x x)x\>
\end{align*}
Wobei
\[
	\<x,f''(a+\tau_x)x\> = \<x,f''(a)x\> + o(|x|^2) \qquad (x\to 0)
\]
denn
\begin{multline*}
\frac 1{|x|^2}\left|\<x,f''(a+\tau_x x)x\>-\<x,f''(a)x\>\right|\\
\quad \le \sum_{i,n=1}^n\underbrace{\frac {|x_ix_k|}{|x|^2}}_{\le 1}\underbrace{\left|\d_i\d_kf(a+\tau_x x)-\d_i\d_kf(a)\right|}_{\to 0 (x\to 0)} \to 0 \qquad (|x|\to 0)
\end{multline*}
denn $\d_1\d_kf$ ist stetig.
\end{proof}
\end{thm}

\begin{df}
Die Funktion $f:D\subset \R^n\to \R$ hat im Punkt $a\in D$ ein \emph{lokales Maximum} falls $B_\varepsilon(a)\subset D$ existiert mit
\[
f(x)\le f(a) \qquad \forall x\in B_\varepsilon(a)
\]
Das lokale Maximum ist \emph{strikt} (oder isoliert), wenn $f(x)<f(a)$ für $x\in \dot B_\varepsilon(a)$ ($=B_\varepsilon \setminus \{a\})$.
(Strikte) \emph{lokale Minima} sind analog definiert und \emph{lokales Extremum} ist der gemeinsame Oberbegriff für lokales Maximum und lokales Minimum.

Ist $f$ differenzierbar und $\nabla f(a)=0$, dann ist $a$ ein \emph{kritischer} oder \emph{stationärer} Punkt von $f$.
\end{df}

\begin{st}
Ist die differenzierbare Funktion $f:D\to \R$ im Punkt $a\in D$ lokal extremal, dann ist $a$ ein kritischer Punkt von $f$ und
\[
\nabla f(a)=0
\]
\begin{proof}
Für $f$ gilt: für jeden Vektor $k\in \R^n$ ist die Funktion
\[
t\mapsto f(a+th)
\]
im Punkt $t=0$ lokal extremal.
Also ist
\[
\d_hf(a) =: \left.\frac d{dt}f(a+th)\right|_{t=0}=0
\]
nach 9.6.
Insbesondere ist $\d_kf(a)=\d_{e_k}f(a)=0$ für $k\in \{1,\dotsc,n\}$.
Das heißt:
\[
\nabla f(a) = \begin{pmatrix}\d_1f(a)\\ \vdots \\ \d_nf(a)\end{pmatrix}=0
\]
\end{proof}
\end{st}

Ist $f\in C^2(D)$ im Punkt $a\in D$ kritisch, also $\nabla f(a)=0$, dann
\[
f(a+x) = f(a)+\frac 12 \<x,f''(a)x\> + o(|x|^2) \qquad (x\to 0)
\]
Im Fall $f''(a)\neq 0$ ist zu erwarten, dass die Natur des kritischen Punktes $a$ durch $f''(a)$ bestimmt ist.

Eine symmetrische $n\times n$-Matrix $A$ heißt
\begin{itemize}
\item positiv definit, $A>0$, falls $\<x,Ax\> > 0$ für alle $x\neq 0$.
\item positiv semi-definit, $A\ge 0$, falls $\<x,Ax\> \ge 0$ für alle $x$.
\item negativ (semi-)definit, wenn $-A$ positiv (semi-)definit ist.
\item indefinit, falls Vektoren $x,y\in \R^n$ existieren mit $\<x,Ax\> >0$ und $\<y,Ay\> < 0$
\end{itemize}

Zu jeder symmetrischen $n\times n$-Matrix $A$ gibt es eine Orthonormalbasis (ONB) $\eta_m,\dotsc, \eta_n$ von $\R^n$ bestehend aus Eigenvektoren von $A$.
\[
A\eta_k = \lambda_k\eta_k \qquad \lambda_k \in \R, \<\eta_i,\eta_k\>=\delta_{ik}
\]
Für $x=\sum_{k=1}^nx_k\eta_k$ gilt
\[
<x,Ax> = \sum_{k=1}^n\lambda_kx_k^2
\]
\begin{proof}
\[
Ax = \sum_{k=1}^nx_kA\eta_k = \sum_{k=1}^n x_k \lambda_k\eta_k
\]
Also
\[
	\<x,Ax\> = \sum_{k=1}^n x_k \lambda_k \<x,\eta_k\> = \sum_{k=1}^n \lambda_kx_k^2
\]
denn 
\[
\<x,\eta_k\>=\left\<\sum_{k=1}^n x_i\eta_i, \eta_k\right\> = \sum_{k=1}^n x_i\underbrace{\<\eta_i,\eta_k\>}_{=\delta_{ik}}=x_k
\]
\end{proof}
Somit ist die Matrix $A$:
\begin{align*}
\text{positi definit } &\iff \forall k: \lambda_k >0\\
\text{positiv semi-definit} &\iff \forall k: \lambda_k \ge 0\\
\text{indefinit } &\iff \exists i,k: \lambda_v<0<\lambda_k
\end{align*}

\begin{st}
	Die reelle symmetrische $n\times n$-Matrix $A=(a_{ik})_{i,k=1,\dotsc,n}$ ist genau dann positv definit, wenn \emph{für alle} $k=1,\dots,n$
\[
\det\begin{pmatrix}a_{11} & \cdots & a_{1k}\\ \vdots & \ddots & \vdots \\ a_{k1} & \cdots & a_{kk}\end{pmatrix} > 0
\]
\end{st}

\begin{ex*}
Die $2\times 2$-Matrix
\[
\begin{pmatrix}a&b\\b&c\end{pmatrix}
\]
ist genau dann positiv definit, wenn $a>0$ und $ac>b^2$
\end{ex*}

$a\in D\subset \R^n$ heißt \emph{kritischer Punkt} von $f$ wenn
\[
\nabla f(a) = 0
\]
\[
f(a+x)=f(a)+\underbrace{\nabla f(a)x}_{=0}+\frac 12 \<x,H_f(a)x\> + o(|x|^2) \qquad (x\to 0)
\]
\[
f(a+x)-f(x) = \frac 12 \<x,H_f(a)x\> + o(|x|^2) \qquad (x\to 0)
\]

\begin{thm}
\label{13.14}
Sei $a\in D$ ein kritischer Punkt, der Funktion $f\in C^2(D)$.
Dann gilt:
\begin{enumerate}[(i)]
\item $H_f(a)$ ist positiv definit $\implies$ $f$ hat in $a$ ein striktes lokales Minimum
\item $H_f(a)$ ist negativ definit $\implies$ $f$ hat in $a$ ein striktes lokales Maximum
\item $H_f(a)$ ist indefinit $\implies$ $f$ hat in $a$ \emph{kein} lokales Extremum
\end{enumerate}
\begin{proof}
Nach \ref{13.11} gilt
\[
f(a+x) = f(a) + \frac 12 \<x,H_f(a)x\> R(a,x)|x|^2
\]
wobei $R(a,x)\to 0$ für $x\to 0$.
\begin{enumerate}[(i)]
\item
Ist $H_f(a)$ positiv definit, dann existiert $c>0$ mit
\[
\<x,H_f(a)x\> \ge c|x|^2 
\]
(Wir können für $c$ den kleinsten Eigenwert von $H_f(a)$ wählen).
Wegen $R(a,x)\to 0$ ($x\to 0$)
\[
\exists \delta > 0: |x|<\delta \implies |R(a,x)|<\frac \varepsilon 2
\]
Also gilt für $x\in \dot B_\delta$ dass
\begin{align*}
f(a+x)-f(a) &\ge \frac 12 c|x|^2 +R(a,x)|x|^2\\
&= \underbrace{\left(\frac 12 c + R(a,x)\right)}_{>0} |x|^2
&> 0
\end{align*}

\item
Betrachte dazu einfach (i) angewandt auf $-f$.

\item
Sei $H_f(a)$ indefinit.
Dann existieren $x_+,x_- \in \R^n$ mit $|x_+|=1=|x_-|$, so dass
\begin{align*}
c_+ &= \<x_+,H_f(a)x_+\> > 0\\
c_- &= \<x_-,H_f(a)x_-\> < 0
\end{align*}
Wir wählen jetzt $\delta >0$ so klein, dass 
\[
|R(a,x)| < \frac 12 \min\{c_+, -c_-\} \qquad |x|<\delta
\]
Dann folgt für $|t|<\delta$
\[
f(a+tx_+)-f(a) = t^2\underbrace{\left( \frac {c_+}2 + R(a,tx_+)\right)}_{>0} > 0
\]
und für $0<|t|<\delta$:
\begin{align*}
f(a+tx)-f(a) &= \frac 12 \<tx_-,H_f(a)tx_-\> + R(a,tx_i)|tx_-|^2\\
&=t^2\underbrace{\left(\f 12 c_- +R(a,tx_-)\right)}_{<0} < 0
\end{align*}
Aus diesen beiden Ungleichungen folgt, dass $f$ in $a$ \emph{kein} lokales Extremum hat.
\end{enumerate}
\end{proof}
\end{thm}

\begin{ex*}
\begin{enumerate}
\item
Für
\[
f(x,y) = x^2+y^2+3xy
\]
gilt
\begin{align*}
\nabla f(0,0) &= \begin{pmatrix}0\\ 0\end{pmatrix}\\
H_f(0,0) &= \begin{pmatrix}2 & 3 \\ 3 & 2\end{pmatrix}
\end{align*}
Der Punkt $(0,0)$ ist ein kritischer Punkt, aber $H_f(0,0)$ ist nicht positiv definit ($\det H_f(0,0) = -5 < \infty$).
Sie ist auch nicht negativ definit ($\<x,H_f(a)x\> > 0$ für $x=(1,0)$) und wegen $\det H_f(0,0)\neq 0$ auch nicht semi-definit. 

Also ist $f$ in $(0,0)$ nicht extremal.

\item
Die Funktion 
\[
f(x,y) = (y-x^2)(y-2x^2) = 2x^4-3x^2y+y^2
\]
hat den kritischen Punkt $(0,0)$ und dort die positiv semi-definite Hessesche Matrix
\[
H_f(0,0) = \begin{pmatrix} 0&0\\0&2\end{pmatrix}
\]
FIXME (Zeichnen)

Diese Funktion hat kein lokales Extremum im Punkt $(0,0)$ (Proof by Picture).
\end{enumerate}
\end{ex*}


\setcounter{subsection}{8}
\section{Taylorsche Formel}


\begin{df*}[Multiindizes]
Für $\alpha=(\alpha_1,\dotsc, \alpha_n)\in \N_0^n$, $x\in \R^n$ und $f\in C^m(D)$, $D\subset \R^n$, definieren wir
\begin{align*}
|\alpha| &:= \sum_{k=1}^n \alpha_k\\
\alpha! &:= \prod_{k=1}^n \alpha_k!\\
x^\alpha &:= \prod_{k=1}^n x_k^{\alpha_k}\\
\d^\alpha f &:= \frac{d^{|\alpha|}}{\d x_1^{\alpha_1}\dotsb \d x_1^{\alpha_n}}f = \d_1^{\alpha_1}\dotsb\d_n^{\alpha_n}f
\end{align*}
\end{df*}

\begin{lem}
\label{13.15}
Sei $f\in C^m(D)$ und $[a,a+x]\subset D\subset \R^n$, dann ist $g:[0,1]\to \R^n:t\mapsto f(a+tx)$ $m$ Mal stetig differenzierbar auf $[0,1]$ und
\[
\frac 1{m!}\frac {d^m}{dt^m} f(a+tx) = \sum_{\alpha:|\alpha|= m}\frac 1{\alpha!}\d^{\alpha}f(a+tx)x^{\alpha}
\]

\begin{proof}
Nach der Kettenregel \ref{13.5} gilt
\begin{align*}
\frac d{dt}f(a+tx) &= \sum_{k=1}^n \d_kf(a+tx)x_k\\
\frac{d^2}{dt^2}f(a+tx) &= \sum_{k=1}^n \frac {\d}{\d t}f(a+tx)x_k\\
						&=\sum_{k_1,k_2=1}^n \d_{k_1}\d_{k_2}f(a+tx)x_{k_1}x_{k_2}
\end{align*}
und per Induktion in m
\begin{equation}
\label{eq:13.5}
\left(\frac{d}{dt}\right)^m f(a+tx) = \sum_{k_1,\dotsc,k_m=1}^n(\d_{k_1}\dotsb\d_{k_m}f)(a+tx)x_{k_1}\cdot\dotsb\cdot x_{k_m}
\end{equation}
Nach dem Satz von Schwarz (Vertauschbarkeit der partiellen Ableitungen) ist
\[
\d_{k_1}\dotsb \d_{k_m} f = \d_1^{\alpha_1}\dotsb \d_n^{\alpha_n} = \d^\alpha f
\]
wobei $\alpha_k\in \N_0$ angibt, wie oft der Index $k$ unter den Indizes $k_1,\dotsc,k_m$ vorkommt.

Mit der Bedingung $|\alpha|=m$ decken wir alle Kombinationen der $\alpha_1,\dotsc,\alpha_n$ mit $\sum_{k=1}^n \alpha_k = m$ ab.

Wir wollen wissen, wie viele Permutationen der $(\d_{k_1},\dotsc,\d_{k_n})$ es für ein bestimmtes $\alpha$ gibt.
Es gibt $m!$ verschiedene Möglichkeiten, die $(\d_{k_1},\dotsc,\d_{k_n})$ untereinander anzuordnen, wovon wir jedoch diejenigen abziehen müssen, bei denen die $\d_i$ nicht untereinander permutieren, denn dies tauchen in \eqref{eq:13.5} nicht auf.
Wir teilen also durch die Anzahl Möglichkeiten für die Permutationen der $\d_i^{\alpha_i}$ und es ergibt sich für die Anzahl der Permutationen, die $\d^\alpha$ für ein bestimmtes $\alpha$ abdeckt
\[
\frac {m!}{\alpha_1!\dotsb\alpha_m!} = \frac {m!}{\alpha!}
\]
Also gibt es $\frac{m!}{\alpha!}$ Ableitungen in \eqref{eq:13.5}, welche mit $\d^{\alpha}f(a+tx)$ übereinstimmen.

Also können wir \eqref{eq:13.5} schreiben als
\[
\sum_{\alpha:|\alpha|=m} \frac{m!}{\alpha!} \d^{\alpha}f(a+tx)x^{\alpha}
\]
\end{proof}
\end{lem}

\begin{thm}
\label{13.16}
Sei $f\in C^m(D)$, $D\subset \R^n$ offen und $[a,a+x]\subset D$.
Dann gilt
\[
f(a+x)=\sum_{|\alpha|\le m-1}\frac 1{\alpha!}\d^{\alpha}f(a)x^\alpha + R_m(a,x)
\]
wobei
\begin{align*}
R_m(a,x) &= m \int_0^1(1-t)^{m-1}\sum_{|\alpha|=m}\frac 1{\alpha!}\d^{\alpha }f(a+tx)x^\alpha dt\\
&= \sum_{|\alpha|=m}\frac 1{\alpha!}\d^{\alpha}f(a+\tau x)x^{\alpha}\qquad \tau x\in (0,1)
\end{align*}

\begin{proof}
Wir wenden die Taylorformel mit Integralrestglied (\ref{10.15}) bzw. mit Lagrange-Restglied (\ref{9.28}) auf $g(t)=f(a+tx)$.
Wir bekommen
\begin{align*}
g(1)-\sum_{k=0}^{n-1}\frac 1{k!}g^{(k)}(a) &= \frac 1{(m+1)!}\int_0^1(1-t)^{m-1}g^{(m)}(t)dt\\
&= \frac 1{m!} g^{(m)}(\tau) \qquad \tau \in (0,1)
\end{align*}
Das Theorem folgt nun aus \ref{13.15}.
\end{proof}
\end{thm}

\begin{kor}
\label{13.17}
Unter den Vorraussetzungen von \ref{13.16} gilt:
\[
	\boxed{f(a+x) = \sum_{|\alpha|\le m}\frac 1{\alpha!}\d^\alpha f(a)x^\alpha + o(|x|^m) \qquad (x\to 0)}
\]

\begin{proof}
Aus $|x^\alpha|=|\prod x_k^{\alpha_k}|=\prod |x_k|^{\alpha_k} \le |x|^m$ folgt
\begin{align*}
\frac 1{|x|^m} \left| \sum_{|\alpha|=m}\left(\frac 1{\alpha!} \d^\alpha f(a+\tau x)x^\alpha - \frac 1{\alpha!}\d^\alpha f(a)x^\alpha\right)\right|
& \le \sum_{|\alpha|=m} \f 1{\alpha !}\underbrace{\left| \d^\alpha f(a+\tau x)-\d^\alpha f(a)\right|}_{\to 0 (x\to 0)} \to 0 \qquad (x\to 0)
\end{align*}
da $d^\alpha f$ stetig ist.
Mit \ref{13.16} folgt:
\begin{align*}
\left| f(a+x)- \sum_{|\alpha|\le m}\f 1{\alpha!}\d^\alpha f(a)x^\alpha\right|
&= \left| R_m(a,x)-\sum_{|\alpha|=m}\f 1{\alpha!}\d^\alpha f(a)x^\alpha\right|\\
&=\left|\sum_{|\alpha|=m}\frac 1{\alpha!} (\d^\alpha f(a+\tau x)-\d^\alpha f(a))\right|\\
&= o(|x|^m) \qquad (x\to 0)
\end{align*}

\end{proof}
\end{kor}



\section{Integrale mit Parameter}

Wir betrachten Funktionen der Form
\[
F(x) = \int_a^bf(x,t)dt \qquad x\in D\subset \R^n
\]

\begin{st}
\label{13.18}
Sei $K\subset \R^n$ kompakt und $f:K\times [a,b]\to \C$ stetig.
Dann ist
\[
F(x) = \int_a^bf(x,t)dt
\]
stetig auf $K$.

\begin{proof}
Da $K\times[a,b]$ abgeschlossen und beschränkt, also kompakt ist, ist $f$ auf $K\times [a,b]$ gleichmäßig stetig (\ref{8.13}).
Zu $\varepsilon>0$ existiert also $\delta>0$, sodass
\[
|(x,t)-(x',t')| < \delta \implies |f(x,t)-f(x',t')| < \frac \varepsilon {2(b-a)}
\]
Daraus folgt, dass für $|x-x'| < \delta$ gilt:
\begin{align*}
|F(x)-F(x')| &\le \int_a^b\underbrace{|f(x,t)-f(x',t)|}_{< \frac \varepsilon{2(b-a)}} dt
\le (b-a)\frac \varepsilon{2(b-a)} < \varepsilon
\end{align*}
\end{proof}

\begin{note}
Im diesem Satz darf $K$ durch eine offen Menge $D$ ersetzt werden, da jeder Punkt $a\in D$ eine kompakte Umgebung $\_{B_f(a)}\subset D$ hat.
\ref{13.18} mit $K=\_{B_f(a)}$ impliziert, dass $F$ im Punkt $a\in D$ stetig ist. 
\end{note}
\end{st}

\begin{st}
\label{13.19}
Sei $D\subset \R^n$ offen und $f,\d_k f: D\times [a,b]\to \C$ stetig.
Dann hat
\[
F(x) = \int_a^bf(x,t)dt
\]
eine stetige partielle Ableitung $\d_k F$ und
\[
\d_k F(x) = \int_a^b\d_kf(x,t)dt
\]

\begin{proof}
Die Stetigkeit von $\int_a^bd_k f(x,t)dt$ folgt aus \ref{13.18}.
Nach \ref{9.2} genügt es den Fall reellwertiger Funktionen für den Beiweis der Differenzierbarkeit zu betrachten.
Nach dem Mittelwertsatz gilt:
\begin{align*}
\f 1h (F(x+he_k)-F(x)) - \int_a^b \d_kf(x,t)dt
&= \f 1h \int_a^b \frac {f(x+he_k,t)-f(x,t)}h - \d_k f(x,t) dt
&= \int_a^b (\d_k f(x+\theta he_k, t) -\d_kf(x,t))dt \qquad \theta \in (0,1)
&= 
\end{align*}
Wähle $r>0$ so klein, dass $\_{B_r(x)}\subset D$.
Dann ist $d_k f$ auf der kompakten Menge $\_{B_r(x)} \times [a,b]$ gleichmäßig stetig.
D.h. zu gegebenem $\varepsilon > 0 \exists \delta > 0$, so dass 
\[
|(x,t)-(x',t')|<\delta
\]
dann
\begin{equation}
\label{13.19.2}
|\d_kf(x',t')-\d_kf(x,t)| < \f \varepsilon{2(b-a)}
\end{equation}
aus ?? und \eqref{13.19.2} folgt, dass
\begin{align*}
\left| \f 1h(F(x+he_k)-F(x)) - \int_a^b\d_kf(x,t)dt\right|
\le \int_a^b|\d_kf(x+\theta k e_k)-\d_kf(x,t)|dt\\
\le \int_a^b \f\varepsilon {2(b-a)}dt = \frac \varepsilon 2 < \varepsilon
\end{align*}
D.h. $\d_k F(x) $ existiert und ist gegeben durch
\[
\int_a^b\d_kf(x,t)dt
\]
\end{proof}
\end{st}

\begin{thm}[Leibnizsche Regel]
\label{13.20}
Seien $I,J\subset \R$ offene Intervalle.
$f,\d_1f: I\times J \to \C$ stetig und
$a,b: I \to J$ differenzierbar.
Dann ist
\[
F(x) = \int_{a(x)}^{b(x)}f(x,t)dt
\]
auf $I$ differenzierbar und
\[
F'(x) = f(x,b(x))b'(x) - f(x,a(x))a'(x) + \int_{a(x)}^{b(x)} \d_xf(x,t)dt
\]
\begin{proof}
Wir schreiben $F$ als
\[
F(x) = \phi(b(x),a(x),x)
\]
mit $\phi:J\times J\times I \to \C$ und definiert durch
\[
\phi(b,a,x) = \int_a^bf(x,t)dt
\]
Nach Vorraussetzung ist $\gamma: x\mapsto  (b(x),a(x),x)$ eine differenzierbar Kurve in $\R^3$ und $\phi$ hat stetige partielle Ableitungen
\begin{align*}
\d_1\phi(b,a,x) &= f(x,b)\\
\d_2\phi(b,a,x) &= -f(x,a)\\
\d_3\phi(b,a,x) &= \int_a^b\d_xf(x,t)dt
\end{align*}
Also ist $\phi$ differenzierbar und somit auch $F=\phi\circ \gamma$.
Aus der Kettenregel folgt
\begin{align*}
F'(x) &= \frac d{dx} \phi(\gamma(x)) \\
&= \phi'(\gamma(x))\gamma'(x)\\
&= \nabla \phi(\gamma(x))\cdot \gamma'(x)\\
&= \sum_{k=1}^3 \d_k\phi(\gamma(x))\gamma_k'(x) \\
&= f(x,b(x))b'(x) - f(x,a(x))a'(x) + \int_a^b\d_xf(x,t)dt\cdot 1
\end{align*}

\end{proof}
\end{thm}


\begin{st}
\label{13.21}
\[
\int_{-\infty}^\infty e^{-x^2}dx = \sqrt{\pi}
\]

\begin{proof}
\begin{align*}
\int_{-\infty}^\infty e^{-x^2}dx = \int_{-\infty}^0 e^{-x^2}dx + \int_0^\infty e^{-x^2}dx
\end{align*}
und
\begin{align*}
		\int_0^\infty e^{-x^2}dx &= \lim_{R\to \infty} \int_0^R e^{-x^2}dx\\
\int_{-\infty}^0 e^{-x^2}dx = \lim_{R\to \infty} \int_{-R}^0 e^{-x^2} &= \lim_{R\to \infty}\int_0^Re^{-x^2}dx
\end{align*}
Es genügt also, nur $\lim_{R\to\infty }\int_0^Re^{-x^2}$ zu berechnen.
Wir definieren
\[
G(R) := \left(\int_0^Re^{-x^2}dx\right)^2
\]
Dann
\begin{align*}
		G'(R)= 2\left(\int_0^R e^{-x^2}dx\right)e^{-R^2}
		&= 2 \int_0^R e^{-(x^2+R^2)}dx \qquad (x=Rt, dx= Rdt)\\
&= 2 \int_0^1 e^{-t^2R^2-R^2}Rdt\\
&= \int_0^1 2R e^{-R^2(1+t^2)}dt\\
&= \int_0^1 \frac \d{\d R }-e^{-R^2(1+t^2)}\frac 1{1+t^2}dt\\
&= - \int_0^1 \frac \d{\d R}\frac {e^{-R^2(1+t^2)}}{1+t^2}dt \qquad \\ 
&=: - F'(R)\qquad  \text{(Leibnizsche Regel)}
%&\stackrel{\ref{13.19}}
\end{align*}
wobei
\begin{align*}
		F(R) = \int_0^1 \frac {e^{-R^2(1+t^2)}}{1+t^2}dt
\end{align*}
Also ist:
\[
G'(R) + F'(R) = 0
\]
und somit
\begin{align*}
G(R) + F(R) &= \underbrace{G(0)}_{0} + F(0) \\
&= \int_0^1 \frac 1{1+t^2} dt\\
&= \left.\arctan(t)\right|_0^1 = \frac \pi 4
\end{align*}
Es folgt:
\begin{align*}
G(R) = \frac \pi 4 - F(R) \to  \frac \pi 4 \qquad (R\to \infty)
\end{align*}
denn 
\begin{align*}
F(R) \le \int_0^1 e^{-R^2}dt = e^{-R^2} \to 0 \qquad (R\to \infty)
\end{align*}
Also  ist
\[
		\int_0^\infty e^{-x^2} = \sqrt{\frac \pi 4} = \frac {\sqrt{\pi}}2
\]
\end{proof}
\end{st}


\begin{note}[Übung/Knobelaufgabe:]

Betrachte den Abstand $r$ eines Punkts $(x,y)$ in der Ebene vom Ursprung und folgenden Ausdruck:
\[
\frac {\d r}{\d x}
\]
Es gilt:
\begin{align*}
r &=\sqrt{x^2+y^2}\\
\frac xr = \cos \phi
  \implies	   r &= \frac{x}{\cos\phi}
\end{align*}
Berechne:
\begin{alignat*}{3}
		\frac {\d r}{\d x} &= \frac {\d}{\d x} (x^2+y^2)^{\frac 12} = \frac 12 (x^2+y^2)^{-\frac 12}2x = \frac x{\sqrt{x^2+y^2}} =\frac xr &= \cos\phi
\intertext{aber aus $r=\frac x{\cos \phi}$ folgt}
\frac {\d r}{\d x} &= \frac{\d}{\d x} \frac x{\cos \phi}&= \frac 1{\cos \phi}
\end{alignat*}
Wo liegt der Fehler?
\end{note}

Für welche Vektorfelder $f:D\subset \R^n\to \R^n$ gibt es ein \emph{Potential} $\phi:D\to \R$ mit
\[
f= \nabla \phi
\]
?

Falls das gilt mit einer Funktion $\phi\in C^2(D)$, dann folgt aus dem Satz von Schwarz, dass
\[
d_if_k = \d_i\d_k\phi = \d_k\d_i \phi = \d_k f_i
\]
also die \emph{Integrabilitätsbedingung}:
\begin{equation}
\label{eq:intbed}
\d_if_k = \d_k f_i \qquad \forall i,k\in\{1,\dotsc,n\}
\end{equation}
Lokal sind diese Bedingungen auch hinreichend für die Existenz von $\phi$.

\begin{st}[Lemma von Poincare]
Sei $R>0$ und $f:B(a,R)\subset \R^n \to \R^n$ ein $C^1$-Vektorfeld auf der Kugel $B(a,R)$,
welches die Integrabilitätsbedingungen \eqref{eq:intbed} erfüllt.
Dann existiert $\phi\in C^2(B(a,R))$ mit 
\[
f=\nabla \phi
\]
\begin{proof}
Sei ohne Beschränkung der Allgemeinheit $a=0$ (sonst führt man entsprechende Verschiebung durch).
Sei
\[
\phi(x) = \int_0^1f(tx)\cdot xdt = \sum_{i=1}^n x_i\int_0^1 f_i(tx)dt
\]
Aus \ref{13.19} folgt, dass
\begin{align*}
\d_k\phi(x) &= \int_0^1f_k(tx)dt +\sum_{i=1}^nx_i \int_0^1 \frac{\d}{\d x_k} f_i(tx)dt \\
&= \int_0^1f_k(tx)dt + \sum_{i=1}^n x_i\int_0^1(\d_kf_i)(tx)t dt\\
&= \int_0^1f_k(tx)dt + \sum_{i=1}^n x_i\int_0^1(\d_if_k)(tx)t dt\\
&= \int_0^1\f{d}{dt} (f_k(tx)\cdot t) dt \qquad \text{(Umgekehrte Kettenregel)} \\
&= f_k(tx)t\Big|_{t=0}^{t=1} = f_k(x)
\end{align*}
\end{proof}
\end{st}



\chapter{Implizite Funktionen}

\section{Der Satz über die Umkehrabbildung}

\begin{st}[Kontraktionsprinzip (Banachscher Fixpunktsatz)]
\label{14.1}
Sei $M\subset \R^d$ \emph{abgeschlossen} und $f:M\to M$ mit
\[
|f(x)-f(y)| \le L|x-y|	\qquad x,y\in M
\]
wobei $L<1$.
Dann existiert genau ein Fixpunkt $x^*\in M$, der auf sich abgebildet wird, also mit:
\[
f(x^*) = x^*
\]
\begin{proof}
Aus
\[
f(x^*) = x^* \text{ und } f(y^*) = y^*
\]
folgt
\begin{align*}
|x^*-y^*| = |f(x^*)-f(y^*)| \le L|x^* - y^*|
\end{align*}
Wegen $L<1$ folgt, dass $|x^*-y^*|=0$, also
\[
x^*=y^*
\]
Damit ist die Eindeutigkeit bewiesen.
Zeige jetzt die Existenz:
Sei $x_0\in M$ fest und sei $(x_n)_{n\in \N_0}$ rekursiv definiert durch
\[
x_{n+1} := f(x_n)
\]
dann gilt
\begin{align*}
|x_{k+1}-x_k| &= |f(x_k)-f(x_{k-1}|\\
&\le L|x_k -x_{k-1}|\\
&\le \cdots \\
&\le L^k|x_1-x_0|
\end{align*}
Daraus folgt für $m>n$, dass
\begin{align*}
|x_m-x_n| &= \left| \sum_{k=n}^{m-1}(x_{k+1}-x_k)\right|\\
&\le \sum_{k=n}^{m-1}|x_{k+1}-x_k|\\
&\le \sum_{k=n}^{m-1}L^k|x_1-x_0|\\
&\le \left(\sum_{k=n}^{\infty}L^k\right)|x_1-x_0|\\
&= \frac {L^n}{1-L}|x_1-x_0| \to 0 \qquad (n\to \infty)
\end{align*}
Also ist $(x_n)$ eine Cauchy-Folge in $\R^d$.
Da $\R^d$ vollständig ist, existiert
\[
x^* = \lim_{k\to \infty}x_k
\]
Aus $x_k\in M$ und $\_{M}=M$ (Abgeschlossenheit von $M$) folgt, dass $x^*\in M$.
Da $f$ stetig ist, gilt
\[
f(x^*) = \lim_{k\to \infty}f(x_k) =\lim_{k\to \infty}x_{k+1} = x^*
\]
\end{proof}
\end{st}

\begin{ex*}
$M=[0,1]\in \R$, $f:M\to M$ differenzierbar mit
\[
\sup |f'(x)| <1
\]
Dann folgt aus
\[
|f(x)-f(y)| \stackrel{\text{MWS}}= |f'(\theta)(x-y)| \le L|x-y|
\]
FIXME: Zeichne Graph und Winkelhalbierende

\end{ex*}


\begin{st}
\label{14.2}
Sei $\GL(n,\R)\subset \Mat(n\times m,\R)$ die Teilmenge der invertierbaren, reellen, $n\times n$ Matrizen.
\begin{enumerate}[a)]
\item Falls $A\in \GL(n,\R)$, $B\in M(n\times n,\R)$ und $\|A-B\|<\|A^{-1}\|^{-1}$, dann ist
\[
	B\in \GL(n,\R)
\]
\item Die Abbildung $A\to A^{-1}$ von $\GL(n,\R)$ auf $\GL(n,\R)$ ist stetig.
\end{enumerate}
\begin{proof}
\begin{enumerate}[a)]
\item
\begin{align*}
B &= A+(B-A)\\
&= A(I + A^{-1}(B-A))
\end{align*}
wobei nach Annahme:
\[
\|A^{-1}(B-A)\| \le \|A^{-1}\|\cdot \|B-A\|<1
\]
Also ist $B$ nach \ref{7.17} invertierbar und
\begin{align*}
B^{-1}&= (E_n-A^{-1}(A-B))^{-1}A^{-1}\\
&=\sum_{k=0}^\infty (A^{-1}(A-B))^k A^{-1}
\end{align*}
Daraus folgt
\begin{align*}
\|B^{-1}\| &\le \sum_{k=0}^\infty \| (A^{-1}(A-B))^{k}A^{-1}\|\\
&\le \sum_{k=0}^\infty \|A-B\|^k\cdot \|A^{-1}\|^{k+1}\\
&= \frac {\|A^{-1}\|}{1-\|A^{-1}\|\cdot \|A-B\|}
\end{align*}

\item
Für $A,B\in \GL(n,\R)$ gilt
\begin{align*}
A^{-1}-B^{-1} &= A^{-1}(B-A)B^{-1}\\
\implies \|A^{-1}-B^{-1}\| &\le\|A^{-1}\|\cdot\|B-A\|\cdot \|B^{-1}\|\\
&\le \frac{\|A{-1}\|^2}{1-\|A^{-1}\|\cdot\|A-B\|}\cdot \|B-A\|\\
&\to 0 \qquad (B\to A)
\end{align*}
\end{enumerate}
\end{proof}
\end{st}


\begin{thm}[Der Satz über die Umkehrabbildung]
	\label{14.3}
Sei $D\subset \R^n$ offen und $f:D\to \R^n$ stetig differenzierbar.
Ist $a\in D$ ein Punkt wo $f'(a)$ invertierbar ist.
Dann existieren offene Umgebungen $U,V$ von $a$, bzw. $f(a)$, so dass
\begin{enumerate}
\item $f:U\to V$ bijektiv
\item $f^{-1}: V\to U$  ist stetig differenzierbar
\end{enumerate}
Insbesondere ist $f'(x)$ invertierbar für alle $x\in U$ und wenn $y=f(x)$, dann
\[
(f^{-1})'(x) = (f'(x))^{-1}
\]
\begin{proof}
Aus (i), (ii) folgt der letzte Teil:
\begin{align*}
f^{-1}(f(x))&=x
\implies (f^{-1})'f'(x) &= I
\implies (f^{-1})'(x) = (f'(x))^{-1}
\end{align*}
Beweise jetzt (i), (ii):

Sei $A=f'(a)$ und $\lambda := \frac 1{2\|A^{-1}\|}$.
Da $x\mapsto f'(x)$ stetig ist, existiert eine offene Kugel $U := B_R(a)$ so, dass
\begin{equation}
\label{14.3.1}
\|f'(x)-A\| < \lambda \qquad \forall x\in U
\end{equation}
Aus \ref{14.2} (mit $B=f'(x)$) folgt, dass $f'(x)$ invertierbar ist für alle $x\in U$.
Sei $V:=f(U)$ und zu $y\in \R^n$ sei $\phi_y : U \to \R^n$ mit:
\[
\phi_y(x) = x-A^{-1}(f(x)-y)
\]
Dann gilt
\[
\phi_y(x) = x \iff f(x) = y
\]
\begin{enumerate}[1)]

\item $f$ ist injektiv und somit bijektiv:\\

Für $x\in U$ gilt:
\begin{align*}
\phi_y'(x) = I -A^{-1}f'(x)
\end{align*}
und somit nach \eqref{14.1}:
\begin{align*}
\|\phi_y'(x)\| &= \|A^{-1}(A-f'(x))\|\\
&\le \underbrace{\|A^{-1}\|}_{=\frac 1{2\lambda}} \cdot \underbrace{\|A-f'(x)\|}_{< \lambda}\\
&< \frac 12
\end{align*}
Daraus folgt mit \ref{13.7}, dass für alle $x_1,x_2\in U$:
\begin{equation}
\label{14.3.2}
|\phi_y(x_1) - \phi_y(x_2)| \le \frac 12 |x_1-x_2|
\end{equation}
Die Abbildung $x\mapsto \phi_y(x)$ hat also höchstens einen Fixpunkt in $U$ und somit hat
$f(x)=y$ höchstens eine Lösung in $U$.

\item $V$ ist offen:\\

Sei $y_0=f(x_0)\in V$ und sei $r>0$ so klein, dass $\_{B(x_0,r)}\subset U$.
Wir zeigen, dass $B(y_0,\lambda r)\subset V$.
Sei $y\in B(y_0,\lambda v)$ fest.
Dann gilt für alle $x\in \_{B(x_0,r)}$ nach \eqref{14.3.2}, dass
\begin{align*}
|\phi_y(x) -x_0| &\le |\phi_y(x) - \phi_y(x_0)| + |\phi_y(x_0) -x_0|\\
&\stackrel{\eqref{14.3.2}}\le \frac 12 |x-x_0| + |A^{-1}(\underbrace{f(x_0)}_{=y_0}-y)|\\
&= \frac 12 \underbrace{|x-x_0|}_{\le r} + \underbrace{\|A^{-1}\|}_{\frac 1{2\lambda}} \cdot \underbrace{|y_0-y|}_{<\lambda r}\\
& < r
\end{align*}
D.h. $\phi_y(x)\in \_{B(x_0,r)}$ und somit
\[
\phi_y: \_{B(x_0,r)} \to \_{B(x_0,r)}
\]
Wegen \eqref{14.3.2} ist $\phi_y$ eine Kontraktion von $\_{B(x_0,r)}$ und hat somit genau einen Fixpunkt
\[
x\in \_{B(x_0,r)}
\]
Also gilt $f(x)=y$ und somit
\[
y\in f(\_{B(x_0,r)}\subset f(U) = V
\]

\item $g =f^{-1}:V\to U$ ist Lipschitz-stetig\\

Sei $x := g(y)$ und
\[
h := g(y+d) -g(y)
\]
Also ist $x+h=g(y+d))$
Dann gilt:
\begin{align*}
\phi_y(x+h) -\underbrace{\phi_y(x)}_{=x} &= x+h-A^{-1}(f(x+h)-y) -x\\
&= h - A^{-1} d
\end{align*}
Also
\begin{align*}
|h| &= |\phi_y(x+h) -\phi_y(x) +A^{-1}d| \\
&\le |\phi_y(x+h -\phi_y(x)| + \|A^{-1}\|\cdot |d|\\
&\le \f12 |h| + \|A^{-1}\|\cdot |d|\\
\end{align*}
Es folgt
\begin{equation}
\label{14.3.3}
|h| \le 2\|A^{-1}\| \cdot |d| = \f 1\lambda |d| \qquad \text{ nach \eqref{14.3.1}}
\end{equation}
Das heißt:
\[
|g(y+d)-g(y)| \le \f {|d|}\lambda
\]
also ist $g$ Lipschitz-stetig

\item $g'(y)=f'(x)^{-1}$ wenn $y=f(x)$\\

Sei $B:= f'(x)^{-1}$.
Dann
\begin{align*}
\underbrace{g(y+d)-g(y)}_{=h}-Bd &= h-B(f(x+h)-f(x))\\
&= B(f'(x)h-(f(x+h)-f(x)))\\
\end{align*}
Daraus folgt
\begin{align*}
\f 1{|d|} |g(y+d)-g(y)-Bd| &\le \f1{|d|} \|B\||f'(x)h-(f(x+h)-f(x))\\
&\stackrel{\eqref{14.3.3}} \le \frac 1\lambda \|B\| \f 1{|h|} |f'(x)h-(f(x+h)-f(x))|\\
&\to 0 \qquad (d\to 0)
\end{align*}
denn $h\to 0$ für $d\to 0$ nach \eqref{14.3.3}.

\item $y\mapsto (f^{-1})'(y)$ ist stetig.\\

Sei $x=g(y) = f^{-1}(y)$.
Dann ist
\[
g'(y) = f'(x)^{-1} = f'(g(y)){-1}
\]
Also ist $y\mapsto g'(y)$ die Verknüpfung der stetigen Abbildungen:
\[
y \stackrel{g}\mapsto g(y) \stackrel{f'}\mapsto f'(g(y)) \mapsto f'(g(y))^{-1}
\]
Also ist $y\mapsto g'(y)$ auch stetig.
Wir haben hier \eqref{14.2} benutzt, wonach das Invertieren einer Matrix stetig ist auf $\GL(n,\R)$.
\end{enumerate}
\end{proof}
\end{thm}


\begin{kor}
\label{14.4}
Ist $D\subset \R^n$ offen, $f:D\to \R^n$ stetig diffbar und $f'(x)$ invertierbar für alle $x\in D$.
Dann ist auch das Bild
\[
f(D)
\]
offen
\begin{proof}
FIXME: Übung!
(folgt aus \ref{14.3})
\end{proof}
\end{kor}


\begin{thm}
\label{14.5}
Ist $D\subset \R^n$ offen und $f:D\to \R^n$ von der Klasse $C^k$, $k\ge 1$ und $f'(a)$ invertierbar.
Dann existieren offene Umgebungen $U$ und $V$ von $a$, bzw. $f(a)$, so dass $f:U\to V$ ein $C^k$-Diffeomorphismus.

D.h. $f^{-1}$ ist ebenfalls von der Klasse $C^k$.
\begin{proof}
Beweise über Induktion in $k$.
Der Induktionsanfang für $k=1$ wurde durch $\ref{14.3}$ geleistet.
Sei die Behauptung richtig für ein festes $k\ge 1$.
Sei $f$ von der Klasse $C^{k+1}$.
Dann ist $f\in C^k$, also ist auch
\[
g=f^{-1}\in C^k
\]
nach Induktionsannahme und es gilt nach \ref{14.3}:
\[
g'(y) = f'(g(y))^{-1}
\]
D.h.
\begin{align*}
\d_ig_j(y) &= (g'(y))_{ji}\\
&= \frac 1{\det f'(g(y))} (-1)^{i+j}\det(f'(g(y))^{(i,j)})
\end{align*}
wobei $f'g(y))^{(i,j)}$ ein $n-1\times n-1$-Untermatrix von $f'(g(y))$ ist.
Wegen $f\in C^{k+1}$ und $g\in C^k$ ist die rechte Seite und somit auch die linke Seite
von obiger Gleichung von der Klasse $C^k$, also ist $g\in C^{k+1}$.
\end{proof}
\end{thm}


\begin{ex*}
$f:\R_+\times \R \to \R^2$ sei definiert durch
\[
f(r,\phi) = \begin{pmatrix}r\cos \phi \\ r\sin \phi\end{pmatrix}
\]
Dann ist $f$ von der Klasse $C^\infty$ und
\[
f'(r,\phi) = \begin{pmatrix} \cos \phi & -r\sin \phi \\ \sin\phi & r\cos\phi\end{pmatrix}
\]
Da
\[
\det(f'(r,\phi)) = r > 0
\]
ist $f'(r,\phi)$ invertierbar.
Nach Theorem \ref{14.5} ist $f$ lokal invertierbar und die Inverse ist auch von der Klasse $C^\infty$.
\end{ex*}


\section{Der Satz über implizite Funktionen}

Sei $f:D\subset \R^2 \to \R$ stetig differenzierbar und $f(a,b)=0$.
Wir wollen die Gleichung
\[
f(x,y) = 0
\]
in der Nähe von $(a,b)$ nach $y$ als Funktion von $x$ auflösen.
Genauer suchen wir eine differenzierbare Funktion $g:B_\epsilon(a) \to \R$ mit $g(a)=b$ und $f(x,g(x))=0$ für alle $x\in B_\epsilon (a)$.
Es folgt
\begin{align*}
0 &= \f \d{\d x} f(x,g(x)) \\
&= (\d_1f)(x,g(x)) +(\d_2f)(x,g(x) g'(x)
\end{align*}
Wenn $\d_2f(a,b)\neq 0$, dann auch $\d_2f(x,g(x)) \neq 0$ für $x$ nahe bei $0$ und es folgt
\[
g'(x) = -\f {\d_1f(x,g(x)}{\d_2f(x,g(x)}
\]

\begin{ex*}
Sei $f(x,y) = x^2+y^2 - 1$ (Lösungen für $f(x,y)=0$ auf dem Einheitskreis).
Wenn $\d_2f(a,b)\neq 0$ erwarten wir, dass $g(x)$ existiert.
\end{ex*}

Allgemeiner betrachten wir Systeme
\begin{align*}
f_1(x_1\dotsc x_n, y_1\dotsc y_m) &= 0\\
\vdots \qquad &= \vdots \\
f_m(x_1\dotsc x_n, y_1\dotsc y_m) &= 0
\end{align*}
in der Nähe einer Lösung $(a,b)\in \R^n\times \R^m$.
Für $x$ in der Nähe von $a$ wollen wir diese $m$ Gleichungen nach den $m$ Unbekannten $y_1,\dotsc, y_m$ auflösen.

Wir suchen also $y=g(x)$ mit $f(x,g(x))=0$ wobei
\[
f = \begin{pmatrix}f_1\\ \vdots \\ f_n\end{pmatrix}
\]
Notation:\\
Ist $f:D\subset \R^n \times \R^m \to \R^l$ differenzierbar, dann sind
$\d_mf(x,y) \in \Mat(l\times n,\R)$ und $d_2f(x,y) \in \Mat(l\times m,\R)$ die Matrizen bestehend aus den ersten $n$ bzw. den letzten $m$ Spalten von $f'(x,y)$.
Für $h=\left(\begin{smallmatrix}h_1\\ h_2\end{smallmatrix}\right)\in \R^{n+ m}$ gilt also 
\[
y'(x,y) h = f'(x,y)\begin{pmatrix}h_1\\ h_2\end{pmatrix} = \d_1f(x,y)h_1 + \d_2f(x,y)h_2
\]

\begin{thm}[Der Satz über die implizite Funktion]
	\label{14.6}
	Sei $D\subset \R^{n+m} = \R^n\times \R^m$ offen und $f:D\to \R^m$ eine $C^k$-Abbildung ($k\ge 1$).
	Falls $a\in \R^n, b\in \R^m$ existieren mit $f(a,b)=0$ und für die die $m\times m$ Matrix $d_2f(a,b)$ invertierbar ist, dann gibt es offene Umgebungen
	$U\in \R^n, V\in \R^m$ von $a$ bzw. $b$ und eine $C^k$-Abbildung $g:U\to V$ so, dass für $(x,y)\in U\times V$ gilt
	\[
		f(x,y) = 0 \iff y= g(x)
	\]
	\begin{proof}
		Sei $F: D\subset \R^n\times \R^m \to \R^n \times \R^m$ definiert durch:
		\[
			F(x,y) = \begin{pmatrix}x\\ f(x,y)\end{pmatrix}
		\]
		Dann ist $F$, wie $f$ eine $C^k$-Abbildung und für $h=(h_1,h_2)^T\in \R^n\times \R^m$ gilt
		\begin{align*}
			F'(a,b)h &= \f d{dt} \left.F(a+th_1, b+th_2)\right|_{t=0}\\
									   &= \f d{dt} \left.\begin{pmatrix}a+th_1\\ f(a+th_1,b+th_2)\end{pmatrix}\right|_{t=0}\\
									   &= \begin{pmatrix}h_1 \\ f'(a,b)h\end{pmatrix}\\
									   &= \begin{pmatrix}h_1\\ \d_1f(a,b)h_1 + \d_2f(a,b)h_2\end{pmatrix}
		\end{align*}
		Also gilt
		\[
			F'(a,b)h= 0
		\]
		\begin{align*}
			\implies h_1 &= 0\\
	\implies \d_f(a,b)h_2&= 0
		\end{align*}
		Also ist $h_2=0$ nach Annahme über $d_2f(a,b)$.
		Also ist $F'(a,b)$ invertierbar und somit ist nach \ref{14.5} $F:\tilde V\to \tilde U$ ein $C^k$-Diffeomorphismus von einer Umgebung $\tilde V\ni (a,b)$ auf eine Umgebung $\tilde U$ von $F(a,b)$.
		Nach Verkleinerung von $\tilde V$ und $\tilde U$ dürfen wir annehmen, dass $\tilde V=V_1\times V_2$, wobei $V_1\subset \R^n, V^2\in \R^m$ offen (siehe \ref{14.4}).
		D.h.
		\[
			F:V_1\times V_2 \to \tilde U
		\]
		ist ein $C^k$ Diffeomorphismus.
		Sei $G:\tilde U\to V_1\times V_2$ die Inverse $G=F^{-1}$ und sei
		\[
			G(x,y) = \begin{pmatrix}G_1(x,y)\\ G_2(x,y)\end{pmatrix}
		\]
		Dann gilt für $(x,y)\in \tilde U$
		\begin{align*}
			\begin{pmatrix}x\\y\end{pmatrix}=F(G(x,y)) = \begin{pmatrix} G_1(x,y)\\ f(G_2(x,y))\end{pmatrix}
		\end{align*}
		Also $G_1(x,y)=x$ und $G(x,y)=(x,G_2(x,y))^T$ und $y=f(x,G_2(x,y))$.
		
		Wir definieren jetzt
		\begin{align*}
			U &:= \{x\in \R^n| (x,0)\in \tilde  U\}
		\end{align*}
		und $g:U\to \R^m$ durch
		\[
			g(x)=G_2(x,0)
		\]
		Dann gilt $U\subset V_1$ und $f(x,g(x)) = 0$, denn aus $x\in U$ folgt $(x,0)\in \tilde U$ und somit $x=G_1(x,0)\in V_1$.
		Und außerdem
		\[
			f(x(g(x)) = f(x,G_2(x,0)) = 0
		\]
		Umgekehrt: wenn $(x,y)\in U\times V_2$ und 
		\[
			f(x,y)=0 = f(x,g(x))
		\]
		Also auch
		\[
			F(x,y) = \begin{pmatrix}x\\f(x,y))\end{pmatrix}=\begin{pmatrix}x\\ f(x,g(x))\end{pmatrix} = F(x,g(x))
		\]
		und somit $(x,y)=(x,g(y) \iff y=g$, da $F$ injektiv.

		Damit ist das Theorem bewiesen mit $V=V_2$.
	\end{proof}
	\begin{note}
		Die Jacobi-Matrix von $g$ bekommt man durch Differentiation von $0=f(x,g(x))$:
		Sei $\gamma(x) = (x,g(x))$, dann ist
		\begin{align*}
			0 &= (f\circ \gamma)'(x)h = f'(\gamma(x))\gamma'(x)h\\
			\gamma'(x) &= \f d{dt}(x+th,g(x+th))|_{t=0}\\
											&= (h,g'(x)h)\\
		\implies 0&= f'(\gamma(x))\begin{pmatrix}h\\ g'(x)h\end{pmatrix} \\
									   &= \d_1f(x,g(x))h +\d_2f(x,g(x))g'(x)h
		\end{align*}
		Also
		\begin{align*}
			\underbrace{\d_2f(x,g(x))}_{\text{invertierbar}}g'(x)h &= -\d_1f(x,g(x))\\
			\implies g'(x) &= -\d_2f(x,g(x))^{-1}\cdot\d_1f(x,g(x))
		\end{align*}
	\end{note}
\end{thm}



\begin{ex*}
	Das Gleichungssystem
	\begin{alignat*}{3}
	f_1(x,y_1,y_2) &= x^3 + y_1^3 + y_2^3 - 7 &= 0\\
	f_2(x,y_1,y_2) &= xy_1 +y_1y_2 + y_2x + 2 &= 0
	\end{alignat*}
	hat die Lösung $(2,-1,0)$ und
	\begin{align*}
	\d_yf(2,-1,0) = \left.\begin{pmatrix}3y_1^2 &3y_2^2 \\ x+y_2 & x+y_1\end{pmatrix}\right|_{(2,-1,0)}
	= \begin{pmatrix} 3 & 0\\ 2 & 1\end{pmatrix}
	\end{align*}
	ist invertierbar.
	Da $f\in C^\infty$ gibt es ein $\delta >0$ mit einer $C^\infty$-Abbildung $g: B_\delta(2) \to \R$:
	\[
	g: x\mapsto (g_1(x),g_2(x))
	\]
	so dass
	\[
	f(x,g(x)) = 0
	\]
	für alle $x\in B_\delta(2)$.

	Es folgt (siehe Herleitung oben):
	\[
	g'(x) = -\d_2f(x,g(x))^{-1}\cdot\d_1f(x,g(x))
	\]
	d.h.
	\[
	g'(2) = -\begin{pmatrix}3&0\\2&1\end{pmatrix} ^{-1}\d_x f(2,-1,0) = -\begin{pmatrix}\f13&0\\-\f23&1\end{pmatrix}\cdot \begin{pmatrix}12\\-1\end{pmatrix} = \begin{pmatrix}-4\\ 9\end{pmatrix}
	\]
\end{ex*}


\section{Niveaulinien}

Sei $D\subset \R^2$ und $f:D\to \R$ eine $C^k$-Funktion $(k\ge 1)$.
Sei $(a,b)$ ein Punkt von
\[
	N_C = \{(x,y)\in D|f(x,y)=C\} \qquad c\in \R
\]
Falls $\nabla f(a,b) \neq 0$, dann lässt sich $N_C$ in der Nähe von $(a,b)$ als Graph einer $C^k$-Funktion $x\mapsto g(x)$ ($\d_2f(a,b)\neq 0$) oder einer $C^k$-Funktion $y\mapsto h(y)$ ($\d_1f(a,b)\neq0$) darstellen.
\begin{proof}
	Wende \ref{14.6} an auf $f-c)$
\end{proof}

\begin{ex*}[Pendel!]
	$f(x,y) = \f 12y^2 -cos(x)$
	FIXME: Zeichne
	\[
		\nabla f = \begin{pmatrix}y\\ \sin x\end{pmatrix}
	\]
\end{ex*}

\begin{ex*}[Störungstheorie für Eigenwerte]
	Sei $D\subset \R^d$ offen und für jedes $x\in D$ sei $A(x)$ eine symmetrische $n\times n$ Matrix deren Koeffizienten $A_{ij}(x)$ $C^k$-Fuktionen von $x\in D$ sind.
	Sei $\lambda_0$ eine \emph{einfacher} Eigenwert von $A(x_0)$.
	Dann gibt es für $x$ in der Nähe von $x_0$ genau einen Eigenwert $\lambda(x)$ in der Nähe von $\lambda_0$ und $x\mapsto \lambda(x)$ ist eine $C^k$-Funktion.
	\begin{proof}
		Sei $p(x,\lambda) = \det(\lambda-A(x))$ das charakteristische Polynom von $A(x)$.
		$p\in C^k(D\times \R)$ und
		\[
			p(x_0,\lambda) = \prod_{i=0}^n(\lambda-\lambda_i)
		\]
		wobei $\lambda_0\neq \lambda_k$ für $k=1,\dotsc,n-1$.

		Die Eigenwerte von $A(x)$ sind die Lösungen von
		\begin{equation}
			\label{ex:ew1}
			p(x,\lambda) = 0
		\end{equation}
		wobei
		\begin{align*}
			\f \d{\d\lambda}p(x_0,\lambda)|_{\lambda=\lambda_0} = (\lambda_0-\lambda_1)\dotsb (\lambda_0-\lambda_{n-1}) \neq 0
		\end{align*}
		Also existiert nach \ref{14.6} eine Umgebung $U$ von $x_0$ und eine Umgebung $V$ von $\lambda_0$, so dass die Lösungen von \eqref{ex:ew1} durch den Graphen einer $C^k$-Abbildung $\lambda:U\to V$ gegeben ist.
	\end{proof}
\end{ex*}


\section{Untermannigfaltigkeiten}


Eine nichtleere Teilmenge $M\subset \R^n$ heißt \emph{$k$-dimensionale Fläche} oder \emph{$k$-dimensionale Untermannigfaltigkeit} von $\R^n$, falls zu jedem Punkt $p\in M$ eine offene Umgebung $U\subset \R^n$ und ein Diffeomorphismus
\[
	\phi:U\to V\subset \R^n
\]
existiert, so das
\[
	\phi(M\cap U) = (\R^k\times\{0\})\cap V \qquad 0\in \R^{n-k}
\]
Die Abbildung $\phi$ heißt \emph{äußere Karte} von $M$ um $p$ oder \emph{Flachmacher}.
Die Zahl $n-k$ heißt \emph{Kodimension} von $M$.
Im Fall $n-k=1$ spricht man von einer \emph{Hyperfläche}.

Hier und im Folgenden ist mit Diffeomorphismus ein $C^1$-Diffeomorphismus gemeint.

\begin{ex*}
	\begin{enumerate}
		\item
			Die $n$-dimensionalen Untermannigfaltigkeiten des $R^n$ sind genau die offenen Teilmengen des $\R^n$.
			Dde $0$-dimensionalen Untermannigfaltigkeiten des $R^n$ sind die Teilmengen bestehend aus isolierten Punkten.
		\item
			Jeder $k$-dimensionale Untervektorraum von $R^n$ ist eine $k$-dimensionale Untermannigfaltigkeit.
		\item
			Der Graph einer $C^1$-Abbildung $f:D\subset \R^k \to \R^m$ ist eine $k$-dimensionale Untermannigfaltigkeit von $\R^{m+k}$.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}
			\item
				Sei $M\subset \R^n$ offen und $p\in M$.
				Wir wählen $U=V=1$ und $\phi(x)=x$ für $x\in U$.
				Das ist ein Flachmacher.
				Sei $M\subset \R^n$ eine Untermannigfaltigkeit, $p\in M$ und $\phi:U\to V$ ein Flachmacher.
				Dann ist
				\[
					\phi(U\cap M) = \R^n \cap V = V = \phi(U)
				\]
				Also $U\cap M= U$ und $U\subset M$.
				Also ist $M$ offen.
			\item
			\item
				Sei $p\in \Gamma(f)$ und $U=D\times \R^m$ und
				\[
					\phi(x,y) = (x,f(x)-y)
				\]
				Das ist eine $C^k$-Abbildung mit Inverse
				\[
					\phi^{-1}(x,y) = (x,f(x)+y)
				\]
				$\phi^{-1}$ ist ein Flachmacher für jeden Punkt $p\in M=\Gamma(f)$.
		\end{enumerate}
	\end{proof}
\end{ex*}

\begin{lem}
	\label{14.8}
	Eine nicht-leere Teilmengee $M\subset \R^n$ ist genau dann eine $k$-dimensionale Untermannigfaltigkeit, wenn es zu jedem Punkt $p\in M$ eine offen Umgebung $U_p \subset \R^n$ so gibt, dass $M \cap U_p$ eine $k$-dimensionale Untermannigfaltigkeit ist.
	\begin{proof}
		FIXME: Übung
	\end{proof}
\end{lem}

ist $M\subset \R^n$ eine $k$-dimensionale Untermannigfaltigkeit in $\R^n$ und $\phi: U \to V$ eine äußere Karte von $M$ um $p$, also 
\[
	p(M\cap U) = (\R^k\times\{0\}) \cap V
\]
dann sind die Punkte $x\in U$, welche in $M$ liegen genau die Lösungen der $n-k$ Gleichungen
\begin{align*}
	\phi_i(x) = 0 \qquad i= k+1,\dotsc, n
\end{align*}
Außerdem sind $\phi_{k+1}'(p), \dotsc, \phi_n'(p)$ linear unabhängig (denn $\phi'(p)$ ist invertierbar).

\begin{thm}
	\label{14.9}
	Eine nichtleere Teilmenge $M\subset \R^n$ ist genau dann eine $k$-dimensionale Untermannigfaltigkeit, wenn es zu jedem Punkt $p\in M$ eine offene Umgebung $U\subset \R^n$ gibt, sowie $n-k$ $C^1$-Funktionen $f_1,\dotsc, f_{n-k}:U\to \R$, so dass
	\begin{enumerate}[(i)]
		\item
			$M\cap U = \{ x\in U | f_1(x) = \dotsb = f_{n-k}(x) = 0\}$
		\item
			$f_1'(p),\dotsc, f_{n-k}'(p)$ sind linear unabhängig
	\end{enumerate}
	\begin{proof}
		Sei $f(x) = (f_1(x), \dotsc, f_{n-k}(x))^T$.
		Nach Annahme hat $f'(p)$ den Rang $n-k$, also $n-k$ linear unabhängige Spalten.
		Nach einer Permutation der Koordinaten $x_1,\dotsc, x_n$, können wir annehmen, dass die letzten $n-k$ Spalten von $f'(p)$ linear unabhängig sind.
		Die quadratische Matrix $(\d_jf_i(p))$ mit $j=k+1,\dotsc$ und $i=1,\dotsc,n-k$ ist somit invertierbar.
		Nach dem Satz über implizite Funktionen gibt es eine Umgebung $U_0\subset U$ von $p$ so, dass
		\[
			\{x\in U_0 | f_1(x) = \dotsb = f_{n-k}(x) = 0\} = (M\cap U) \cap U_0 = M\cap U_0
		\]
		der Graph einer $C^1$-Funktion $g: \R^k\supset W \to \R^{n-k}$.
		($x\in M\cap U_0 \iff (x_{k+1} \dotsb x_n)^T = g(x_1,\dotsc, x_k)$).

		Also ist $M\cap U_0$ nach \ref{14.3} eine $k$-dimensionale Untermannigfaltigkeit.
		Nach \ref{14.8} ist also $M$ eine $k$-dimensionale Untermannigfaltigkeit.
	\end{proof}
\end{thm}

\begin{df*}
	Sei $f:D\subset \R^n \to \R^m$ eine $C^1$-Abbildung, $D\subset \R^n$ offen und $n\ge m$.
	Ein Punkt $x\in D$ heißt \emph{regulärer Punkt} von $f$, wenn $df(x) :\R^n\to \R^m$ surjektiv ist.
	D.h. die Jacobi-Matrix $f'(x)$ hat maximalen Rang.

	Ein Punkt $a\in \R^m$ heißt \emph{regulärer Wert} von $f$, wenn $f^{-1}(\{a\}) = \{x\in D| f(x) = a \}$ nur aus regulären Punkten besteht (oder leer ist).
	
	\begin{note}
		Die Menge der regulären Punkte von $f$ ist offen.
		\begin{proof}
			FIXME: Übung
		\end{proof}
	\end{note}
\end{df*}

\begin{thm}[Satz vom regulären Wert]
	\label{14.10}
	Sei $D\subset \R^n$ offen, $f:D\to \R^m$ von der Klasse $C^1$ und $a\in R^m$ ein regulärer Wert von $f$.
	Dann ist
	\[
		M = \{ x\in D| f(x) =a\} = f^{-1}(\{a\})
	\]
	eine $n-m$-dimensionale Untermannigfaltigkeit von $R^n$ (oder leer). 
	\begin{proof}
		Für jeden Punkt $p$ sei $U=D$ und $g_i : U\to \R$ sei definiert durch
		\[
			g_i(x) = f_i(x) - a_i \qquad i=1,\dotsc,m
		\]
		Dann gilt 
		\[
			M\cap U = \{ x\in U|g_i(x) = 0, i=1,\dotsc, n\}
		\]
		und $g_i'(p) = f_i'(p)$.
		D.h. $g_1'(p), \dotsc, g_m'(p)$ sind die $m$ Zeilen von $f'(p)$ und somit linear unabhängig.
		Nach \ref{14.9} ist $M$ eine $n-m$-dimensionale Untermannigfaltigkeit.
	\end{proof}
\end{thm}


\begin{ex*}
	\begin{enumerate}[1)]
		\item
			Die Sphäre (Hyperfläche)
			\[
				S^{n-1} := \{x\in \R^n | |x| = 1\}
			\]
			ist eine $n-1$-dimensionale Untermannigfaltigkeit von $R^n$.
			\begin{proof}
				Sei $f:\R^n\setminus\{0\} \to \R$ die Funktion $f(x)=|x| = \sqrt{\sum_{k=1}^nx_k^2}$.
				Dann ist $f$ von der Klasse $C^1$ und
				\[
					\R^n \ni \nabla f(x) = \f x{|x|} \neq 0
				\]
				D.h. $f'(x)$ hat Rang 1.
				Also ist $1$ ein regulärer Wert von $f$ und somit $S^{n-1}$ eine $n-1$-dimensionale Untermannigfaltigkeit.
			\end{proof}
		\item
			Die orthogonale Gruppe 
			\[
				O(n) =\{A\in \Mat(n,\R) | A^TA = I_n\}
			\]
			ist eine Untermannigfaltigkeit von $\Mat(n,\R) \isomorph \R^{n\times n}$ der Dimension $\f 12 n(n-1)$.
			\begin{proof}
				Wir zeigen, dass $I_n$ ein regulärer Wert der Abbildung $f:\Mat(n,\R) \to S(n) := \{B\in M(n,\R)|B^T=B\}$:
				\[
					f(A) = A^TA
				\]
				ist.
				D.h. wir zeigen, dass $f$ eine $C^1$-Abbildung ist und dass $df(A)$ surjektiv ist für $A\in O(n)$.
				Für $H=\Mat(n,\R)$.
				\begin{align*}
					df(A)H &= \f d{dt} f(A+tH)\Big|_{t=0}\\
									   &= \f d{dt} (A+tH)^T(A+tH)\Big|_{t=0}\\
									   &=\f d{dt} A^T A + t(H^TA + A^TH) + t^2H^TH\Big|_{t=0}\\
						   &= H^TA + A^TH
				\end{align*}
				Sei $B\in S(n)$ gegeben und
				\[
					H := \frac 12 AB
				\]
				Dann gilt
				\[
					df(A)H = \f 12 (B^T + B) = B
				\]
				denn $A^TA = I_n$.

				Die Dimension von $S(n)$ ist $\f 12 n(n+1)$ (Vektorraum der symmetrischen Matrizen).
				Also ist
				\[
					\dim(O(n)) = n^2 - \frac 12n(n+1) = \frac 12 n(n-1)
				\]
			\end{proof}
	\end{enumerate}
\end{ex*}


\section{Der Tangentialraum}

\begin{df*}		
	Sei $M\subset \R^n$ eine $k$-dimensionale Untermannigfaltigkeit und $p\in M$.
	Ein Vektor $v\in \R^n$ heißt \emph{Tangentialvektor} an $M$ im Punkt $p$, wenn es eine $C^1$-Kurve $\gamma: (-\epsilon, \epsilon) \to M$ gibt mit
	\[
		\gamma(0) = p \quad \text{und} \quad \dot\gamma(0) = v
	\]
	Die Menge $T_pM$ aller Tangentialvektoren an $M$ in $p$ heißt \emph{Tangentialraum} von $M$ im Punkt $p$.
\end{df*}

\begin{note}
	Wir stellen uns die Tangentialvektoren $v\in T_pM$ im Punkt $p\in M$ „festgemacht“ vor.
	Diese Vorstellung kann man formalisieren indem man die Paare $(p,v)$ als Tangentialvektoren bezeichnet.
\end{note}

\begin{st}
	\label{14.10}
	Sei $M\subset\R^n$ eine $k$-dimensionale Untermannigfaltigkeit und $p\in M$.
	Für jede äußere Karte $\phi: U\to V$ von $M$ um $p$ gilt
	\[
		T_pM = d\phi^{-1}(q)(\R^k\times\{0\}) \qquad q := \phi(p)
	\]
	insbesondere ist $T_pM$ ein Vektorraum der Dimension $k$.
	\begin{proof}
		Zeige „$\supset$“.
		Sei $w\in \R^k\times\{0\}$, d.h. $w=(w_1,\dotsc, w_k, 0,\dotsc, 0)^T$.
		Sei $\sigma(t) = q+tw$ für $t\in (-\epsilon, \epsilon)$ mit $\epsilon > 0$ so klein, dass $\sigma(t) \in V$ für alle $|t| < \epsilon$ (möglich, da $V$ offen ist).
		Sei $\gamma(t) = \phi^{-1}(\sigma(t))$ für $t\in (-\epsilon,\epsilon)$.
		Dann ist
		\begin{align*}
			\gamma(0) = \phi^{-1}(\sigma(0)) = p
		\end{align*}
		Somit ist $\dot\gamma(0) \in T_pM$.
		Außerdem gilt
		\begin{align*}
			\dot\gamma(0) = \f\d{dt}\phi^{-1}(\sigma(t))\Big|_{t=0} = d(\phi^{-1})(\sigma(0))\cdot \dot \sigma(0) = d(\phi^{-1})(q)w
		\end{align*}
		D.h. $d\phi^{-1}(q)w\in T_pM$.

		Zeige jetzt „$\subset$“.
		Sei $v\in T_pM$, d.h. $v=\dot \gamma (0)$, wobei $\gamma : (-\epsilon,\epsilon)\to M$ eine $C^1$-Kurve ist mit $\gamma(0) = p$.
		Sei $\sigma(t) := \phi(\gamma(t)) \subset (\R^k\times\{0\})\cap V$, dabei sei ohne Beschränkung der Allgemeinheit $\gamma(t)\in U, |t|<\epsilon$.
		Sei $w:= \dot \sigma(0) \in \R^k\times\{0\}$.
		Es gilt dann $\gamma(t) = \phi^{-1}(\phi(\gamma(t))) = \phi^{-1}(\sigma(t))$ und für die Ableitung:
		\begin{align*}
			v = \dot\gamma(0) &= \f d{dt}\phi^{-1}(\sigma(t))\Big|_{t=0}\\
																		   &= d\phi^{-1}(\sigma(0))\dot\sigma(0)\\
															   &= d\phi^{-1}w
		\end{align*}
	\end{proof}
\end{st}


\begin{st}
	\label{14.11}
	Sei $f: D\subset \R^n \to \R^m$ eine $C^1$-Abbildung und $a\in \R^m$ ein regulärer Wert von $f$ und $M=f^{-1}(\{a\}) \neq \emptyset$.
	Dann gilt für alle $p\in M$
	\begin{enumerate}[(i)]
		\item
			$T_pM = \ker(df(p))$
		\item
			$(T_pM)^\orth = \langle \nabla f_1(p), \dotsc, \nabla f_m(p)\rangle$
	\end{enumerate}
	\begin{note}
		(ii) besagt insbesondere, dass
		\[
			\nabla f_1(p), \dotsc, \nabla f_m(p) \orth T_pM
		\]
		mit anderen Worten: $\nabla f_1, \dotsc, \nabla f_m$ stehen senkrecht auf den Nivaeuflächen von $f$.
		Im Fall $m=1$ kommt uns das sehr bekannt vor.
	\end{note}
	\begin{proof}
		\begin{enumerate}[(i)]
			\item
				Sei $v\in T_pM$, d.h. $v=\dot\gamma(0)$, wobei $\gamma:(-\epsilon,\epsilon) \to M$ $C^1$-Kurve mit $\gamma(0)=p$.
				Dann ist $f(\gamma(t))=a$ für alle $f\in (-\epsilon,\epsilon)$.
				Also
				\begin{align*}
					0 &= \f d{dt} f(\gamma(t))\Big|_{t=0} \\
					  &= df(\gamma(0))\dot\gamma(0) \\
					  &= df(p)
				\end{align*}a
				D.h. $v\in \ker df(p)$ und somit $T_pM \subset \ker(df(p))$.
				
				Wegen $\dim T_pM = n-m$ und $\dim(\ker df(p)) = n - \dim(\im df(p)) = n- m$ (da $p$ ein regulärer Punkt von $f$).
				Wegen $T_pM \subset \ker df(p)$ und $\dim T_pM = \dim(\ker df(p))$ folgt
				\[
					T_pM = \ker df(p)
				\].
			\item
				Es ist
				\[
				df(p)w = f'(p)w = \begin{pmatrix}f_1'(p)\\\vdots\\ f_m'(p)\end{pmatrix}w = \begin{pmatrix}\nabla f_1(p)w\\ \vdots\\ \nabla f_m(p)w\end{pmatrix}
				\]
				d.h.
				\[
					\ker df(p) = \{w\in \R^n| w \orth \nabla f_k(p), k=1,\dotsc,m\} = \langle \nabla f_1(p),\dotsc, \nabla f_m(p)\rangle^\orth
				\]
				Also
				\[
					\ker df(p)^\orth = \langle \nabla f_1(p),\dotsc, \nabla f_m(p)\rangle
				\]
				Damit folgt (ii) aus (i).
		\end{enumerate}
	\end{proof}
\end{st}


\begin{ex*}
	Sei
	\begin{align*}
		f_1(x,y,z) &= x^2 +y^2\\
		f_2(x,y,z) &= \f y2 + z
	\end{align*}
	und
	\[
		M=\{ u\in\R^3 | f_1(u) = 1 = f_2(u)\}
	\]
	FIXME: Zeichne Kreiszylinder
\end{ex*}


\section{Extrema unter Nebenbedingungen}


Seien $f,\phi_1,\dotsc, \phi_m : \R^n \supset D \to \R$ und $a_1,\dotsc,a_m\in \R$ gegeben und sei
\[
	D \supset M = \{x\in D| \phi_1(x) = a_1, \dotsc, \phi_m(x) = a_m\}
\]
Wir interessieren uns für das Verhalten von $f$ auf $M$ und insbesondere für die Punkte $x_0\in M$, wo $f\big|_M$ lokal extremal ist, d.h. wo
\begin{align*}
	f(x) \le f(x_0)\quad \text{oder}\quad f(x) \ge f(x_0)\qquad \forall x\in M\cap B_\epsilon(x_0)
\end{align*}
wobei $\epsilon > 0$.
Man sagt dann $f$ sei \emph{bedingt lokal extremal} oder lokal extremal bezüglich den Nebenbedingungen $\phi_1 = a_1, \dotsc, \phi_m=a_m$.
Der Punkt $x_0$ heißt \emph{lokaler} Extremalpunkt von $f$ unter den Nebenbedingungen $\phi_1=a_1,\dotsc, \phi_m=a_m$.

\begin{ex*}
	Sei $m=1$.
	Gegeben $M = \{x:\phi(x)=0\}$.
	Die $\nabla \phi(x)$ stehen immer senkrecht zu $M$.
	\fixme
\end{ex*}

\begin{thm}
	\label{14.12}
	Sei $f:D\subset \R^n \to \R$ differenzierbar und seien $\phi_1,\dotsc, \phi_m\in C^1(D)$.
	Ist $f$ im Punkt $x_0\in D$ bedingt lokal extremal unter den Nebenbedingungen $\phi_1 = a_1, \dotsc, \phi_m = a_m$ und sind $\nabla \phi_1(x_0),\dotsc, \nabla \phi_m(x_0)$ linear unabhängig.
	Dann existieren $\lambda_1,\dotsc, \lambda_m\in \R$ so, dass
	\[
		\nabla f(x_0) = \sum_{k=1}^m\lambda_k\nabla \phi_k(x_0)
	\]
	\begin{proof}
		Sei $\phi=(\phi_1,\dotsc, \phi_m)^T: D \subset\R^n\to \R^m$ und $a=(a_1,\dotsc, a_m)^T\in \R^m$ und $M=\{x\in D| \phi(x)=a\}$.
		\begin{enumerate}[{Schritt} 1]
			\item
				Es gibt eine Umgebung $U\subset \R^n$ von $x_0$ so, dass $M=\{x\in U| \phi(x)=0\}$ eine $(n-1)$-dimensionale Untermannigfaltigkeit von $\R^n$ ist.
				\begin{proof}
					Seien $v_{m+1}, \dotsc, v_n \in \R^n$ so gewält, dass
					\[
						\{\nabla\phi_1(x_0), \dotsc, \nabla\phi_n(x_0), v_{m+1}, \dotsc, v_n\}
					\]
					eine Basis ist von $\R^n$.
					Sei
					\[
						\delta(x) := \det(\nabla\phi_1(x),\dotsc, \nabla\phi(x),v_{m+1},\dotsc, v_n)
					\]
					Dann $\delta(x_0) \neq 0$ und $x\mapsto \delta(x)$ ist stetig, also existiert eine Umgebung $U =B_\epsilon(x_0)$, so dass $\delta(x)\neq 0$ für alle $x\in U$.
					Es folgt, dass $\nabla\phi_1(x),\dotsc, \nabla(\phi_m(x)$ linear unabhängig sind für alle $x\in U$.
					Somit sind alle $x\in U$ reguläre Punkte von $\phi : U\to \R^n$ (denn $d\phi(x):\R^n\to \R^m)$.
					Somit ist $a$ ein regulärer Wert von $\phi\big|_U$.
					Also ist 
					\[
						M_0 := \{x\in U|\phi(x)=a\} = (\phi\big|_U)^{-1}(\{a\})
					\]
					eine Untermannigfaltigkeit von $\R^n$.
				\end{proof}
			\item
				\begin{proof}
					Sei $v\in T_{x_0}M$, zeige: $\<v,\nabla f(x_0)\>=0$.
					Sei $\gamma:(-\epsilon,\epsilon)\to T_{x_0}M_0$ mit $\gamma(0) =x_0$ und $\dot\gamma(0) = v$.
					Da $f$ in $x_0$ lokal extremal ist, ist die $t\mapsto f(\gamma(t))$ in $t=0$ lokal extremal.
					Also
					\begin{align*}
						0 = \f d{dt}f(\gamma(t))\big|_{t=0} = \nabla f(\gamma(0))\dot \gamma(0) =\<\nabla f(x_0),v\>
					\end{align*}
				\end{proof}
		\end{enumerate}
	Nach Schritt 2 ist $\nabla f(x_0) \in (T_{x_0}M_0)^\orth = \< \nabla\phi_1(x_0),\dotsc, \nabla\phi_m(x_0)\>$ (\ref{14.11} (ii)).
		Also $\exists \lambda_1,\dotsc, \lambda_m$, sodass
		\[
			\nabla f(x_0) = \sum_{k=1}^m\lambda_k\nabla\phi_k(x_0)
		\]
	\end{proof}
\end{thm}

\begin{note}
	Gemäß dem Theorem sind die Punkte, wo $f$ bedingt lokal extremal ist zu suchen unter den Lösungen von
	\begin{align*}
		\nabla f(x) - \sum_{k=1}^m\lambda_k\nabla\phi_k(x) &= 0\\
		\phi_k(x) - a_k &= 0 \qquad k=1,\dotsc, m
	\end{align*}
	Das sind $(n+m)$ Gleichungen für die $(n+m)$ Unbekannten $x_1,\dotsc, x_n,\lambda_1,\dotsc, \lambda_m$.
	Die Werte der sogentannten \emph{Lagrange Multiplikatoren} $\lambda_1,\dotsc, \lambda_m$ sind in der Regel nicht von Interesse.

	Ist $(x_0,\lambda_1,\dotsc, \lambda_m)$ eine Lösung des Gleichungssystem, dann heißt $x_0$ ein \emph{bedingt kritischer Punkt} von $f$.
	Nach \ref{14.12} ist $f$ in $x_0$ bedingt lokal extremal, dann ist $x_0$ ein bedingt kritischer Punkt.
	Die Umkehrung dieser Aussage gilt nicht!

	(Analog zu herkömmlichen Extrema im Eindimensionalen: $f'(x)\stackrel !=0$ bedingt einen kritischen Punkt, aber ein Extrema muss nicht vorliegen, z.B. bei $f''(x)=0$.
	Liegt jedoch ein Extrema vor, so ist in jedem Fall $f'(x)=0$.)
\end{note}

\begin{note}
	Manchmal ist es nützlich die Funktion 
	\[
		F(x) := f(x) - \sum_{k=1}^m\lambda_k\phi_k(x)
	\]
	einzuführen.
	Dann ist das Gleichungssystem äquivalent zu
	\begin{align*}
		\nabla F(x) &= 0\\
		\phi_k(x) &= a_k\qquad k=1,\dotsc,m\\
	\end{align*}
\end{note}

\begin{ex*}	
	Wir bestimmen Maximum und Minimum von 
	\[
		f(x,y) = x^2+y^2 -8x-6y = (x-y)^2 + (y-3)^2 - 25
	\]
	unter der Nebenbedingung $x^2+y^2 = 100$ (Kreis mit Radius $10$).
	
	$f$ ist stetig und $M =\{(x,y)	| x^2+y^2=100\}$ ist kompakt, also nimmt $f$ auf $M$ Maximum und Minimum an (nach \ref{8.11}).
	Sei $\phi(x,y) = x^2+y^2$ und
	\[
		F(x,y) := f(x,y) -\lambda\phi(x,y) = x^2(1-\lambda) + y^2(1-\lambda) - 8x-6y
	\]
	Die bedingten Extremalstellen von $f\big|_M$ erfüllen nach \ref{14.12} die Gleichungen
	\begin{align*}
		0 &= \d_x F = 2x(1-\lambda) -8\\
		0 &= \d_y F = 2y(1-\lambda) -6\\
		100 &= x^2+y^2
	\end{align*}
	Also
	\[
		\f xy = \f 86
	\]
	Dan $8^2+t^2 = 100$ haben wir die bedingt kritischen Punkte $\pm (8,6)$.
	\begin{align*}
		f(8,6) &= 0 \qquad \text{absolutes Minimum}\\
		f(-8,-6) &= 200 \qquad \text{absolutes Maximum}
	\end{align*}
\end{ex*}

\begin{ex*}
	Sei $f(x,y) = x^2+y^2-8x-6y$ (wie oben) und sei $K\subset \R^2$  definiert durch die Figur:
	\begin{align*}
		x^2 + y^2 &= 100\\
		\fixme
	\end{align*}
	Bestimme $\min_{x\in K}f(x)$ und $\max_{x\in K}f(x)$.

	\underline{Vorgehen:}
	\begin{enumerate}[1)]
		\item
			Bestimme die kritischen Punkte von $f$ in $\mathring{K}$
		\item
			Bestimme die bedingt kritischen Punkte von $f$ auf den Untermannigfaltigkeiten, welche zusammen den Rand $\d K$ bilden.
		\item
			Berechne $f$ in allen kritischen Punkten aus 1) und 2) und bestimme den kleinsten und den größten Wert.
	\end{enumerate}

	In $\mathring K$ hat $f$ den kritischen Punkt $P_1=(4,3)$.
	Auf $\kappa_1$ gibt es den bedingt kritischen Punkt $P_2=(8,6)$ (nach vorigem Beispiel).
	Auf $\kappa_2$ gibt es keine bedingt kritischen Punkte (Übung).
	Auf $\kappa_3$ ist $x=0$ und $y\in (-10,5)$ wobei $f(0,y) = y^2 -6y$ bei $y=3\in (-10,5)$ das Minimum hat.
	Damit ist $P_3=(0,3)$ der einzige bedingt kritische Punkt auf $\kappa_3$.
	Also (mit „Eckpunkte“ $P_4, P_5, P_6$
	\begin{align*}
		\max_{x\in K} f(x) &= \max\{f(P_1),\dotsc,f(P_6\} = f(P_5) = 180\\
		\min_{x\in K} f(x) &= \min\{f(P_1), \dotsc, f(P_6)\} = f(P_1) = -25
	\end{align*}
\end{ex*}

\begin{ex*}
	Sei $A$ eine reelle, symmetrische $n\times n$-Matrix und sei $f:\R^n\to \R$ die quadratische form $f(x) = \<x,Ax\>$.
	Wir bestimmen die bedingt kritischen Punkte von $f$ unter der Nebenbedingung $|x| = 1$.
	Sei
	\[
		F(x) = f(x) -\lambda |x|^2 = \<x,Ax\> - \lambda \<x,x\>
	\]
	Dann ist
	\[
		\nabla F(x) = 2Ax - 2\lambda x
	\]
	Also ist $x\in \R^n$ genau dann ein bedingt kritischer Punkt von $f$, wenn
	\begin{align*}
		Ax &= \lambda x\\
		|x| &= 1
	\end{align*}
	d.h. die normierten Eigenvektoren von $A$ und $\lambda$ ist der zugehörige Eigenwert.
	Da $S^{n-1} =\{ x\in \R^n\big| |x| = 1\}$ kompakt und $f$ stetig ist, nimmt $f\big|_{S^{n-1}}$ das Maximum und das Minimum an und
	\begin{align*}
		\min_{|x|=1}f(x) &= \text{kleinster Eigenwert von $A$}\\
		\max_{|x|=1}f(x) &= \text{größter Eigenwert von $A$}
	\end{align*}
	denn aus $Ax =\lambda x$, $|x|=1$ folgt dass
	\[
		\<x,Ax\> =\lambda \<x,x\> = \lambda
	\]
\end{ex*}


\chapter{Maß- und Integrationstheorie}


\section{Einleitung}


Wir wollen das Konzept des Integrals $\int_a^bf(x)dx$ verallgemeinern auf Funktionen $f:D\subset \R^n \to \R$.
Linearität, etc. soll erhalten bleiben.
Wenn $f\ge 0$, dann soll $\int fd^nx$ die Interpretation eines Volumens unterhalb dem Graphen von $f$ haben.
Insbesondere
\begin{align*}
\tag{15.1}
	\int x_\Omega a^nx &= \text{Fläche($\Omega$)}\cdot 1 \qquad n=2\\
															  &= \text{Volumen($\Omega$)}\cdot 1 \qquad n=3
\end{align*}

D.h. wir brauchen ein \emph{Maß} $\my$, welches möglichst vielen Mengen $\Omega\in \R^n$ ein $n$-dimensionales Volumen $\my(\Omega)$ zuordnet.

Natürlich soll für
\[
	\Omega = \{ x\in \R^n : a_i \le x \le b_i\}
\]
gelten
\[
	\my(\Omega) = \prod_{i=1}^n (b_i-a_i)
\]
weiter soll 
\[
	\my(\Omega') = \my(\Omega)
\]
wenn $\Omega'$ und $\Omega$ kongruent sind und
\[
	\my\left(\bigcup_{k=1}^n \Omega_k\right) = \sum_{k=1}^n \my(\Omega_k)
\]
wenn $\Omega_i\cap \Omega_k\neq \emptyset$ für $i\neq k$.

Es gibt kein Volumenmaß $\my$ mit diesen drei Eigenschaften, welches für \emph{alle} Teilmengen von $\R^n$ definiert ist (jedenfalls für $n\ge 3$).
Man muss sich auf \emph{messbare} Teilmengen einschränken.

Gegeben ein (Volumen-)Maß $\my$ würde man auf Grund von \ref{15.1} vermuten, dass für $f\ge 0$ gilt
\begin{equation}
	\label{15.2}
	\int f d\my = \int_0^\infty \my(\{x: f(x) > t\}) dt
\end{equation}
d.h. die Mengen $\{x:f(x) >t\}$ sollten für alle $t\ge 0$ messbar sein.
Funktionen $f$ mit dieser Eigenschäft heißen \emph{messbar}.

Die Funktion $t\mapsto \my (\{x:f(x)>t\})$ ist monoton fallend und damit eine Regelfunktion.
Wir können also $\int f\d\my$ durch \ref{15.2} definieren.

Wir werden eine andere (direktere) Definition wählen, die äquivalent zu \ref{15.2} ist.


\section{Maßräume}


Sei $X$ eine beliebige Menge (z.B. $X=\R^n$).
Eine $\sigma$-Algebra $\scr M$ in $X$ ist eine Familie von Teilmengen von $X$ mit
\begin{enumerate}[(i)]
	\item
		$\emptyset, X \in \scr M$
	\item
		$E \in \scr M \implies X \setminus E \in \scr M$
	\item
		$E_k \in \scr M, k=1,\dotsc, N \le \infty$, dann ist
		\[
			\bigcup_{k=1}^N E_k \in \scr M
		\]
\end{enumerate}
Das Paar $(X,\scr M)$ heißt \emph{messbarer Raum} der \emph{Messraum} und die Elemente von $\scr M$ heißen messbare Mengen

\begin{note}
	\begin{enumerate}[1)]
		\item
			Ist $E_k \in \scr M$, $k=1,\dotsc, N$, dann auch
			\[
				\bigcap_{k=1}^N E_k \in \scr M
			\]
			denn
			\[
				X \setminus \left(\bigcap_{k=1}^N E_k\right) = \bigcup_{k=1}^N (X\setminus E_k) \stackrel{\text{(iii)}} \in \scr M
			\]
			Also nach (ii) ist $\cap_{k=1}^N E_k \in \scr M$
		\item
			sind $E, F \in \scr M$, dann $E \setminus F = E \cap F^c \in \scr M$
		\item
			Das „$\sigma$“ in $\sigma$-Algebra steht für \emph{abzählbar} (vgl. $\sigma$-additiv, $\sigma$-endlich).
	\end{enumerate}
\end{note}


\begin{ex*}
	\begin{enumerate}[1)]
		\item
			Die Potenzmenge $\scr P(x)$ von $X$ ist eine $\sigma$-Algebra.
		\item
			$\scr M = \{\emptyset, X\}$ ist eine $\sigma$-Algebra in $X$.
		\item
			Die Familie aller offenen Teilmengen von $\R^n$ ist keine $\sigma$-Algebra (sondern eine Topologie)
	\end{enumerate}
\end{ex*}

\begin{st}
	\label{15.1}
	Sei $F$ eine beliebige Familie von Teilmengen einer Menge $X$.
	Dann gibt es eine kleinste $\sigma$-Algebra $\scr M$ mit $\scr M \supset F$.
	Sie ist gegeben durch
	\begin{equation}
		\label{15.3}
		\scr M = \bigcap_{\substack{\scr M' \supset F\\\scr M' \text{ist $\sigma$-Algebra}}} \scr M'
	\end{equation}
	\begin{proof}
		Sei $\scr M$ definiert durch \ref{15.3}.
		Wenn $\scr M$ eine $\sigma$-Algebra ist, dann die kleinste mit $\scr M\supset F$ (per Definition).
		Wir zeigen: $\scr M$ ist $\sigma$-Algebra:

		Für alle $\scr M' \supset F, \scr M = \sigma$-Algebra gilt $\emptyset, X\in \scr M'$.
		Also $\emptyset, X \in \bigcap_{\substack{\scr M' \supset F\\\scr M' \text{ist $\sigma$-Algebra}}} \scr M'$.
		Wenn $E_k \in \scr M$ für $k=1,\dotsc, N$, dann $E_k\in \scr M'$ für alle $\scr M'$.
		Also $E_k \in \bigcap_{\substack{\scr M' \supset F\\\scr M' \text{ist $\sigma$-Algebra}}} \scr M'$ für $k=1,\dotsc, N$.

		Beweis von Axiom (ii): Übung
	\end{proof}
\end{st}

\begin{note}
	$\scr M$ heißt die von $F$ erzeugte $\sigma$-Algebra.
	Die kleinste $\sigma$-Algebra, welche alle offene Teilmengen von $\R^n$ (und somit auch alle abgeschlossenen Teilmengen) enthält, heißt \emph{Borel-$\sigma$-Algebra}.
	Sie wird mit $\scr B$ bezeichnet.
	Die Elemente von $\scr B$ heißen \emph{Borelmengen}.
\end{note}


Sei $(X, \scr M)$ ein messbarer Raum.
Ein \emph{Maß} auf $\scr M$ ist eine Abbildung $\my: \scr M \to \_\R$ mit
\begin{enumerate}[(i)]
	\item $\my(\emptyset) = 0$
	\item $\my(E) \ge 0$ für alle $E \in \scr M$
	\item $\my$  ist $\sigma$-additiv, d.h. wenn $E_1,\dotsc, E_N \in \scr M$ ($N\le \infty$) und $E_i \cap E_k = \emptyset$ , $i\neq k$, dann
		\[
			\my\left(\bigcup_{k=1}^NE_k\right) = \sum_{k=1}^N \my(E_k)
		\]
\end{enumerate}
$\my(E)$ heißt \emph{Maß} von $E$ und $(X, \scr M, \my)$ heißt \emph{Maßraum}.


\begin{ex*}
	\begin{enumerate}[1)]
		\item
			$(\N, \scr P(\N),\my)$ mit
			\[
				\my(E) = \card(E) = \text{Anzahl Elemente von $E$}
			\]
			ist ein Maßraum.
		\item
			Sei $a\in \R$ fest gewählt, dann ist $(\R, \scr P(\R), \my_a)$ mit
			\[
				\my_a(E) = \begin{cases}1 & a\in E\\ 0 & a\not\in E\end{cases}
			\]
			ein Maßraum
		\item
			Es gibt genau ein Maß auf $(\R^n, B)$ ($B$ Borel-Algebra), das translationsinvariant ist und mit $\my(W) = 1$ wenn
			\[
				W = \{x\in \R^n \big| 0 \le x_i \le 1, i=1,\dotsc, n\}
			\]
			Dieses Maß heißt \emph{Lebesgue-Maß} auf $\R^n$.
	\end{enumerate}
\end{ex*}


\begin{lem}
	\label{15.2}
	Sei $(X,\scr M, \my)$ ein Maßraum und $E, F\in \scr M$ messbare Mengen mit $E\subset F$.
	Dann $\my(E) \le \my(F)$ und wenn $\my(E) < \infty$, dann $\my(F\setminus E) = \my(F) - \my(E)$.
	\begin{proof}
		Zerlege
		\[
			F = E \cup (F\setminus E) \implies \my(F) = \my(E) + \underbrace{\my(F\setminus E)}_{\ge 0} \ge \my(E)
		\]
		Wenn $\my(E) < \infty$, dann folgt
		\[
			\my(F) -\my(E) = \my(F\setminus E)
		\]
	\end{proof}
\end{lem}


\begin{lem}
	\label{15.3}
	Sei $(X,\scr M, \my)$ ein Maßraum und $(E_k), (F_k)$ seien Folgen messbarer Mengen.
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			Falls $E_k \nearrow	E$, ($n\to \infty$), d.h. $E_n\subset E_{n+1}$ und $E=\cup E_n$, dann
			\[
				\my(E) = \lim_{n\to \infty}\my (E_n)
			\]
		\item
			Falls $\my(F_1)<\infty$ und $F_n \searrow F$ ($n\to \infty$), d.h. $F_n \supset F_{n+1}$ und  $F=\cap_{n\ge 1}F_n$, dann gilt
			\[
				\my(F) = \lim_{n\to \infty}\my(F_n)
			\]
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Sei $S_1=E_1$ und $S_n = E_n \setminus E_{n-1}$ für $n\ge 2$.
				Dann gilt
				\[
					E= \bigcup_{n=1}^\infty S_n, E_n = \bigcup_{k=1}^n S_k \qquad S_i \cap S_k = \emptyset\quad (i\neq k)
				\]
				Also
				\[
					\my(E) = \sum_{n=1}^\infty \my(S_n) = \lim_{N\to\infty}\sum_{n=1}^N = \lim_{N\to \infty}\underbrace{\left(\bigcup_{n-1}^N S_n\right)}_{E_N}
				\]
			\item
				folgt aus (a):
				Es gilt $
					(F_1 \setminus F_n) %aufsteigend
					(F_1 \setminus F)
				$
				denn $(F_1\setminus F_n) \subset (F_1\setminus F_{n+1})$, da $F_n \supset F_{n+1}$ und
				\[
					\bigcup_{n\ge 1}(F_1\setminus F_n) = F_1 \setminus \left(\bigcap_{n\ge 1}F_n\right) = F_1 \setminus F
				\]
				Also
				\[
					\my(F_1\setminus F) = \lim_{n\to\infty} \my(F_1\setminus F_n)
				\]
				wobei $\my(F_1\setminus F) = \my(F_1) - \my(F)$ und $\my(F_1\setminus F_n) = \my(F_1) -\my(F_n)$ nach \ref{15.2}, denn $\infty > \my(F_1) \ge \my(F_n) \ge \my(F)$.
		\end{enumerate}
	\end{proof}
\end{lem}


\begin{lem}
	\label{15.4}
	Ist $(X,\scr M,\my)$ ein Maßraum und $E_k\in \scr M$, $k=1,\dotsc, N\le \infty$, dann
	\[
		\my\left(\bigcup_{n=1}^N E_n\right) \le \sum_{k=1}^N \my(E_n)
	\]
	\begin{proof}
		Sei $A_1=E_1, A_2 := E_2 \setminus A_1, A_3 := E_3 \setminus (A_1\cup A_2), \dotsc $.
		Dann gilt $A_i \cap A_k = \emptyset$ für $i\neq k$ und
		\[
			\bigcup_{k=1}^n E_k = \bigcup_{k=1}^n A_k \qquad n\le N
		\]
		Also
		\begin{align*}
		\my\left(\bigcup_{k=1}^n E_k\right) &= \my\left( \bigcup_{k=1}^n A_k\right)\\
																														&=\sum_{k=1}^n \my(A_k) \\
									   &\le \sum_{k=1}^n \my(E_k)
		\end{align*}
		Für $N< \infty$ ist die Behauptung bewiesen, für $N=\infty$ folgt mit \ref{15.3} a)
		\begin{align*}
			\my\left(\bigcup_{k=1}^\infty E_k\right) &= \lim_{n\to\infty}\my\left(\bigcup_{k=1}^n E_k\right) \\
																								   &\le \lim_{n\to \infty}^n\my(E_k) \\
									&=\sum_{k=1}^\infty \my(E_k)
		\end{align*}
	\end{proof}
\end{lem}


\section{Messbare Funktionen}

\begin{df*}
	Sei $(X,\scr M)$ ein Messraum.
	Eine Funktion $f: X\to \_\R = \R\cup \{\pm \infty\}$ heißt \emph{messbar}, falls für alle $t\in \R$
	\[
		\{x\in X|f(x)>t\} \in \scr M
	\]
	Eine Funktion $f:X\to \C$ heißt \emph{messbar}, wenn $\Re f$ und $\Im f$ messbar sind.
\end{df*}


\begin{st}
	\label{15.5}
	Sei $(X, \scr M)$ ein Messraum und $f:X\to \_\R$.
	Dann sind äquivalent
	\begin{enumerate}[(i)]
		\item
			$\{x|f(x)>t\} \in \scr M \qquad \forall t\in \R$
		\item
			$\{x|f(x)\le t\} \in \scr M \qquad \forall t\in \R$
		\item
			$\{x|f(x)<t\} \in \scr M \qquad \forall t\in \R$
		\item
			$\{x|f(x)\ge t\} \in \scr M \qquad \forall t\in \R$
	\end{enumerate}

	\begin{proof}
		$(i)\iff(ii)$, denn $\{f(x)\le t\} = \{f(x)>t\}^C$

		$(iii)\iff(iv)$, denn $\{f(x)\ge t\} = \{f(x)<t\}^C$

		$(i)\implies (iv)$, denn $\{f(x)\ge t\} = \cup_{n\in \N}\{f(x)>t-\f 1n\}$

		$(iii)\implies (ii)$, denn $\{f(x)\le t\} = \cup_{n\in \N}\{f(x)<t+\f 1n\}$
	\end{proof}
\end{st}


\begin{ex*}
	\begin{enumerate}[1)]
		\item
			Sei $E\subset X$, dann ist die \emph{charakteristische Funktion} auf $E$, definiert durch:
			\[
				\chi_E(x) = \begin{cases}1 & x\in E \\ 0 &x\not\in E\end{cases}
			\]
			genau dann messbar, wenn $E$ messbar ist.
			\begin{proof}
				\[
					\{x\in X\big|\chi_E(x)>t\} = \begin{cases} X & t < 0\\
														E & 0\le t < 1\\
					 \emptyset & 1 \le t
					\end{cases}
				\]
				Da $\emptyset$ und $X$ stets messbar sind auf unserer $\sigma$-Algebra $(X,\scr M)$, ist also $\{x\in X\big|\chi_E(x)>t\}$ genau dann messbar, wenn $E$ messbar ist.
			\end{proof}
		\item
			Jede stetige Funktion $f:\R^n \to \C$ ist Borel-messbar.
			\begin{proof}
				Sei $f=f_1+if_2$.
				Da $f_k$ stetig, ist $\{x|f_k(x)>t\}$ offen (Übung),
				also Borel-messbar.
			\end{proof}
	\end{enumerate}
\end{ex*}

\begin{st}
	\label{15.6}
	Sei $f_n:X\to \_\R, n\in \N$ eine Folge messbarer Funktionen und für jedes $x\in X$ sei
	\begin{align*}
		f(x) &:= \inf_{n}f_n(x)\\
		F(x) &:= \inf_{n}f_n(x)\\
		f^*(x) &:= \liminf_{n\to \infty}f_n(x)\\
		F^*(x) &:= \limsup_{n\to \infty}f_n(x)
	\end{align*}
	Dann sind $f,F,f^*,F^*$ messbar.
	
	\begin{proof}
		Es gilt
		\[
			\{x|f(x)\ge t\} = \bigcap_{n\in \N} \{x|f_n(x)\ge t\} \text{ messbar}
		\]
		denn
		\begin{align*}
			f(x) &\ge t \implies f_n(x) \ge f(x) \ge t \qquad \forall n\\
			f_n(x) &\ge t \implies f(x) = \inf_{n\in \N} f_n(x) \ge t \qquad \forall n
		\end{align*}
		Weiter
		\[
			\{x|f(x)>t\} = \bigcup_{n\in \N}\{x|f_n(x)>t\} \text{ messbar}
		\]
		Außerdem
		\begin{align*}
			f^*(x) &= \liminf_{n\to \infty}f_n(x)\\
							   &= \sup_{n\in \N}(\underbrace{\inf_{k\ge n}f_k(x)}_{\text{ messbar}})\\
		\end{align*}
		und
		\begin{align*}
			F^*(x) &= \limsup_{n\to \infty}f_n(x)\\
							   &= \inf_{n\in \N}(\underbrace{\sup_{k\ge n}f_k(x)}_{\text{ messbar}})\\
		\end{align*}
	\end{proof}
	\begin{note}
		Sind $f_n:X\to \R$ messbar und $f_n(x)\to f(x)$ für $n\to \infty$, dann ist $f$ messbar, denn $f(x) = \liminf_{n\to \infty}f_n(x)$.
	\end{note}
\end{st}

Ist $f:X\to \_\R$ messbar, dann sind nach \ref{15.6} auch $f_{\pm}$, wobei
\begin{align*}
	f_+(x) &:= \max\{f(x), 0\} \ge 0\\
	f_-(x) &:= \max\{-f(x), 0\} \ge 0
\end{align*} 
Offenbar gilt
\[
	f=f_+ - f_- \qquad \text{und}\qquad |f| = f_+ + f_-
\]
und dort wo $|f|<\infty$ gilt $f_{\pm}=\f 12 (|f|\pm f)$.
\begin{proof}
	Definiere passende Folgen und wende \ref{15.6} darauf an
\end{proof}

\begin{lem}
	\label{15.7}
	Jede offene Menge $\Omega\in \R^n$ lässt sich schreiben als abzählbare Vereinigung
	\[
		\Omega = \bigcup_{k\ge 1}W_k
	\]
	abgeschlossener (achsenparalleler) Würfel $W_k$ mit $\mathring W_k \cap \mathring W_l =\emptyset$ für $k\neq l$.
	\begin{proof}
		Geometrisches Argument.
		Sei $F_1$ die Familie der Würfel mit Ecken in $\Z^n$ welche ganz in $\Omega$ liegen.
		Sei $F_2$ die Familie der Würfel mit Ecken in $\Omega \setminus (\cup_{W\in F_1})$ welche Ecken in $\left( \f\Z 2\right)^n$ haben, etc.
		So bekommt man eine abzählbare Familie $F = \cup_{k\ge 1}F_k$ von Würfeln, welche ganz $\Omega$ abdecken.
	\end{proof}
\end{lem}


\begin{st}
	\label{15.8}
	Sind $f_1,\dotsc, f_n:X\to \R$ messbar und ist $\phi : \R^n\to \R$ stetig, dann ist
	\[
		h(x) := \phi(f_1(x),\dotsc, f_n(x))
	\]
	messbar.

	\begin{proof}
		Sei $f(x) = (f_1(x),\dotsc,f_n(x))$.
		Dann ist $h=\phi\circ f$.
		Sei $I_t = (t,\infty)$.
		Zeige $\{x|h(x)>t\} = \{x|h(x)\in I_t\} = h^{-1}(I_t)$ ist messbar.

		\begin{align*}
			\{x|h(x)\in I_t\} = \{ x|\phi(f(x))\in I_t = \{x|f(x) \in \phi^{-1}(I_t)\} = f^{-1}(\phi^{-1}(I_t))
		\end{align*}
		wobei $\phi^{-1}(I_t)$ offen ist, da $\phi$ stetig ist (Übung).
		Also nach \ref{15.7} gilt
		\[
			\phi^{-1}= \bigcup_{k\ge 1}W_k
		\]
		mit abgeschlossenen Würfeln $W_k$.
		Also
		\[
			f^{-1}(\phi^{-1}(I_k)) = f^{-1}(\cup_{k\ge 1} W_k) = \cup_{k\ge 1}f^{-1}(W_k)
		\]
		Es bleibt zu zeigen, dass $f^{-1}(W_k)$ messbar ist für jedes $k$.
		
		\[
			W_k = \{x|a_i\le x_i \le b_i, i=1,\dotsc, n\}
		\]
		Also
		\begin{align*}
			f^{-1}(W_k) &= \{x|f(x) \in W_k\} \\
						&= \{x| a_i\le f_i(x) \le b_i, i=1,\dotsc, n\}\\
			   &=\bigcap_{i=1}^n (\{x|a_i\le f_i(x)\} \cap \{x|f_i(x)\le b\})\quad \text{messbar}
		\end{align*}
		Die drei Aussagen beweisen die Behauptung.
	\end{proof}
\end{st}


\begin{kor}
	\label{15.9}
	Sind $f,g:X\to \C$ messbar, dann sind $f+g, f\cdot g$ und $|f|$ messbar.

	\begin{proof}
		Seien $f,g$ reellwertig.
		Da $(u,v) \mapsto (u+v)$, $(u,v)\mapsto u\cdot v$ und $(u,v)\mapsto \sqrt{u^2+v^2}$ stetige Abbildungen auf $\R^2$ sind, folgt aus \ref{15.8}, dass
		\begin{align*}
			x&\mapsto f(x) +g(x)\\
			x&\mapsto f(x)\cdot g(x)\\
			x&\mapsto \sqrt{f(x)^2+g(x)^2}
		\end{align*}
		Die Behauptung für komplexwertige $f,g$ folgt nun durch Zerlegen von $f,g$ in Real- und Imaginärteil.
	\end{proof}
\end{kor}

\begin{df*}
	Eine Funktion $s:X\to \R$, welche nur endlich verschiedene Werte $\alpha_1,\dotsc, \alpha_n\in\R$ annimmt, heißt \emph{Elementarfunktion}.
	Setzt man $A_k := \{x|s(x)=\alpha_k\}$, dann gilt
	\begin{equation}
		s(x) = \sum_{k=1}^n \alpha_k \chi_{A_k}(x)\qquad 
	\end{equation}
	wobei
	\begin{equation}
		A_i\cap A_k = \emptyset \qquad \alpha_i\neq \alpha_k, i\neq k
		X = \bigcup_{k=1}^n A_k
	\end{equation}
	Die Darstellung in der ersten Gleichung von $s$ welche die zweite erfüllt, heißt \emph{Standardform} der Elementarfunktion $s$.
\end{df*}
	
\begin{ex*}
	Die Standardform der Dirichkletfunktion $f=\chi_\Q$ ist
	\[
		f = 1\cdot \chi_\Q + 0 \cdot \chi_{\R\setminus \Q}
	\]
\end{ex*}


\begin{thm}
	\label{15.10}
	Zu jeder (messbaren) Funktion $f:X\to [0,\infty]$ gibt es eine Folge (messbarer) Elementarfunktionen $s_n : X\to \R$ mit
	\begin{enumerate}[(a)]
		\item
			$0\le s_n \le s_{n+1}\le f \qquad \forall n$
		\item
			$ \lim_{n\to \infty} s_n(x) = f(x)$
	\end{enumerate}
	
	\begin{proof}
		Wir definieren
		\begin{align*}
			E_{n,k} &:= \left\{x|\f k {2^n} \le f(x) < \f {k+1}{2^n}\right\} \qquad k=0,\dotsc, n2^n-1\\
			E_{n,k} &:= \{x| n\le f(x)\} \qquad k=n2^n
		\end{align*}
		und
		\[
			s_n := \sum_{k=0}^{n2^n}\f k{2^n}\chi_{E_{n,k}}
		\]
	\end{proof}
\end{thm}


\section{Integration positiver Funktionen}

\begin{df*}
	Sei $(X,\scr M, \my)$ ein Maßraum und $s\ge 0$ eine Elementarfunktion mit Standarddarstellung
	\[
		s=\sum_{k=1}^n \alpha_k \chi_{A_k} \qquad (i\neq k \implies a_i\neq a_k) \land A_i\cap A_k =\emptyset \land \bigcup_{k=1}^nA_k = X
	\]
	Dann ist
	\[
		\int s\;d\my := \sum_{k=1}^n \alpha_k \my(A_k)
	\]
	Wobei in der Integrationstheorie $0\cdot \infty := 0$ gesetzt wird (zusätzlich zur bekannten Arithmetik in $\_\R$).
\end{df*}


\begin{ex*}
	Sei $\my$ ein Borelmaß auf $\R$ und $A_1 = \{1\}, A_2 = [0,1), A_3 = \R\setminus \{A_2\cup A_3\}$.
	Dann hat
	\[
		s= \sum_{k=1}^3 \alpha_k \chi_{A_k}
	\]
	das Integral
	\begin{align*}
		\int s d\my &= \sum_{k=1}^3 \alpha_k \my(A_k)\\
											   &= \alpha_1\cdot 0  + \alpha_2 \my(A_2) + \alpha_3 \my(A_3)\\
										 &= \alpha_2\my(A_2) + \alpha_3 \my(A_3)
	\end{align*}
\end{ex*}

\begin{df*}
	Ist $f:X\to [0,\infty]$ ($\infty$ erlaubt) messbar, dann ist
	\[\boxed{
		\int f d\my := \sup_{0\le s\le f} \int s d\my
	}\]
	wobei das Supremum über alle messbaren Elementarfunktionen $s$ mit $0\le s\le f$ genommen wird.

	Ist zusätzlich eine messbare Menge $E\subset X$ gegeben, dann
	\[\boxed{
		\int_E f d\my := \int \chi_E f d\my
	}\]
\end{df*}

\begin{note}
	\begin{enumerate}[1)]
		\item
			Addition und Multiplikation auf $[0,\infty)$ erfüllen Kommutativ-, Assoziativ-, und Distributivgesetz und außerdem folgt aus
			\[
				0 \le a_n \nearrow a \le \infty, \qquad  0 \le b_n \nearrow b \le \infty \qquad (n\to \infty)
			\]
			dass
			\[
				a_n\cdot b_n \to a\cdot b, \qquad a_n + b_n \to a + b \qquad (n\to infty)
			\]
			\begin{proof}
				\fixme[Übung]
			\end{proof}
		\item
			Sind $f,g:X\to [0,\infty]$ messbar, dann sind auch $f\cdot g$ und $f+g$ messbar.
			\begin{proof}
				Verwende 1) und \ref{15.10}.
				Oder wie in auf Blatt 11.
			\end{proof}
		\item
			Ist $f\ge 0$ eine messbare Elementarfunktion mit Standarddarstellung $f=\sum_{k=1}^n\beta_k \chi_{B_k}$, dann stimmen die Ausdrücke in den beiden Definitionen oben überein.
			Also
			\[
				\sum_{k=1}^m \beta_k \my (B_k) = \sum_{0\le s \le f}\int sd\my
			\]
			\begin{proof}
				„$\le$“ folgt aus der Tatsache, dass $f$ Elementarfunktion ist.
				
				Zeige $\ge$, bzw.
				\[
					s\le f \implies \int s d\my \le \sum_{k=1}^m \beta_k \my(B_k)
				\]
				Sei $s = \sum_{i=1}^k \alpha_i\chi_{A_i}$ (Standarddarstellung) mit $s\le f$.
				Dann gilt
				\begin{align*}
					\sum_{i=1}^n \alpha_i \my(A_i) &= \sum_{i=1}^n \alpha_i\my(\cup_{k=1}^n (A_i\cap B_k))\\
																														   &= \sum_{i=1}^n \alpha_i \sum_{k=1}^m \my(A_i\cap B_k)\\
																												  &= \sum_{i=1}^n \sum_{k=1}^m \alpha_i \my(A_i \cap B_k)\\
					\intertext{
						da $s\le f$ ist $\alpha_i \le \beta_k$ wegen $A_i\cap B_k\neq \emptyset$.
					}
					&\le \sum_{i=1}^n \sum_{k=1}^m \beta_k \my (A_i\cap B_k)\\
					&=\sum_{k=1}^m \beta_k \sum_{i=1}^n \my(A_i \cap B_k)\\
					&= \sum_{k=1}^m \beta_k \sum_{i=1}^n \underbrace{\left(\bigcup_{i=1}^n (A_i\cap B_k)\right)}_{=B_k}\\
					&= \sum_{k=1}^m \beta_k \my(B_k)
				\end{align*}
			\end{proof}
	\end{enumerate}
\end{note}

\begin{ex*}
	Sei $f:\N \to [0,\infty)$ gegeben durch $f(n) = a_n$ und sei $\my$ das Zählmaß.
	
	Dann ist
	\[
		\sum_{n=1}^\infty a_n = \int_\N f d\my
	\]
	\begin{proof}
		\fixme[siehe Skript]
	\end{proof}
\end{ex*}


\begin{lem}
	\label{15.11}
	Seien $f,g: X \to [0,\infty]$ messbare Funktionen und $A,B,E \subset X$ messbare Mengen.
	Dann gilt
	\begin{enumerate}[a)]
		\item
			$0\le f \le g \implies \int fd\my \le \int gd\my$
		\item
			$A\subset B, f\ge 0 \implies \int_A fd\my \le \int_B fd\my$
		\item
			Falls $f(x)=0$ für alle $x\in E$, dann
			\[
				\int_E fd\my = 0
			\]
		\item
			$\my(E) = 0 \implies \int_E fd\my = 0$
		\item
			$\int_E fd\my = \sup_{0\le s\le f}\int_E sd\my$
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}
			\item \fixme
			\item \fixme
			\item \fixme
			\item
				Sei $\my(E) = 0$, dann ist
				\[
					\int_E f d\my = \int \chi_E fd\my = \sup_{0\le s \le \chi_E f}\int s d\my
				\]
				Sei $0\le s \le \chi_E f$ soeine Funktion mit Standarddarstellung
				\[
					s= \sum_{i=1}^n \alpha_i \chi_{A_i}
				\]
				Dann gilt $A_i \subset E$ oder $\alpha_i = 0$ für alle $i=1,\dotsc, n$.
				Also
				\[
					\my(A_i) = 0 \quad \text{oder}\quad \alpha_i = 0
				\]
				und somit
				\[
					\int s d\my = \sum_{i=1}^n \alpha_i \my(A_i) = 0
				\]
			\item
				\fixme[Übung]
		\end{enumerate}
	\end{proof}
\end{lem}

\begin{st}
	\label{15.12}
	Seien $s_1,s_2:X\to [0,\infty)$ messbare Elementarfunktionen und $c\ge 0$.
	Dann gilt
	\begin{enumerate}[a)]
		\item
			$\int c s_1 d\my = c\int s_1 d\my$
		\item
			$\int (s_1 + s_2) d\my = \int s_1 d\my + \int s_2 d\my$
		\item
			Die Abbildung $\phi: E \mapsto \int_E s_1 d\my$ ist ein Maß.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[a)]
			\item
				Sei $c=0$.
				Dann hat $cs_1$ die Standarddarstellung $0\chi_X$ und somit
				\[
					\int cs_1 d \my = 0\cdot \my(X) = 0 = 0 \cdot \int s_1 d\my
				\]
				Sei $c>0$.
				Dann hat $cs_1$ dide Standarddarstellung $\sum_{i=1}^n (c\alpha_i)\chi_{A_i}$, wenn
				$\sum_{i=1}^n \alpha_i \chi_{A_i}$ die Standarddarstellung von $s_1$ ist.
				Also
				\[
					\int cs_1 d\my = \sum_{i=1}^n (c\alpha_i) \my(A_i) = c \sum_{i=1}^n\alpha_i \my(A_i) = c \int s_1d\my
				\]
			\item
				Sei $\sum_{i=1}^m \beta_i \chi_{B_i}$ die Standarddarstellung von $s_2$ und sei
				$E_{ij} = A_i \cap B_j$.
				Dann ist $E_{ij}$ messbar, $\cup_{i,j}E_{ij} = X$ und die Mengen $E_{ij}$ sind paarweise disjunkt.
				Außerdem
				\begin{align*}
					\int_{E_{ij}}(s_1+s_2)d\my &= \int \chi_{E_{ij}}(s_1+s_2)d\my\\
					&= (\alpha_i +\beta_j)\my(E_{ij}\\
					\int_{E_{ij}}s_1d\my &= \alpha_i \my(E_{ij})\\
					\int_{E_{ij}}s_2d\my &= \beta_i \my(E_{ij})
				\end{align*}
				Also ist
				\[
					\int_{E_{ij}}(s_1+s_2) d\my = \int_{E_{ij}} s_1d\my + \int_{E_{ij}}s_2d\my
				\]
				Aus c) folgt damit, dass
				\begin{align*}
					\int (s_1+s_2)d\my &= \sum_{i,j}\int_{E_{ij}}(s_1+s_2)d\my\\
																					   &= \sum_{i,j}\left(\int_{E_{ij}}s_1d\my + \int_{E_{ij}}s_2d\my\right)\\
																					   &=\sum_{i,j}\int_{E_{ij}}s_1d\my + \sum_{i,j}\int_{E_{i,j}}s_2d\my\\
					= \int s_1d\my + \int s_2 d\my
				\end{align*}
				denn
				\begin{align*}
					E &\mapsto \int_E s_1 +s_2d\my\\
					 &\mapsto \int_E s_1d\my\\
					 &\mapsto \int_E s_2d\my
				\end{align*}
				sind Maße, also $\sigma$-additiv.
			\item
				Sei $\phi(E) =\int_E s_1d\my$ für messbare Mengen $E$.
				Weiter gilt $\phi(E) \ge 0$ und $\phi(\emptyset) = \int_\emptyset s_1d\my = 0$ (nach \ref{15.11}), denn $\my(\emptyset) = 0$.
				\begin{lem*}
					Für $E\subset X$ messbar gilt
					\[
						\int_E s_1d\my = \sum_{i=1}^n \alpha_i \my(A_i \cap E)
					\]
					wenn $s_1 = \sum_{i=1}^n\alpha_i \chi_{A_i}$ (Standarddarstellung)
					\begin{proof}
						\[
							\int_E s_1d\my = \int\chi_E s_1d\my
						\]
						wobei
						\begin{align*}
							\chi_E s_1 &= \sum_{i=1}^n \alpha_i \chi_E \chi_{A_i}\\
														 &= \sum_{i=1}^n \alpha_i \chi_{A_i\cap E}\\
												   &= \sum_{\substack{A_i\cap E \neq \emptyset\\ \alpha_i \neq 0}}\alpha_i \chi_{A_i\cap E} + 0\cdot \chi_B\\
						\end{align*}
						mit
						\[
							B:=\{x| \chi_E s_1(x) = 0\}
						\]
						Das ist die Standarddarstellung von $\chi_{E}s_1$.
						Also
						\begin{align*}
							\int \chi_E s_1d\my &= \sum_{\substack{A_i\cap E\neq \emptyset\\\alpha_i\neq 0}}\alpha_i \my(A_i\cap E) + 0\cdot\my(B)\\
																					   &= \sum_{i=1}^n\alpha_i \my(A_i\cap E)
						\end{align*}
					\end{proof}
				\end{lem*}
				Sei $E$ messbar und $E=\cup_{k=1}^\infty E_k$, $E_k$ messbar und paarweise disjunkt.
				Dann ist mit dem grade bewiesenem Lemma
				\begin{align*}
					\phi(E) &= \int_E s_1 d\my\\
										   &= \sum_{i=1}^n\alpha_i\my(A_i\cap E)\\
										   &= \sum_{i=1}^n\alpha_i \my(\underbrace{A_i\cap(\cup_{k=1}^\infty E_k)}_{=\cup (A_i\cap E_k})\\
										   &= \sum_{i=1}^n \alpha_i \sum_{k=1}^\infty \my (A_i\cap E_k)\\
										   &=\sum_{k=1}^\infty \sum_{i=1}^n \alpha_i \my(A_i\cap E_k)\\
										   &= \sum_{k=1}^\infty \int_{E_k}s_1d\my\\
										   &= \sum_{k=1}^\infty \phi(E_k)
				\end{align*}					
		\end{enumerate}
	\end{proof}

	\begin{note}
		Aus \ref{15.12} folgt, dass
		\[
			\int \sum_{i=1}^n \alpha_i \chi_{A_i} d\my = \sum_{i=1}^n \alpha_i \my(A_i)
		\]
		auch wenn $\sum_{i=1}^n \alpha_i \chi_{A_i}$ nicht die Standarddarstellung einer Elementarfunktion ist.
		\begin{proof}
			$s_i = \alpha_i \chi_{A_i}$ ist Elementarfunktion mit Standarddarstellung
			\[
				s_i = \begin{cases} \alpha_i \chi_{A_i} + 0\cdot \chi_{A_i^c} & \alpha_i \neq 0\\
				0 \cdot \chi_X & \alpha_i = 0
				\end{cases}
			\]
			Es folgt
			\begin{align*}
				\int s_i d\my &= \alpha_i \my(A_i) + 0\cdot \my(A_i^C) = \alpha_i \my(A_i) &\alpha_i \neq 0\\
				\int s_i d\my &= 0\cdot \my(X) = c = \alpha_i \my(A_i) &\alpha_i = 0
			\end{align*}
			Somit
			\[
				\int \sum_{i=1}^n \alpha_i \chi_{A_i}d\my = \stackrel{\text{(b)}}= \sum_{i=1}^n \int \alpha_i \chi_{A_i}d\my = \sum_{i=1}^n \alpha_i \my (A_i)
			\]
		\end{proof}
	\end{note}
\end{st}

\begin{ex*}
	\begin{align*}
		\int(7\cdot \chi_{[0,5]} + 18 \cdot \chi_{[2,8]})d\my
		&= 7\int \chi_{[0,5]}d\my + 13 \int \chi_{[2,8]}d\my\\
		&= 7 \cdot5 +  13 \cdot 6 \qquad (\text{für $\my = $ Lebesguemaß})
	\end{align*}
\end{ex*}

\begin{thm}[Satz von der monotonen Konvergenz]
	\label{15.13}
	Sei $f_n: X\to [0,\infty], n\in \N$ eine Folge messbarer Funktionen mit $f_n(x) \le f_{n+1}(x)$ für alle $x\in X, n\in \N$.
	Dann ist 
	\[
		f(x) := \lim_{n\to\infty} f_n(x)
	\]
	messbar und es gilt
	\[
		\left(\int \lim_{n\to \infty} f_n \;d\my = \right) \int f\;d\my = \lim_{n\to \infty}\int f_n \;d\my \le \infty
	\]
	\begin{note}
		Auch wenn $f_n : X \to [0,\infty)$ (ohne $\infty$), dann kann $\lim_{n\to \infty}f_n = f$ nach $[0,\infty]$ abbilden.
		Eine Konvergenz von $f_n$ in $\R$ ist also nicht erforderlich, $f$ ist in jedem Fall wohldefiniert.
	\end{note}
	\begin{proof}
		Die Messbarkeit folgt aus \ref{15.6}.
		
		Aus $f_n\le f_{n+1}\le f$ folgt
		\[
			\int f_n d\my \le \int f_{n+1}d\my \le \int fd\my
		\]
		Also existiert 
		\[
			L := \lim_{n\to \infty}\int f_n d\my \le \int fd\my
		\]
		Es bleibt zu zeigen, dass 
		\[
			L \ge \int fd\my = \sup_{0\le s\le f}\int sd\my
		\]
		Wir zeigen $L \ge \int s d\my$ für jede Elementarfunktion $0\le s\le f$.
		Sei also $s$ eine solche Elementarfunktion und sei $\alpha\in (0,1)$.
		Sei für $n\in \N$
		\[
			E_n := \{x\big| f_n(x) \ge \alpha s(x)\}
		\]
		Dann ist $E_n$ messbar (Übung), $E_n \subset E_{n+1}$ und
		\[
			\bigcup_{n=1}^\infty E_n = X
		\]
		\begin{proof}
			Falls $f(x)= 0$, dann ist $s(x)=0, f_1(x)=0$.
			Also $f_1(x) \ge \alpha s(x)$ und somit $x\in E_1$.
			
			Falls $f(x)> 0$, dann $f(x) > \alpha s(x)$, also $f_n(x) \ge \alpha s(x)$ für $n$ groß genug.
		\end{proof}
		Es folgt
		\[
			\int f_n d\my \ge \int_{E_n}f_n d\my \ge \int_{E_n}\alpha sd\my = \alpha \int_{E_n}sd\my
		\]
		Also ist nach \ref{15.12} c) und \ref{15.3}:
		\begin{align*}
			L &= \lim_{n\to \infty}\int f_n d\my \\
			  &= \alpha \lim_{n\to\infty}\int_{E_n}sd\my \\
			  &=\alpha \int_{\cup E_n} sd\my \\
			  &=\alpha \int sd\my
		\end{align*}
		Da $\alpha < 1$ beliebig war, folgt
		\[
			L\ge \int sd\my
		\]
	\end{proof}
\end{thm}

\begin{kor}
	\label{15.14}
	Sind $f,g:X\to [0,\infty]$ messbar und $c\ge 0$, dann gilt
	\begin{align*}
		\int c fd\my &= c\int fd\my\\
		\int (f+g)d\my &= \int fd\my + \int gd\my
	\end{align*}
	\begin{proof}
		Nach \ref{15.10} existieren messbare Elementarfunktionen $s_n, \sigma_n$ mit $0\le s_n \nearrow f$ und $0\le \sigma_n \nearrow g$.
		Nach \ref{15.13} gilt dann
		\begin{align*}
			\int fd\my &= \lim_{n\to \infty}\int s_nd\my\\
			\int gd\my &= \lim_{n\to \infty}\int \sigma_nd\my\\
			\int (f+g)d\my &= \lim_{n\to \infty}\int(s_n+\sigma_n) d\my\\
														 &= \lim_{n\to \infty}\left(\int s_n d\my + \int \sigma_nd\my\right)\\
						&=\int f d\my + \int gd\my
		\end{align*}
		nach \ref{15.12}.

		$c=0$ trivial, sei also $c>0$.
		Dann ist $0\le c s_n \nearrow cf$.
		Also nach \ref{15.12} gilt
		\begin{align*}
			\int c fd\my &\stackrel{\ref{15.13}}= \lim_{n\to\infty} \int cs_n d\my\\
			&\stackrel{\ref{15.12}}= \lim_{n\to \infty} c\int s_nd\my\\
			&\stackrel{\ref{15.13}}= c\int fd\my
		\end{align*}
	\end{proof}
\end{kor}

\begin{thm}[Lemma von Fatou]
	\label{15.15}
	Sei $f_n:X\to [0,\infty]$ eine Folge messbarer Funktionen, dann gilt
	\[
		\int \liminf_{n\to\infty}f_n \;d\my \;\le\; \liminf_{n\to\infty}\int f_n \;d\my
	\]
	\begin{proof}
		\begin{align*}
			\liminf_{n\to \infty} f_n &= \lim_{n\to\infty}(\inf_{k\ge n}f_k)
		\end{align*}
		wobei $g_n=\inf_{k\ge n}f_k$ monoton wachsend ist, $0\le g_n \le g_{n+1}$ messbar.
		Also
		\begin{align*}
			\int \liminf_{n\to \infty} f_n d\my &= \int \lim_{n\to\infty} g_n d\my \\
																																	   &\stackrel{\ref{15.13}} =\lim_{n\to\infty} \int g_n d\my \\
			\int g_nd\my &= \int \underbrace{\inf_{k\ge n}f_k}_{\le f_k} d\my \le \inf_{k\ge n}\int f_k d\my
		\end{align*}
		Also
		\[
			\int \liminf_{n\to\infty} f_n d\my \le \lim_{n\to\infty}\left(\inf_{k\ge n}\int f_k d\my\right)
			=\liminf_{n\to\infty}\int f_n d\my
		\]
	\end{proof}
\end{thm}


\section{Integration reell- und komplexwertiger Funktionen}

\begin{df*}
	Sei $(X,\scr M, \my)$ beliebiger Maßraum.
	Eine messbare Funktion $f:X\to \C$ heißt \emph{integrierbar} genau dann, wenn
	\[
		\int_X |f| d\my < \infty
	\]

	Die Menge der integrierbaren Funktionen auf $X$ wird mit $\scr L(X,\my)$ oder $\scr L(X)$ bezeichnet.

	Sei $f=u +iv \in \scr L(x)$, $u = \Re(f), v=\Im(f)$, dann definiert man
	\begin{align*}
		\int fd\my &:= \int ud\my + i\int vd\my\\
		&:= \left(\int u_+d\my - \int u_- d\my\right) + i\left(\int v_+ d\my - \int v_- d\my\right)
	\end{align*}
	Wegen $u_\pm \le |u| \le |f| \;,\;\; v_\pm \le |v| \le |f|$ und $\int |f|d\my < \infty$ sind diese vier Integrale endlich und somit $\int fd\my \in \C$.
	
	Ist $f:X\to \_\R$ messbar und wenigstens eines der beiden Integral $\int f_\pm d\my$ endlich, dann ist
	\[
		\int fd\my = \int f_+ d\my - \int f_- d\my \in \_\R
	\]
	wohldefiniert.
	Man sagt: das Integral $\int fd\my$ \emph{existiert}.
\end{df*}

\begin{st}
	\label{15.16}
	Seien $f,g\in \scr L(X)$ und $\alpha\in \C$, dann sind $\alpha f, f+g\in \scr L(X)$ und
	\begin{enumerate}[(a)]
		\item
			$\displaystyle \int \alpha f \;d\my = \alpha \int f \;d\my$
		\item
			$\displaystyle \int (f+g)\;d\my = \int f \;d\my + \int g \;d\my$
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Sei $\alpha >0$ und $f$ reellwertig.
				Dann ist $(\alpha f)_+ = \alpha f_+$ und $(\alpha f_-)= \alpha f_-$ und somit
				\begin{align*}
					\int \alpha fd\my &= \int \alpha f_+ d\my - \int \alpha f_- d\my\\
																			 &\stackrel{\ref{15.14}}= \alpha \left(\int f_+ d\my - \int f_- d\my\right)\\
								&= \alpha \int fd\my
				\end{align*}
				Weiter $(-f)_+ = f_-$ und $(-f)_-=f_+$ und somit
				\begin{align*}
					\int (-f)d\my &= \int (-f)_+ d\my - \int (-f)_- d\my\\
					&=\int f_- d\my - \int f+ d\my\\
					&= - \int fd\my
				\end{align*}
				Rest: Übung
			\item
				Seien $f,g$ reellwertig und $h=f+g$.
				Im Allgemeinen gilt nicht $h_+ = f_+ + g_+$!
				Es gilt aber
				\[
					h_+ - h_- = h = f + g = (f_+ - f_-)+ (g_+ - g_-)
				\]
				Also
				\[
					h_+ + f_- + g_- = f_+ + g_+ + h_-
				\]
				Nach \ref{15.14} ist
				\[
					\int h_+d\my + \int f_-d\my + \int g_- = \int f_+d\my + \int g_+d\my + \int h_-d\my
				\]
				und somit
				\[
					\int h d\my := \int h_+d\my + \int h_-d\my = \left(\int f_+d\my -\int f_-d\my\right) + \left(\int g+d\my -\int g_-d\my \right) = \int fd\my + \int gd\my
				\]
				Beweis für komplexwertige $f,g$: Übung.
		\end{enumerate}
	\end{proof}
\end{st}

\begin{st}
	\label{15.17}
	Sei $f\in \scr L(X,\my)$, dann gilt
	\[
		\left|\int fd\my\right| \le \int |f|d\my
	\]
	\begin{proof}
		Sei $\int fd\my = e^{i\phi} \left| \int fd\my\right|$ die Polardarstellung der komplexen Zahl $\int fd\my$.
		Dann ist
		\begin{align*}
			\left| \int f d\my\right| &= e^{-i\phi}\int fd\my\\
														&=\int e^{-i\phi}f\d\my\\
										 &=\Re\left(\int e^{-i\phi}fd\my\right)\\
								   &=\int \Re(e^{-i\phi}f)d\my\\
								   &\le \int (\Re e^{-i\phi} f)_+ d\my\\
							 &\le\int |\Re e^{-i\phi}|d\my \\
				 &\le \int |f|d\my
		\end{align*}
	\end{proof}
\end{st}

\begin{thm}[Lebesguescher Satz von der majorisierten Konvergenz]
	\label{15.18}
	Sei $f_n: X\to \C$ eine Folge messbarer Funktionen mit $f_n(x) \to f(x)$ für alle $x\in X$.
	Falls eine integrierbare Funktion $g\in \scr L(X)$ existiert mit $|f_n(x)| \le |g(x)|$ für alle $x\in X, n\in \N$, dann ist $f\in \scr L(X)$ und
	\[
		\left(\int \lim_{n\to \infty} f_n \;d\my = \right)\int f\;d\my = \lim_{n\to \infty}\int f_n \;d\my
	\]
	\begin{note}
		Das Theorem besagt: Limes und Integral dürfen vertauscht werden bei punktweiser Konvergenz, wenn eine integrierbare Majorante existiert.
	\end{note}
	\begin{proof}
		Die Messbarkeit von $f$ folgt aus \ref{15.6} und die Integriebarkeit von $f$ folgt aus
		\[
			|f(x)| = \lim_{n\to\infty}|f_n(x)| \le g(x)
		\]
		d.h. $\int |f|d\my \le \int gd\my < \infty$.

		Wir zeigen jetzt $\int |f_n - f|d\my \to 0$ ($n\to\infty$), dann folgt aus \ref{15.17}, dass
		\[
			\left|\int fd\my -\int f_n d\my \right| = \left| \int(f-f_n)d\my\right| \le \int |f-f_n| d\my \to 0 \qquad (n\to \infty)
		\]
		
		Aus
		\[
			|f_n-f| \le |f_n| + |f| \le 2g
		\]
		folgt, dass
		\[
			2g - |f_n -f| \ge 0
		\]
		Nach dem Lemma von Fatou \ref{15.15} gilt
		\begin{align*}
			\int 2g d\my &= \int \liminf_{n\to\infty} (2g-|f_n-f|)d\my\\
												 &= \liminf_{n\to \infty}\left(\int 2g-|f_n-f|d\my \right)\\
			&= \liminf_{n\to \infty}\left(\int 2gd\my - \int|f_n-f|d\my\right)\\
			&= \int 2gd\my - \limsup \int |f_n -f| d\my
		\end{align*}
		Also
		\[
			0\le \limsup \int |f_n-f| d\my \le 0
		\]
		d.h.
		\[
			\lim_{n\to\infty} \int |f_n-f| d\my = 0
		\]
	\end{proof}
\end{thm}


\section{Nullmengen sind vernachlässigbar}

\begin{df*}
	Sei $(X, \scr M, \my)$ ein Maßraum und für jedes $x\in X$ sei eine Aussage $A(x)$ definiert.
	Man sagt
	\begin{align*}
		&A(x) \text{ gilt ($\my$)-fast überall auf $X$} \qquad \text{oder}\\
		&A(x) \text{ gilt für ($\my$)-fast alle $x\in X$}
	\end{align*}
	wenn eine messbare Menge $N\subset X$ existiert mit $\my(N) = 0$, so, dass $A(x)$ für alle $x\in X\setminus N$ wahr ist.

	Messbare Mengen mit Maß Null heißen \emph{Nullmengen}.
\end{df*}

\begin{thm}
	\label{15.19}
	Sei $f:X\to \_\R$ messbar und $f\ge 0$.
	Dann ist $\int fd\my = 0$ genau dann, wenn
	\[
		f(x) = 0 \text{ für $\my$-fast alle $x\in X$}
	\]
	\begin{proof}
		Sei $f(x)=0$ fast überall und sei $N\subset X$ eine Nullmenge mit $f(x)=0$ für $x\in X\setminus N$.
		Dann ist
		\begin{align*}
			\int fd\my &= \int (\chi_N f + \chi_{X\setminus N}f)d\my\\
								   &= \int \chi_N fd\my + \int \chi_{X\setminus N}fd\my\\
							 &=\int_N fd\my + \int_{X\setminus N}fd\my
			&=0
		\end{align*}
		Nach \ref{15.1}.

		Sei $\int fd\my = 0$.
		Wir zeigen: $\{x\big| f(x) > 0\}$ hat Maß Null.
		Sei $E_n = \{x| f(x) \ge \f 1n\}$, $n\in \N$.
		Dann gilt
		\[
			\{x\big| f(x) > 0\} = \bigcup_{n=1}^\infty E_n
		\]
		$E_n$ ist messbar und
		\[
			\f 1n \chi_{E_n} \le f
		\]
		Daraus folgt
		\[
			\f 1n \my(E_n) = \int \f 1n \chi_{E_n}d\my \le \int f d\my = 0
		\]
		Also ist $\my(E_n) = 0$.		
		Es folgt
		\[
			\my(\{x\big |f(x)>0\}) = \my\left( \bigcup_{n\ge 1}E_n\right) \le \sum_{n\ge 1} \my(E_n) = 0
		\]
	\end{proof}
\end{thm}


\begin{kor}
	\label{15.20}
	Sind $f,g:X\to \C$ integrierbar und $f(x)=g(x)$ $\my$-fast überall, dann gilt
	\[
		\int fd\my = \int gd\my
	\]
	\begin{proof}
		Da $|f-g|=0$ $\my$-fast überall, folgt aus \ref{15.19} und \ref{15.17}, dass
		\begin{align*}
			\left|\int fd\my - \int gd\my \right| &= \left| \int(f+g) d\my\right|\\
																																	  &\stackrel{\ref{15.17}}\le \int |f-g| d\my \\
																										   &\stackrel{\ref{15.19}}= 0
		\end{align*}
		Die Rückrichtung erfolgt analog.
	\end{proof}
\end{kor}

\begin{note}
	\begin{enumerate}[1)]
		\item
			Nach \ref{15.19} und \ref{15.20} sind Nullmengen bei der Integration vernachlässigbar.

			Insbesondere genügt es in \ref{15.13} und \ref{15.18}, wenn die Vorraussetzungen nur für fast alle $x$ erfüllt sind.
		\item
			Ein Maßraum heißt \emph{vollständig}, wenn jede Teilmenge einer Nullmenge messbar und somit ebenfalls eine Nullmenge ist.
			Zu jedem Maßraum $(X,\scr M, \my)$ gibt es einen Maßraum $(X,\scr M', \my')$ (\emph{Vervollständigung von $(X,\scr M,\my)$}), definiert durch
			\[
				E \in \scr M' \iff \exists A,B\in \scr M : A\subset E \subset B \land \my(B\setminus A) = 0
			\]
			und
			\[
				\my'(E) := \my(A)
			\]
			\begin{proof}
				Übung
			\end{proof}
	\end{enumerate}
\end{note}


\chapter{Lebesgue-Maß und Integration in $\R^n$}


\section{Konstruktion des Lebesgue-Maßes}

\begin{df*}
	Ein $n$-dimensionaler \emph{Quader} ist eine Menge $I\subset \R^n$ der Form
	\[
		I = \{x=(x_1,\dotsc x_n) \big| a_k \le x_k \le b_k \; k=1,\dotsc,n\}
	\]
	mit $a_k,b_k\in \R$.
	Jede der Ungleichungen „$\le$“ darf durch „$<$“ ersetzt werden und man spricht immernoch von einem Quader.

	Das Volumen $|I|$ des Quaders $I$ ist definiert durch
	\[
		|I| = \prod_{k=1}^n (b_k -a_k) < \infty
	\]

	Sei $E\subset \R^n$ beliebig.
	Wir definieren das \emph{äußere Maß} $m^*(E)$ durch
	\[
		m^*(E) := \inf \left\{\sum_{k=1}^\infty |I_k| \Big| E \subset \cup_{k=1}^\infty I_k\right\}
	\]
	wobei das Infimum über die abzählbaren Familien $\{I_k, k\in \N\}$ von Quadern genommen wird, mit $E \subset \cup_{k\ge  1}I_k$.
\end{df*}

\begin{note}
	\begin{enumerate}[1)]
		\item
			Der Wert von $m^*(E)$ ändert sich nicht, wenn man in der Definition nur abgeschlossene oder nur offene Quader zulässt.
			\begin{proof}
				Für abgeschlossen Quader ist die Aussage klar (das Volumen nimmt durch den Abschluss der einzelnen Quader nicht zu und $E\subset \cup_{k=1}^\infty I_k$ bleibt offensichtlich weiterhin gültig).

				Sei $E\subset \cup_{k\ge 1}I_k$ und sei $\epsilon > 0$.
				Zu jedem Quader $I_k$ gib es einen offenen Quader $J_k\supset I_k$ mit
				\[
					|J_k| < |I_k| + \f {\epsilon}{2^k}
				\]
				Dann ist $I \subset \cup_{k\ge 1} J_k$ und
				\[
					\sum_{k\ge 1}|J_k| < \sum_{k\le 1}\left( |I_k| + \f \epsilon {2^k} \right) = \left(\sum_{k\ge 1}|I_k|\right) + \epsilon
				\]
				Also
				\[
					\inf_{E\subset \cup J_k \land J_k \text{ offen}} \sum_{k\ge 1}|J_k| = m^*(E)
				\]
			\end{proof}
		\item
			Ist $E\subset \R^n, d\in \R^n$ und 
			\[
				E+d := \{x + d | x\in E\}
			\]
			dann ist
			\[
				m^* ( E+d) = m^* (E)
			\]
			(Translationsinvarianz des äußeren Maßes)
		\item
			Ist $I\subset \R^n$ ein Quader, dann $|I|=m^*(I)$.

			\begin{proof}
				„$\ge$“ ist trivial.
				„$\le$“ siehe Literatur (R. Bartle).
			\end{proof}
	\end{enumerate}
\end{note}


\begin{st}
	\label{16.1}
	Das äußere Maß $m^*$ auf $\scr P(\R^n)$ hat folgende Eigenschaften
	\begin{enumerate}[(1)]
		\item
			$\displaystyle m^*(\emptyset) = 0 \quad \land \quad \forall E\subset \R^n:0\le m^*(E) \le \infty$
		\item
			$\displaystyle F\subset E \implies m^*(F) \le m^*(E)$
		\item
			$\displaystyle m^*\left(\bigcup_{k\ge 1}E_k\right) \le \sum_{k=1}^\infty m^*(E_k)$
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(1)]
			\item
			\item
				Folgen aus der Definition des äußeren Maßes
			\item
				Sei $\epsilon >0$ und für jedes $k\in \N$ sei $E_k\subset \bigcup_{n=1}^\infty I_{k,n}$ mit Quadern
				$I_{k,n}$, so dass
				\[
					\sum_{n=1}^\infty |I_{k,n}| < m^*(E_k) + \f \epsilon {2^k}
				\]
				Dann
				\[
					\bigcup_{k\ge 1}\subset \bigcup_{k\ge 1}\left(\bigcup_{n\ge 1}I_{k,n}\right)
				\]
				und somit
				\begin{align*}
					m^*\left( \bigcup_{k\ge 1} E_k\right) &\le \sum_{k\ge 1}\sum_{n\ge 1}|I_{k,n}|\\
								   &<\sum_{k\ge 1} \left(m^*(E_k) + \f \epsilon{2^k}\right)\\
													   &=\left(\sum_{k\ge 1}m^*(E_k)\right) +\epsilon
				\end{align*}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{note}
	Das äußere Maß $m^*$ ist \emph{kein} Maß:
	es ist auch für disjunkte Mengen $A,B\subset \R^n$ möglich, dass
	\[
		m^*(A\cup B) < m^*(A) + m^*(B)
	\]
\end{note}

Eine Teilmenge $E\subset \R^n$ erfüllt die \emph{Caratheodory-Bedingung}, falls für jede Menge $A\in \R^n$ gilt
\[
	m^*(A) = m^*(A\cap E) + m^*(A\cap E^C)
\]
\begin{note}
	Wegen $A\subset ((A\cap E)  \cup (A\cap E^C))$ und \ref{15.1} c) ist
	\[
		m^*(A) \le m^*(A\cap E) + m^*(A\cap E^C)
	\]
	Nur „$\ge$“ muss gefordert werden und nur für $m^*(A) <\infty$.
\end{note}

\begin{thm}[Caratheodory]
	\label{16.2}
	Die Menge
	\[
		\scr L := \{ E\subset \R^n \big| E \text{ erfüllt die Caratheodory-Bedingung}\}
	\]
	ist ein $\sigma$-Algebra und $m:= m^*\big|_{\scr L}$ ist ein Maß.
	\begin{proof}
		Siehe Literatur.
	\end{proof}
\end{thm}

Die Elemente von $\scr L$ heißen \emph{Lebesgue-messbare Mengen} und $m$ heißt \emph{Lebesgue-Maß}.

\begin{st}[Vollständigkeit von $(\R^n, \scr L, m)$]
	\label{16.3}
	Sei $Z\subset \R^n$ mit $m^*(Z)=0$.
	Dann ist $Z\in \scr L$ und jede Teilmenge $W\subset Z$ ist auch in $\scr L$.
	\begin{proof}
		Sei $m^*(Z)=0$ und $A\subset \R^n$.
		Dann ist $m^*(A\cap Z) \le m^*(Z) = 0$.
		Also ist
		\[
			m^*(A) = m^*(A\cap Z) + m^*(A) \ge m^*(A\cap Z) + \underbrace{m^*(A\cap Z^C)}_{m^*(A)}
		\]
		D.h. $Z$ erfüllt die Caratheodory-Bedingung .
		$W\subset Z$, dann $m^*(W) \le m^*(Z) = 0$ und somit $W\in \scr L$.
	\end{proof}
\end{st}

\begin{st}
	\label{16.4}
	Jede Borel-Menge ist Lebesgue-messbar
	\begin{proof}
		Es genügt zu zeigen, dass jede offene Menge $G\subset \R^n$ in $\scr L$ ist.
		Da $\scr L$ $\sigma$-Algebra ist, folgt dann $\scr L\supset B$, denn $B$ ist die kleinste $\sigma$-Algebra, welche alle offenen Mengen enthält.

		Da nach \ref{15.7} jede offene Menge dargestellt werden kann als Vereinigung abgeschlossener Würfel (Quader), genügt es zu zeigen, dass die $\sigma$-Algebra $\scr L$ jeden abgeschlossenen Quader $I$ enthält.

		Jeder abgeschlossen Quader ist der Durchschnitt von Halbräumen der Form
		\[
			H_k=\{x\big|x_k\le b_k\} \quad\text{bzw.}\quad \{x|x_k \ge a_k\}
		\]
		Also genügt es zu zeigen, dass $H_k\in \scr L$ ist.

		Sei $A\in \R^n$ beliebig, $\epsilon > 0$ und
		\[
			m^*(A)+\epsilon \le \sum_{k\ge 1}|I_k| \qquad A\subset \bigcup_{k\ge 1}I_k
		\]
		Dann ist
		\begin{align*}
			A\cap H_k &\subset \bigcup_{j=1}^\infty (I_j \cap H_k)\\
			A\cap H_k^C &\subset \bigcup_{j=1}^\infty (I_j \cap H_k^C)
		\end{align*}
		wobei $I_j\cap H_k, I_j\cap H_k^C$ Quader sind mit
		\[
			|I_j| = |I_j\cap H_k| + |I_j\cap H_k^C|
		\]
		Also
		\begin{align*}
			m^*(A) +\epsilon &\ge \sum_{j\ge 1}|I_j| \\
								  &=\sum_{j\ge 1}|I_j\cap H_k| + \sum_{j\ge 1}|I_j\cap H_k^C|\\
							&\ge m^*(A\cap H_k) + m^*(A\cap H_k^C)
		\end{align*}
		Im Limes $\epsilon \to 0$ ist das genau die Caratheodory-Bedingung.
	\end{proof}
\end{st}

\begin{kor}
	\label{16.5}
	Sei $f:[a,b]\to \C$ eine Regelfunktion.
	Dann ist $f$ integrierbar und
	\[
		\int_a^b f(x)dx = \int_{[a,b]}fdm
	\]
	\begin{proof}
		Nach \ref{10.3} gibt es eine Folge $(\phi_n)$ von Treppenfunktionen $\phi_n:[a,b]\to \C$ mit
		\[
			\sup_{x\in[a,b]}|\phi_n(x)-f(x)| < \f 1n
		\]
		Jede Treppenfunktion $\phi_n$ ist Borel-messbar und damit nach \ref{16.4} auch Lebesgue-messbar.
		Nach \ref{10.4} ist $f$ beschränkt.
		Definiere
		\[
			M := \sup_{x\in[a,b]}|f(x)| < \infty
		\]
		also mit obigem:
		\[
			\sup_{x}|\phi_n(x)| \le M + 1 \qquad \forall n\in \N
		\]
		Die Funktion $(M+1)\chi_{[a,b]}$ ist integrierbare Majorante für $\phi_n \chi_{[a,b]}$.
		Also ist $f \chi_{[a,b]}$ nach \ref{15.18} integrierbar und
		\begin{align*}
			\int_{[a,b]}fdm &= \int \chi_{[a,b]}fdm \\
							&=\lim_{n\to \infty}\int \chi_{[a,b]}\phi_n dm\\
				&=\lim_{n\to \infty}\int_a^b\phi_n(x)dx\\
			 &=\int_a^bf(x)dx
		\end{align*}
	\end{proof}
\end{kor}


\begin{lem}
	\label{16.6}
	Zu jeder Menge $E \subset \R^n$ mit $m^*(E)<\infty$ und zu jedem $\epsilon>0$ gibt es eine offene Menge $G\supset E$ mit $m(G) < m^*(E) + \epsilon$.
	\begin{proof}
		Sei $E\subset \cup_{k\ge 1}J_k$ eine Überdeckung durch offene Quader $J_k$ mit
		\[
			\sum_{k\ge 1} |J_k| \le m^*(E) + \epsilon
		\]
		Sei $G:= \cup_{k\ge 1}J_k$.
		Dann ist $G$ offen und
		\[
			m(G) \le \sum_{k\ge 1}m(J_k) = \sum_{k\ge 1}|J_k| < m^*(E) + \epsilon
		\]
	\end{proof}
\end{lem}


\begin{st}
	\label{16.7}
	Sei $E\subset \R^n$, dann sind äquivalent
	\begin{enumerate}[(a)]
		\item
			$E$ ist messbar
		\item
			Zu jedem $\epsilon > 0$ existiert eine offene Menge $G\supset E$ mit $m^*(G\setminus E) < \epsilon$.
		\item
			Zu jedem $\epsilon > 0$ existiert eine abgeschlossene Menge $A\subset E$ mit $m^*(E\setminus A) < \epsilon$.
	\end{enumerate}
	\begin{proof}
		\begin{seg}{$(a)\implies (b)$}
			Sei $E\subset \R^n$ messbar und $m(E) <\infty$.
			Nach \ref{16.6} existiert $G\supset E$ offen mit $m(G)<m(E)+\epsilon$ ($m^*(E) = m(E)$, da $E$ messbar).
			Also
			\[
				m(E) + m(G\setminus E) = m(G) < m(E) + \epsilon
			\]
			Da $m(E)$ endlich, folgt
			\[
				m(G\setminus E) < \epsilon
			\]

			Sei jetzt $E\subset \R^n$ messbar und $m(E) =\infty$.
			Sei
			\[
				E_k := \{x\in E|k-1 \le |x|<k\}
			\]
			für $k\in \N$.
			Dann ist $E_k$ messbar, $E_i\cap E_k =\emptyset$ ($i\neq k$) und $\bigcup_{k\in \N} = E$.
			Da $m(E_k) <\infty$ existiert $G_k \supset E_k$ offen mit $m(G_k\setminus E_k) < \f {\epsilon}{2^k}$.
			Also ist $G := \bigcup_{k\ge 1}G_k$ offen mit $G\supset E$ und
			\[
				G\setminus E = \bigcup_{k\ge 1} (G_k \setminus E) \subset \bigcup_{k\ge 1}(G_k \setminus E_k)
			\]
			Also
			\[
				m(G\setminus E) \le \sum_{k\ge 1}m(G_k\setminus E_k) < \sum_{k\ge 1}\frac \epsilon {2^k} = \epsilon
			\]
		\end{seg}
		\begin{seg}{$(b)\implies (a)$}
			Nach Annahme existiert zu jedem $k\in \N$ eine offene Menge $G_k\supset E$ mit $m^*(G_k\setminus E) < \f 1k$.
			Sei $H:= \bigcap_{k\ge 1}G_k$.
			Dann ist $H$ messbar, $H\supset E$ und
			\[
				m^*(H\setminus E) \le m(G_k\setminus E) < \f 1k
			\]
			für jedes $k\in \N$.
			Also ist $Z:=H\setminus E$ eine Nullmenge und damit insbesondere messbar (\ref{16.3}).
			Also ist auch
			\[
				E = H\setminus Z
			\]
			messbar
		\end{seg}
		\begin{seg}{$(b)\iff(c)$}
			Übung
		\end{seg}		
	\end{proof}
\end{st}


\begin{thm}[Eindeutigkeit des Lebesgue-Maßes]
	\label{16.8}
	Ist $\my$ ein Maß auf $\scr L$ mit $\my(I) = |I|$ für jeden offenen Quader $I\subset \R^n$, dann gilt
	\[
		\my = m
	\]
	mit Lebesgue-Maß $m$.
	\begin{proof}
		Sei $I_m = \{x\in \R\big| \forall k=1,\dotsc,n: -m<x_k<m\}$.
		Sei $E\subset I_m$ messbar und sei $E\subset \cup_{k\ge 1}J_k$ eine Überdeckung durch offene Quader $J_k$ mit
		\[
			\sum_{k\ge 1}|J_k| < m(E) + \epsilon
		\]
		Dann gilt
		\[
			\my(E)  \le \my(\cup_{k\ge 1} J_k \le \sum_{k\ge 1}\my(J_k) = \sum_{k\ge 1}|J_k| < m(E) +\epsilon
		\]
		Da $\epsilon >0$ beliebig war, folgt $\my(E) \le m(E)$.

		Ebenso
		\[
			\my(I_m \setminus E) \le m(I_m \setminus E)
		\]
		Also folgt mit $\my(I_m) = m(I_m)$ folgt
		\[
			\my(E) = \my(I_m) - \my(I_m\setminus E) \ge m(I_m) - m(I_m\setminus E) = m(E)
		\]
		Also $\my(E) = m(E)$.

		Sei nun $E\subset \R^n$ messbar mit $m(E) \le \infty$.
		Sei $E_1 := E \cap I_1$ und
		\[
			E_m := E \cap ( I_m\setminus I_{m-1} \qquad m\ge2
		\]
		Dann ist $E_m$ messbar, $\my(E_m) = m(E_m)<\infty$ mit
		$E_i\cap E_k=\emptyset$ ($i\neq k$) und $E= \cup_{m\ge 1}E_m$
		Somit gilt
		\[
			\my(E) = \sum_{m\ge 1}\my(E_m) = \sum_{m\ge 1}m(E_m) = m(E)
		\]
	\end{proof}
\end{thm}


\section{Das Prinzip von Cavalieri}


\begin{df*}
	Gegeben $E\subset \R^{n+m}$ definieren wir
	\begin{align*}
		E_x &= \{y\in \R^m \big| (x,y) \in E\}\\
		E^y &= \{x\in \R^n \big| (x,y) \in E\}
	\end{align*}
\end{df*}

\begin{thm}[Prinzip von Cavalieri]
	\label{16.9}
	Sei $E\subset \R^{n+m}$  Lebesguemessbar.
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			$E_x \subset \R^m$ ist messbar für fast alle $x\in \R^n$ und
			$E^y \subset \R^n$ ist messbar für fast alle $y\in \R^m$.
		\item
			$x\mapsto m(E_x)$ und $y\mapsto m(E^y)$ sind messbare Funktionen auf $\R^n$ bzw. $\R^m$.
		\item
			Es gilt
			\[
				\int_{\R^n}m(E_x) \;dm(x) = m(E) = \int_{\R^m}m(E^y)\;dm(y)
			\]
	\end{enumerate}
	\begin{note}
		$m(E), m(E_x), m(E^y)$ bezeichnen zwar alles Lebesgue-Maße, aber jeweils in $\R^{n+m}$, $\R^{m}$, bzw. $\R^n$.
	\end{note}
	\begin{note}
		Man kann nicht erwarten, dass $E_x,E^y$ für alle $x,y$ messbar sind.
		Sei $B\subset \R$ nicht messbar und sei
		\[
			E := \{a\}\times B \subset \R^2
		\]
		Dann ist $E$ eine Nullmenge und ist insbesondere messbar, aber
		\[
			E_a = B
		\]
		ist nicht messbar.
	\end{note}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item siehe Literatur
			\item siehe Literatur
			\item
				Wir definieren $\my:\scr L \to [0,\infty]$ ($\scr L$ ist die Menge aller Lebesgue-messbaren Mengen in $\R^{n+1}$) durch
				\[
					\my(E) = \int_{\R^n}m(E_x)dm(x)
				\]
				Wir zeigen $\my=m$.
				$\my$ ist ein Maß (Übung).

				Sei $I\subset \R^{n+1}$ ein offener Quader.
				Dann können wir schreiben: $I=A\times B$ mit offenen Quadern $A\subset \R^n, B\subset \R^m$.
				Also
				\[
					m(I_x) = \chi_A(x)\cdot m(B) = \chi_A(x)|B|
				\]
				Also
				\begin{align*}
					\my(I) &:= \int m(I_x) dm(x)\\
						   &=\int_{\R^n}\chi_A(x) |B| dm(x)\\
						&=m(A)|B| = |A|\cdot|B| = |A\times B| = |I|
				\end{align*}
				Wegen der Eindeutigkeit aus \ref{16.8} folgt $\my=m$.
		\end{enumerate}
	\end{proof}
\end{thm}

\begin{ex*}[Das Volumen einer Kugel im $\R^n$]
	Sei $B^n_R := \{x\in \R^n \big| |x| \le \R\}$.
	$B^n_R$ ist abgeschlossen, also Lebesgue-messbar.
	Es gilt für $n=1$:
	\[
		m(B^1_R) = m([-R,R]) = 2R
	\]
	für $n=2$:
	\begin{align*}
		m(B^2_R) &= \int_\R m(B^2_{R,x})dm(x)\\
				 &=\int_\R \chi_{[-R,R]}(x)\cdot 2\sqrt{R^2-x^2}\\
		   &=2\int_{-R}^R\sqrt{R^2-x^2}dx \qquad x=Rx\\
		   &= 4R^2 \int_{-1}^1\sqrt{1-u^2}du\\
		   &= R^2\pi
	\end{align*}
	Wir wollen zeigen
	\[
		m(B_R^n) = R^n\my(B_1^n)
	\]
\end{ex*}

\begin{st}
	\label{16.10}
	Es gilt für das Volumen der $n$-dimensionalen Einheitskugel:
	\[
		m(B_1^n) = \f{\pi^{\f n2}}{\Gamma(\f n2 + 1)}
	\]
	\begin{proof}
		$V_n := m(B_1^n)$.
		Nach \ref{16.9} gilt
		\[
			V_n = \int_\R m(B_{1,x}^n)dx 
		\]
		wobei
		\[
			R_{1,x}^n = \{ y\in \R^{n-1}\big| x^2+y^2 \le 1\} = \{y\in \R^{n-1} \big| |y| \le \sqrt{1-x^2}\} = \begin{cases}B_{\sqrt{1-x^2}}^{n-1} & x\in [-1,1]\\ \emptyset & |x| > 1\end{cases}
		\]
		Also ist
		\begin{align*}
			V_n &= \int_{-1}^1 m(B_{\sqrt{1-x^2}}^{n-1})dx\\
			&=\int_{-1}^1V_{n-1}(1-x^2)^{\f {n-1}2}\\
			&=:V_{n-1}\alpha_n
		\end{align*}
		wobei
		\[
			\alpha_n = 2\int_0^1(1-x^2)^{\f {n-1}2}dx = 2\int_0^{\f\pi 2}(\cos t)^n dt = \f {n-1}{n} \alpha_{n-2}
		\]
		Es folgt
		\[
			V_n = V_{n-1}\alpha_n = V_{n-2}(\alpha_{n-1}\alpha_n) =: V_{n-2}\beta_n
		\]
		mit 
		\[
			\beta_n = \alpha_{n-1}\alpha_n = \left(\f {n-1}n \alpha_{n-2}\right)\alpha_{n-1} = \f {n-1}n \beta_{n-1}
		\]
		also 
		\[
			n\beta_n = (n-1)\beta_{n-1} = \cdots 1\cdot \beta_1 = \alpha_0\alpha_1	= 2 \pi 
		\]
		und somit $\beta_n = \f {2\pi}n$ und
		\[
			V_n = V_{n-2} \f{2\pi}n
		\]
		Weiter für gerade Dimensionen
		\begin{align*}
			V_{2n} 
			&= V_{2(n-1)}\f{2\pi}{2n} \\
			&= \underbrace{\f{2\pi}{2n}\cdot \f{2\pi}{2(n-1)} \cdots \f{2\pi}{2\cdot 1}}_{n \text{Faktoren}} \\
			&= \f{\pi^n}{n!} \\
			&= \f {\pi^{\f{2n}2}}{\Gamma\left(\f{2n}{2}+1\right)}\\
		\end{align*}
		und für ungerade Dimensionen
		\begin{align*}
			V_{2n+1} 
			&= \underbrace{\f{2\pi}{2n+1}\cdot \f{2\pi}{2n-1}\cdots\f{2\pi}{3}}_{n+1 \text{Faktoren}}\cdot \f {2}{1}\\
			&= \f{\pi^n}{(n+\f12)(n-\f12)\cdots} \\
			&= \f{\pi^{\f 12}}{\f 12 \Gamma(\f 12)}\\ 
			&= \f{\pi^{n+\f 12}}{\Gamma(n+\f 32)} \\
			&= \f{\pi^{\f{2n+1}2}}{\Gamma(\f{2n+1}2 + 1)}
		\end{align*}
	\end{proof}
\end{st}

\begin{st}
	\label{16.11}
	Sei $f:\R^n\to [0,\infty]$ messbar und $E = \{(x,t)\in \R^{n+1} \big| f(x) > t \ge 0\}$.
	Dann ist $E$ messbar und
	\[
		m(E) = \int_{\R^n} f dm = \int_0^\infty m(\{x\big| f(x) > t\})dt
	\]
	\begin{proof}
		$E$ ist messbar, denn
		\begin{align*}
			E &= \{(x,t) \big| f(x) > t\ge 0\}\\
		   	&= \bigcup_{r\in \Q}\{(x,t)\big| f(x) > r\land r\ge t\ge 0\} \\
			&=\bigcup_{r\in \Q}\{x\big| f(x) > r\} \times [0,r]\\
		\end{align*}
		ist auch messbar (Übung: Das Kartesische Produkt zweier messbarer Mengen ist messbar).

		Nach \ref{16.9} gilt
		\[
			m(E) = \int_{\R^n}m(E_x) dm = \int_{\R^n}f dm
		\]
		denn
		\[
			E_x = \{t\ge 0\big| f(xx) > t\} = [0,f(x))
		\]
		\[
			m(E) = \int_\R m(E_t)dm(t) = \int_{\R}m(\{x\big|f(x)>t\})\chi_{[0,\infty)}(t) dm(t)
			= \int_{[0,\infty)} m(\{x\big|f(x)>t\})dm(t)
		\]
	\end{proof}
\end{st}


\section{Mehrfache Integrale}


Wir betrachten messbare Funktionen $f$ auf messbaren Mengen $E\subset \R^(n+m)$ (d.h. $\tilde f$ gegeben durch $\tilde f=f$ auf $E$ und $\tilde f=0$ auf $\R^n\setminus E$ ist messbar).

\begin{seg}{Notation}
	\begin{align*}
		\int_E f(x,y) d(x,y) &:= \int_E fdm \qquad (x,y)\in \R^n\times \R^m, E\subset \R^n\times \R^m\\
		\int_{E_x}f(x,y) dy &:= \int_{E_x}f_x dm\\
		\int_{E_y}f(x,y) dx &:= \int_{E^y}f^y dm
	\end{align*}
	wobei $f_x := f(x,y), f^y(x) = f(x,y)$ auf $E_x$, bzw. $E^y$ definiert sind
\end{seg}

\begin{thm}[Tonelli]
	\label{16.12}
	Seien $E\subset \R^{n+m}$ messbar und $f: E\to [0,\infty]$ messbar, dann gilt
	\begin{enumerate}[(a)]
		\item
			$y\mapsto f(x,y)$ ist messbar für fast alle $x$.
			$x\mapsto f(x,y)$ ist messbar für fast alle $y$.
		\item
			$x\mapsto \int_{E_x}f(x,y)dy$ und $y\mapsto \int_{E^y}f(x,y)dx$ sind messbar und
			\[
				\int_{\R^m}\left(\int_{E^y}f(x,y)dx\right)dy =  \int_E f(x,y) d(x,y) = \int_{R^n}\left(\int_{E_x}f(x,y)dy\right)dx
			\]
	\end{enumerate}
	\begin{note}
		\begin{enumerate}[1)]
			\item
				In $(a), (b)$ ist mit $f$ immer die Funktion $\tilde f = \chi_E f$ auf $\R^{n+m}$ gemeint.
			\item
				Wenn eines der drei Integrale in $(b)$ endlich ist, so sind alle drei endlich.
		\end{enumerate}
	\end{note}
	\begin{proof}
		Aus Symmetriegründen genügt es jeweils die erste Aussage in $(a)$ und $(b)$ zu beweisen.
		\begin{enumerate}[(a)]
			\item
				Siehe Skript
			\item
				Sei $A = \{(x,y)\big| \tilde f(x,y) > t \ge 0\}$ ($\tilde f = \chi_E f$).
				\[
					\int_E fd(x,y) = \int_{\R^{n+m}}\tilde f dm = m(A) = /nt_{\R^n}m(A_x) dm(x)
				\]
				Nach \ref{16.11} ist das
				\[
					= \int_{\R^n}\left(\int_{\R^m}\tilde f_x(y)dy\right)dx = \int_{\R^n}\left(\int_{E_x}f(x,y)dy\right)dx
				\]
		\end{enumerate}
	\end{proof}
\end{thm}

\begin{ex*}
	\begin{enumerate}[1)]
		\item
			Was ist
			\[
				\int_0^1 \left(\int_x^1e^{y^2}dy\right)dx
			\]
			Die Stammfunktion von $e^{y^2}$ ist nicht elementar.
			
			Wir „vertauschen“ die Integrale:
			\begin{align*}
				\int_0^1\left(\int_x^1e^{y^2}dy\right)dx &= \int_E e^{y^2}d(x,y)\\
				&=\int_0^1 \left(\int_{E_y}e^{y^2}dx\right)dy
				\intertext{mit $E_y = \{x\big| 0\le x\le y\}$}
				&= \int_0^1\left(\int_0^y e^{y^2}dx\right)dy \\
				&= \int_0^1 e^{y^2}\left(\int_0^y dx \right) dy \\
				&= \int_0^1 y e^{y^2} dy\\
				&= \f 12 e^{y^2}\Big|_0^1\\
				&= \f 12 (e-1)
			\end{align*}
		\item
			Was ist das Volumen von
			\[
				E = \{ (x,y,z)\in \R^3 \big| x,y,z \ge 0 \land x+y+z\le \sqrt{2} \land x^2+y^2 \le 1\}
			\]
			Sei die Bodenfläche durch $B$ gegeben.
		
			\begin{align*}
				m(E) &= \int_{\R^2}m(E_{x,y})d(x,y) \\
					 &= \int_{\R^2}\sqrt 2 - (x+y) \chi_B d(x,y) \\
				  &= \int_B \sqrt 2 -(x+y) d(x,y) \\
				  &= \sqrt 2 \int_B d(x,y) - \int_B x\; d(x,y) - \int_B y\; d(x,y)\\
				  &= \sqrt 2 \; m(B) - 2 \int_B y\; d(x,y)\\
				  &= \sqrt 2 \f \pi 4 - 2 \int_{\R} \left(\int_{B_x}y\;dy\right) dx\\
				  &= \sqrt 2 \f \pi 4 - 2 \int_0^1 \left(\int_0^{\sqrt{1-x^2}}y\;dy\right) dx\\
				  &= \sqrt 2 \f \pi 4 - 2 \int_0^1 \f 12 (1-x^2) dx\\
				  &= \sqrt 2 \f \pi 4 - \f 23
			\end{align*}
	\end{enumerate}
\end{ex*}

\begin{thm}[Fubini]
	\label{16.13}
	Sei $E\subset \R^{n+m}$ messbar und $f:E\to \C$ integrierbar (also messbar und $\int |f|d(x,y) < \infty$).
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			$f_x \in \scr L(E_x)$ für fast alle $x$.\\
			$f^y \in \scr L(E^y)$ für fast alle $y$.
		\item
			Die Funktionen $x\mapsto \int_{E_x}f(x,y)dy$ und $y\mapsto \int_{E^y}f(x,y)dx$ sind integrierbar und
			\[
				\int_{\R^m}\left( \int_{E^y}f(x,y)dx\right) dy = \int_E f(x,y) d(x,y) = \int_{\R^n} \left( \int_{E_x}f(x,y)dy\right) dx
			\]
	\end{enumerate}
	\begin{proof}
		Ohne Beschränkung der Allgemeinheit können wir annehmen, dass $f$ reellwertig ist.
		Aus Symmetriegründen genügt es jeweils die erste Aussage zu beweisen.

		Da $f_\pm$ messbar sind folgt aus \ref{16.1}, dass
		\begin{align*}
			y \mapsto f_\pm(x,y) \text{ messbar für fast alle $x$}\\
			x \mapsto f_\pm(x,y) \text{ messbar für fast alle $y$}\\
			x \mapsto \int_{E_x}f_\pm(x,y) dy \text{ ist messbar}\\
		\end{align*}
		und
		\[
			\int_{f_\pm} d(x,y) = \int_{\R^n}\left(\int_{E_x}f_\pm(x,y)dy\right)dx
		\]
		Wegen obigem ist $y\mapsto f(x,y) = f_+(x,y) - f_-(x,y)$ messbar für fast alle $x$ und wegen
		\[
			\int_E f_\pm d(x,y) \le \int_E |f|d (x,y) < \infty
		\]
		ist $x\mapsto \int_{E_x} f_\pm(x,y)dy$ integrierbar.
		Also ist nach \ref{15.16}
		\[
			(x \mapsto \int_{E_x}f(x,y) dy) := \int_{E_x} f_+(x,y)dy-\int_{E_x}f_-(x,y)dy
		\]
		integrierbar und
		\begin{align*}
			\int \left( \int_{E_x}f(x,y)dy\right) dx &= \int \left(\int f_+(x,y)dy\right) - \int\left(\int f_-(x,y)dy\right)dx \\
													 &= \int_{E}f_+d(x,y) - \int_E f_- d(x,y) =: \int_E fd(x,y)
		\end{align*}
	\end{proof}
	\begin{note}
		\begin{enumerate}[1)]
			\item				
				Der Satz von Fubini (\ref{16.12}) wird gebraucht um die Vorraussetzung $\int|f|dm < \infty$ zu prüfen, denn in jedem Fall:
				\[
					\int_{\R^m}\left(\int_{E^y}f(x,y)dx\right)dy =  \int_E f(x,y) d(x,y) = \int_{R^n}\left(\int_{E_x}f(x,y)dy\right)dx
				\]
			\item
				Falls $\int|f|dm = \infty$, dann ist die Aussage von \ref{} im Allgemeinen falsch.
				\begin{proof}
					Sei $f:[0,1)\times [0,1)\to \R$ definiert durch die Figur:
					\[\fixme
						f = \begin{cases} 4 &  0 \le x,y \le \f 12\\
						16 & \f 12 \le x,y \le \f 34\\
					\end{cases}
					\]
					Dann gilt
					\begin{align*}
						\int_{[0,1)} f(x,y) dy &= 2 \cdot \chi_{[0,\f 12)}(x) \\
\implies						\int_{[0,1)}\int_{[0,1)} f(x,y) dy  dx &= 2 \cdot \int_{[0,1}\chi_{[0,\f 12)}(x)dx = 1
					\end{align*}
					Aber
					\begin{align*}
						\int_{[0,1)} f(x,y) dx &= 0\\
							\implies						\int_{[0,1)}\int_{[0,1)} f(x,y) dy  dx &= 0
					\end{align*}
					und
					\[
						\int |f| d(x,y) \ge 4 \cdot \f 14 + 16 \cdot \f 1{16} + \cdots = \infty
					\]
				\end{proof}
		\end{enumerate}
	\end{note}
\end{thm}


\section[Das Lebesgue-Maß unter linearen Abbildungen]{Verhalten des Lebesgue-Maßes unter linearen Abbildungen}


Unser Ziel ist eine Formel, wie
\[
	\int_{\phi(E)}f dx = \int_E (f\circ \phi) |\phi'(x)| dx
\]

\begin{st}
	\label{16.14}
	Sei $T : D\subset \R^n \to \R^n$ Lipschitz-stetig, dann bildet $T$ Nullmengen auf Nullmengen und messbare Mengen auf messbare Mengen ab.
	\begin{proof}
		Nach Vorraussetzung existiert $M\in \R$ mit $|T(x) - T(y)| \le M|x-y|$ für $x,y\in D$.
		\begin{enumerate}
			\item
				Ist $W\subset \R^n$ ein achsenparalleler Würfel mit Kantenlänge $a$, dann ist $T(W)$ enthalten in einem Würfel der Kantenlänge $M\cdot \sqrt n a$ (Übung).
				Also ist
				\[
					m^*(T(W\cap D)) \le (M\sqrt n)^n a^n = (M\sqrt n)^n |W|
				\]
			\item
				ist $z\subset D$ eine Nullmenge und $\epsilon >0$, dann gibt es eine offene Menge $G \supset Z$ mit $m(G) < \epsilon$.
				Nach \ref{15.7} gibt es abgeschlossene, achsenparallele Würfel $W_k$ mit $G=\cup_{k\ge 1}W_k$ mit $\mathring W_i \cap \mathring W_k = \emptyset$ und $\sum_{k\ge 1} |W_k| = m(G) < \epsilon$.
				Es folgt
				\[
					T(Z) \subset T(G\cap D) = \bigcup_{k\ge 1}T(W_k \cap D)
				\]
				also
				\begin{align*}
					m^*(T(Z)) &\le \sum_{k\ge 1}m^*(T(W_k \cap D))
				\intertext{das ist aber nach dem ersten Beweisschritt}
					&\le \sum_{k\ge 1}|W_k| (M\sqrt n)^n < \epsilon ( M\sqrt n)^n
				\end{align*}
				Da $\epsilon > 0$ beliebig klein gewählt werden kann, folgt, dass $T(Z)$ eine Nullmenge ist.
			
				Sei $E\subset D$ messbar.
				Dann ist $E = F \cup Z$, wobei $F$ eine $F_\sigma$-Menge und $Z$ eine Nullmenge ist (Beweis: Übung).
				D.h.
				\[
					F = \bigcup_{k\ge 1} F_k \qquad \text{$F_k$ abgeschlossen}
				\]
			\item
				Sei $K\subset D$ kompakt.
				Dann ist $T(K)$ kompakt, also messbar.
				Sei $A\subset D$ abgeschlossen und
				\[
					A_k = \{x\in A \big| |x| \le n\}
				\]
				Dann ist $A_n$ kompakt und  $A = \cup_{n\ge 1} A_n$.
				Also ist
				\[
					T(A) = \cup_{n\ge 1} T(A_n)
				\]
				messbar.

				Es folgt, dass 
				\[
					T(E) = T(F) \cup T(Z)
				\]
				wobei $T(Z)$ eine Nullmenge ist, also messbar.
				Und 
				\[
					T(F) = \cup_{k\ge 1}\underbrace{T(F_k)}_{\text{messbar nach (3)}}
				\]
				D.h. $T(E)$ ist messbar.
		\end{enumerate}
	\end{proof}
\end{st}


\begin{thm}
	\label{16.15}
	Sei $L\in \Mat(n\times n, \R)$.
	Dann ist für jede messbare Menge $E\subset \R^n$ $LE$ messbar und es gilt
	\[
		m(LE) = |\det L|\cdot m(E)
	\]
	\begin{proof}
		Wir betrachten zuerst Elementarmatrizen aus $\GL(n,\R)$ vom Typ Transposition $P$, Dilatation? $S(\lambda)$ und Scherung $Q$.
		\begin{enumerate}
			\item
				Zeige: die behauptete Gleichung gilt für Quader, wenn $L\in \{P,S(\lambda), Q\}$.

				Wenn $E=I$ ein Quader ist, dann sind auch $PE$ und $S(\lambda)E$ Quader und
				\[
					m(PE) = m(E) = |\det P|\cdot m(E)
				\]
				und
				\[
					m(S(\lambda)E) = |\lambda|\cdot m(E) = |\det S(\lambda)|\cdot m(E)
				\]
				Nach Cavalieri gilt
				\[
					m(QE) = m(E) = |\det Q|m(E)
				\]
			\item
				Zeige: die behauptete Gleichung gilt für $L\in \{P,S(\lambda),Q\}$ und beliebige messbare Mengen $E\subset \R^n$.

				Sei $\my(E) = \f 1{|\lambda|}m(S(\lambda)E)$ für $E\subset \R^n$ Lebesgue-messbar.
				Nach \ref{16.14} ist $\my$ wohldefiniert und außerdem $\sigma$-additiv und $\ge 0$, also ein Maß.
				Nach Schritt 1 ist $\my(I) = m(I)$ für jeden Quader $I\subset \R^n$.

				Aus \ref{16.8} folgt, dass $\my=m$.
				Analog für $L=P$ und $L=Q$.
			\item
				Zeige: die behauptete Gleichung gilt für invertierbare Matrizen $L\in \Mat(n\times n,\R)$.

				Ist $L$ invertierbar, dann gibt es Elementarmatrizen $L_1,\dots, L_n$ mit $L_k\in \{P,S(\lambda), Q \big| \lambda \in \R\setminus \{0\}\}$, so dass
				\[
					L = L_1L_2\dotsb L_n
				\]
				Aus Schritt 2 folgt
				\[
					m(LE) = m(L_1L_2\dotsb L_nE) = |\det L_1| \cdot m(L_2\dotsb L_nE) = \prod_{k=1}^n |\det L_k| m(E) = |\det (L)| m(E)
				\]
			\item
				Zeige: die behauptete Gleichung gilt auch, wenn $\det(L) = 0$.

				Wenn $\det L = 0$, dann gibt es Elementarmatrizen $L_1,\dotsc, L_n$, so dass die letzte Zeile von $L_1\dotsb L_nL$ verschwindet.
				D.h. $L_1\dotsb L_nLE \subset \R^{n-1}\times \{0\}$.
				Also
				\[
					0 = m(L_1\dotsb L_nLE) = \underbrace{\prod_{k=1}^n |\det L_k|}_{\neq 0} m(LE)
				\]
				Und damit $m(LE) = 0$.
		\end{enumerate}
	\end{proof}
\end{thm}

\begin{ex*}
	$P = LW$, mit $W = [0,1] \times [0,1]$, $L = \begin{pmatrix}a_1, a_2\end{pmatrix}$.
	Nach \ref{16.15} ist dann
	\[
		m(P) = |\det L|\cdot m(W) = |\det (a_1,a_2)|
	\]
\end{ex*}

\begin{kor}
	\label{16.16}
	Sei $P = \left\{\sum_{k=1}^n x_k a_k \big| 0\le x_k \le 1\right\}$ das Parallelepipet aufgespannt durch die Vektoren $a_1,\dotsc, a_n\in \R^n$.
	Dann gilt
	\[
		m(P) = \left|\det \begin{pmatrix}a_1 & \cdots & a_n\end{pmatrix}\right|
	\]
	\begin{proof}
		Sei $W = [0,1]^n$ und $A=(a_1 \;\cdots\; a_n) \in \Mat(n\times n,\R)$ dann gilt $P=AW$, also nach \ref{thm:16.1r}
		\[
			m(P) = m(AW) = |\det A| \underbrace{m(W)}_{=1}
		\]
	\end{proof}
\end{kor}

\begin{ex*}
	Das Parallelogramm im $\R^2$ aufgespannt durch $(3,1)^T$ und $(2,5)^T$ hat die Fläche
	\[
		\det \begin{pmatrix}3&2\\1&5\end{pmatrix} = 13
	\]
\end{ex*}

\begin{note}
	Man kann das Volumen $m(P)$ auch durch die Wurzel einer sogenannten \emph{Gramschen Determinante} ausdrücken:
	\[
		m(P) = \sqrt{\det(A^TA)}
	\]
	wobei $A= (a_1, \dotsc, a_n)\in \Mat(n\times n,\R)$.
	\begin{proof}
		Es gilt
		\[
			\det(A^TA) = \det(A^T)\det(A) = \det(A)^2
		\]
	\end{proof}
	Es gilt
	\[
		(A^TA)_{ik} = \<a_i,a_k\>
	\]
	Vergleiche Analysis 3
\end{note}


\section{Die Transformationsformel}


Aus Analysis 1 wissen wir:
\[
	\int_{\phi(a)}^{\phi(b)}f(u) du = \int_a^b f(\phi(u))\phi'(x)dx
\]
Ist $\phi$ monoton und $I\subset \R$ ein kompaktes Intervall, dann können wir das schreiben als
\[
	\int_{\phi(I)}f(u)du = \int_If(\phi(x))|\phi'(x)|dx
\]
Der Betrag $|\phi'(x)|$ ist notwendig, da
\[
	\int_{\phi(I)}\dotso =  \int_{\phi(b)}^{\phi(a)} \dotso = - \int_{\phi(a)}^{\phi(b)}\dotso
\]
wenn $\phi$ monoton fallend (also $\phi' \le 0$) ist.

Die Formel 
\[
	\int_{\phi(I)}f(u)du = \int_If(\phi(x))|\phi'(x)|dx
\]
werden wir auf Integration in $\R^n$ verallgemeinern.

\begin{st}
	\label{16.17}
	Sei $\Omega\subset \R^n$ offen und $\phi:\Omega \to \R^n$ stetig differenzierbar.
	Dann bildet $\phi$ Nullmengen auf Nullmengen und messbare Mengen auf messbare Mengen ab.
	\begin{proof}
		Nach \ref{15.7} ist $\Omega$ darstellbar als Vereinigung abzählbar vieler kompakter Würfel $W_k \subset \Omega$:
		\[
			\Omega = \bigcup_{k\ge 1}W_k
		\]
		Da $x\mapsto \|\phi'(x)\| := \left(\sum_{i,k=1}^n |\d_i\phi_k|^2\right)^{\f 12}$ stetig und $W_k$ kompakt ist, gilt
		\[
			M_k = \sup_{u\in W_k}\|\phi'(x)\| < \infty
		\]
		nach \ref{8.11}.
		Also nach \ref{13.7} ist
		\[
			|\phi(x) - \phi(y)| \le M_k |x-y| 
		\]
		für $x,y\in W_k$.
		D.h. $\phi\big|_{W_k}$ ist Lipschitz-stetig.
		Ist $Z\subset \Omega$ eine Nullmenge und $E\subset \Omega$ messbar, dann ist $Z\cap W_k$ eine Nullmenge und $E\cap W_k$ messbar, also ist auch
		\[
			\phi(Z) = \bigcup_{k\ge 1}\phi(Z\cap W_k)
		\]
		eine Nullmenge und
		\[
			\phi(E) = \bigcup_{k\ge 1}\phi(E\cap W_k)
		\]
		ist messbar, denn $\phi(Z\cap W_k)$ ist Nullmenge und $\phi(E\cap W_k)$ ist messbar nach \ref{16.14}.
	\end{proof}
\end{st}

\begin{st}
	\label{16.18}
	Sei $\Omega \subset \R^n$ offen, $\phi:\Omega \to \R$ stetig differenzierbar und \emph{injektiv}.
	Dann gilt für jede messbare Menge $E\subset \R^n$
	\[
		m(\phi(E)) = \int_E |\det \phi'(x)|\; dm(x)
	\]
	\begin{note}
		\begin{enumerate}[1)]
			\item
				Für eine lineare Abbildung $\phi(x) = Lx$ mit $L\in \Mat(n\times n,\R)$ reduziert sich die Formel auf die Aussage von \ref{16.15}, denn
				\[
					\int_E |\det \phi'(x)|dm = \int_E |\det L|dm = |\det L| m(E)
				\]
			\item
				Im Fall $n=1$ und $E=[a,b]$ muss $\phi$ monoton sein.
				Es folgt
				\[
					m(\phi(E)) = |\phi(b) - \phi(a)| = \left|\int_a^b \phi'(x)dx\right| = \int_E |\phi'(x)|dx
				\]
				Die Aussage des Satzes reduziert sich also auf den Hauptsatz der Differential- und Integralrechnung.
			\item
				Die Bemerkung 2 zeigt, dass Injektivität für diesen Satz notwendig ist.
		\end{enumerate}
	\end{note}
	\begin{proof}[Heuristik, Königsberger Ana2 oder Rudin: Real \& Complex Analysis]
		Kein wirklicher Beweis \dots\\
		Für einen kleinen Würfel $W\subset \R^n$ mit Mittelpunkt $a\in W$ gilt für $x\in W$:
		\[
			\phi(x) \approx \phi(a) + \phi'(a)\cdot(x-a)
		\]
		d.h.
		\[
			\phi(W) \approx \phi(a) + \phi'(a)\cdot(W-a)
		\]
		Also
		\[
			m(\phi(W)) \approx m(\phi(a) + \phi'(a)(W-a)) = m(\phi'(a)(W-a)) \stackrel{\ref{16.15}}= |\det \phi'(a)|m(W-a) = |\det \phi'(a)|m(W)
		\]
		Ist $E\subset \R^n$ offen, dann ist $E=\bigcup_{k\ge 1} W_k$ mit beliebig kleinen Würfeln $W_k$ mit Mittelpunkten $a_k$.
		Also gilt
		\begin{align*}
			m(\phi(E)) &= m\left(\phi\left(\bigcup_{k\ge 1}W_k\right)\right) \\
					   &= m\left(\bigcup_{k\ge 1} \phi(W_k) \right) \\
				 &\stackrel{\ref{16.17}}= \sum_{k\ge 1}m(\phi(W_k))\\
			  &\approx \sum_{k\ge 1}|\det \phi'(a_k)|m(W_k)\\
			  &\approx \int_E |\det \phi'(x)| dm
		\end{align*}
	\end{proof}
\end{st}

\begin{thm}
	\label{16.19}
	Sei $\Omega \subset \R^n$ offen, $\phi:\Omega \to \R^n$ injektiv und stetig differenzierbar.

	Ist $f:\phi(\Omega)\to [0,\infty]$ messbar, dann ist $f\circ \phi \cdot |\det \phi'|$ messbar und
	\[
		\int_{\phi(\Omega)}f \;dm = \int_{\Omega}(f\circ \phi)|\det \phi'|\; dm
	\]
	\begin{proof}
		Es genügt das Theorem für $f=\chi_A$ (mit $A\subset \phi(\Omega)$ messbar) zu beweisen.
		Daraus folgt dann das Theorem für Elementarfunktionen und dann für messbare $f\ge 0$ nach dem Satz über monotone Konvergenz.

		\begin{enumerate}
			\item
				Ist $A\subset \phi(\Omega)$ Borel-messbar, dann ist $\chi_A \circ \phi$ eine Borel-messbare Funktion.

				Es gilt 
				\[
					\{x\big| \chi_A\circ \phi(x) > t\} = (\chi_A \circ \phi)^{-1}((t,\infty)) =\phi^{-1}\circ \underbrace{\chi_A^{-1}((t,\infty))}_{\text{Borel-messbar}}
				\]
				Da $\phi$ stetig ist $\phi$ Borel-messbar und $\phi^{-1}$ auch messbar (Übung).
			\item
				Ist $A\subset \phi(\Omega)$ Borel-Menge, dann gilt das Theorem für $f=\chi_A$.

				$\chi_A \circ \phi$ ist messbar nach 1. und $x\mapsto |\det \phi'(x)|$ ist stetig (da $\phi$ stetig differenzierbar), also Borel-messbar.
				Also ist
				\[
					(\chi_A \circ \phi) |\det \phi'|
				\]
				(Borel-)messbar.

				Sei $E=\phi^{-1}(A) = \{x\in \Omega \big| \phi(x) \subset A\}\subset \Omega$.
				Dann ist
				\[
					\chi_E(x) = \chi_A(\phi(x))
				\]
				Also ist $\chi_E = \chi_A\circ \phi$ messbar (siehe oben).
				Somit
				\begin{align*}
					\int_{\phi(\Omega)}\chi_A dm &= \int_{\R^n}\chi_A dm = m(A) = m(\phi(E)) \\
					&\stackrel{\ref{16.18}}= \int_E|\det \phi'(x)|dm\\
					&= \int_{\R^n}\chi_E \cdot |\det \phi'| dm \\
					&= \int_{\Omega}(\chi_A\circ \phi) |\det \phi'|dm\\
				\end{align*}
			\item
				Das Theorem gilt für $f=\chi_Z$ wenn $Z\subset \phi(\Omega)$ eine Nullmenge ist.

				Es gibt eine Borel-Menge $A$ mit $Z\subset A \subset \phi(\Omega)$ und $m(A)=0$ (nach Aufgabe 12.1).
				Nach 2. gilt
				\[
					0 = \int_{\phi(\Omega)} \chi_A dm = \int_{}(\chi_A \circ \phi) \cdot |\det \phi'| dm \ge 0
				\]
				Also ist
				\[
					(\chi_A \circ \phi)\cdot |\det \phi'| = 0
				\]
				fast überall.
				Insbesondere ist $(\chi_Z\circ \phi)\cdot |\det \phi'|=0$ fast überall und somit ist
				\[
					(\chi_z \circ \phi)\cdot |\det \phi'|
				\]
				messbar und
				\[
					\int_{\phi(\Omega)} (\chi_z \circ \phi)\cdot |\det \phi'| dm = 0 = \int_{\phi(\Omega)} \chi_z dm
				\]
			\item
				Sei $A\subset \phi(\Omega)$ messbar, dann gilt $A = F\cup Z$, wobei $F$ eine Borel-Menge ($F_\sigma$-Menge) und $Z$ eine Nullmenge ist.
				Also ist
				\[
					\chi_A = \chi_E + \chi_Z
				\]
				und
				\[
					\chi_A \circ \phi = \chi_E \circ \phi + \chi_Z \circ \phi
				\]
				und das Theorem für $f=\chi_A$ folgt aus diesen beiden Gleichungen und 2. und 3.
		\end{enumerate}
	\end{proof}
\end{thm}

\begin{kor}
	\label{16.20}
	Seien $U,V\subset \R^n$ offen und $\phi:U\to V$ ein $C^1$-Diffeomorphismus.
	Dann ist $f:\phi(U)=V \to \C$  genau dann integrierbar, wenn $(f\circ \phi)\cdot |\det \phi'| : U\to \C$ integrierbar ist.
	In diesem Fall gilt
	\[
		\int_{\phi(U)}f\;dm = \int_U (f\circ \phi)\cdot |\det \phi'| \; dm
	\]
	\begin{proof}
		\fixme[Übung]
	\end{proof}
\end{kor}


\subsection{Integration im Kugel-Koordinaten}

Sei $P_2 : \R_+ \times (0,2\pi)\to \R^2$ definiert durch
\[
	(r,\phi) \mapsto \begin{pmatrix}r\cos \phi\\ r\sin \phi\end{pmatrix}
\]
Dann ist $P_2$ ein Diffeomorphismus von $\R_+ \times (0,2\pi)$ auf $\R^2 \setminus \{(x,y) | x\ge 0, y= 0\}$ und
$\det P_2'(r,\phi) = r$.
\begin{note}
	Fläche eines Sektorstücks bei Linearisierung kann man exakt angeben:
	\[
		m(P_2'(r,\phi)W) = |\det P_2'(r,\phi)|m(W)
	\]
\end{note}
Also gilt für integrierbare $f\in \scr L(\R^2)$ nach \ref{16.20}.
\begin{align*}
	\int_{\R^2\setminus [0,\infty)}f\;d(x,y) &= \int_{\R_+\times (0,2\pi)}f(r\cos \phi, r\sin \phi) r \; d(r,\phi)\\
	\intertext{und nach Fubini}
	&= \int_0^\infty dr \int_0^{2\pi}d\phi f(r\cos \phi,r\sin \phi) r\\
	&= \int_{\R^2} f(x,y) \; d(x,y)
\end{align*}

\begin{ex*}
	Wir zeigen noch einmal, dass
	\[
		\int_\R e^{-x^2} dx = \sqrt \pi
	\]
	\begin{proof}
		Betrachte 
		\begin{align*}
			\left( \int_\R e^{-x^2}dx \right)^2 &= \left(\int_\R e^{-x^2}dx\right)\left(\int_\R e^{-y^2}dy\right)\\
												&= \int_\R dx\; e^{-x^2} \left(\int_\R e^{-y^2} dy\right)\\
					 &= \int_\R dx \int dy\; e^{-(x^2+y^2)}\\
			&= \int_{\R^2}e^{-(x^2+y^2)}\; d(x,y)\\
			&= \int_0^\infty dr \int_0^{2\pi}d\phi\; e^{-r^2} r\\
			&= \int_0^\infty dr \; e^{-r^2}r \left(\int_0^{2\pi}d\phi\right)\\
			&= \pi \int_0^\infty e^{-r^2}2r\; dr \qquad (t = r^2, dt = 2r \;dr)\\
			&= \pi \int_0^\infty e^{-t}dt\\
			&= \pi
		\end{align*}
		Also 
		\[
			\int_\R e^{-x^2} dx = \sqrt \pi
		\]
	\end{proof}
\end{ex*}

Sei jetzt $P_3 : \R_+ \times (0,2\pi)\times \left(-\f \pi2, \f \pi 2\right)$ definiert durch
\[
	P_3 (r, \phi, \theta) = \begin{pmatrix}r\cos \theta \cos \phi \\ r\cos \theta \sin \phi \\ r\sin \theta\end{pmatrix}
\]
$P_3$ ist Diffeomorphismus mit Bild $\R^3\setminus \{(x,y,z) \big| x=0,y\ge 0\}$ und
\[
	\det P_3'(r,\phi,\theta) = r^2 \cos \theta
\]
Für $f\in \scr L(\R^3)$ gilt nach \ref{16.20}
\[
	\int_{\R^3}f(x,yz) \;d(x,y,z) = \int_0^\infty dr \int_0^{2\pi}d\phi \int_{-\f\pi2}^{\f \pi2} d\theta f(r\cos \theta\cos \phi, r\cos\theta \sin \phi, r\sin \theta) \cdot r^2 \cos \theta
\]
Wenn $f$ nur von $r=\sqrt{x^2+y^2+z^2}$ abhängt, d.h. $f(x,y,z) = F(\sqrt{x^2+y^2+z^2})$, dann folgt
\[
	\int_{\R^3} f\; d(x,y,z) = 4\pi \int_0^\infty F(r)r^2 \; dr
\]

\fixme[Höhere Dimensionen]
$P_n : \R_+ : (0,2\pi) \times (-\f \pi 2,\f \pi2)^{n-2} \to \R^n$
rekursiv definiert durch
\[
P_n (r,\phi_1,\dotsc, \phi_{n-1}) = \begin{pmatrix} P_{n-1}(r, \phi_1, \dotsc, \phi_{n-2},\cos \phi_{n-1})\\ \sin \phi_{n-1}\end{pmatrix}
\]
\[
	\det P_n' (r,\phi_1,\dotsc,\phi_{n-1}) = r^{n-1}\prod_{k=2}^{n-1}\cos^{k-1}\phi_k
\]


\chapter[DGL-Systeme und DGLs höherer Ordnung]{Differentialgleichungssysteme und Differentialgleichungen höherer Ordnung}

\section{Systeme erster Ordnung}

Wir betrachten Systeme von Differentialgleichungen der Form
\begin{align*}
	\dot y_1 &=  F_1(t, y_1,\dotsc,y_n)\\
	\vdots\; &= \qquad \vdots \\
	\dot y_n &= F_n(t,y_1,\dotsc, y_n)
\end{align*}
bzw. in vektorieller Form
\[
	\dot y = F(t,y)
\]
mit einer stetigen Funktion $F:D\subset \R^{n+1}\to \R^n$.
Eine Lösung von soeinem System ist eine differenzierbare Funktion $\phi:I\to \R^n$ auf einem Intervall $I\subset \R$, wobei $\Gamma(\phi)\subset D$ und 
\[
	\dot\phi(t) = F(t,\phi(t))\qquad \forall t\in I
\]
Man nennt soein System, bzw. das zweidimensionale Vektorfeld $F$ auch ein \emph{dynamisches System}.

Jeder Punkt $(t_0,y_0)\in D$ definiert eine Anfangsbedingung
\[
	y(t_0) = y_0
\]
zum Differentialgleichungssystem.

\begin{ex*}
	Sei $A\in \Mat(n\times n,\R)$.
	Dann hat das Anfangswertproblem
	\[
		\dot y = Ay \quad\land\quad y(t_0) = y_0
	\]
	die \emph{eindeutige Lösung}
	\[
		\phi(t) = e^{A(t-t_0)}y_0
	\]
	wobei
	\[
		e^{At} = \sum_{k\ge 0}\f 1{k!}(At)^k
	\]
	Diese Reihe ist absolut konvergent, also insbesondere konvergent.
	\begin{proof}
		\begin{enumerate}[(1)]
			\item
				Es gilt (man betrachte die Reihen)
				\[
					e^{A(s+t)} = e^{As}e^{At} \qquad \forall s,t\in \R
				\]
				Das folgt aus der absoluten Konvergenz der Exponentialreihe durch Ausmultiplizieren der Reihen von $e^{At}$ und $e^{As}$.
			\item
				\[
					\f 1h (e^{Ah}-1) \to A \qquad (h \to 0)
				\]
				Das gilt, denn
				\begin{align*}
					\f 1h (e^{Ah}-1) - A &= \f 1n(e^{Ah}-1-Ah) \\
										 &=\f 1h \sum_{k=2}^\infty \f 1{k!}(Ah)^k\\
						  &= h \sum_{k=2}^\infty \f 1{k!}A^kh^{k-2}
				\end{align*}
				Also
				\begin{align*}
					\|\f 1h(e^{Ah}-1) -A\| &\le |h|\sum_{k=2}^\infty \f1{k!}\underbrace{\|A^k\|}_{\le \|A\|^k}|h|^{k-2}\\
																		 &\le |h|e^{\|A\|} \to 0 \qquad (h\to 0)
				\end{align*}
			\item
				\[
					\phi(t) = e^{A(t-t_0}y_0
				\]
				löst das Anfangswertproblem, denn
				\[
					\phi(t_0) = e^{A\cdot 0}y_0 = I y_0 = y_0
				\]
				und
				\begin{align*}
					\dot\phi(t) &= \lim_{h\to 0}\f 1h (\phi(t+h)-\phi(t))\\
								&=\lim_{h\to 0}\f1h (e^{Ah}-1) \\
					   &=Ae^{A(t-t_0)}y_0 =A\phi(t)
				\end{align*}
			\item
				Beweise die Eindeutigkeit.
				Sei $\phi$ irgendeine Lösung des Anfangswertproblems, dann gilt
				\begin{align*}
					\f d{dt} e^{-At} \phi(t) &= -Ae^{-At}\phi(t) + e^{-At}\dot \phi(t)\\
											 &=-Ae^{-At}\phi(t) + e^{-At}A\phi(t)\\
						   &= 0
				\end{align*}
				($A$ und $e^{-At}$ kommutieren, man betrachte die Reihen).
				Also
				\[
					e^{-At}\phi(t) = e^{-At_0}\phi(t_0) \implies \phi(t) = e^{A(t-t_0)}y_0
				\]
		\end{enumerate}
	\end{proof}
\end{ex*}

\begin{ex*}
	Sei $A\in \Mat(n,\R), b\in \R^n$.
	Wir suchen die Lösung von 
	\[
		\dot y = Ay + b \quad \land \quad y(0)=y_0
	\]
	\begin{note}
		$b$ muss im Wertebereich von $A$ liegen!
	\end{note}
	\begin{seg}{$A$ ist invertierbar}
		Wenn $A$ invertierbar ist, dann ist eine partikuläre Lösung gegeben durch
		\[
			y_p = -A^{-1}b
		\]
		Die allgemeine Lösung ist dann
		\[
			\phi(t) = e^{At}c - A^{-1}b
		\]
		Die Anfangswertbedingung ist erfüllt für
		\[
			c= y_0 +A^{-1}b
		\]
		damit erhält man also 
		\[
			\boxed{\phi(t) = e^{At}(y_0+A^{-1}b) - A^{-1}b}
		\]
	\end{seg}
	\begin{seg}{$A$ ist nicht invertierbar}
		Wenn $A$ nicht invertierbar ist, dann bekommt man die Lösung durch Variation der Konstanten $c\in \R^n$:
		\[
			\phi(t) = e^{At}c(t)
		\]
		Einsetzen in die DGL liefert
		\[
			A\phi(t) + e^{At}\dot c(t) = \dot \phi(t) = A\phi(t) + b
		\]
		Also ist
		\[
			\dot c = e^{-At}b
		\]
		und somit
		\[
			c(t) = c(0) + \int_0^te^{-As}b \;ds
		\]
		Also
		\[
			\phi(t) = e^{At}\left(c(0) + \int_0^t e^{-As}b \; ds\right)
		\]
		wobei die Anfangsbedingung $y(0) = y_0$ genau dann gelöst wird, wenn $c(0):=y_0$.
		Also
		\[
			\boxed{\phi(t) = e^{At}\left(y_0 + \int_0^t e^{-As}b \; ds\right)}
		\]
	\end{seg}
	\begin{note}
		Wenn $A$ invertierbar ist, dann ist
		\[
			\int_0^t e^{-As}\; ds = - A^{-1}e^{-As}\Big|_0^t
		\]
		Also
		\begin{align*}
			\phi(t) &= e^{At}\left(y_0 + \int_0^t e^{-as}b \; ds\right)\\
					&= e^{At}(y_0 - b[A^{-1}e^{-As}]_0^t)\\
			&= e^{At}(y_0 + A^{-1}b) - A^{-1}b
		\end{align*}
		was mit dem invertierbaren Fall übereinstimmt.
	\end{note}
\end{ex*}

\begin{ex*}
	Sei $\times$ das Kreuzprodukt und
	\[
		m \ddot x = q E + q\dot x \times B
	\]
	das ist äquivalent zu
	\[
		\dot v = -\f qm B \times v + \f qm E =: Av + b
	\]
	was eine lineare inhomogene Differenzialgleichung ist mit Vektor $v$.
	\[
	B \times v = \begin{pmatrix}B_2v_3 - B_3v_2\\ B_3v_1 - B_1v_3 \\ B_1v_2-B_2v_1\end{pmatrix} =
	\begin{pmatrix}0&-B_3&B_2\\B_3&0&-B_1\\-B_2&B_1&0\end{pmatrix}\begin{pmatrix}v_1\\v_2\\v_3\end{pmatrix}
	\]
	d.h.
	\[
		A = -\f qm	\begin{pmatrix}0&-B_3&B_2\\B_3&0&-B_1\\-B_2&B_1&0\end{pmatrix}\begin{pmatrix}v_1\\v_2\\v_3\end{pmatrix}
	\]
	siehe Übung
\end{ex*}


\begin{thm}
	\label{17.1}
	Ist $D\subset \R^{n+1}$ offen, $F:D\to \R^n$ stetig und $(t_0,y_0)\in D$.
	Dann besitzt das Anfangswertproblem
	\[
		\dot y = F(t,y) \quad \land\quad y(t_0) = y_0
	\]
	mindestens eine Lösung.
	Jede Lösung lässt sich links und rechts von $t_0$ bis zum Rand von $D$ fortsetzen.
\end{thm}

\begin{df*}
	Eine Funktion $F:(t,y) \mapsto F(t,y)$ genügt in $D\subset \R^{n+1}$ einer lokalen Lipschitz-Bedingung bezüglich $y$, wenn zu jedem Punkt $(t_0,y_0)\in D$ ein $\epsilon >0$ und $L\in \R$ existieren, so dass
	\[
		|F(t,y) - F(t,\tilde y)| \le L |y-\tilde y|
	\]
	für alle $(t,y),(t,\tilde y) \in B_\epsilon(t_0,t_0)\cap D$.
\end{df*}

\begin{thm}
	\label{17.2}
	Sei $D\subset \R^{n+1}$ offen, $F:D\subset \R^{n+1} \to \R^n$ stetig und bezüglich $y$ lokal Lipschitz-stetig.
	Dann hat jedes Anfangswertproblem 
	\[
		\dot y = F(t,y) \quad \land\quad y(t_0) = y_0
	\]
	eine Lösung, welche sich nicht fortsetzen lässt und welch links und rechts von $t_0$ den Rand von $D$ beliebig nahe kommt.
	Jede andere Lösung des Anfangswertproblems ist eine Restriktion von $\phi$ ($=\phi$, aber auf einem kleineren Bereich definiert).
	\begin{proof}
		Beweis der lokalen Eindeutigkeit wie im Beweis von \ref{11.5}.
	\end{proof}
\end{thm}

\begin{note}
	Grundlegend für den Existenzbeweis von \ref{17.2} ist folgendes Lemma
\end{note}

\begin{lem}
	\label{17.3}
	Sei $F:D\subset \R^{n+1}\to \R^n$ stetig, $I\subset \R$ ein Intervall und $\phi:I\to \R^n$ mit $\Gamma(\phi)\in D$.
	Dann sind äquivalent
	\begin{enumerate}[(i)]
		\item
			$\phi$ ist eine Lösung von
			\[
				\dot y = F(t,y) \quad \land\quad y(t_0) = y_0
			\]
		\item
			$\phi$ ist stetig und für alle $t\in I$ gilt
			\[
				\phi(t) = y_0 + \int_{t_0}^t F(s,\phi(s))\;ds
			\]
			Man nennt diese Gleichung auch \emph{Integralgleichung} der DGL.
	\end{enumerate}
	\begin{proof}
		\begin{seg}{$(i)\implies (ii)$ }
			Es gilt
			\begin{align*}
				\phi(t) &= \phi(t_0) + \int_{t_0}^t \dot \phi(s)ds\\
				&= y_0 + \int_{t_0}^t F(s,\phi(s))ds
			\end{align*}			
		\end{seg}
		\begin{seg}{$(ii)\implies (i)$}
			Da $F$ und $\phi$ stetig sind, ist auch $s\mapsto F(s,\phi(s))$ stetig und somit ist
			$f\mapsto \int_0^t F(s,\phi(s))ds$ differenzierbar (nach dem Hauptsatz).

			Da nach Annahme die Integralgleichung erfüllt ist, folgt, dass $\phi$ differenzierbar ist und
			\begin{align*}
				\dot \phi(t) &= \f d{dt}\int_0^t F(s,\phi(s))ds\\
												  &= F(t,\phi(t)
			\end{align*}
			Außerdem gilt
			\[
				\phi(t_0) = y_0
			\]
		\end{seg}
	\end{proof}
\end{lem}

Um die Integralgleichung einer DGL zu lösen, iterieren wir sie, d.h. wir definieren rekursiv Funktionen $\phi_n(t)$ durch
\begin{align*}
	\phi_0 (t) &= y_0\\
	\phi_1 (t) &= y_0 + \int_{t_0}^t F(s,y_0) ds\\
	\vdots \quad &= \qquad \vdots\\
	\phi_{n+1}(t) &= y_0 + \int_{t_0}^t F(s,\phi_n(s)) ds
\end{align*}
Wenn $F(t,y)$ bezüglich $y$ lokal Lipschitz-stetig ist, kann man zeigen, dass eine Funktion $\phi : B_\epsilon(t_0) \to \R^n$ existiert, so dass $\phi_n\to \phi$ ($n\to \infty$) \emph{gleichmäßig} für $t\in B_\epsilon(t_0)$

Dann ist $\phi$ stetig und erfüllt die Integralgleichung.


\begin{ex*}
	Sei $F(t,y) = Ay$, $t_0=0$, also
	\[
		\dot y = Ay \quad \land \quad y(0) = y_0
	\]
	Dann ist
	\begin{align*}
		\phi_0(t) &= y_0\\
		\phi_1(t) &= y_0 + \int_0^t Ay_0 ds = y_0 + tAy_0\\
		\phi_2(t) &= y_0 + \int_0^t F(s,\phi_1(s)) ds \\
							  &= y_0 + \int_0^t A\phi_1(s) ds\\
					 &=y_0 + \int_0^t A(y_0+sAy_0)ds\\
			   &= y_0 + tAy_0 +\f {t^2}2 A^2y_0\\
		\phi_3(t) &= y_0 + \int_0^t A\phi_2(s) ds\\
									   &= y_0 + tAy_0 + \f{t^2}2 A^2y_0 + \f{t^3}{6} A^3y_0
	\end{align*}
	Also
	\[
		\phi_n(t) = \sum_{m=0}^n\f{t^m}{m!}A^m y_0 \to e^{At}y_0 \qquad (n\to \infty)
	\]
	und
	\[
		\phi(t) = e^{At}y_0
	\]
	ist lösung des Differentialgleichungssysstems.
\end{ex*}


\section{Differentialgleichungen höherer Ordnung}


Sei $f:D\subset \R^{n+1}\to \R$.
Wir betrachten Differentialgleichungen $n$-ter Ordnung von der Form
\[
	y^{(n)} = f(x,y,y',\dotsc,y^{(n-1)})
\]
Eine Lösung einer solchen Differentialgleichung ist eine $n$ Mal differenzierbare Funktion $\phi : I\to \R$ auf einem Intervall $I$ mit
\begin{enumerate}[(a)]
	\item
		$(x,\phi(x),\phi'(x),\dotsc,\phi^{(n-1)}(x)) \in D$
	\item
		$\phi^{(n)}(x) = f(x,\phi(x),\phi'(x), \dotsc, \phi^{(n-1)(x)})$
\end{enumerate}

Sei $\phi_1 : I\to \R$ eine Lösung von
\[
	y^{(n)} = f(x,y,y',\dotsc,y^{(n-1)})
\]
Sei $\phi_k := \phi_1^{(k-1)}$, dann ist $\phi(\phi_1,\dotsc, \phi_n) : I \to \R$ eine Lösung von
\[
	y' = F(x,y) \qquad \text{mit} \qquad F(x,y) := \begin{pmatrix}y_2 \\ y_3 \\\vdots\\ y^{n-1}\\f(x,y_1,\dotsc,y_n)\end{pmatrix}
\]

Ist umgekehrt $\phi=(\phi_1,\dotsc,\phi_n)^T :I \to \R^n$ eine Lösung des Systems erster Ordnung, dann ist $\phi_1$ ein Lösung von der Differentialgleichung höherer Ordnung, denn per Induktion (Übung).
\begin{align*}
	\phi_1^{(k-1)} &= \phi_k\\
	\phi_1^{(n)} = f(x,\phi_1,\dotsc, \phi_n) = f(x,\phi_1,\phi_1',\dotsc,\phi_1^{(n-1)})
\end{align*}
Die Anfangsbedingung für $\xi,\eta \in \R^n$.
\[
	y(\xi) = \eta
\]
mit $(\xi,\eta)\in D$ für das Differentialgleichungssystem  entspricht dem Anfangswertproblem
\[
	y(\xi) = \eta_1, y'(\xi) = \eta_2 ,\dots , y^{(n-1)}(\xi) = \eta_n
\]

\begin{thm}
	\label{17.4}
	Sei $D\subset \R^{n+1}$ offen, $f:D\to \R$ stetig und $(\xi,\eta_1,\dotsc,\eta_n)\in D$ gegeben.
	Dann hat das Anfangswertproblem
	\begin{align*}
		y^{(n)} =f(x,y,y',\dotsc,y^{(n-1)}) \quad \land \quad y(\xi) = \eta_1 \land \dotsb \land y^{(n-1)}(\xi)=\eta_n
	\end{align*}
	\begin{proof}
		Folgt aus \ref{17.1} und obigen Bemerkungen.
	\end{proof}
\end{thm}

\begin{thm}
	\label{17.5}
	Sei $D\subset \R^{n+1}$ offen, $f:D\to \R$ stetig und lokal Libschitz-stetig bezüglich $y$.
	Sei $(\xi,\eta)\in D$.
	Dann hat das Anfangswertproblem
	\begin{align*}
		y^{(n)} =f(x,y,y',\dotsc,y^{(n-1)}) \quad \land \quad y(\xi) = \eta_1 \land \dotsb \land y^{(n-1)}(\xi)=\eta_n
	\end{align*}
	eine Lösung $\phi$, welche sich nicht fortsetzen lässt und welche links und rechts von $\xi$ dem Rand von $D$ beliebig nahe kommt.

	Jede andere Lösung ist eine Restriktion von $\phi$.
	\begin{proof}
		Verwende \ref{17.2}.
		Noch zu zeigen ist: wenn $f$ Lipschitzstetig ist, dann auch $F$.

		Sei $(\xi,\eta)\in D$.
		Dann existiert $\epsilon > 0, L\in R$, so dass
		\[
			|f(x,y) - f(x,\tilde y) | \le L|y-\tilde y|
		\]
		für $(x,y), (x,\tilde y)\in B_\epsilon(\xi,\eta) \cap D$.
		Daraus folgt
		\begin{align*}
			|F(x,y) - f(x,\tilde y) | &= |(y_2,\dotsc, y_n, f(x,y)) - (\tilde y_2, \dotsc, \tilde y_n, f(x,\tilde y))|\\
																	   &= \Big(\underbrace{\sum_{k=2}^n |y_k-\tilde y_k|^2}_{\le |y-\tilde y|^2} +\left.\underbrace{|f(x,y) - f(x,\tilde y)|}_{\le L|y-\tilde y|}\right.^2 \Big)^{\f 12}\\
			&= (1+L^2)^{\f 12}|y-\tilde y|
		\end{align*}
		für $(x,y), (x,\tilde y)\in B_\epsilon(\xi,\eta) \cap D$.
	\end{proof}
\end{thm}

\begin{ex*}
	Wir betrachten $N$ Punktteilchen mit Positionen $x_1(t),\dotsc, x_N(t)\in \R^3$ und Massen $m_1,\dotsc,m_N>0$.
	Die Bewegung sei gegeben durch
	\[
		m_k \ddot x_k = -\sum_{i=1 \land i\neq k}^N \f{Gm_im_k}{|x_k-x_i|^3}(x_k-x_i) \qquad k=1,\dotsc, N
	\]
	Das ist ein System von $3N$ Gleichungen $2$-rer Ordnung.
	Es ist äquivalent zu einem System von $6N$ Gleichungen erster Ordning der Form
	\[
		\dot x = F(x)
	\]
	mit $F:D\subset \R^{6N+1}\to \R^{6N}$ wobei
	\[
		D = U \times \R^{3N+1}
	\]
	wobei
	\[
		U := \{(x_1,\dotsc,x_N)\in \R^{3N}\big| \forall i\neq k: x_i\neq x_k \}
	\]
	$F$ ist differenzierbar und somit lokal Lipschitz-stetig.

	Also gibt es zu vorgegebenen Anfangswerten (Anfanspositionen und Anfangsgeschwindigkeiten)
	\[
		x_k(0), \dot x_k(0) \qquad k=1,\dotsc, N
	\]
	genau eine Lösung, welche fortgesetzt werden kann, bis zwei Teilchen kollidieren oder eines nach $\infty$ entwischt.
\end{ex*}


\section{Lineare Systeme}


Wir betrachten nun lineare Systeme der Form
\[
	\dot y = A(t) y + b(t)
\]
wobei $A: I \to \Mat(n,\K)$ und $b :I \to \K^n$ stetig und $I\subset \R$ ein Intervall ist.
Das System hat zu jedem Anfangswert $y(t_0) = y_0$ genau eine Lösung, welche auf ganz $I$ existiert.
Wir werden diese Aussage beweisen, indem wir die Lösung weitgehend explizit konstruieren.

\begin{lem}[Gronwell]
	\label{17.6}
	Sei $g: [t_0,t_1] \to \R$ stetig und
	\[
		g(t) \le a + b\int_{t_0}^t g(s) ds \qquad \text{für $t\in [t_0,t_1]$}
	\]
	Dann gilt
	\[
		g(t) \le ae^{b(t-t_0)}
	\]
	\begin{proof}	
		Siehe Übung 3.1
	\end{proof}
\end{lem}

\begin{st}
	\label{17.7}
	Sei $A:I \to \Mat(n,\K), b:I\to \K^n$ stetig und $\phi_1,\phi_2: I \to \K^n$ Lösungen von
	\[
		\dot y = A(t) y + b(t)
	\]
	Dann gibt es zu jedem kompakten Intervall $J\subset I$ ein $L\in \R$, so dass
	\[
		|\phi_1(t) - \phi_2(t)| \le |\phi_1(t_0) -\phi_2(t_0)| e^{L|t-t_0|}
	\]
	für $t_0, t\in J$.
	\begin{proof}
		Sei
		\[
			L := \sup_{t\in D}\|A(t)\| < \infty
		\]
		Nach dem Hauptsatz der Integralrechnung gilt
		\[
			\phi_1(t) - \phi_2(t) = \phi_1(t_0) - \phi_2(t_0) + \int_{t_0}^t A(s) (\phi_1(s) - \phi_2(s))\; ds
		\]
		Sei $g(t) = |\phi_1(t) - \phi_2(t)|$, dann folgt
		\[
			g(t) \le g(t_0) + \int_{t_0}^tLg(s)\; ds
		\]
		Mit Gronwell \ref{17.6} folgt
		\[
			g(t) \le g(t_0) e^{L(t-t_0)} \qquad t\ge t_0
		\]
		analog für $t\le t_0$

	\end{proof}
\end{st}

\subsection{Homogene Systeme}

Nach \ref{17.3} ist $\phi:I \to \K^n$ genau dann eine Lösung von
\[
	\dot y = A(t) y  \quad \land\quad y(t_0) = y_0
\]
wenn $\phi$ stetig ist und
\[
	\phi(t) = y_0 + \int_{t_0}^t A(s) \phi(s)\; ds
\]
Wir definieren rekursiv eine Folge von Funktionen $\phi_k: I \to \K^n$ durch $\phi_0(t) = y_0$ und
\[
	\phi_{k+1}(t) = y_0 + \int_{t_0}^tA(s)\phi_k(s) \;ds
\]
D.h.
\begin{align*}
	\phi_k(t) = y_0 &+ \int_{t_0}^tA(s)y_0\;ds \\
					&+ \int_{t_0}^tds_1\int_{t_0}^{s_1}ds_2 \; A(s_1)A(s_2)y_0 \\
		&+ \dotsb \\
	 &+ \int_{t_0}^tds_1 \int_{t_0}^{s_1}ds_2 \dotso \int_{t_0}^{s_{k-1}}ds_k A(s_1)\dotsb A(s_k)y_0
\end{align*}

\begin{thm}
	\label{17.8}
	Sei $A:I \to\Mat(n,\K)$ stetig, $t_0\in I$ und $y_0\in \K^n$. 
	Dann ist die Reihe 
	\begin{align*}
		\phi_k(t) = y_0 &+ \int_{t_0}^tA(s)y_0\;ds \\
						&+ \int_{t_0}^tds_1\int_{t_0}^{s_1}ds_2 \; A(s_1)A(s_2)y_0 \\
			&+ \dotsb \\
		 &+ \int_{t_0}^tds_1 \int_{t_0}^{s_1}ds_2 \dotso \int_{t_0}^{s_{k-1}}ds_k A(s_1)\dotsb A(s_k)y_0
	\end{align*}
	für jedes $t\in I$ konvergent und ihre Summe $\phi(t)$ ist die eindeutiige Lösung von 
	\[
		\dot y = A(t) y  \quad \land\quad y(t_0) = y_0
	\]
	\begin{proof}
		Sei $J\subset I$ kompakt mit $t_0\in J$ und sei
		\[
			L = \sup_{t\in J}\|A(t)\| < \infty
		\]
		Dann gilt
		\begin{align*}
			\left\|\int_{t_0}^t ds_1 \int_{t_0}^{s_1}ds_2 \dotso \int_{t_0}^{s_{k-1}}ds_k A(s_1) \dotsb A(s_k) y_0\right\|
			& \le \int_{t_0}^t ds_1 \int_{t_0}^{s_1}ds_2 \dotso \int_{t_0}^{s_{k-1}}ds_k \|A(s_1)\|\dotsb \|A(s_k)\|\cdot |y_0|\\
			& \le L^k|y_0| 	\int_{t_0}^t ds_1 \int_{t_0}^{s_1}ds_2 \dotso \underbrace{\int_{t_0}^{s_{k-1}}ds_k 1}_{s_{k-1}-t_0}\\ 
			& \le L^k|y_0| \f 1{k!}(t-t_0)^k\\
			& \le L^k|y_0| \f 1{k!} l^k \qquad l = m(J)
		\end{align*}
		Die Reihe konvergiert: $\sum_{k\ge 0}L^k \f{l^k}{k!}|y_0| < \infty$.
		Also konvergiert die Reihe auf $J$ gleichmäßig nach dem Weierstraßschen M-Test.

		Es folgt dann aus
		\[
			\phi_{k+1}(t) = y_0 + \int_{t_0}^t A(s) \phi_{k}(s) \;ds
		\]
		dass im Grenzwert $k\to \infty$, dass
		\[
			\phi(t) = y_0 + \int_{t_0}^t A(s) \phi(s)\; ds
		\]
		Limes und Grenzwert dürfen wegen der gleichmäßigen Konvergenz vertauscht werden.
		Nach \ref{17.3} ist das Theorem bewiesen.
		Die Eindeutigkeit folgt aus \ref{17.7}.
	\end{proof}
\end{thm}

\begin{kor}
	\label{17.9}
	Sei $A:I \to \Mat(n, \K)$ stetig, $t_0 \in I$  und $y_0 \in \K^n$.
	Falls $A(t)A(s) = A(s)A(t)$ für alle $s,t\in I$, dann gilt
	\[
		\phi(t) = e^{\int_{t_0}^t A(s)\;ds}y_0
	\]
	die eindeutige Lösung des Anfangswertproblems
	\[
		\dot y = A(t) y  \quad \land\quad y(t_0) = y_0
	\]
	\begin{note}
		Im Fall $A(t)=A$ für alle $t\in I$ reduziert sich die Lösung auf den bekannten Ausdruck
		\[
			\phi(t) = e^{A(t-t_0)}y_0
		\]
	\end{note}
	\begin{proof}
		\begin{align*}
			\left(\int_{t_0}^t A(s) \;ds\right)^k &= \int_{[t_0,t]^k} A(s_1) \dotsb A(s_k)\; d(s_1,\dotsc,s_k)\\
				&= k! \int_{t_0\le s_k < s_{k-1} <\dotsb < s_1 \le t} A(s_1) \dotsb A(s_k) \; d(s_1,\dotsc,s_k)\\
			 &= k! \int_{t_0}^tds_1\int_{t_0}^{s_1}ds_2 \int_{t_0}^{s_2}ds_3\dotsi\int_{t_0}^{s_k} A(s_1) \dotsb A(s_k)
		\end{align*}
	\end{proof}
\end{kor}

\begin{thm}
	Sei $A: I\to \Mat(n,\K)$ stetig, $I\subset \R$ ein Intervall.
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			Die Menge der Lösungen $\phi : I\to \K^n$ von
			\[
				\dot y = A(t) y
			\]
			ist ein $n$-dimensionaler Vektorraum über $\K$.
		\item
			Für $k$ Lösungen $\phi_1,\phi_k$ von 
			\[
				\dot y = A(t) y
			\]
			sind folgende Aussagen äquivalent
			\begin{enumerate}[(i)]
				\item
					$\phi_1,\dotsc, \phi_k$ sind linear unabhängig
				\item
					Es gibt $t_0\in I$ so dass die $\phi_0(t_0), \dotsc, \phi_k(t_0) \in \K^n$ linear unabhängig sind
				\item
					Für jedes $t\in I$ sind $\phi_1(t),\dotsc ,\phi_k(t)$ linear unabhängig in $\K^n$.
			\end{enumerate}
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Sei $\scr L$ die Menge der Lösungen des DGL-Systems.
				Dass $\scr L$ ein Vektorraum ist, folgt aus der Linearität der Gleichung (Superpositionsprinzip !?)

				Sei $\phi_k$ ($k=1,\dotsc, n$) die (eindeutige) Lösung des Anfangswertproblems
				\[
					\dot y = A(t_0)y \quad \land \quad y(t_0) = e_k
				\]
				Wobei $e_1,\dotsc, e_n$ eine Basis von $\K^n$ sei.
				Dann sind $\phi_1(t_0), \dotsc, \phi_n(t_0)$ linear unabhängig, also sind $\phi_1,\dotsc, \phi_n$ linear unabhängig nach (b).
				Also $\dim \scr L \ge n$.
				Sind $\phi_1,\dotsc \phi_m$ linear unabhängige Lösungen, dann sind
				$\phi_1(t_0), \dotsc, \phi_m(t_0)$ linear unabhängig in $\K^n$ nach (b), also $m\le n$.
				Somit gilt
				\[
					\dim \scr L = n
				\]
			\item
				\begin{seg}{„(iii)$\implies$(ii)}
					Klar?
				\end{seg}
				\begin{seg}{„(ii)$\implies$(i)“}
					Wäre $\sum_{l=1}^k c_l\phi_k \ge 0$ dann 
					\[
						\sum_{l=1}^k c_l \phi_l(t_0) = 0
					\]
				\end{seg}
				\begin{seg}{„(i)$\implies$ (iii)“}
					Angenommen (iii) sei falsch, d.h. $\exists t_0\in I$, so dass
					$\phi_1(t_0),\dotsc, \phi_k(t_0)$ linear abhängig sind.
					Dann existieren $c_1,\dotsc, c_k$ so, dass
					\[
						\sum_{l=1}^kc_l\phi_l(t_0) = 0
					\]
					$\phi=\sum_{l=1}^kc_l\phi_l$ ist eine Lösung von
					\[
						\dot y = A(t) y \quad \land \quad y(t_0) = 0
					\]
					Dieses Anfangswertproblem wird durch die Nullfunktion gelöst, also ist wegen der Eindeutigkeit der Lösung
					\[
						\phi = 0
					\]
					Ein Widerspruch zu: $\phi_1,\dotsc, \phi_k$ linear unabhängig.
				\end{seg}
		\end{enumerate}
	\end{proof}
\end{thm}

Eine Basis $\phi_1,\dotsc, \phi_n$ des Lösungsraums von
\[
	\dot y = A(t) y
\]
heißt \emph{Fundamentalsystem} des Differentialgleichungssystems.
Ist $\Phi(t) = (\phi_1(t), \dotsc, \phi_n(t))$ die zugehörige $n\times n$-Matrix, dann ist
\[
	\Phi(t) c = \sum_{l=1}^n \phi_l(t) c_l
\]
die allgemeine Lösung des Differentialgleichungssystem.
Es folgt $\dot \phi = A(t) \phi(t)$


\subsection{Inhomogene Systeme}

Sei $A : I \to \Mat(n,K)$, $b:I\to \K^n$ stetig.
Dann bekommen wir die Lösung von
\[
	\dot y = A(t)y + b(t) \quad \land \quad y(t_0) = y_0
\]
durch Variation der Konstanten (also dem Vektor $c$).
Unser Ansatz lautet	$\phi(t) = \Phi(t) u(t)$, wobei
$\Phi(t) = (\phi_1(t),\dotsc, \phi_n(t))$ aus einem Fundamentalsystem $\phi_1,\dotsc, \phi_n$ der homogenen Gleichung $\dot y = A(t)y$ besteht.
Einsetzen von $\phi$ liefert
\[
	\dot \Phi u + \Phi \dot u = \dot \phi = A\Phi u + b
\]
d.h. $\dot u(t) = \Phi(t)^{-1}b$

\begin{st}
	Ist $\phi(t) = (\phi_1(t),\dotsc, \phi_n(t))$ Fundamentalsystem von Lösungen zu $\dot y = A(t)y$ mit $\phi(t_0) = I$ die Einheitsmatrix.
	Dann ist
	\[
		\phi(t) = \Phi(t)\left(y_0 + \int_{t_0}^t\Phi(s)^{-1}b(s) \; ds\right)
	\]
	die eindeutige Lösung des Anfangswertproblems
	\[
		\dot y = A(t)y + b(t) \quad \land \quad y(t_0) = y_0
	\]
	\begin{proof}
		\fixme[Ergänzen]
		Die Anfangsbedingung ist erfüllt:
		\begin{align*}
			\phi(t_0) = \Phi(t_0) \Big(y_0+\underbrace{\int_{t_0}^t \dotso \;ds}_{=0} \Big) = I y_0 = y_0
		\end{align*}
		und
		\begin{align*}
			\dot \phi(t) &= \dot \Phi(t) (\dotso) + \Phi(t) \f {d}{dt}(\dotso)\\
			&= A\Phi(t)(\dotso) + \Phi(t)\Phi(s)^{-1}b(s)\Big|_{s=t}\\
			&= A\phi(t) + b(t)
		\end{align*}
	\end{proof}
	\begin{note}
		Das stimmt für $n=1$ mit der bekannten Formel überein (in diesem Fall vertauschen die Matrizen)
		\[
			\phi(t) = e^{\int_{t_0}^t a(s) \;ds} \left(y_0 + \int_{t_0}^t e^{-\int_{t_0}^s a(s) ds} b(s) \;ds\right)
		\]
	\end{note}
\end{st}


\subsection{Lineare Systeme mit konstanten Koeffizienten}


Sei $A\in \Mat(n\times n),\C)$ und $v_1,\dotsc,v_n$ eine Basis von $\C^n$, dann ist
\[
	e^{At}v_1, \dotsc, e^{At}v_n
\]
ein Fundamentalsystem von $\dot y= Ay$.

Wir wollen soeine Basis $v_1,\dotsc, v_n$ von $\C^n$ konstruieren, so dass sich obiges Fundamentalsystem explizit berechnen lässt.

Ist $Av = \lambda v$, dann ist
\[
	e^{At}v = e^{\lambda t}v
\]
Wenn also eine Basis aus $v_1,\dotsc, v_n$ von Eigenvektoren von $A$ zu Eigenwerten $\lambda_1,\dotsc, \lambda_n$ existiert, dann ist
\[
	e^{\lambda_1 t}v_1, \dotsc, e^{\lambda_n t}v_n
\]
Wenn $A^* = A$ oder $A^*A = AA^*$, dann existiert sogar eine Orthonormalbasis bestehend aus Eigenvektoren von $A$.

\begin{df*}
	Ein Vektor $v\in \C^n$ heißt \emph{Hauptvektor der Stufe $k$} von $A\in \Mat(n\times n,\C)$, wenn $\lambda \in \C$ existiert, so dass
	\[
		(A-\lambda)^kv = 0 \qquad \land \qquad (A-\lambda)^{k-1}v \neq 0
	\]
	\begin{note}
		Ein Hauptvektor der Stufe $k$ ist aus dem Hauptraum der Stufe $k$: $\ker(A-\lambda I)^k$.
	\end{note}
	\begin{note}
		\begin{enumerate}[1)]
			\item
				Nach der Bedingung ist $(A-\lambda)^{k-1}v$ ein Eigenvektor von $A$ zum Eigenwert $\lambda$.
			\item
				Die Hauptvektoren der Stufe $1$ sind genau die Eigenvektoren.
			\item
				Es folgt
				\[
					e^{At}v = e^{\lambda t}e^{(A-\lambda)t}v = e^{\lambda t} \sum_{m=0}^{k-1}\f{t^m}{m!}(A-\lambda)^m v
				\]
		\end{enumerate}
	\end{note}
\end{df*}


\begin{st}
	\label{17.12}
	Zu jeder Matrix $A\in \Mat(n\times n,\C)$ gibt es eine Basis von $\C^n$ bestehend aus Hauptvektoren von $A$.

	Zu jedem $k$-Fachen Eigenwert gibt es $k$ Hauptvektoren der Stufe $\le k$.
	\begin{proof}
		Es existiert eine invertierbare Matrix $C$, so dass $C^{-1}AC$ in Jordanform, bestehend aus quadratischen Blöcken $J_i\in \Mat(r_i\times r_i, \C)$ der Form
		\[
			J_i = \lambda_i I_{r_i} + N_i
		\]
		besteht, wobei $N_i^{r_i} = 0$.
		Für jeden Vektor $v$ im zugehörigen $r_i$-dimensionalen Unterraum von $\C^n$ gilt also
		\[
			C^{-1}(A-\lambda_i)^{r_i}Cv = (C^{-1}AC - \lambda_i)^r_i v = N_i^{r_i}v = 0
		\]
		Also
		\[
			(A-\lambda_i)^{r_i}(Cv) = 0
		\]
	\end{proof}
\end{st}

\begin{ex*}
	Sei
	\[
		A = \begin{pmatrix}\lambda & 1 & 2\\ 0& \lambda&1\\ 0& 0& \lambda\end{pmatrix}
	\]
	Dann ist
	\begin{align*}
		(A-\lambda)e_1 = 0 &\implies e^{At}e_1 = e^{\lambda t}e_1\\
		(A-\lambda)e_2 = e_1 \implies (A-\lambda)^2e_2 = 0 &\implies e^{At}e_2 = e^{\lambda t}(I+t(A-\lambda))e_2 = e^{\lambda t}(e_2 + t e_1)\\
		(A-\lambda)e_3 = 2e_1 + e_2 \implies (A-\lambda)^3e_3 = 0 &\implies e^{At}e_3 = e^{lambda t}(E + t(A-\lambda) + \f{t^2}2 (A-\lambda)^2) e_3 = e^{\lambda t}((2t + \f {t^2}2)e_1 + te_2 + e_3)
	\end{align*}
\end{ex*}


\section{Lineare DGL $n$-ter Ordnung}


Wir betrachten
\[
	y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dotsb + a_1(x)y' + a_0(x)y = b(x)
\]
wobei $a_k, b : I\to \K$ stetig sind und $I\subset \R$ ein Intervall ist.

\begin{st}
	\label{17.13}
	Sei $a_k, b : I\to \K$ stetig und $I\subset \R$ ein Intervall.
	Sei folgende Differentialgleichung gegeben:	
	\[
		y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dotsb + a_1(x)y' + a_0(x)y = b(x)
	\]
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			Die Menge der Lösungen $\phi:I\to \K$ der homogenen Differentialgleichung
			\[
				y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dotsb + a_1(x)y' + a_0(x)y = 0
			\]
			ist ein $n$-dimensionaler Vektorraum über $\K$.
			Eine Basis dieses Vektorraums heißt Fundamentalsystem der homogenen Differentialgleichung.
		\item
			Ist $\phi_p$ eine partikuläre Lösung der inhomogenen Differentialgleichung und $\phi_1,\dotsc, \phi_n$ ein Fundamentalsystem der homogenen Gleichung, dann ist
			\[
				\phi_p + \sum_{k=1}^n c_k\phi_k \qquad c_k \in \K
			\]
			die allgemeine Lösung des inhomogenen Systems
		\item
			$n$ Lösungen $\phi_1,\dotsc, \phi_n$ der homogenen Systems sind genau dann linear unabhängig, wenn für ein $x$ (und damit für alle $x\in I$) die \emph{Wronski-Determinante}
			\[
				W(x) = \det \begin{pmatrix}\phi_1(x) & \phi_2(x) & \cdots & \phi_n(x)\\
				\phi_1'(x) & \phi_2'(x) & \cdots & \phi_n'(x)\\
				\vdots & \vdots & \ddots & \vdots\\
				\phi_1^{(n-1)}(x) & \phi_2^{(n-1)}(x) & \cdots & \phi_n^{(n-1)}(x)
				\end{pmatrix}
			\]
			von Null verschieden ist.
	\end{enumerate}
	\begin{proof}
		Jede Lösung $\phi$ der inhomogenen Gleichung entsprucht einer Lösung $(\phi,\phi',\dotsc, \phi^{(n-1)})^T$ des Systems
		\begin{align*}
			y_1' &= y_2\\
			y_2' &= y_3 \\
			\vdots \; &= \; \vdots\\
			y_n' &= -a_0(x) y_1 -a_1(x)y_2 - \dotsb -a_{n-1}(x)y_n + b(x)
		\end{align*}
		Daher folgen die Aussagen (a) und (c) aus \ref{17.10}.

		Die rechte Seite der inhomogenen Gleichung sei mit $Ly$ bezeichnet, also
		\[
			Ly = y^{(n)} + a_{n-1}(x)y^{(n-1)} + \dotsb + a_0(x)y
		\]
		Dann gilt
		\[
			L\left(\phi_p + \sum_{k=1}^nc_k\phi_k\right) = L\phi_p + \sum_{k=1}^n c_k(L\phi_k) = b
		\]
		Sei umgekehrt $L\phi = b$ und $L\phi_p = b$, dann
		\[
			L(\phi-\phi_p) = 0
		\]
		Also kann man schreiben
		\[
			\phi-\phi_p = \sum_{k=1}^nc_k \phi_k
		\]
		und die Lösung lässt sich darstellen als
		\[
			\phi = \phi_p + \sum_{k=1}^n c_k \phi_k
		\]
	\end{proof}
\end{st}

\subsection{Partikuläre Lösung}

Wir schreiben das inhomogene System als
\[
	y' = A(x)y + \beta(x)
\]
wobei
\[
	A(x) = \begin{pmatrix}
		0 & 1 & \cdots & 0 \\
		\vdots & \ddots & \ddots & \vdots \\
		-a_0 & -a_1 & \cdots & -a_n\\
	\end{pmatrix} \qquad \beta(x) = \begin{pmatrix} 0\\\vdots \\ 0\\ b(x)\end{pmatrix}
\]
Ist $\phi_1,\dotsc, \phi_n$ ein Fundamentalsystem der homogonen Gleichung, dann ist
			\[
				\Phi(x) = \begin{pmatrix}\phi_1(x) & \phi_2(x) & \cdots & \phi_n(x)\\
				\phi_1'(x) & \phi_2'(x) & \cdots & \phi_n'(x)\\
				\vdots & \vdots & \ddots & \vdots\\
				\phi_1^{(n-1)}(x) & \phi_2^{(n-1)}(x) & \cdots & \phi_n^{(n-1)}(x)
				\end{pmatrix}
			\]
eine \emph{Fundamentalmatrix} von $y'=Ay$.
Nach \ref{17.11} ist
\[
	\Phi(x) \int_{x_0}^x \Phi(s)^{-1}\beta(s) \; ds
\]
eine partikuläre Lösung von
\[
	y' = A(x)y + \beta(x)
\]
wobei $\alpha(s) = \Phi(s)^{-1}\beta(s)$ aus $\Phi(s)\alpha(s) = \beta(s)$ mit der Cramerschen Regel bestimmen können.
Es gilt
\[
	\alpha_i(x) = \f 1{W(x)} \det \begin{pmatrix} 
		\phi_1 & \cdots & \phi_{i-1} & 0 & \phi_{i+1} & \cdots & \phi_n\\
		\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
		\phi_1^{(n-1)} & \cdots & \phi_{i-1}^{(n-1)}
	\end{pmatrix}
	= (-1)^{i+n}\f{W_i(x)}{W(x)}
\]
wobei $W(x) = \det \phi(x)$ und $W_i =: \det (\Phi^{(n,i)})$.
$\Phi^{(n,i)}$ ist eine $(n-1)\times(n-1)$-Matrix entstanden aus $\phi$ durch Streichen der $n$-ten Zeile und der $i$-ten Spalte.

Also
\[
	\phi_p(x) = \left(\Phi(x) \int_{x_0}^x \alpha(s) \; ds\right)_1 = \sum_{k=1}^n \Phi_{1,k}(x) \int_{x_0}^x \alpha_k(s) \; ds = \sum_{k=1}^n (-1)^{k+n}\phi_k(x) \int_{x_0}^x \f{W_k(s)}{W(s)}b(s) \; ds
\]
Im Fall $n=2$ erhalten wir eine einfachere Form für die partikuläre Lösung
\[
	\phi_p(x) = \int_{x_0}^x \f{\phi_2(x)\phi_1(s) - \phi_1(x) \phi_2(s)}{W(s)}b(s) \; ds
\]
wobei $\phi_1,\phi_2$ ein Fundamentalsystem der homogenen Gleichung und $W=\phi_1\phi_2' - \phi_1'\phi$ die zugehörige Wornski-Determinante ist.


\section[DGLs $n$-ter Ordnung mit konstanten Koeffizienten]{Differentialgleichungen $n$-ter Ordnung mit konstanten Koeffizienten}


Sei $Ly = y^{(n)} + a_{n-1}y^{(n-1)}+ \dotsb + a_1y' + a_0 y$ mit $a_i \in \C$.
Zur Bestimmung des Lösungsraums machen wir den Ansatz $\phi(x) = e^{\lambda x}$, $\lambda\in \C$.
Wegen
\[
	L\phi = p(\lambda)e^{\lambda x}
\]
mit dem charakteristischen Polynom (Übung: entspricht bis auf Vorzeichen dem charakeristischen Polynom der Matrix)
\[
	p(x) = \lambda^n + a_{n-1}\lambda^{n-1} + \dotsb + a_1\lambda + a_0
\]
D.h. $\phi$ ist genau dann eine Lösung von $Ly=0$, wenn $\lambda$ eine Nullstele von $p$ ist.

\begin{st}
	\label{17.14}
	Ist $\lambda$ eine $m$-fache Nullstelle von $p$, dann entsprechen ihr die $m$ linear unabhängigen Lösungen
	\[
		e^{\lambda x}, xe^{\lambda x}, \dotsc, x^{m-1}e^{\lambda x}
	\]
	von $Ly=0$.
	Die Kollektion dieser Lösungen zu allen Nullstellen von $p$ ist ein Fundamentalsystem von $Ly=0$.

	Sind die $a_i$ \emph{reell} und ist $\my + iv$ ein Paar von $m$-fachen Nullstellen von $p$, dann kann man die zugehörigen $2m$ Lösungen des Fundamentalsystems durch die reellen Lösungen
	\[
		\left\{ x^ke^{\my x}\cos(\my u), x^k e^{\my x}\sin(\my x) \Big| k= 0,\dotsc, m-1\right\}
	\]
	ersetzen.
	\begin{proof}
		Sei $\lambda_0$ eine $m$-fache Nullstelle von $p$, d.h. $p^{(k)}(\lambda_k) = 0$ für $k=0,\dotsc,m-1$.
		Dann gilt
		\begin{align*}
			L (x^ke^{\lambda_0 x}) &= L\left( \left(\f{\d}{\d \lambda}\right)^k e^{\lambda x}\right) \Big|_{\lambda=\lambda_0}
			&= \left(\f{\d}{\d \lambda} \right)^k L(e^{\lambda x}\Big|_{\lambda = \lambda_0}\\
			&= \left(\f{\d}{\d \lambda}\right)^k p(\lambda) e^{\lambda x} \Big|_{\lambda = \lambda_0}\\
			&= \sum_{l=0}^k \binom{k}{l}p^{(l)}(\lambda) \left( \f{\d}{\d \lambda}\right)^{k-l}e^{\lambda y}\Big|_{\lambda - \lambda_0}\\
			&= \sum_{l=0}^k \binom{k}{l}\underbrace{p^{(l)}(\lambda_0)}_{=0} x^{k-l}e^{\lambda_0 x} = 0
		\end{align*}
		Rest: Übung
	\end{proof}
\end{st}

\begin{ex*}
	Sei folgende DGL gegeben:
	\[
		2y''' - 5y'' + 6y' - 2y = 0
	\]
	Die charakteristische Gleichung
	\[
		2\lambda^3 - 5\lambda^2 + 6\lambda - 2 = 0
	\]
	hat die Lösungen $\lambda_1 = \f 12, \lambda_2 = 1+i, \lambda_3 = 1-i$.
	Das Fundamentalsystem hat die Form
	\[
		e^{\f x2}, e^{(1+i)x}, e^{(1-i)x}
	\]
	bzw.
	\[
		e^{\f x2}, e^{x}\cos x, e^{x}\sin x
	\]
\end{ex*}

Eine partikuläre Lösung der inhomogenen Gleichung
\[
	Ly = (b_0 + b_1 x + \dotsb + b_k x^k)e^{w x} \qquad w\in \C
\]
findet man mit einem Ansatz vom Typ der rechten Seite.
D.h. man macht den Ansatz
\[
	\phi(x) = (A_0 + A_1 + \dotsb + A_kx^k) e^{wx} \qquad p(w) \neq 0
\]
bzw.
\[
	\phi(x) = x^m(A_0 + A_1 + \dotsb + A_kx^k) e^{wx} \qquad \text{ wenn $w$ $m$-fache Nullstelle von $p$}
\]
\begin{note}
	Auch für $b(x) = x^k e^{wx}$ macht man obige Ansätze mit Polynomen $x_0 + A_1x + \dotsb + A_kx^k$.
	Keine Vereinfachung.
\end{note}

\begin{ex*}
	Sei folgende Differentialgleichung gegeben
	\[
		y'' + 4y = x^2 + 5 \cos(2x)
	\]
	Suche partikuläre Lösungen $\phi_1, \phi_2$ von
	\[
		y'' + 4y = x^2 \qquad \text{bzw.} y'' + 4y = 5e^{2ix}
	\]
	Dann ist $\phi_p = \phi_1 + \Re(\phi_2)$ eine partikuläre Lösung der Differentialgleichung wegen:
	\begin{proof}
		\[
			L\phi_p = L(\phi_1 + \Re(\phi_2)) = L\phi_1 + L\left(\f{\phi_2 + \_{\phi_2}}2\right) = x^2 + \Re(5e^{2ix}) = x^2 + 5\cos(2x)
		\]
	\end{proof}
	\begin{seg}{Ansatz für $\phi_1$}
		\[
			\phi_1(x) = A + Bx + Cx^2
		\]
		denn $p(\lambda) = \lambda^2 + 4$ hat die Nullstellen $\pm 2i$ und nicht $w=0$.
		Man erhält durch Einsetzen
		\[
			A = -\f 18, \; B=0,\; C = \f 14
		\]
		Also
		\[
			\phi_1(x) = -\f 18 + \f 14 Cx^2
		\]
	\end{seg}
	\begin{seg}{Ansatz für $\phi_2$}
		\[
			\phi_2(x) = xDe^{2ix}
		\]
		denn $p(\lambda) = \lambda^2 + 4$ hat die Nullstellen $\pm 2i$, also ist $w=2i$ einfache Nullstelle.
		Man erhält
		\[
			D = -\f	54 i
		\]
		Also
		\[
			\phi_2(x) = -\f 54 i xe^{2ix}
		\]
	\end{seg}
	Die partikuläre Lösung ergibt sich dann durch
	\[
		\phi_p = \phi_1 + \Re(\phi_2) = -\f 18 + \f 14x^2 + \f 54 x\sin(2x)
	\]
	Die allgemeine Lösung ergibt sich dann als
	\[
		\phi = \phi_p + c_1\cos(2x) + c_2\sin(2x)
	\]
\end{ex*}


\end{document}
