\chapter{Vektorbündel und Tensoren}

\Timestamp{2015-12-09}

Neben dem Tangentialbündel wollen wir nun auch andere Vektorräume punktweise an eine Mannigfaltigkeit „anheften“, vor allem Vektorräume, die sich nicht durch Grundkonstruktionen der Linearen Algebra aus dem Tangentialbündel ergeben, z.B. Linearformen und Multilinearformen auf dem Tangentialraum oder Endomorphismen des Tangentialraums.
Dies führt auf den Begriff des Vektorbündels.

\begin{df}[Faserbündel] \label{5.1}
    Seien $M, B, Z$ glatte Mannigfaltigkeiten, $\pi: M \to B$ eine glatte Abbildung, $(U_j)_{j\in J}$ eine offene Überdeckung von $B$ und seien
    \begin{math}
        h_j: \pi^{-1}(U_j) \to U_j \times Z
    \end{math}
    Diffeomorphismen, so dass $\pi|_{\pi^{-1}(U_j)} = \proj_1 \circ h_j$.
    Dann heißt $\pi$ zusammen mit $(h_j)_{j\in J}$ \emphdef{Faserbündel mit typischer Faser $Z$}.
    Die $h_j$ heißen \emphdef{lokale Trivialisierungen}.
    $B$ heißt \emphdef{Basis}, $M$ \emphdef{Totalraum des Bündels}.

    Gilt $M = B \times Z$ mit $\pi = \proj_1$, dann heißt $\pi$ \emphdef{triviales Bündel}.

    Für $p \in B$ heißt $\pi^{-1}(\Set{p})$ \emphdef{Faser über $p$}.
\end{df}

\begin{ex*}
    \begin{enumerate}[(i)]
        \item
            Das Tangentialbündel $\T M$ mit Basis $M$ und $\pi$ Fußpunktabbildung und typischer Faser $\T_p M$ für ein $p \in M$ bilden ein Faserbündel.
        \item
            $\R^{n+1} \setminus \Set 0$ ist ein Faserbündel über $\RP^n$ mit
            \begin{math}
                \pi: (x_1, \dotsc, x_{n+1}) \mapsto [x_1: \dotsb : x_{n+1}]
            \end{math}
            und typischer Faser $\R \setminus \Set 0$.
        \item
            Hopf-Faserung, siehe Übungsblatt 8.
    \end{enumerate}
\end{ex*}

\begin{st}[Ehresmannscher Faserungssatz] \label{5.2}
    Seien $M, B$ glatte Mannigfaltigkeiten und sei $\pi: M \to B$ eine eigentliche (d.h. Urbilder kompakter Mengen sind kompakt), surjektive Submersion.
    Dann ist $\pi$ ein Faserbündel.
    \begin{proof}
        Siehe Literatur.
    \end{proof}
\end{st}

\begin{df} \label{5.3}
    Ein Faserbündel mit diskreter Faser wird auch \emphdef{Überlagerung} genannt. 
    Ist die Faser endlich mit Kardinalität $n$, so spricht man von $n$-facher Überlagerung.
    \begin{note}
        \begin{itemize}
            \item
                Im Falle einer Überlagerung ist $\pi$ ein lokaler Diffeomorphismus.
            \item
                $U_j$ wird hier auch \emphdef{überlagerte Umgebung} genannt.
        \end{itemize}
    \end{note}
\end{df}

\begin{ex*}
    \begin{enumerate}[(i)]
        \item
            Sei $S^n \subset \R^{n+1}$ die Einheitssphäre, dann ist $\pi: S^n \to \RP^n, x \mapsto [x]$ (homogene Koordinaten) eine $2$-fache Überlagerung.
            Die Faser über $[x] \in \RP^n$ ist $\pi^{-1}([x]) = \Set{x, -x}$.
        \item
            $\pi: \operatorname{Spin}(n) \to \SO(n)$ ist $2$-fache Überlagerung, falls $n \ge 3$.
        \item
            $\pi: \R \mapsto S^1, t \mapsto e^{it}$ ist eine Überlagerung mit abzählbar unendlichen Fasern $t + 2\pi\Z$.
    \end{enumerate}
\end{ex*}

\begin{df} \label{5.4}
    Ein \emphdef{Schnitt} eines Faserbündels $\pi: M \to B$ ist eine glatte Abbildung $s: B \to M$, sodass $\pi \circ s = \id_B$ gilt.

    Die Menge der Schnitte wird mit $\Gamma(B, M)$ bezeichnet.
    \begin{note}
        Ein Schnitt ist eine Einbettung $s: B \to M$.
    \end{note}
\end{df}

\begin{ex*}
    \begin{itemize}
        \item
            Vektorfelder auf einer Mannigfaltigkeit $M$ sind genau die Schnitte im Tangentialbündel $\T M$, d.h. $\scr X(M) = \Gamma(M, \T M)$.
        \item
            $C^\infty(M) = \Gamma(M, M \times \R)$.
    \end{itemize}
\end{ex*}

\begin{nt} \label{5.5}
    Sei $\pi: M \to B$ ein Faserbündel mit lokalen Trivialisierungen $h_j$, $j \in J$.
    Für $j, k \in J$ ist die Abbildung
    \begin{math}
        h_j \circ h_k^{-1}: (U_j \cap U_k) \times Z \to (U_j \cap U_k) \times Z
    \end{math}
    von der Form $(u, z) \mapsto (u, g_{jk}(u,z))$, wobei $g_{jk}(u,\argdot)$ ein Diffeomorphismus auf $Z$ ist (vgl. Übungsaufgabe 28).

    Die Abbildung $g_{jk}(u, \argdot)$ wird \emphdef{Übergangsabbildung} genannt.
\end{nt}

\begin{df} \label{5.6}
    Ein Faserbündel heißt \emphdef{$\K$-Vektor(raum)bündel} vom \emphdef{Rang} $r$, falls die typische Faser $Z$ ein $\K$-Vektorraum der Dimension $r$ ist und alle Übergangsabbildungen $g_{jk}(u, \argdot)$ linear sind.

    Jedes Vektorraumbündel hat als kanonischen Schnitt den \emphdef{Nullschnitt} $s \equiv 0$.

    Ein Vektorraumbündel vom Rang $1$ heißt \emphdef{Linienbündel}.
    \begin{note}
        \begin{itemize}
            \item
                Die Übergangsabbildungen sind quasi Vektorraumautomorphismen von $Z$.
            \item
                $\dim(E) = \dim(Z) + \dim(B)$.
        \end{itemize}
    \end{note}
\end{df}

\begin{ex*}
    Vektorraum-Bündel
    \begin{enumerate}[(i)]
        \item
            $\T M$.
        \item
            Zylinder $\Set{(e^{it}, s) & t,s \in \R} \subset \C^2$.
        \item
            Möbiusband $\Set{(e^{it}, s e^{i\frac{t}{2}}) & t,s \in \R} \subset \C^2$.
    \end{enumerate}
\end{ex*}

\Timestamp{2015-12-15}

\begin{df}[Pullback] \label{5.7}
    Sei $f: M \to N$ eine glatte Abbildung und $\pi: E \to N$ ein Vektorbündel über $N$.
    Definiere
    \begin{math}
        f^* E := \Set{(p,v) \in M \times E & \pi(v) = f(p)}.
    \end{math}
    Das Vektorbündel $f^* \pi = \proj_1: f^* E  \to M$ heißt \emphdef{Pullback} von $E$ unter $f$.
    \begin{note}
        Hat $E$ lokale Trivialisierungen $h_j: \pi^{-1}(U_j) \to U_j \times V$, dann hat $f^* E$ lokale Trivialisierungen
        \begin{math}
            f^* h_j: \proj_1^{-1}(f^{-1}(U_j)) &\to f^{-1}(U_j) \times V, \\
            (p, v) &\mapsto (p, \proj_2(h_j(v))).
        \end{math}
    \end{note}
    Der Pullback von Vektorbündeln induziert auch einen \emphdef{Pullback} von Schnitten:
    \begin{math}
        f^*: \Gamma(N, E) &\to \Gamma(M, f^*E) \\
        s &\mapsto s \circ f
    \end{math}
    \begin{note}
        Anschaulich bedeutet $f^* E$, dass an jedem $p \in M$ der Vektorraum $E_{f(p)}$ „angehängt wird“.
        Die umgekehrte Konstruktion „Pushforward“  funktioniert im Allgemeinen für Vektorbündel nicht (z.B. weil $f$ im Allgemeinen kein Homömorphismus ist).
        Für Diffeomorphismen $g: N \to M$ definieren wir den Pushforward als $g_* E := (g^{-1})^* E$.
    \end{note}
\end{df}

\begin{df} \label{5.8}
    Für zwei Vektorbündel $\pi: E \to M$, $\tilde \pi: F \to M$ über derselben Mannigfaltigkeit $M$ heißt eine Abbildung $\phi: E \to F$ heißt \emphdef{Vektorbündelhomomorphismus}, falls
    \begin{enumerate}[(i)]
        \item
            das folgende Diagramm kommutiert:
            \begin{math}
                \begin{tikzcd}
                    E \ar[rr,"\phi"] \ar[rd,"\pi"'] & & F \ar[ld,"\tilde \pi"] \\
                    & M
                \end{tikzcd},
            \end{math}
            d.h. $\phi$ bildet für alle $p \in M$ die Faser $E_p$ in die Faser $F_p$ ab
        \item
            und $\phi$ \emphdef{faserweise linear} ist, d.h. die nach (i) induzierte Abbildungen $\phi_p: E_p \to F_p$ sind linear für alle $p \in M$.
    \end{enumerate}
    \begin{note}
        Zum Beispiel ist die Weingartenabbildung einer regulären Fläche ein Vektorbündelendomorphismus.
    \end{note}
\end{df}


\section[Tensoren]{Tensoren und ein „Baukasten“ für Vektorräume und Vektorbündel}

Die Grundkonstruktionen (für Vektorräume) der linearen Algebra liefern zu gegebenen Vektorräumen $V, W, \dotsc$ neue, daraus konstruierte, z.B. die direkte Summe $V \oplus W$, den Dualraum $V^*$, die linearen Abbildungen $\Hom(V,W)$, die Bilinearformen $\Bil(V)$.

Diese Konstruktionen wollen wir auf Vektorbündel übertragen und unter einem einheitlichen Gesichtspunkt zusammenfassen.


\begin{df} \label{5.9}
    Seien $\pi: E \to M$, $\tilde \pi: F \to M$ Vektorbündel über der selben Mannigfaltigkeit $M$.
    Seien (ohne Einschränkung durch entsprechende Einschränkung) die lokalen Trivialisierungen
    \begin{math}
        h_j: \pi^{-1}(U_j) &\to U_j \times V, \\
        \tilde h_j: \tilde \pi^{-1}(U_j) &\to U_j \times W
    \end{math}
    gegeben.

    Dann ist die direkte Summe $E \oplus F \to M$ das Vektorbündel
    \begin{math}
        E \oplus F := \Set{(p,v,w) & p \in M, v \in E_p, w \in F_p}
        \xto{\hat \pi = \proj_1} M
    \end{math}
    mit den lokalen Trivialisierungen
    \begin{math}
        \hat h_j: \hat \pi^{-1}(U_j) &\to U_j \times (V \oplus W) \\
        (p,v,w) &\mapsto (p, h_j(v), \tilde h_j(w)).
    \end{math}
    Analog definiert man $E^*$, $\Hom(E, F)$, $E / F$ (\emphdef{Quotientenbündel} für ein Unterbündel $F \subset E$), z.B.
    \begin{math}
        E^* = \Set{ (p, \alpha) & p \in M, \alpha \in E_p^*}
    \end{math}
    mit lokaler Trivialisierung
    \begin{math}
        h_j^*: \Set{(p, \alpha) & p \in U_j, \alpha \in E_p^*} &\to U_j \times V^* \\
        (p, \alpha) &\mapsto (p, \alpha \circ h_j^{-1}(p, \argdot))
    \end{math}
\end{df}


Das \emphdef{Tensorprodukt} $V \otimes W$ zweier Vektorräume $V$ und $W$ ist eine Konstruktion mit der man bilineare Abbildungen $V \times W \to Z$ beschreiben kann.

Beispielsweise lässt sich jede Bilinearform $\beta: V \times W \to \K$ durch die Werte von $\beta$ auf Paaren von Basisvektoren $(v_i, w_j)$ beschreiben, wobei $(v_i)_{i\in I}$, $(w_j)_{j\in J}$ Baasen von $V$, bzw. $W$ sind, dann gilt ja:
Ist $v = \sum_i \lambda_i v_i$, $w = \sum_j \mu_j w_j$, so gilt
\begin{math}
    \beta(v,w)
    = \beta\l(\sum_i \lambda_i v_i, \sum_j \mu_j w_j\r)
    = \sum_{i,j} \lambda_i \mu_j \beta(v_i, w_j).
\end{math}
Die \emph{bilineare} Abbildung $\beta$ lässt sich somit durch eine lineare Abbildung $U \to \K$ ersetzen, wobei $U$ der Vektorraum ist, für den die Paare $(v_i, w_j)$ eine Basis bilden.
(Bei endlich-dimensionalen Vektorräumen $V, W$ ordnet man $\beta$ die Strukturmatrix $\beta(v_i, w_j))_{i,j}$ zu.)


\Timestamp{2015-12-16}


Idee: Ersetze bilineare Abbildung durch eine lineare: ist z.B. $\beta: V \times W \to \K$ eine Bilinearform, dann ist $\beta$ durch seine Werte $\beta(v_i, w_j)$ bereits eindeutig bestimmt (falls $V$ und $W$ endlichdimensional, dann durch eine Strukturmatrix).

\begin{df} \label{5.10}
    Seien $V, W$ $\K$-Vektorräume.
    Das \emphdef{Tensorprodukt} ist der Vektorraum $V \otimes W$, zusammen mit einer bilinearen Abbildung $\kappa: V \times W \to V \otimes W$, so dass folgende universelle Eigenschaft gilt:
    Für alle bilinearen Abbildungen $\sigma: V \times W \to Z$ gibt es genau eine lineare Abbildung $f_\sigma: V \otimes W \to Z$, so dass das folgende Diagramm kommutiert:
    \begin{math}
        \begin{tikzcd}
            V \times W \ar[r,"\kappa"] \ar[rd,"\sigma"'] & V \otimes W \ar[d,"\exists! f_\sigma",dashed] \\
            & Z
        \end{tikzcd}
    \end{math}
    \begin{note}
        Dies kann man so interpretieren: $V \otimes W$ ist einerseits „groß genug“, um alle bilinearen Abbildungen $V \times W \to Z$ zu beschreiben und andererseits der „kleinste“ solche Vektorraum.

        Eindeutigkeit: siehe folgendes Lemma.
        Existenz: siehe Literatur.
    \end{note}
\end{df}

\begin{lem} \label{5.11}
    $V \otimes W$ ist eindeutig bestimmt (bis auf Isomorphie).
    \begin{proof}
        Angenommen es gibt ein zweites Tensorprodukt $\tilde \kappa: V \times W \to V \tilde \otimes W$.
        Dann hat man folgendes kommutative Diagramm:
        \begin{math}
            \begin{tikzcd}
                & V \otimes W \ar[dd,"\exists! f_\kappa"',shift right,dashed] & \\
                V \times W \ar[ru,"\kappa"] \ar[rd,"\tilde \kappa"] & \\
                & V \tilde \otimes W \ar[uu,"\exists! f_{\tilde \kappa}"',shift right,dashed]
            \end{tikzcd}
        \end{math}
        woraus
        \begin{math}
            \kappa
            = f_{\tilde \kappa} \circ \tilde \kappa
            = f_{\tilde \kappa} \circ f_\kappa \circ \kappa
        \end{math}
        folgt.
        Betrachte nun
        \begin{math}
            \begin{tikzcd}
                V \times W \ar[r,"\kappa"] \ar[dr,"\kappa"'] & V \otimes W \ar[d,"\id_{V\otimes W}"',shift right] \ar[d,"f_{\tilde \kappa} \circ f_\kappa",shift left] \\
                & V \otimes W
            \end{tikzcd}.
        \end{math}
        Wegen der universellen Eigenschaft folgt also $f_{\tilde \kappa} \circ f_\kappa = \id_{V \otimes W}$.
        Analog folgt $f_\kappa \circ f_{\tilde \kappa} = \id_{V \tilde \otimes W}$, also sind die Abbildungen invers zueinander und $V \otimes W \isomorphic V \tilde \otimes W$.
    \end{proof}
    \begin{note}
        \begin{itemize}
            \item
                Für endlich-dimensionale Vektorräume gilt $\dim(V \otimes W) = \dim(V) \dim(W)$.
            \item
                Das Bild $\kappa(v,w)$ eines Paares $(v, w)$ von Vektoren $v \in V$, $w \in W$ wird mit $v \otimes w$ bezeichnet.
                Dies sind die sogenannten \emphdef{reinen Tensoren}.
            \item
                Die Elemente von $V \otimes W$ lasssen sich als Linearkombinationen von Elementen der Form $v \otimes w$ darstellen:
                \begin{math}
                    \sum_{i\in I, j \in J} a_{ij} v_i \otimes w_j,
                \end{math}
                wobei $(v_i)_{i \in I}$, $(w_j)_{j \in J}$ Basen von $V$, bzw. $W$ sind.
            \item
                Im Fall $V = \R^n$, $W = \R^m$ gilt $V \otimes W = \R^{n \times m}$ und dann ist die Abbildung $\kappa: V \times W \to V \otimes W$ gegeben als
                \begin{math}
                    \kappa(x,y) = x y^T.
                \end{math}
                Insbesondere $e_i \otimes e_j = E_{i,j}$ (Matrix mit 1 in $(i,j)$ und sonst Null).
        \end{itemize}
    \end{note}
\end{lem}

\begin{lem} \label{5.12}
    Für die beiden Verknüpfungen $\oplus$ und $\otimes$ auf den $\K$-Vektorräumen haben folgende Eigenschaften:
    \begin{enumerate}[(i)]
        \item
            Distributivität: $(U \oplus V) \otimes W \isomorphic (U \otimes W) \oplus (V \otimes W)$,
        \item
            neutrales Element: $V \otimes K \isomorphic V$,
        \item
            Assoziativität: $(U \otimes V) \otimes W \isomorphic U \otimes (V \otimes W)$,
        \item
            Kommutativität: $V \otimes W \isomorphic W \otimes V$.
    \end{enumerate}
    Falls $V$ und $W$ endlich-dimensional sind, gilt auch
    \begin{enumerate}[(i),start=5]
        \item
            $(V \otimes W)^* \isomorphic V^* \otimes W^*$.
        \item
            $\Hom(V, W) \isomorphic V^* \otimes W$.
    \end{enumerate}
    Alle diese Isomorphismen sind \emph{kanonisch}, d.h. können ohne Wahlen von Basen angegeben werden.
    \begin{proof}
        Zeige (vi), Rest Übung.
        Definiere
        \begin{math}
            f: V^* \otimes W &\to \Hom(V, W) \\
            \alpha \otimes w &\mapsto (v \mapsto \alpha(v) w).
        \end{math}
        Zeige Linearität und Injektivität durch Basisvektoren, Bijektivität folgt aus Dimensionsgründen.
    \end{proof}
\end{lem}

Anwendung: Damit lässt sich jede verschachtelte Kombination von $\Bil, \End, \Hom, \otimes, \argdot^*$,
endlichdimensionaler Vektorräume $V_1, \dotsc, V_m$ als Tensorprodukt mit den Faktoren $V_1, \dotsc, V_m, V_1^*, \dotsc V_m^*$ schreiben, z.B. gilt
\begin{math}
    \Hom(V, V') \otimes \Hom(W, W')
    &\isomorphic V^* \otimes V' \otimes W^* \otimes W' \\
    &\isomorphic \Hom(V \otimes W, V' \otimes W').
\end{math}
oder
\begin{math}
    \Hom(\Hom(U,V), W)
    &= \Hom(U,V)^* \otimes W \\
    &= (U^* \otimes V)^* \otimes W \\
    &= U \otimes V^* \otimes W.
\end{math}

\begin{note}
    Für Homomorphismen $f: V \to V'$, $g: W \to W'$ definiert man $f \otimes g: V \otimes W \to V' \otimes W'$ durch
    \begin{math}
        (f \otimes g)(v \otimes w)
        := f(v) \otimes g(w).
    \end{math}
\end{note}

\begin{df} \label{5.13}
    Sei $V$ ein reeller Vektorraum, $q \in \N$.
    Der Raum der \emphdef{$q$-Multilinearformen} auf $V$ ist
    \begin{math}
        {V^*}^{\otimes q} := \underbrace{V^* \otimes V^* \otimes \dotsb \otimes V^*}_{\text{$q$-mal}}.
    \end{math}
    Die \emphdef{Tensoralgebra} auf $V$ ist $\bigotimes V^* = \bigoplus_{q \ge 0} {V^*}^{\otimes q}$ mit Operationen $(\oplus, \otimes)$.
\end{df}

\Timestamp{2015-12-22}

Analog wie in \ref{5.9} definiert man $E \otimes F$ für zwei Vektorbündel $E, F$ über $M$.

\begin{df} \label{5.14}
    Das Vektorbündel $\T^* M := (\T M)^*$ heißt \emphdef{Kotangentialbündel} von $M$.
    Setze
    \begin{math}
        \T^p_q M := {\T M}^{\otimes p} \otimes (\T M^*)^{\otimes q}.
    \end{math}
    Die \emph{Schnitte} von $\T^p_q M$, d.h. Elemente aus $\Gamma(M, \T^p_q)$ heißen \emphdef{$(p,q)$-Tensoren}, oder \emphdef[Tensor!kovariant]{$p$-fach kovariante} und \emphdef[Tensor!kontravariant]{$q$-fach kontravariante} Tensoren.
\end{df}

\begin{ex*}
    Sei $M$ eine reguläre Fläche im $\R^3$ (d.h. 2-dimensionale Untermannigfaltigkeit des $\R^3$).
    \begin{enumerate}[(i)]
        \item
            Die erste, bzw. zweite Fundamentalform sind Schnitte in $(\T M^*)^{\otimes 2}$, d.h. (0,2)-Tensoren.
        \item
            Die Weingartenabbildung (Endomorphismus des Tangentialraumes an jedem Punkt) ist ein (1,1)-Tensor, d.h. ein Element in $\Gamma(M, T_1^1 M)$, oder ein Schnitt in $\T^* M \otimes \T M$.
        \item
            Der Riemannsche Krümmungstensor $R_{xy} Z$ ist ein Schnitt in $(\T^* M)^{\otimes 3} \otimes \T M$, d.h. ein (1,3)-Tensor.
        \item
            Auf jeder Mannigfaltigkeiten sind die Funktionen (reellwertig) $(0,0)$-Tensoren, d.h. $C^\infty(M) = \Gamma(M, \T_0^0 M)$
    \end{enumerate}
\end{ex*}


\subsection{Operationen auf Tensoren}

Zwei wichtige Operationen mit Tensoren: Einsetzen und Spurbildung.

\begin{df} \label{5.15}
    Sei $w \in \Gamma(M, \T^p_{q+1} M)$, d.h. ein $p$-fach kovarianter und $(q+1)$-fach kontravarianter Tensor auf $M$ und sei $X \in \scr X(M) = \Gamma(M, \T M)$ ein Vektorfeld.
    Der $(p,q)$-Tensor $\iota_X \omega$ ensteht durch Einsetzen von $X$  in das erste Argument von $\omega$, genauer: $\iota_X \omega \in \Gamma(M, \T_0^p M)$ mit
    \begin{math}
        (\iota_X \omega)(Y_1, \dotsc, Y_q) = \omega(X, Y_1, \dotsc, Y_q).
    \end{math}
    Man setzt außerdem $\iota_X \omega = 0$, falls $\omega \in \Gamma(M, \T_0^p M)$.
\end{df}

\begin{ex*}
    Sei $g(\argdot, \argdot)$ die erste Fundamentalform auf einer regulären Fläche im $\R^3$ und seien $X, Y$ zwei Vektorfelder auf der Fläche.
    Dann ist $\iota_Y(\iota_X(g)) = g(X,Y)$ eine Funktion auf $M$.
\end{ex*}

\begin{df} \label{5.16}
    Sei $1 \le j \le p$ und $1 \le k \le q$.
    Wir definieren die \emphdef{Spurbildung} (auch \emphdef{Verjüngung}, \emphdef{Kontraktion}) von $(p,q)$-Tensoren als
    \begin{math}
        &\Tr_{jk}(X_1 \otimes \dotsb \otimes X_p \otimes \alpha_1 \otimes \dotsb \otimes \alpha_q) \\
        &\quad:= \alpha_k(X_j) \otimes X_1 \dotsb \otimes \hat{X_j} \otimes \dotsb \otimes X_p \otimes \alpha_1 \otimes \dotsb \otimes \hat{\alpha_k} \otimes \dotsb \otimes \alpha_q.
    \end{math}
    Es gilt $\Tr_{jk}: \Gamma(M, \T_q^p M) \to \Gamma(M, \T_{q-1}^{p-1} M)$.
\end{df}

\begin{note}
    Zum Tensorprodukt von Vektorbündeln:
    Seien $E \to M$, $F \to M$ zwei Vektorbündel über $M$.
    Dann kann man das Tensorprodukt $E \otimes F$ auch faserweise verstehen, d.h.
    \begin{math}
        E_p \otimes F_p := (E \otimes F)_p
    \end{math}
    und die Abbildung $\kappa$ (aus der Definition des Tensorprodukts) ist faserweise definiert, d.h. es gibt eine bilineare Abbildung $E_p \times F_p \to (E \otimes F)_p$, $(v,w) \mapsto v \otimes w$, die punktweise angewendet, eine bilineare Abbildung $\Gamma(M,E) \times \Gamma(M,F) \to \Gamma(M, E \otimes F)$ definiert.
\end{note}

\begin{ex*}
    Beispiele für Spurbildung:
    \begin{enumerate}[(i)]
        \item
            Einsetzen ist ein Spezialfall von Spurbildung:
            \begin{math}
                \iota_X \omega = \Tr_{11}(X \otimes \omega).
            \end{math}
        \item
            Sei $L$ die Weingartenabbildung einer regulären Fläche im $\R^3$.
            Dann ist $L \in \Gamma(\T^* M \otimes \T M)$ und $\Tr_{11}$ ist die Spur, d.h. das doppelte der mittleren Krümmung.
    \end{enumerate}
\end{ex*}


\begin{df} \label{5.17}
    Sei $f: M \to N$ eine glatte Abbildung und sei $\omega$ ein $q$-fach kontravarianter Tensor auf $N$, d.h. $\omega \in \Gamma(N, \T_q^0 N)$.

    Der \emphdef{Pullback} $f^* \omega \in \Gamma(M, T_q^0 M)$ ist (punktweise) definiert durch
    \begin{math}
        (f^* \omega)(x)(X_1, \dotsc, X_q)
        := \omega(f(x))(\T_x f(X_1(x)), \dotsc, \T_x f(X_q(x)))
    \end{math}
    für alle $x \in M$.

    \begin{note}
        Der Pullback von $q$-Multilineareformen ist eine äußerst wichtige Operation.
        Man beachte, dass $f$ für den Pullback kein Diffeomorphismus sein muss (im Unterschied zum Pushforward von Vektorfeldern).

        Ist $f: M \to N$ ein Diffeomorphismus, so lässt sich der Pullback von einem Vektorfeld definieren, nämlich
        \begin{math}
            f^* X := (f^{-1})_* X.
        \end{math}
    \end{note}
\end{df}

\Timestamp{2016-01-12}

\begin{lem} \label{5.18}
    Es gilt
    \begin{math}
        (g \circ f)^* = f^* \circ g^*
    \end{math}
    \begin{proof}
        Mit der Kettenregel
        \begin{math}
            ((g \circ f)^*) \omega(x)(X_1, \dotsc, X_q)
            &= \omega(T_x(g \circ f)(X_1), \dotsc, T_x(g \circ f)(X_q)) \\
            &= \omega(T_{f(x)} g \circ T_x f(X_1), \dotsc, T_{f(x)} g \circ T_x f(X_q))) \\
            &= (g^* \omega) (f(x)) (T_x f(X_1), \dotsc, T_x f(X_q)) \\
            &= ((f^* \circ g^*) \omega)(g(f(x))(X_1, \dotsc, X_q).
        \end{math}
    \end{proof}
    \begin{nt}
        Mit anderen Worten: Die Abbildung $f \mapsto f^*$ ist ein kontravarianter Funktor zwischen der Kategorie der Mannigfaltigkeiten (mit glatten Abbildungen) und der Kategorie der Vektorräume (mit linearen Abbildungen).
    \end{nt}
\end{lem}

\begin{st} \label{5.19}
    Es existiert ein eindeutiger additiver Operator $L_X$ zu jedem Vektorfeld $X \in \scr X(M)$ auf $\Gamma(M, \T_q^p M)$, genannt \emphdef{Lie-Ableitung} mit folgenden Eigenschaften:
    \begin{enumerate}[(i)]
        \item
            Für alle Funktionen $f \in C^\infty(M) = \Gamma(M, \T_0^0 M)$ gilt
            \begin{math}
                L_X f = X(f).
            \end{math}
        \item
            Für alle Vektorfelder $Y \in \scr X(M) = \Gamma(M, \T_0^1)$ gilt
            \begin{math}
                L_X Y = [X, Y].
            \end{math}
        \item
            $L_X$ ist eine Derivation auf der Algebra der Tensoren
            \begin{math}
                L_X(\omega \otimes \eta) = (L_X \omega) \otimes \eta + \omega \otimes (L_X \eta).
            \end{math}
        \item
            $L_X$ vertauscht mit Kontraktionen:
            \begin{math}
                L_X \Tr_{jk} \omega = \Tr_{jk} L_X \omega.
            \end{math}
    \end{enumerate}
    \begin{proof}
        \begin{seg}{Eindeutigkeit}
            Wie in \ref{3.1} zeigt man, dass $L_X$ ein lokaler Operator ist.
            Also genügt es, zu zeigen, dass zwei solche Operatoren $L_X$, $K_X$ auf einer Karte $\phi: U \to V$ übereinstimmen.

            Sei $\alpha \in \Gamma(U, T^*U)$ eine 1-Form auf $U$ und $Y_j := \phi^* e_j$ ein Koordinatenvektorfeld.
            \begin{math}
                (K_X \alpha)(Y_j)
                &= \Tr((K_X \alpha) \otimes Y_j) \\
                &\stack{\text{(iii)}}= \Tr( K_X(\alpha \otimes Y_j) - \alpha \otimes K_X Y_j) \\
                &\stack{\text{(iv), (ii)}}= K_X( \Tr(\alpha \otimes Y_j)) - \alpha([X, Y]) \\
                &\stack{\text{(i)}}= X.(\alpha(Y_j)) - \alpha([X, Y]).
            \end{math}
            Da $Y_j(p)$ an jedem Punkt $p \in M$ eine Basis von $\T_p M$ ist, folgt $L_X \alpha = K_X \alpha$.
            Dies zeigt die Eindeutigkeit auf (0,1)-Tensoren, für (0,0)-Tensoren und vom Typ (1,0)-Tensoren ist sie durch (i), bzw (ii) gegeben.
            Für alle anderen Tensoren folgt die Eindeutigkeit induktiv mit (iii).
        \end{seg}
        \begin{seg}{Existenz}
            Wir definieren einen Operator $L_X$ analog zur Lie-Ableitung von Vektorfeldern und zeigen, dass er alle nötigen Eigenschaften erfüllt.
            Sei
            \begin{math}
                L_X: \Gamma(M, \T^p_q M) \to \Gamma(M, \T^p_q M)
                \omega \mapsto \ddx[t]|_{t=0} (\Phi^X_t)^* \omega
            \end{math}
            \begin{enumerate}[(i)]
                \item
                    Für $f \in C^\infty(M) = \Gamma(M, \T_0^0 M)$ gilt punktweise
                    \begin{math}
                        L_X f = \ddx[t]|_{t=0} (\Phi_t^X)^* f
                        = \ddx[t]|_{t=0} f \circ \Phi_t^X
                        = X(f).
                    \end{math}
                \item
                    Für $Y \in \scr X(M)$ gilt
                    \begin{math}
                        L_X Y = \ddx[t]|_{t=0} (\Phi_t^X)^* Y
                        = \ddx[t]|_{t=0} (\Phi_{-1}^X)_* Y
                        = [X, Y].
                    \end{math}
                \item
                \item
                    folgen durch Anwenden von $\ddx[t]|_{t=0}$ auf $(\Phi_t^X)^*(\omega \otimes \eta) = (\Phi_t^X)^* \omega \otimes (\Phi_t^X)^* \eta$ (Übung) bzw. $(\Phi_t^X)^* \Tr_{jk} \omega = \Tr_{jk} (\Phi_t^X)^* \omega$ (Übung).
            \end{enumerate}
        \end{seg}
    \end{proof}
\end{st}

\begin{nt*}
    Mit Ausnahme der Lie-Ableitung von Funktionen (d.h. (0,0)-Tensoren) hängt der Wert der Lie-Ableitung $(L_X \omega)(p)$ auch vom Verhalten von $X$ in einer Umgebung von $p$ ab (bei der „kovarianten Ableitung“ nur von $X(p)$).
\end{nt*}



