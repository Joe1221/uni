% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 3.0 Unported License. To view a copy of
% this license, visit http://creativecommons.org/licenses/by-nc-sa/3.0/ or send
% a letter to Creative Commons, 444 Castro Street, Suite 900, Mountain View,
% California, 94041, USA.

\chapter{Fourierreihen II}

\section{Kompakte symmetrische Operatoren}


\begin{df} \label{3.1}
	Sei $M \subset L$ ($L$ Prä-Hilbertraum).
	Dann heißt
	\[
		M^\orth := \Big\{ x \in L \mid| \forall y \in M : \<x,y\> = 0 \Big\}
	\]
	\emph{orthogonales Komplement} von $M$.
\end{df}

\begin{st} \label{3.2}
	\begin{enumerate}[1)]
		\item
			$M^\orth$ ist ein linearer Teilraum und abgeschlossen (d.h. enthält alle Häufungspunkte).
		\item
			\begin{align*}
				(\LH \{M\})^\orth &= M\orth \\
				\_M^\orth = M^\orth
			\end{align*}
	\end{enumerate}
	\begin{proof}
		Einfache Übung.
	\end{proof}
\end{st}

\begin{conv*}
	Wir betrachten hier und im Folgenden nur \emph{lineare} Operatoren.
\end{conv*}

\begin{st} \label{3.3}
	Sei $A: L \to L$ symmerisch und beschränkt.
	Dann gilt
	\begin{enumerate}[1)]
		\item
			$\displaystyle \<Ax,x\> \in \R$,
		\item
			$\displaystyle \im(A)^\orth = \ker(A)$,
		\item
			$\displaystyle A \Big|_{\_{\im (A)} }$ ist injektiv und $A \Big|_{\ker(A)} = 0$,
		\item
			$\displaystyle \|A\| = \sup_{\|x\|=1} |\<Ax,x\>|$.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[1)]
			\item
				Da $A$ symmetrisch, gilt
				\[
					\<Ax, x\> = \<x, Ax\> = \_{\<Ax,x\>}.
				\]
				Also $\<Ax, x\> \in \R$.
			\item
				Da $A$ symmetrisch, gilt
				\begin{align*}
					x \in \im(A)^\orth
					& \iff \forall y \in \im(A) : \<x,y\> = 0 \\
					& \iff \forall \tilde y \in L: \<x, A\tilde y\> = 0 \\
					& \iff \forall \tilde y \in L: \<Ax,\tilde y\> = 0 \\
					& \iff Ax = 0 \\
					& \iff x \in \ker(A)
				\end{align*}
			\item
				Seien $x,y \in \_{\im(A)}$, also auch $x-y \in \_{\im(A)}$ (Betrachte dazu $x,y$ als Folgengrenzwerte).

				Sei $Ax = Ay$.
				Dann ist $A(x-y) = 0$, also nach 2)
				\[
					x-y \in \ker (A) = \im(A)^\orth = \_{\im(A)}^\orth
				\]
				Also 
				\[
					x-y \in \_{\im(A)} \cap \_{\im(A)}^\orth = \{0\}.
				\]
				und damit $A$ injektiv.
			\item
				Falls $\|A\| = 0$, also $A=0$, dann ist $0 = \sup |\<Ax,x\>|$ trivial.

				Sei nun $\|A\| > 0$ und $d := \sup_{\|x\|=1} |\<Ax,x\>|$.
				Zeige $d = \|A\|$:
				\begin{enumerate}[a)]
					\item
						Es gilt $d \le \|A\|$, denn
						\begin{align*}
							|\<Ax,x\>| 
							&\stack{\text{CSB}} \le \|Ax\| \underbrace{\|x\|}_{=1} \\
							&\stack{\ref{1.23}}\le \|A\| \|x\|
							= \|A\|.
						\end{align*}
					\item
						Zeige $d \ge \|A\|$.

						Für $y \neq 0$ gilt
						\[
							|\<Ay,y\>| 
							= \|y\|^2 \Big| \< A \tf{y}{\|y\|}, \tf{y}{\|y\|} \> \Big| 
							\le d\|y\|^2
						\]

						Für $\alpha > 0$ gilt
						\begin{align*}
							\Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \f 1\alpha A x \Big\>
							- \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \f 1\alpha A x \Big\>
							&= 2\< A\alpha x, \tf 1\alpha A x\> + 2\<A (\tf 1\alpha Ax), \alpha x\> \\
							&= 4 \|Ax\|^2
						\end{align*}
						Falls $\|Ax\| = 0$, dann ist offensichtlich $\|Ax\| \le d$.
						Sei also $\|x\| = 1$ mit $\|Ax\| \neq 0$.
						Setze $\alpha^2 := \|Ax\|$, dann ist
						\begin{align*}
							4\|Ax\|^2
							&= 
							\bigg| \Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \tf 1\alpha A x \Big\>
							- \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \tf 1\alpha A x \Big\> \bigg| \\
							&\le \bigg| \Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \tf 1\alpha A x \Big\>
							\bigg| + \bigg| \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \tf 1\alpha A x \Big\> \bigg| \\
							&\le  d \Big\| \alpha x + \tf 1\alpha Ax \Big\|^2 + d \Big\| \alpha x - \tf 1\alpha Ax \Big\|^2 \\
							&= d ( \|\alpha x\|^2 + 2 \Re \<\alpha x, \tf 1\alpha Ax\> + \| \tf 1\alpha Ax\|^2
							+  \|\alpha x\|^2 - 2 \Re \<\alpha x, \tf 1\alpha Ax\> + \| \tf 1\alpha Ax\|^2) \\
							&= 2d (\|\alpha x\|^2 + \|\tf 1\alpha Ax\|^2) \\
							&= 2d (\|A x\|\|x\|^2 + \f 1{\|Ax\|}\|Ax\|^2) \\
							&= 4d \|Ax\|
						\end{align*}
						Also $\|Ax\| \le d$ für $\|x\| = 1$ und damit
						\[
							\|A\| = \sup_{\|x\|=1} \|Ax\| \le d
						\]
				\end{enumerate}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{nt} \label{3.4}
	Ist zusätzlich zu \ref{3.3} $(L,\<\argdot,\argdot\>)$ ein Hilbertraum, dann kann 2) in der Form
	\[
		L = \_{\im(A)} \oplus \ker(A)
	\]
	als direkte Summe geschrieben werden.
	Dies bedeutet
	\[
		\forall x \in L \exists! y \in \_{\im(A)} \exists! z \in \ker(A) : x = y + z
	\]
	\begin{proof}
		Folgt aus dem Projektionssatz (siehe Funktionalanalysis).
	\end{proof}
\end{nt}


\begin{st}[Hauptsatz über symmetrische, kompakte Operatoren] \label{3.5}
	Sei $(L, \<\argdot,\argdot\>)$ unendlichdimensionaler Prähilbertraum und $A: L \to L$ linearer, symmetrischer, kompakter Operator.

	Dann gilt:
	\begin{enumerate}[1)]
		\item
			$\lambda = \|A \|$ oder $\lambda = - \|A\|$ ist Eigenwert von $A$.
		\item
			Jeder Eigenwert $\lambda \neq 0$ ist reell und hat endliche Vielfachheit.
		\item
			Falls $A$ nur endlich viele Eigenwerte ungleich $0$ besitzt, dann ist $\lambda = 0$ Eigenwert mit unendlicher Vielfachheit (d.h. $\dim (\ker (A)) = \infty)$.

			Falls $A$ unendlich viele Eigenwerte ungleich $0$ besitzt, dann ist die Menge dieser Eigenwerte abzählbar und für die Folge $(\lambda_j)$ der Eigenwerte gilt $\lambda_j \to 0$ ($j \to \infty$).
		\item
			Sei $(\lambda_j)$ eine Abzählung der Eigenwerte, die so gebildet wird, dass
			\begin{itemize}
				\item
					$|\lambda_j|$ ist monoton fallend.
				\item
					Jeder Eigenwert $\lambda$ kommt in der Folge so oft vor, wie es seiner Vielfachheit entspricht.
			\end{itemize}
			Zu dieser Folge existiert ein ONS $(e_j)$ aus Eigenelementen.
			Dieses ONS ist vollständig in $\_{\im (A)}$, d.h.
			\[
				\forall x \in \_{\im(A)} : x = \sum_{j=1}^\infty \<x,e_j\> e_j
			\]
	\end{enumerate}
	\begin{proof}
		Falls $A = 0$ ist nichts zu beweisen.
		Sei also $A \neq 0$ und damit insbesondere $\|A\| > 0$.
		\begin{enumerate}[1)]
			\item
				Wegen \ref{3.3} 4) existiert eine Folge $(x_n)$ mit
				\[
					\|x_n\| = 1 \qquad \land \qquad |\<Ax_n,x_n\>| \to \|A\|
				\]
				Da $A$ kompakt, existiert eine Teilfolge $(x_{n_k})_{k\in \N}$ mit $Ax_{n_k} \to y \in L$ für $k \to \infty$.
				Sei 
				\[
					\lambda := \lim_{k\to\infty} \<Ax_{n_k},x_{n_k}\> = \pm \|A\| \neq 0
				\]
				Es gilt
				\begin{align*}
					\|Ax_{n_k} - \lambda x_{n_k}\|^2
					&= \underbrace{\|Ax_{n_k} \|^2}_{\le \|A\|^2 \|x_{n_k}\|^2} - 2 \Re \underbrace{\< Ax_{n_k}, \lambda x_{n_k} \>}_{\in \R} + \lambda^2 \underbrace{\|x_{n_k}\|^2}_{=1} \\
					&\le \underbrace{\|A\|^2 + \lambda^2}_{=2\lambda^2} - 2 \lambda \underbrace{\<Ax_{n_k}, x_{n_k}\>}_{\to \lambda} \\
					& \to 0 \qquad (k\to \infty).
				\end{align*}
				Also 
				\[
					y = \lim_{k\to \infty} Ax_{n_k} = \lim_{k\to \infty} \lambda x_{n_k}.
				\]
				Weil $A$ stetig ist (da beschränkt, siehe \ref{1.27} und \ref{1.25}), gilt:
				\[
					Ay 
					= A \lim_{k\to\infty} A x_{n_k} 
					= A \lim_{k\to\infty} \lambda x_{n_k}
					= \lambda \lim_{k\to\infty} Ax_{n_k}
					= \lambda y
				\]
				Weiter ist
				\[
					\|y\| 
					= \Big\|\lim_{k\to\infty} \lambda x_{n_k}\Big\|
					= \lim_{k\to\infty} |\lambda| \|x_{n_k}\|
					= |\lambda|
					> 0
				\]
				Also ist $\lambda = \pm \|A\|$ Eigenwert zum Eigenvektor $y$. 
			\item

				Angenommen $\lambda \neq 0$ sei Eigenwert mit unendlicher Vielfachheit, also
				\[
					\dim \ker (A - \lambda \Id) = \infty
				\]
				Sei $\{v_1,v_2,\dotsc\}$ eine abzählbar unendliche linear unabhängige Teilmenge von $\ker(A-\lambda \Id)$.
				Gram-Schmidt auf $\{v_1,v_2,\dotsc\}$ angewandt liefert ein abzählbar unendliches ONS $(e_j)$ in $\ker (A-\lambda \Id)$.
				Es gilt
				\begin{itemize}
					\item
						$Ae_j = \lambda e_j$,
					\item
						$(e_j)$ ist beschränkt.
				\end{itemize}
				Da $A$ kompakt, müsste $(Ae_j)$ eine konvergente Teilfolge besitzen.
				$(Ae_j)$ kann jedoch keine konvergente Teilfolge enthalten, denn
				\[
					\|Ae_j - Ae_k\| = |\lambda| \|e_j-e_k\| = |\lambda| \sqrt 2 = \const \neq 0.
				\]
				Ein Widerspruch, also hat $\lambda$ endliche Vielfachheit.

				Dass $\lambda$ reell ist folgt direkt aus der Symmetrie.
			\item
				Wegen 1) existiert $v_1 \neq 0$ mit $Av_1 = \lambda_1v_1$ und $|\lambda_1| = \|A\|$.

				Betrachte nun $A_1 = A \Big|_{\{v_1\}^\orth}$.
				Es gilt für alle $v \orth v_1$:
				\[
					\<A_1v,v_1\> = \<Av,v_1\> = \<v,Av_1\> = \lambda_1\<v,v_1\> = 0
				\]
				bzw. $\im (A_1) \subset \{v_1\}^\orth$, $A$ operiert also im Prähilbertraum $\{v_1\}^\orth$.
				Außerdem gilt
				\begin{align*}
					\|A_1\| 
					&= \sup_{\substack{v\in \{v_1\}^\orth \\ \|v\|=1}} \|A_1 v\| \\
					&\le \sup_{\substack{v\in L \\ \|v\|=1}} \|A v\| 
					= \|A\|
				\end{align*}
				$A_1$ ist kompakt: für eine beschränkte Folge $\{x_n\}$ in $\{v_1\}^\orth$ existiert eine konvergente Teilfolge bezüglich $A$:
				\[
					A x_{n_k} \to y \in L
				\]
				Es gilt $A_1 x_{n_k} \in \{v_1\}^\orth$ und $y \in \{v_1\}^\orth$, da $\{v_1\}^\orth$ abgeschlossen.

				Außerdem ist $A_1$ symmetrisch.

				Wegen 1) existiert $v_2 \neq 0$ mit $Av_2 = \lambda_2v_2$ und $|\lambda_2| = \|A_1\| \le \|A\|$.
				Betrachte nun 
				\[
					A_2 = A \Big|_{\{v_1,v_2\}^\orth} 
				\]
				Setze dies induktiv fort und erhalte eine Folge von Eigenwerten $(\lambda_j)$ von $A$ mit $|\lambda_{j+1}| \le |\lambda_j|$.
				Betrachte zwei Fälle:
				\begin{enumerate}[1. {Fall}]
					\item
						Es existiert ein (minimales) $j\in\N$ mit $\lambda_j = 0$, dann ist	wegen $\|A_{j-1}\| = 0$ und $Av_i\neq 0$ (für $1\le i \le j-1$)
						\[
							\{v_1,\dotsc,v_{j-1}\}^\orth = \ker(A_{j-1}) = \ker(A)
						\]
						und somit $\dim (\ker(A)) = \dim \{v_1,\dotsc, v_{j-1}\}^\orth = \infty$.
						Also ist $\lambda = 0$ Eigenwert von $A$ mit unendlicher Vielfachheit.
					\item
						Für alle $j \in \N$ ist $\lambda_j \neq 0$.
						Angenommen $\lambda_j \not\to 0$ ($j \to \infty$), d.h. es existiert $a > 0$ mit $|\lambda_j| \ge a$ für alle $j \in \N$.

						Wende in jedem Eigenraum Gram-Schmidt an (Eigenvektoren zu verschiedenen Eigenwerten sind schon orthogonal) und erhalte ein ONS $(e_j)_{j\in\N}$ aus Eigenvektoren mit
						\[
							A e_j = \lambda_j e_j
							\qquad \text{und} \qquad
							\text{$\lambda_j$ monoton fallend}
						\]
						$(\f 1 {\lambda_j} e_j)$ ist beschränkt, aber $(A \f 1 {\lambda_j} e_j)$ kann keine konvergente Teilfolge enthalten, da $A \f 1 {\lambda_j} e_j = e_j$.
						Ein Widerspruch, also gilt $\lambda_j \to 0$.
				\end{enumerate}
			\item
				Verwende die Folge $(\lambda_j)$ mit zugehörigem ONS $(e_j)$ wie im Beweis von 3) konstruiert.

				Sei $x \in L$ und definiere
				\[
					x_n := x - \sum_{j=1}^n \<x,e_j\> e_j.
				\]
				Es gilt
				\begin{itemize}
					\item
						$x_n \in \{e_1,\dotsc,e_n\}^\orth$, denn
						\[
							\<x_n, e_k\> = \<x, e_k\> - \sum_{j=1}^n \<x,e_j\> \<e_j, e_k\> = 0
						\]
					\item
						$\|Ax_n\| \to 0$ für $n\to \infty$, denn
						\begin{align*}
							\|x_n\|^2  = \<x_n, x_n\>
							&= \|x\|^2 - \sum_{j=1}^n \underbrace{\<x,e_j\>\<e_j,x\>}_{=|\<x,e_j\>|^2} - \sum_{j=1}^n \underbrace{\_{\<x,e_j\>} \<x,e_j\>}_{=|\<x,e_j\>|^2} + \sum_{j=1}^n |\<x,e_j\>|^2 \\
							&= \|x\|^2 - \sum_{j=1}^n (\<x,e_j\>)^2 \\
							&\le \|x\|^2
						\end{align*}
						Also $\|x_n\| \le \|x\|$ und deswegen
						\[
							\|Ax_n\| = \|A_{n-1}x_n\| \le \|A_{n-1}\| \|x_n\| \le \|A_{n-1}\| \|x\| \to 0
							\qquad (n \to \infty).
						\]
				\end{itemize}
				Es gilt
				\[
					\<x,e_j\> A e_j
					= \<x,e_j\> \lambda_j e_j
					= \<x,\lambda_j e_j\> e_j
					= \<x,A e_j\> e_j
					= \<Ax,e_j\> e_j
				\]
				Damit ist
				\[
					Ax = \lim_{n\to\infty} Ax_n + \sum_{j=1}^n \<x,e_j\> Ae_j = \sum_{j=1}^\infty \<Ax, e_j\> e_j \in \im (A)
				\]
				und somit für alle $y \in \im (A)$
				\[
					y = \sum_{j=1}^\infty \<y,e_j\> e_j.
				\]
				Nach \ref{1.12} 3) gilt selbiges für $\_{\im (A)}$.
		\end{enumerate}
	\end{proof}
\end{st}

\setcounter{thm}{4} % Nummerierung wurde in der Vorlesung wiederholt
\begin{ex}[Schwingende Saite] \label{3.5}
	$u(t,x)$ gebe die Auslenkung der Saite im Punkt $x$ zur Zeit $t$ an. 
	Die Physik liefert die DGL:
	\[
		\rho(x) \partial_t^2 u(t,x) - \sigma(x) \partial_x^2 u(t,x) = 0
	\]
	Dabei bezeichnet $\rho(x) > 0$ die Massendichte und $\sigma(x) > 0$ die Federkonstante.
	Außerdem gilt die Randbedingung für die eingespannte Saite
	\[
		u(t,0) = u(t,l) = 0
		\qquad t \ge 0
	\]
	und die Anfangswertbedingungen
	\begin{align*}
		u(0,x) &= u_0(x) \\
		\partial_t u(0,x) &= u_1(x)
	\end{align*}
	für gegebene Anfangsauslenkung $u_0(x)$ und Anfangsgeschwindigkeit $u_1(x)$ im Zeitpunkt $t = 0$.

	Wir zeigen jetzt die Existenz einer Lösung.

	Setze $c(x) := \sqrt{\f {\sigma(x)}{\rho(x)}}$ und schreibe
	\[
		\partial_t^2 u(t,x) - c^2(x) \partial_x^2 u(t,x) = 0
	\]
	Als Naiver Ansatz, setze $u(t,x) = v(t)w(x)$ in die DGL ein.
	\[
		v''(t) w(x) - c^2(x) v(t) w''(x) = 0
	\]
	Falls $v,w \neq 0$, ist
	\[
		\f {v''(t)}{v(t)} = c^2(x) \f {w''(x)}{w(x)} = \const =: - \lambda
	\]
	(die linke Seite ist nur von $t$ und die rechte nur von $x$ abhängig, also müssen sie konstant sein).
	Wir erhalten zwei DGLs:
	\begin{align*}
		v''(t) + \lambda v(t) &= 0 \quad \land  \quad v(0), v'(0) \text{ vorgegeben} \qquad t \ge 0 \\
		c^2 w''(t) + \lambda w(t) &= 0 \quad \land \quad w(0) = w(l) = 0 \qquad 0 \le x \le l
	\end{align*}
	Erstere stellt ein Anfangswertproblem, zweitere ein Randwertproblem dar.

	Betrachte den Spezialfall $c = 1$.
	Das Randwertproblem besitzt nur für 
	\[
		0 < \lambda = \lambda_j = \Big( \f {j\pi}{l} \Big)^2
	\]
	die Lösungen
	\[
		w_j(x) = \sqrt{\f 2l} \sin( \tf {j\pi}l x)
	\]
	Die $w_j$ sind normiert, denn $\int_{0}^l \omega_j \omega_k \dx = \delta_{jk}$.

	Die dazugehörige Lösung des Anfangswertproblems ist
	\[
		v_j(t) = v_j(0) \cos(\tf {j\pi}l t) + \f l{j\pi} v_j'(0) \sin(\tf{j\pi}l t)
	\]
	Die Lösungen
	\[
		u_j(t,x) = w_j(x) v_j(x)
	\]
	sind Eigenschwingenen der Saite (es sind auch alle Lösungen, ohne Beweis).
	
	Die allgemeine Lösung lässt sich auch als Fourierreihe darstellen:
	\[
		u(t,x) = \sum_{j=1}^\infty w_j(x) v_j(t)
	\]
	Es bleibt zu zeigen, dass die Reihe und ihre Ableitungen gleichmäßig konvergieren.
\end{ex}


\begin{df}[Sturm-Liouville'sches Eigenwertproblem] \label{3.6}
	Gesucht sind $\lambda \in \R$ und $u \in C^2([a,b]\to \R)$ mit $u \neq 0$ und
	\begin{align} \label{eq:3.1}
		\begin{aligned}
		(p'u')' - qu + \lambda ru &= 0 \qquad a\le x \le b \\
		R_1 u := \alpha_1 u(a) + \alpha_2 u'(a) &= 0 \\
		R_2 u := \beta_1 u(b) + \beta_2 u'(b) &= 0
		\end{aligned}
	\end{align}
	wobei $p \in C^2([a,b] \to \R)$, $p > 0$ auf $[a,b]$, $q,r \in C([a,b] \to \R)$, $r>0$, $\alpha_1^2 + \alpha_2^2 > 0$, $\beta_1^2 + \beta_2^2 > 0$.

	$\lambda$ heißt \emph{Eigenwert}, $u$ \emph{Eigenfunktion} von \ref{eq:3.1}.
\end{df}

\begin{nt} \label{3.7}
	\begin{enumerate}[1)]
		\item
			Wir unterscheiden folgende Sezialfälle bei der Randwertbedingung $u(a) = u(b) = 0$:

			Die \emph{Dirichletsche Randbedingung}: $\alpha_1 = \beta_1 = 1, \alpha_2 = \beta_2 = 0$.

			Die \emph{Neumannsche Randbedingung}: $\alpha_1 = \beta_1 = 0, \alpha_2 = \beta_2 = 1$.
		\item
			Es gilt
			\begin{align*}
				R_1 u = 0
				&\iff \begin{pmatrix}
					u(a) \\ u'(a) 
				\end{pmatrix} \orth \begin{pmatrix}
					\alpha_1 \\ \alpha_2
				\end{pmatrix} \\
				&\iff \exists c \in \R : \begin{pmatrix}
					u(a) \\ u'(a)
				\end{pmatrix} = c \begin{pmatrix}
					\alpha_2 \\ -\alpha_1
				\end{pmatrix}
			\end{align*}


	\end{enumerate}
\end{nt}

\section{Randwertprobleme zweiter Ordnung}
