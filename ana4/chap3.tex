% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 3.0 Unported License. To view a copy of
% this license, visit http://creativecommons.org/licenses/by-nc-sa/3.0/ or send
% a letter to Creative Commons, 444 Castro Street, Suite 900, Mountain View,
% California, 94041, USA.

\chapter{Fourierreihen II}

\section{Kompakte symmetrische Operatoren}


\begin{df} \label{3.1}
	Sei $M \subset L$ ($L$ Prä-Hilbertraum).
	Dann heißt
	\[
		M^\orth := \Big\{ x \in L \mid| \forall y \in M : \<x,y\> = 0 \Big\}
	\]
	\emph{orthogonales Komplement} von $M$.
\end{df}

\begin{st} \label{3.2}
	\begin{enumerate}[1)]
		\item
			$M^\orth$ ist ein linearer Teilraum und abgeschlossen (d.h. enthält alle Häufungspunkte).
		\item
			\begin{align*}
				(\LH \{M\})^\orth &= M\orth \\
				\_M^\orth = M^\orth
			\end{align*}
	\end{enumerate}
	\begin{proof}
		Einfache Übung.
	\end{proof}
\end{st}

\begin{conv*}
	Wir betrachten hier und im Folgenden nur \emph{lineare} Operatoren.
\end{conv*}

\begin{st} \label{3.3}
	Sei $A: L \to L$ symmerisch und beschränkt.
	Dann gilt
	\begin{enumerate}[1)]
		\item
			$\displaystyle \<Ax,x\> \in \R$,
		\item
			$\displaystyle \im(A)^\orth = \ker(A)$,
		\item
			$\displaystyle A \Big|_{\_{\im (A)} }$ ist injektiv und $A \Big|_{\ker(A)} = 0$,
		\item
			$\displaystyle \|A\| = \sup_{\|x\|=1} |\<Ax,x\>|$.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[1)]
			\item
				Da $A$ symmetrisch, gilt
				\[
					\<Ax, x\> = \<x, Ax\> = \_{\<Ax,x\>}.
				\]
				Also $\<Ax, x\> \in \R$.
			\item
				Da $A$ symmetrisch, gilt
				\begin{align*}
					x \in \im(A)^\orth
					& \iff \forall y \in \im(A) : \<x,y\> = 0 \\
					& \iff \forall \tilde y \in L: \<x, A\tilde y\> = 0 \\
					& \iff \forall \tilde y \in L: \<Ax,\tilde y\> = 0 \\
					& \iff Ax = 0 \\
					& \iff x \in \ker(A)
				\end{align*}
			\item
				Seien $x,y \in \_{\im(A)}$, also auch $x-y \in \_{\im(A)}$ (Betrachte dazu $x,y$ als Folgengrenzwerte).

				Sei $Ax = Ay$.
				Dann ist $A(x-y) = 0$, also nach 2)
				\[
					x-y \in \ker (A) = \im(A)^\orth = \_{\im(A)}^\orth
				\]
				Also 
				\[
					x-y \in \_{\im(A)} \cap \_{\im(A)}^\orth = \{0\}.
				\]
				und damit $A$ injektiv.
			\item
				Falls $\|A\| = 0$, also $A=0$, dann ist $0 = \sup |\<Ax,x\>|$ trivial.

				Sei nun $\|A\| > 0$ und $d := \sup_{\|x\|=1} |\<Ax,x\>|$.
				Zeige $d = \|A\|$:
				\begin{enumerate}[a)]
					\item
						Es gilt $d \le \|A\|$, denn
						\begin{align*}
							|\<Ax,x\>| 
							&\stack{\text{CSB}} \le \|Ax\| \underbrace{\|x\|}_{=1} \\
							&\stack{\ref{1.23}}\le \|A\| \|x\|
							= \|A\|.
						\end{align*}
					\item
						Zeige $d \ge \|A\|$.

						Für $y \neq 0$ gilt
						\[
							|\<Ay,y\>| 
							= \|y\|^2 \Big| \< A \tf{y}{\|y\|}, \tf{y}{\|y\|} \> \Big| 
							\le d\|y\|^2
						\]

						Für $\alpha > 0$ gilt
						\begin{align*}
							\Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \f 1\alpha A x \Big\>
							- \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \f 1\alpha A x \Big\>
							&= 2\< A\alpha x, \tf 1\alpha A x\> + 2\<A (\tf 1\alpha Ax), \alpha x\> \\
							&= 4 \|Ax\|^2
						\end{align*}
						Falls $\|Ax\| = 0$, dann ist offensichtlich $\|Ax\| \le d$.
						Sei also $\|x\| = 1$ mit $\|Ax\| \neq 0$.
						Setze $\alpha^2 := \|Ax\|$, dann ist
						\begin{align*}
							4\|Ax\|^2
							&= 
							\bigg| \Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \tf 1\alpha A x \Big\>
							- \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \tf 1\alpha A x \Big\> \bigg| \\
							&\le \bigg| \Big\< A(\alpha x + \tf 1\alpha Ax), \alpha x + \tf 1\alpha A x \Big\>
							\bigg| + \bigg| \Big\< A(\alpha x - \tf 1\alpha Ax), \alpha x - \tf 1\alpha A x \Big\> \bigg| \\
							&\le  d \Big\| \alpha x + \tf 1\alpha Ax \Big\|^2 + d \Big\| \alpha x - \tf 1\alpha Ax \Big\|^2 \\
							&= d ( \|\alpha x\|^2 + 2 \Re \<\alpha x, \tf 1\alpha Ax\> + \| \tf 1\alpha Ax\|^2
							+  \|\alpha x\|^2 - 2 \Re \<\alpha x, \tf 1\alpha Ax\> + \| \tf 1\alpha Ax\|^2) \\
							&= 2d (\|\alpha x\|^2 + \|\tf 1\alpha Ax\|^2) \\
							&= 2d (\|A x\|\|x\|^2 + \f 1{\|Ax\|}\|Ax\|^2) \\
							&= 4d \|Ax\|
						\end{align*}
						Also $\|Ax\| \le d$ für $\|x\| = 1$ und damit
						\[
							\|A\| = \sup_{\|x\|=1} \|Ax\| \le d
						\]
				\end{enumerate}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{nt} \label{3.4}
	Ist zusätzlich zu \ref{3.3} $(L,\<\argdot,\argdot\>)$ ein Hilbertraum, dann kann 2) in der Form
	\[
		L = \_{\im(A)} \oplus \ker(A)
	\]
	als direkte Summe geschrieben werden.
	Dies bedeutet
	\[
		\forall x \in L \exists! y \in \_{\im(A)} \exists! z \in \ker(A) : x = y + z
	\]
	\begin{proof}
		Folgt aus dem Projektionssatz (siehe Funktionalanalysis).
	\end{proof}
\end{nt}


\begin{st}[Hauptsatz über symmetrische, kompakte Operatoren] \label{3.5}
	Sei $(L, \<\argdot,\argdot\>)$ unendlichdimensionaler Prähilbertraum und $A: L \to L$ linearer, symmetrischer, kompakter Operator.

	Dann gilt:
	\begin{enumerate}[1)]
		\item
			$\lambda = \|A \|$ oder $\lambda = - \|A\|$ ist Eigenwert von $A$.
		\item
			Jeder Eigenwert $\lambda \neq 0$ ist reell und hat endliche Vielfachheit.
		\item
			Falls $A$ nur endlich viele Eigenwerte ungleich $0$ besitzt, dann ist $\lambda = 0$ Eigenwert mit unendlicher Vielfachheit (d.h. $\dim (\ker (A)) = \infty)$.

			Falls $A$ unendlich viele Eigenwerte ungleich $0$ besitzt, dann ist die Menge dieser Eigenwerte abzählbar und für die Folge $(\lambda_j)$ der Eigenwerte gilt $\lambda_j \to 0$ ($j \to \infty$).
		\item
			Sei $(\lambda_j)$ eine Abzählung der Eigenwerte, die so gebildet wird, dass
			\begin{itemize}
				\item
					$|\lambda_j|$ ist monoton fallend.
				\item
					Jeder Eigenwert $\lambda$ kommt in der Folge so oft vor, wie es seiner Vielfachheit entspricht.
			\end{itemize}
			Zu dieser Folge existiert ein ONS $(e_j)$ aus Eigenelementen.
			Dieses ONS ist vollständig in $\_{\im (A)}$, d.h.
			\[
				\forall x \in \_{\im(A)} : x = \sum_{j=1}^\infty \<x,e_j\> e_j
			\]
	\end{enumerate}
	\begin{proof}
		Falls $A = 0$ ist nichts zu beweisen.
		Sei also $A \neq 0$ und damit insbesondere $\|A\| > 0$.
		\begin{enumerate}[1)]
			\item
				Wegen \ref{3.3} 4) existiert eine Folge $(x_n)$ mit
				\[
					\|x_n\| = 1 \qquad \land \qquad |\<Ax_n,x_n\>| \to \|A\|
				\]
				Da $A$ kompakt, existiert eine Teilfolge $(x_{n_k})_{k\in \N}$ mit $Ax_{n_k} \to y \in L$ für $k \to \infty$.
				Sei 
				\[
					\lambda := \lim_{k\to\infty} \<Ax_{n_k},x_{n_k}\> = \pm \|A\| \neq 0
				\]
				Es gilt
				\begin{align*}
					\|Ax_{n_k} - \lambda x_{n_k}\|^2
					&= \underbrace{\|Ax_{n_k} \|^2}_{\le \|A\|^2 \|x_{n_k}\|^2} - 2 \Re \underbrace{\< Ax_{n_k}, \lambda x_{n_k} \>}_{\in \R} + \lambda^2 \underbrace{\|x_{n_k}\|^2}_{=1} \\
					&\le \underbrace{\|A\|^2 + \lambda^2}_{=2\lambda^2} - 2 \lambda \underbrace{\<Ax_{n_k}, x_{n_k}\>}_{\to \lambda} \\
					& \to 0 \qquad (k\to \infty).
				\end{align*}
				Also 
				\[
					y = \lim_{k\to \infty} Ax_{n_k} = \lim_{k\to \infty} \lambda x_{n_k}.
				\]
				Weil $A$ stetig ist (da beschränkt, siehe \ref{1.27} und \ref{1.25}), gilt:
				\[
					Ay 
					= A \lim_{k\to\infty} A x_{n_k} 
					= A \lim_{k\to\infty} \lambda x_{n_k}
					= \lambda \lim_{k\to\infty} Ax_{n_k}
					= \lambda y
				\]
				Weiter ist
				\[
					\|y\| 
					= \Big\|\lim_{k\to\infty} \lambda x_{n_k}\Big\|
					= \lim_{k\to\infty} |\lambda| \|x_{n_k}\|
					= |\lambda|
					> 0
				\]
				Also ist $\lambda = \pm \|A\|$ Eigenwert zum Eigenvektor $y$. 
			\item

				Angenommen $\lambda \neq 0$ sei Eigenwert mit unendlicher Vielfachheit, also
				\[
					\dim \ker (A - \lambda \Id) = \infty
				\]
				Sei $\{v_1,v_2,\dotsc\}$ eine abzählbar unendliche linear unabhängige Teilmenge von $\ker(A-\lambda \Id)$.
				Gram-Schmidt auf $\{v_1,v_2,\dotsc\}$ angewandt liefert ein abzählbar unendliches ONS $(e_j)$ in $\ker (A-\lambda \Id)$.
				Es gilt
				\begin{itemize}
					\item
						$Ae_j = \lambda e_j$,
					\item
						$(e_j)$ ist beschränkt.
				\end{itemize}
				Da $A$ kompakt, müsste $(Ae_j)$ eine konvergente Teilfolge besitzen.
				$(Ae_j)$ kann jedoch keine konvergente Teilfolge enthalten, denn
				\[
					\|Ae_j - Ae_k\| = |\lambda| \|e_j-e_k\| = |\lambda| \sqrt 2 = \const \neq 0.
				\]
				Ein Widerspruch, also hat $\lambda$ endliche Vielfachheit.

				Dass $\lambda$ reell ist folgt direkt aus der Symmetrie.
			\item
				Wegen 1) existiert $v_1 \neq 0$ mit $Av_1 = \lambda_1v_1$ und $|\lambda_1| = \|A\|$.

				Betrachte nun $A_1 = A \Big|_{\{v_1\}^\orth}$.
				Es gilt für alle $v \orth v_1$:
				\[
					\<A_1v,v_1\> = \<Av,v_1\> = \<v,Av_1\> = \lambda_1\<v,v_1\> = 0
				\]
				bzw. $\im (A_1) \subset \{v_1\}^\orth$, $A$ operiert also im Prähilbertraum $\{v_1\}^\orth$.
				Außerdem gilt
				\begin{align*}
					\|A_1\| 
					&= \sup_{\substack{v\in \{v_1\}^\orth \\ \|v\|=1}} \|A_1 v\| \\
					&\le \sup_{\substack{v\in L \\ \|v\|=1}} \|A v\| 
					= \|A\|
				\end{align*}
				$A_1$ ist kompakt: für eine beschränkte Folge $\{x_n\}$ in $\{v_1\}^\orth$ existiert eine konvergente Teilfolge bezüglich $A$:
				\[
					A x_{n_k} \to y \in L
				\]
				Es gilt $A_1 x_{n_k} \in \{v_1\}^\orth$ und $y \in \{v_1\}^\orth$, da $\{v_1\}^\orth$ abgeschlossen.

				Außerdem ist $A_1$ symmetrisch.

				Wegen 1) existiert $v_2 \neq 0$ mit $Av_2 = \lambda_2v_2$ und $|\lambda_2| = \|A_1\| \le \|A\|$.
				Betrachte nun 
				\[
					A_2 = A \Big|_{\{v_1,v_2\}^\orth} 
				\]
				Setze dies induktiv fort und erhalte eine Folge von Eigenwerten $(\lambda_j)$ von $A$ mit $|\lambda_{j+1}| \le |\lambda_j|$.
				Betrachte zwei Fälle:
				\begin{enumerate}[1. {Fall}]
					\item
						Es existiert ein (minimales) $j\in\N$ mit $\lambda_j = 0$, dann ist	wegen $\|A_{j-1}\| = 0$ und $Av_i\neq 0$ (für $1\le i \le j-1$)
						\[
							\{v_1,\dotsc,v_{j-1}\}^\orth = \ker(A_{j-1}) = \ker(A)
						\]
						und somit $\dim (\ker(A)) = \dim \{v_1,\dotsc, v_{j-1}\}^\orth = \infty$.
						Also ist $\lambda = 0$ Eigenwert von $A$ mit unendlicher Vielfachheit.
					\item
						Für alle $j \in \N$ ist $\lambda_j \neq 0$.
						Angenommen $\lambda_j \not\to 0$ ($j \to \infty$), d.h. es existiert $a > 0$ mit $|\lambda_j| \ge a$ für alle $j \in \N$.

						Wende in jedem Eigenraum Gram-Schmidt an (Eigenvektoren zu verschiedenen Eigenwerten sind schon orthogonal) und erhalte ein ONS $(e_j)_{j\in\N}$ aus Eigenvektoren mit
						\[
							A e_j = \lambda_j e_j
							\qquad \text{und} \qquad
							\text{$\lambda_j$ monoton fallend}
						\]
						$(\f 1 {\lambda_j} e_j)$ ist beschränkt, aber $(A \f 1 {\lambda_j} e_j)$ kann keine konvergente Teilfolge enthalten, da $A \f 1 {\lambda_j} e_j = e_j$.
						Ein Widerspruch, also gilt $\lambda_j \to 0$.
				\end{enumerate}
			\item
				Verwende die Folge $(\lambda_j)$ mit zugehörigem ONS $(e_j)$ wie im Beweis von 3) konstruiert.

				Sei $x \in L$ und definiere
				\[
					x_n := x - \sum_{j=1}^n \<x,e_j\> e_j.
				\]
				Es gilt
				\begin{itemize}
					\item
						$x_n \in \{e_1,\dotsc,e_n\}^\orth$, denn
						\[
							\<x_n, e_k\> = \<x, e_k\> - \sum_{j=1}^n \<x,e_j\> \<e_j, e_k\> = 0
						\]
					\item
						$\|Ax_n\| \to 0$ für $n\to \infty$, denn
						\begin{align*}
							\|x_n\|^2  = \<x_n, x_n\>
							&= \|x\|^2 - \sum_{j=1}^n \underbrace{\<x,e_j\>\<e_j,x\>}_{=|\<x,e_j\>|^2} - \sum_{j=1}^n \underbrace{\_{\<x,e_j\>} \<x,e_j\>}_{=|\<x,e_j\>|^2} + \sum_{j=1}^n |\<x,e_j\>|^2 \\
							&= \|x\|^2 - \sum_{j=1}^n (\<x,e_j\>)^2 \\
							&\le \|x\|^2
						\end{align*}
						Also $\|x_n\| \le \|x\|$ und deswegen
						\[
							\|Ax_n\| = \|A_{n-1}x_n\| \le \|A_{n-1}\| \|x_n\| \le \|A_{n-1}\| \|x\| \to 0
							\qquad (n \to \infty).
						\]
				\end{itemize}
				Es gilt
				\[
					\<x,e_j\> A e_j
					= \<x,e_j\> \lambda_j e_j
					= \<x,\lambda_j e_j\> e_j
					= \<x,A e_j\> e_j
					= \<Ax,e_j\> e_j
				\]
				Damit ist
				\[
					Ax = \lim_{n\to\infty} Ax_n + \sum_{j=1}^n \<x,e_j\> Ae_j = \sum_{j=1}^\infty \<Ax, e_j\> e_j \in \im (A)
				\]
				und somit für alle $y \in \im (A)$
				\[
					y = \sum_{j=1}^\infty \<y,e_j\> e_j.
				\]
				Nach \ref{1.12} 3) gilt selbiges für $\_{\im (A)}$.
		\end{enumerate}
	\end{proof}
\end{st}


\section{Randwertprobleme zweiter Ordnung}


\setcounter{thm}{4} % Nummerierung wurde in der Vorlesung wiederholt
\begin{ex}[Schwingende Saite] \label{3.5}
	$u(t,x)$ gebe die Auslenkung der Saite im Punkt $x$ zur Zeit $t$ an. 
	Die Physik liefert die DGL:
	\[
		\rho(x) \partial_t^2 u(t,x) - \sigma(x) \partial_x^2 u(t,x) = 0
	\]
	Dabei bezeichnet $\rho(x) > 0$ die Massendichte und $\sigma(x) > 0$ die Federkonstante.
	Außerdem gilt die Randbedingung für die eingespannte Saite
	\[
		u(t,0) = u(t,l) = 0
		\qquad t \ge 0
	\]
	und die Anfangswertbedingungen
	\begin{align*}
		u(0,x) &= u_0(x) \\
		\partial_t u(0,x) &= u_1(x)
	\end{align*}
	für gegebene Anfangsauslenkung $u_0(x)$ und Anfangsgeschwindigkeit $u_1(x)$ im Zeitpunkt $t = 0$.

	Wir zeigen jetzt die Existenz einer Lösung.

	Setze $c(x) := \sqrt{\f {\sigma(x)}{\rho(x)}}$ und schreibe
	\[
		\partial_t^2 u(t,x) - c^2(x) \partial_x^2 u(t,x) = 0
	\]
	Als Naiver Ansatz, setze $u(t,x) = v(t)w(x)$ in die DGL ein.
	\[
		v''(t) w(x) - c^2(x) v(t) w''(x) = 0
	\]
	Falls $v,w \neq 0$, ist
	\[
		\f {v''(t)}{v(t)} = c^2(x) \f {w''(x)}{w(x)} = \const =: - \lambda
	\]
	(die linke Seite ist nur von $t$ und die rechte nur von $x$ abhängig, also müssen sie konstant sein).
	Wir erhalten zwei DGLs:
	\begin{align*}
		v''(t) + \lambda v(t) &= 0 \quad \land  \quad v(0), v'(0) \text{ vorgegeben} \qquad t \ge 0 \\
		c^2 w''(t) + \lambda w(t) &= 0 \quad \land \quad w(0) = w(l) = 0 \qquad 0 \le x \le l
	\end{align*}
	Erstere stellt ein Anfangswertproblem, zweitere ein Randwertproblem dar.

	Betrachte den Spezialfall $c = 1$.
	Das Randwertproblem besitzt nur für 
	\[
		0 < \lambda = \lambda_j = \Big( \f {j\pi}{l} \Big)^2
	\]
	die Lösungen
	\[
		w_j(x) = \sqrt{\f 2l} \sin( \tf {j\pi}l x)
	\]
	Die $w_j$ sind normiert, denn $\int_{0}^l \omega_j \omega_k \dx = \delta_{jk}$.

	Die dazugehörige Lösung des Anfangswertproblems ist
	\[
		v_j(t) = v_j(0) \cos(\tf {j\pi}l t) + \f l{j\pi} v_j'(0) \sin(\tf{j\pi}l t)
	\]
	Die Lösungen
	\[
		u_j(t,x) = w_j(x) v_j(x)
	\]
	sind Eigenschwingenen der Saite (es sind auch alle Lösungen, ohne Beweis).
	
	Die allgemeine Lösung lässt sich auch als Fourierreihe darstellen:
	\[
		u(t,x) = \sum_{j=1}^\infty w_j(x) v_j(t)
	\]
	Es bleibt zu zeigen, dass die Reihe und ihre Ableitungen gleichmäßig konvergieren.
\end{ex}


\begin{df}[Sturm-Liouville'sches Eigenwertproblem] \label{3.6}
	Gesucht sind $\lambda \in \R$ und $u \in C^2([a,b]\to \R)$ mit $u \neq 0$ und
	\begin{align} \label{eq:3.1}
		\begin{aligned}
		(p'u')' - qu + \lambda ru &= 0 \qquad a\le x \le b \\
		R_1 u := \alpha_1 u(a) + \alpha_2 u'(a) &= 0 \\
		R_2 u := \beta_1 u(b) + \beta_2 u'(b) &= 0
		\end{aligned}
	\end{align}
	wobei $p \in C^2([a,b] \to \R)$, $p > 0$ auf $[a,b]$, $q,r \in C([a,b] \to \R)$, $r>0$, $\alpha_1^2 + \alpha_2^2 > 0$, $\beta_1^2 + \beta_2^2 > 0$.

	$\lambda$ heißt \emph{Eigenwert}, $u$ \emph{Eigenfunktion} von \ref{eq:3.1}.
\end{df}

\begin{nt} \label{3.7}
	\begin{enumerate}[1)]
		\item
			Wir unterscheiden folgende Sezialfälle bei der Randwertbedingung $u(a) = u(b) = 0$:

			Die \emph{Dirichletsche Randbedingung}: $\alpha_1 = \beta_1 = 1, \alpha_2 = \beta_2 = 0$.

			Die \emph{Neumannsche Randbedingung}: $\alpha_1 = \beta_1 = 0, \alpha_2 = \beta_2 = 1$.
		\item
			Es gilt
			\begin{align*}
				R_1 u = 0
				&\iff \begin{pmatrix}
					u(a) \\ u'(a) 
				\end{pmatrix} \orth \begin{pmatrix}
					\alpha_1 \\ \alpha_2
				\end{pmatrix} \\
				&\iff \exists c \in \R : \begin{pmatrix}
					u(a) \\ u'(a)
				\end{pmatrix} = c \begin{pmatrix}
					\alpha_2 \\ -\alpha_1
				\end{pmatrix}
			\end{align*}


	\end{enumerate}
\end{nt}

\begin{st} \label{3.8}
	Jeder Eigenwert $\lambda$ von \eqref{eq:3.1} hat Vielfachheit $1$.
	\begin{proof}
		Wir nehmen an, $\lambda$ habe Vielfachheit $\ge 2$.

		Seien $u_1, u_2$ Lösungen von \eqref{eq:3.1} und $\{u_1,u_2\}$ linear unabhängig.
		$\{u_1,u_2\}$ spannt den ganzen Lösungsraum der DGL in \eqref{3.1} auf.

		Es existiert $(c_1,c_2)^T \in \R$ mit
		\[
			\underbrace{\begin{pmatrix}
				u_1(a) & u_2(a) \\
				u_1'(a) & u_2'(a)
			\end{pmatrix}}_{\det(\argdot) \neq 0}
			\begin{pmatrix}
				c_1 \\ c_2
			\end{pmatrix}
			= \begin{pmatrix}
				\alpha_1 \\ \f{\alpha_2}{p(a)}
			\end{pmatrix}
		\]
		Also gilt für $u:= c_1u_1 + c_2 u_2$:
		\begin{align*}
			R_1 u &= \alpha_1(c_1u_1(a) + c_2u_2(a)) + \alpha_2 p(a) (c_1u_1'(a) + c_2u_2'(a)) \\
			&= \alpha_1^2 + \alpha_2^2
			\neq 0
		\end{align*}
		Was im Widerspruch zu $R_1u = c_1R_1u_1 + c_2R_1u_2 = 0$ steht.
		Also hat $\lambda$ Vielfachheit $1$.
	\end{proof}
\end{st}

\begin{df} \label{3.9}
	Sei $J := [a,b]$, $L := C([a,b] \to \R)$ mit $\<f,g\> := \int_a^b f(x)g(x) \dx$ Prähilbertraum über $\R$.
	Definiere
	\begin{align}
		\label{eq:3.2}
		\begin{aligned}
			\tilde A u &:= (pu')' - qu \\
			D(A) &:= \Big\{ u \in C^2([a,b] \to \R) : R_1u = R_2u = 0 \Big\} \\
			Au &:= \tilde A u \qquad \text{für $u\in D(A)$}
		\end{aligned}
	\end{align}
\end{df}

\setcounter{thm}{8}
\begin{st} \label{3.9}
	Mit den Vorrausetzungen aus \eqref{eq:3.2} ist $A$ symmetrisch.
	\begin{proof}
		Es gilt
		\begin{align*}
			\<Au,v\> 
			&= \int_a^b (pu')'v - quv) \dx \\
			&= pu'v \Big|_a^b - \int_a^b (pu'v' + quv) \dx \\
			&= \underbrace{\Big[ pu'v - upv' \Big]_{x=a}^b}_{\text{=0 \text{ (s.u.)}}} + \underbrace{\int_a^b (u(pv')' - quv) \dx}_{= \<u,Av\>} \\
		\end{align*}
		Außerdem:
		\begin{align*}
			pu'v - upv' 
			&= \f 1{\alpha_1^2 + \alpha_2^2} \Big( \alpha_1^2 (pu'v - upv') + \alpha_2^2 (pu'v-upv') \Big) \\
			&= \f 1{\alpha_1^2 + \alpha_2^2} \bigg( \alpha_1^2 pu'\underbrace{(\alpha_1 v + \alpha_2 pv')}_{=R_1v = 0} - \alpha_1^2 pv'\underbrace{(\alpha_2pu'+ \alpha_1 u)}_{= R_1u = 0} \\
			 & \qquad\qquad\qquad + \alpha_2 v\underbrace{(\alpha_2 p u' + \alpha_1 u}_{=R_1 u = 0}  - \alpha_2 u \underbrace{(\alpha_1 v + \alpha_2 pv')}_{= R_1v= 0} \bigg)  \\
			 &= 0
		\end{align*}
		Also ist $\<Au,v\> = \<Av,u\>$ und damit $A$ symmetrisch.
	\end{proof}
\end{st}

\begin{nt} \label{3.10}
	Nur im Fall $r= 1$ sind die Eigenwerte von $A$ und von \eqref{eq:3.1} die selben.
	Ist $\lambda$ Eigenwert von \eqref{eq:3.1} mit Eigenfunktion $u$, so gilt
	\[
		A u(x) = \lambda r(x) u(x)
	\]
\end{nt}

\begin{df} \label{3.11}
	Eine Funktion $G: I \times I \to \R$ heißt \emph{Greensche Funktion} zu $A$, falls
	\begin{enumerate}[1)]
		\item
			$G \in C(I\times I \to \R)$
		\item
			\fixme[Bild]
			$\partial_1 G, \partial_1^2 G \in C(\Delta_1 \to \R)$ und sind stetig fortsetzbar auf $\_{\Delta_1}$.

			$\partial_1 G, \partial_1^2 G \in C(\Delta_2 \to \R)$ und sind stetig fortsetzbar auf $\_{\Delta_2}$.
		\item
			Für festes $\xi \in I$ gilt
			\begin{align*}
				\tilde A G(\argdot, \xi) = 0 \qquad \text{in $I \setminus \{\xi\}$} \\
				R_1 G(\argdot, \xi) = R_2 G(\argdot, \xi) = 0 
			\end{align*}
		\item
			Für $\xi \in ]a,b[$ gilt
			\begin{align*}
				\partial_1 G (\xi + 0, \xi) - \partial_1 G(\xi - 0, \xi) = -\f 1{p(\xi)}
			\end{align*}
	\end{enumerate}
\end{df}

\begin{st} \label{3.12}
	Existiert eine Greensche Funktion $G$ zu $A$, so sind für $\phi \in C(I \to \R)$ folgende Aussagen äquivalent:
	\begin{enumerate}[(i)]
		\item
			$Au = -\phi$, also insbesondere $u \in D(A)$,
		\item
			$u(x) = \int_a^b G(x,y) \phi(y) \dx[y]$
	\end{enumerate}
	\begin{proof}
		\begin{seg}[(ii) $\implies$ (i)]
			Es gilt
			\begin{align*}
				u(x)
				&= \int_a^x G(\underbrace{x,y}_{\in \Delta_2})\phi(y) \dx[y] + \int_x^b G(\underbrace{x,y}_{\in \Delta_1})\phi(y) \dx[y] \\
				\implies \quad u'(x) &=
				G(x,x) \phi(x) - 0 + \int_a^x \partial_1 G(x,y) \phi(y) \dx[y] + 0 - G(x,x) \phi(x) + \int_x^b \partial_1 G(x,y) \phi(y) \dx[y] \\
				&=\int_a^x \partial_1 G(x,y) \phi(y) \dx[y] + \int_x^b \partial_1 G(x,y) \phi(y) \dx[y]  \\
				\implies \quad u''(x) &=
				\underbrace{\partial_1 G(x,x-0)}_{= \partial_1 G(x+0,x)} \phi(x) + 0 - \int_a^x \partial_1^2 G(x,y) \phi(y) \dx[y] \\
				&\qquad\qquad+ 0 - \underbrace{\partial_1 G(x,x+0)}_{=\partial_1 G(x-0,x)} \phi(x) + \int_x^b \partial_1^2 G(x,y) \phi(y) \dx[y] \\
				&= \int_a^x \partial_1^2 G(x,y) \phi(y) \dx[y] + \int_x^b \partial_1^2 G(x,y) \phi(y) \dx[y] \phi(x)\underbrace{\partial_1 G(x+0,x) + \partial_1 G(x-0,x)}_{= - \f 1{p(x)}} \\
				&= \int_a^x \partial_1^2 G(x,y) \phi(y) \dx[y] + \int_x^b \partial_1^2 G(x,y) \phi(y) \dx[y] - \f {\phi(x)}{p(x)} \\
			\end{align*}
			Also
			\[
				\tilde A u = \int_a^b \underbrace{\tilde A G(\argdot , y)}_{=0 \text{ nach 3)}} \dx[y] + p \Big( - \f {\phi(x)}{p(x)} \Big) = - \phi(x)
			\]
			Damit ist $u \in C^2$.
			Außerdem
			\[
				R_1 u = \int_a^b \underbrace{R_1G(\argdot, y)}_{=0 \text{ nach 3)}} \dx[y] = 0
			\]
			und $R_2 u = 0$, also $u \in D(A)$.
		\end{seg}
		\begin{seg}[(i) $\implies$ (ii)]
			Sei $x \in ]a,b[$ fest, dann ist
			\begin{align*}
				\int_a^b G(x,y) \phi(y) \dx[y]
				&\stack{\text{(i)}}= - \int_a^b G(x,y) Ax(y) \dx[y] \\
				&= -\int_a^b \underbrace{G(x,y)}_{=G(y,x) \text{ nach \ref{3.13}}} \Big( (p(y)u'(y) )' - q(y)u(y) \Big) \dx[y] \\
				&= -\int_a^x G(y,x) \Big( (p(y)u'(y) )' - q(y)u(y) \Big) \dx[y] - \int_x^b G(y,x) \Big( (p(y)u'(y) )' - q(y)u(y) \Big) \dx[y] \\
				&= - \Big[G(y,x)p(y) u'(y) - \partial_1 G(y,x) p(y) u(y) \Big]_{y=a}^x \Big|_{y=x}^b \\
				& \qquad- \int_a^b \Big( \partial_1(p(y)\partial_1 G(y,x)) u(y) - G(y,x) q(y) u(y) \Big) \dx[y]
			\end{align*}
			\fixme[Ende fehlt]
		\end{seg}
	\end{proof}
\end{st}

\begin{st} \label{3.13}
	Es gilt
	\begin{enumerate}[1)]
		\item
			$G$ ist symmetrisch: $G(x,y) = G(y,x)$.
		\item
			Zu $A$ existiert höchstens eine Greensche Funktion.
	\end{enumerate}
	\begin{proof}
		Seien $G,H$ Greensche Funktionen zu $A$ und $\phi, \psi \in C(I \to \R)$.
		Setze
		\begin{align*}
			u(x) := \int_a^b G(x,y) \phi(y) \dx[y] \\
			v(x) := \int_a^b H(x,y) \psi(y) \dx[y] \\
		\end{align*}
		Dann ist
		\begin{align*}
			\int_a^b \Big(u \cdot \underbrace{Av}_{= -\psi} - \underbrace{Au}_{= - \phi} \cdot v\Big) \dx
			&= \<u,Av\> - \<Au,v\> = 0
		\end{align*}
		Also
		\begin{align*}
			-\int_a^b \underbrace{\int_a^b G(x,y) \phi(y) \dx[y]}_{= u(x)} \psi(x) \dx + \int_a^b \phi(y) \underbrace{\int_a^b H(y,x) \psi(x) \dx}_{= v(y)} \dx[y] = 0
		\end{align*}
		und
		\[
			\int_a^b \int_a^b (G(x,y - H(y,x)) \phi(y) \dx[y] \psi(x) \dx = 0
		\]
		für alle $\phi, \psi \in C(I \to \R)$ und damit $G(x,y) = H(y,x)$ für alle $(x,y) \in I\times I$, da $G$ und $H$ stetig.

		1) folgt dann für $H:= G$ und 2) da $H$ symmetrisch nach 1):
		\[
			G(x,y) = H(y,x) = H(x,y) 
		\]
	\end{proof}
\end{st}


