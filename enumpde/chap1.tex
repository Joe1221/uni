\chapter{Grundlagen} \label{chap:1}

\section{Definitionen und Notationen} \label{sec:1.1}

\begin{df}[Multiindex und partielle Ableitung] \label{1.1}
	Sei $u: \R^d \to \R$ hinreichend oft differenzierbar.
	Wir nennen $\beta = (\beta_1, \dotsc, \beta_d)^T \in \N_0^d$ mit $k := |\beta| := \sum_{i=1}^d \beta_i$ einen \emphdef[Multiindex]{Multiindex der Ordnung $k$}.

	Wir definieren
	\[
		\partial^\beta u := (\pddx[x_1])^{\beta_1} \dotsb (\pddx[x_d])^{\beta_d} u,
	\]
	die \emphdef[partielle Ableitung]{partielle Ableitung von $u$ zum Index $\beta$}.

	Sei $\mathbb{B}_k := \Set{\beta \in \N_0^d & |\beta| = k}$ die Menge aller Multiindizes der Ordnung $k$ und
	\[
		\Df^k u := (\partial^\beta u)_{\beta \in \mathbb{B}_k}
	\]
	der Vektor aller partieller Ableitungen der Ordnung $k$ (in beliebiger Reihenfolge).
\end{df}

\begin{df}[Ableitungsoperatoren] \label{1.2}
	Für $u: \R^d \to \R$ hinreichend oft differenzierbar definieren wir den \emphdef[Gradient]{Gradienten}
	\[
		\grad u(x) := \Nabla u(x) := \Vector{ \partial_{x_1} u(x) & \dots & \partial_{x_d} u(x) },
	\]
	wobei $x = (x_1, \dotsc, x_d)$ und $\partial_{x_i} := \pddx[x_i]$ für $i = 1, \dotsc, d$.

	Für ein hinreichend oft differenzierbares Vektorfeld $v: \R^d \to \R^d$ definieren wir die \emphdef{Divergenz} durch
	\[
		\div v(x) := \Nabla \cdot v(x) = \sum_{i=1}^d \partial_{x_i} v_i (x)
	\]
	und im Fall $d = 3$ zusätzlich die \emphdef{Rotation} durch
	\[
		\rot v(x) := \Nabla \times v(x) = \Vector{ \partial_{x_2} v_3 - \partial_{x_3} v_2 & \partial_{x_3} v_1 - \partial_{x_1} v_3 & \partial_{x_1} v_2 - \partial_{x_2} v_1 }.
	\]
	Wir nutzen die Abkürzung $\partial_{x_i}^2 := (\partial_{x_i})^2$ und definieren den \emphdef{Laplace-Operator} durch
	\[
		\Laplace u(x) := \Nabla \cdot (\Nabla u) = \div( \grad  u(x) ) = \sum_{i=1}^d \partial_{x_i}^2 u(x).
	\]
	Skalare Operatoren werden für vektorielle Funktionen komponentenweise definiert, z.B.
	\[
		\Laplace v(x) := \Vector{\Laplace v_1(x) & \dots & \Laplace v_d(x)},
	\]
	und für $b \in \R^d$
	\[
		(b \cdot \Nabla) v := \Big(\sum_{i=1}^d b_i \partial_{x_i}\Big) v
		= \Vector { \sum_{i=1}^d b_i \partial_{x_i} v_1 & \dots & \sum_{i=1}^d b_i \partial_{x_i} v_d }.
	\]
\end{df}

\begin{df}[Räume stetig differenzierbarer Funktionen] \label{1.3}
	Sei $\Omega \subset \R^d$ offen und beschränkt.
	Wir bezeichnen mit $C^m(\_\Omega, \R^n)$ den Raum der $m$-mal stetig differenzierbaren Funktionen (differenzierbar auf $\Omega$, sodass die $m$-ten Ableitungen stetig auf $\_\Omega$ fortsetzbar sind) von $\_\Omega$ nach $\R^n$.

	Für $n = 1$ schreiben wir auch kurz $C^m(\_\Omega) = C^m(\_\Omega, \R^1)$ und definieren hier für $u \in C^0(\_\Omega)$ die \emphdef{Supremumsnorm}
	\[
		\|u\|_\infty := \sup_{x\in \_\Omega} |u(x)|.
	\]
	Auf $C^m(\_\Omega)$ definieren wir damit eine Norm:
	\[
		\|u\|_{C^m(\_\Omega)} := \sum_{|\beta| \le m} \|\partial^\beta u\|_\infty,
	\]
	wobei $u \in C^m(\_\Omega)$.
	\begin{note}
		\begin{itemize}
			\item
				$C^m(\_\Omega)$ ist ein Banachraum, d.h. ein vollständiger, normierter Raum (Alt, Lemma 1.8)
			\item
				Man kann auch $C^m(\Omega)$ für offenes oder potentiell unbeschränktes $\Omega$ und auch $m = \infty$ definieren.
				Statt einer Norm wird dann eine Metrik (Frechét-Metrik) eingeführt, bzgl. der $C^m(\Omega)$ immernoch vollständig ist (Alt, Abschnitt 1.6).
		\end{itemize}
	\end{note}
\end{df}

\begin{df}[$L^p$-Räume] \label{1.4}
	Für $p \in [1, \infty)$ definieren wir
	\[
		\tilde L^p(\Omega) := \Set{ u: \Omega \to \R \text{ Lebesgue-messbar} & \big(\mathsmaller{\int}_\Omega |u|^p \big)^{\f 1p} < \infty}
	\]
	mit Seminorm
	\[
		\|u\|_p := \|u\|_{L^p(\Omega)}  := \Big(\int_\Omega |u|^p \Big)^{\f 1p}.
	\]
	Für $p = \infty$ definieren wir
	\[
		\tilde L^\infty(\Omega) := \Set{ u: \Omega \to \R \text{ Lebesgue-messbar} & \esssup_{x\in \Omega} |u(x)| < \infty }
	\]
	mit $\|u\|_\infty := \|u\|_{L^\infty(\Omega)} := \esssup_{x\in \Omega} |u(x)|$.

	Sei $\sim$ die Äquivalenzrelation auf $\tilde L^p(\Omega)$ via
	\[
		u \sim v \defiff \exists N \subset \Omega \text{ Nullmenge} : \forall x \in \Omega \setminus \N : u(x) = v(x).
	\]
	Dann definieren wir $L^p(\Omega)$ als die Menge der Äquivalenzklassen
	\[
		L^p(\Omega) := \tilde L^p(\Omega) / \sim.
	\]
	$\|u\|_p$ ist auf jeder einzelnen Äquivalenzklasse konstant und ist daher ohne weiteres auf $L^p(\Omega)$ erweiterbar.
	Wir nennen $(L^p(\Omega), \|\argdot\|_p)$ \emphdef[$L^p$-Raum]{normierter $L^p$-Raum}.
	\begin{note}
		\begin{itemize}
			\item
				$L^p(\Omega)$ ist vollständig bezüglich $\|\argdot\|_p$, also ein Banachraum (Alt, Lemma 1.1, Satz 1.14),
			\item
				Elemente von $L^p(\Omega)$ sind also Äquivalenzklassen von Funktionen, die sich nur auf einer Nullmenge unterscheiden.
				Konsequente Unterscheidung zwischen Funktionen und Äquivalenzklassen wäre mühsam.
				Daher folgende praktische Konvention: $u \in L^p(\Omega)$ soll heißen $u \in U \in L^p(\Omega)$ für eine geeignete Äquivalenzklasse $U$ mit $u: \Omega \to \R$ als Repräsentant von $U$.
			\item
				Wir nennen $L^p(\Omega)$ trotz der Äquivalenzklassen einen \emph{Funktionenraum}.
				Beim Arbeiten mit $L^p$-Räumen muss jedoch immer bedacht/hinterfragt werden, ob die betrachteten Operationen sinnvoll definiert sind, d.h. unabhängig vom Repräsentanten sind.
				Beispielsweise ist die Punktauswertung $u(x)$ nicht wohldefiniert, eine Mittelung über alle Funktionswerte jedoch schon.
\Timestamp{2014-10-17}
			\item
				$(u,v) := \<u,v\>_{L^(\Omega)} := \int_\Omega uv$ ist ein Skalarprodukt auf $L^2(\Omega)$ und $\|u\|_2 = \sqrt{(u,v)}$, also $L^2(\Omega)$ ist vollständig bezüglich einer aus einem Skalarprodukt induzierten Norm, also ein sogenannter \emphdef{Hilbertraum}.
			\item
				Zu einem Banachraum $V$ ist der \emph{Dualraum} $V'$
				\[
					V' := \Set{ \phi: V \to \R & \phi \text{ linear und stetig} }
				\]
				mit der induzierten Norm
				\[
					\|\phi\|_{V'} := \sup_{u\in V\setminus \Set 0} \frac{|\phi(u)|}{\|u\|_V}
				\]
				wieder ein Banachraum.
			\item
				Für $1 < p,q < \infty$ mit $\f 1p + \f 1q = 1$ ist $L^p(\Omega)$ ist isomorph zu $(L^q(\Omega))'$.
			\item
				$L^2(\Omega)$ ist also wegen $\f 12 + \f 12 = 1$ isomorph zu $L^2(\Omega)'$.
		\end{itemize}
	\end{note}
\end{df}

\begin{df}[lokal integrierbare Funktionen] \label{1.5}
	Wir definieren
	\[
		L^1_{\text{loc}}(\Omega) :=
		\Set{ u : \Omega \to \R \\ \text{ lebesgue-messbar} & \forall  K \subset \Omega \text{ kompakt } : \int_K |u(x)| \di[x] < \infty }
	\]
\end{df}

\begin{ex*}
	\begin{itemize}
		\item
			Es gilt offenbar $L^1(\Omega) \subset L^1_{\text{loc}}(\Omega)$,
			die Umkehrung jedoch nicht.
			Setze dazu $u(x) = 1$ für alle $x \in \Omega := \R$,
			es folgt $u \not\in L^1(\Omega)$, aber $u \in L^1_{\text{loc}}(\Omega)$.
	\end{itemize}
\end{ex*}

\begin{df}[Funktionen mit kompaktem Träger] \label{1.6}
	Wir definieren für $\Omega \subset \R^d$ offen (möglicherweise unbeschränkt) und $m \in \N_0 \cup \Set \infty$.
	\[
		C_0^m(\Omega)
		:= \Set{ u \in C^m(\Omega) & \supp(u) \subset \Omega \text{ ist beschränkt} },
	\]
	wobei $\supp(u) := \_{\Set{x \in \Omega & u(x) \neq 0}}$ den \emphdef{Träger} (engl. “support”) von $u$ bezeichnet.
\end{df}

\begin{st}[Fundamentalsatz der Variatonsrechnung] \label{1.7}
	Sei $u \in L^1_{\text{loc}}, \Omega \subset \R^d$ offen. Dann sind äquivalent
	\begin{enumerate}[i)]
		\item
			$\forall v \in C_0^\infty(\Omega) : \int_\Omega uv = 0$
		\item
			$u = 0$ fast überall in $\Omega$.
	\end{enumerate}
	\begin{proof}
		2.11 in Alt.
	\end{proof}
\end{st}

\begin{df}[Skalare PDE] \label{1.8}
	Sei $F: \R^{|\mathbb{B}_k|} \times \R^{|\mathbb{B}_{k-1}|} \times \dotsb \times \R^d \times \R \times \Omega \to \R$ gegeben.
	Dann ist
	\begin{equation} \label{eq:1.1}
		F\Big(\Df^k u(x), \Df^{k-1} u(x), \dotsc, \Df^1 u(x), u(x), x\Big) = 0,
		\qquad x \in \Omega
	\end{equation}
	eine \emphdef[partielle Differentialgleichung!skalare]{skalare partielle Differentialgleichung der Ordnung $k$} für eine unbekannte Lösung $u: \Omega \to \R$.
\end{df}

\begin{df}[Lineare/Nichtlineare PDE] \label{1.9}
	Die PDE \eqref{1.1} ist
	\begin{enumerate}[i)]
		\item
			\emphdef{linear}, falls sie die Form
			\[
				\sum_{|\beta| \le k} a_\beta(x) \partial^\beta u(x) = f(x)
			\]
			für einen Multiindex $\beta \in \N_0^d$ und gegebenen Funktionen $a_\beta, f$ besitzt.
			Die PDE heißt \emphdef{homogen}, falls $f(x) = 0$, sonst \emphdef{inhomogen}.
		\item
			\emphdef{semilinear}, falls sie die Form
			\[
				\sum_{|\beta| = k} a_\beta(x) \partial^\beta u(x) + a \Big(\Df^{k-1} u, \dotsc, \Df^1 u, u, x\Big) = 0
			\]
			besitzt.
		\item
			\emphdef{quasilinear}, falls sie die Form
			\[
				\sum_{|\beta| = k} a_\beta\Big(\Df^{k-1}u, \dotsc, u, x\Big) \partial^\beta u(x) + a\Big(\Df^{k-1} u, \dotsc, u, x\Big) = 0
			\]
			besitzt.
		\item
			\emphdef{voll nichtlinear} falls sie nichtlinear von $\Df^k$ abhängt.
	\end{enumerate}
	\begin{note}[Systeme]
		Ein System von PDEs ist eine Sammliung mehrerer skalarer PDEs für mehrere unbekannte Funktionen $u = (u_1, \dotsc, u_n)^T$.
		Typischerweise sind die einzelnen PDEs miteinander gekoppelt und die Anzahl der Gleichungen und der Unbekannten stimmen überein. 
	\end{note}
	\begin{note}[zeitäbhängige Probleme]
		Alle Notationen und Definitionen für $\Omega \subset \R^d$ mit $x = (x_1, \dotsc, x_d)^T \in \Omega$ erweitern wir auf Orts-Zeit-Zylinder $\Omega_T := \Omega \times (0, T) \subset \R^d \times \R$ mit $(x,t) \in \Omega_T$, $T \in \R^+ \cup \Set \infty$.
		Ortsvariable $x$, Zeitvariable $t$.
		Insbesondere $\partial_t := \pddx[t], \partial_t^2 := \pddx[t^2]$.
		Dann bezeichnet für $u \in C^1(\Omega_t)$
		\begin{align*}
			\Nabla_x u(x) &:= \Vector{ \partial_{x_1} u(x) & \dots & \partial_{x_d} u(x) }, \\
			\Laplace_x u(x) &:= \sum_{i=1}^d \partial_{x_i}^2 u(x)
		\end{align*}
		Falls keine Verwechslungsgefahr besteht, lässt man das Subskript $x$ in $\Nabla_x, \Laplace_x$ auch weg.
	\end{note}
\end{df}

Im Folgenden sind einige der häufiger auftretenden PDEs aufgelistet.
Etwaige Koeffizienten sind oft der Einfachheit halber gleich $1$ gesetzt.

\begin{ex}[Lineare PDEs] \label{1.10}
	\begin{itemize}
		\item
			\emphdef{Laplace-Gleichung}: $-\Laplace u = 0$,
		\item
			\emphdef{Poisson-Gleichung}: $-\Laplace u = f$,
		\item
			\emphdef{Helmholtz-Gleichung}: $-\Laplace u - \lambda u = 0$ für $\lambda > 0$,
		\item
			\emphdef{Advektions-Gleichung}: $\partial_t u + b \cdot \Nabla u = 0$ für $b \in \R^d$
		\item
			\emphdef{Wärmeleitungs-Gleichung} oder \emphdef{Diffusionsgleichung}: $\partial_t u - \Laplace u = 0$.
		\item
			\emphdef{Schrödinger-Gleichung}: $i \partial_t u + \Laplace u = 0$, wobei $i = \sqrt{-1} \in \C$.
		\item
			\emphdef{Wellengleichung}: $\partial_t^2 u - \Laplace u = 0$,
		\item
			\emphdef{Airy's-Gleichung}: $\partial_t u + \partial_x^3 u = 0$
		\item
			\emphdef{Balken-Gleichung}: $\partial_t u + \partial_x^4 u = 0$.
		\item
			\emphdef{Allgemeine Diffusions-Advektions-Reaktions-Gleichung}:
			\[
				- \div \cdot (A \Nabla u) + b \cdot \Nabla u + c u = f,
			\]
			wobei $A \in \R^{d\times d}, b \in \R^d, c \in \R$.
			% fixme: bezeichnung : Diffusion, Advektion, Reaktions, Quellterm
	\end{itemize}
\end{ex}

\begin{ex}[Nichtlineare PDEs] \label{1.11}
	\begin{itemize}
		\item
			\emphdef{Nichtlineare Poission-Gleichung}: $-\Laplace u = f(u)$,
		\item
			\emphdef{$p$-Laplace-Gleichung}: $\div (|\Nabla u|^{p-2} \Nabla u) = 0$,
		\item
			\emphdef{Minimalflächen-Gleichung}: $\div ( \f{\Nabla u}{\sqrt{1 + |\Nabla u|^2}} ) = 0$,
		\item
			\emphdef{Hamilton-Jacobi-Gleichung}: $\partial_t u + H(\Nabla u, u) = 0$,
		\item
			\emphdef{Burgers-Gleichung}: $\partial_t u + \partial_x(\f 12 u^2) = 0$,
		\item
			\emphdef{skalare Erhaltungsgleichung}: $\partial_t u + \Nabla \cdot(f(u, \Nabla u)) = 0$,
		\item
			\emphdef{Korteweg de Vries Gleichung (KdV)}: $\partial_t u + u \partial_x u + \partial_x^3 u = 0$,
		\item
			\emphdef{allgemeine Transport-Reaktions-Gleichung}: $\partial_t u + \div(f(u, \Nabla u)) = g(u)$.
	\end{itemize}
\end{ex}

\begin{ex}[Lineare Systeme] \label{1.12}
	\begin{itemize}
		\item
			\emphdef{Maxwell-Gleichungen}:
			\begin{align*}
				\partial_t E &= \rot B, \\
				\partial_t B &= - \rot E, \\
				0 &= \div B = \div E.
			\end{align*}
		\item
			\emphdef{Oseen-Gleichungen}:
			\begin{align*}
				(b \cdot \Nabla) u - \mu \Laplace u + \Nabla p &= 0, \\
				\div u &= 0.
			\end{align*}
			Für $b = 0$ sind dies die \emphdef{Stokes-Gleichungen}.
		\item
			\emphdef[Poisson-Gleichung!gemischte Formulierung]{gemischte Formulierung der Poisson-Gleichung}:
			\begin{align*}
				\div v &= f, \\
				v + \Nabla u &= 0
			\end{align*}
	\end{itemize}
\end{ex}

\begin{ex}[Nichtlineare Systeme] \label{1.13}
	\begin{itemize}
		\item
			System von Erhaltungsgleichungen
			\[
				\partial_t u + \div(F(u)) = 0
			\]
			für $F: \R^d \to \R^d$
		\item
			\emphdef{Navier-Stokes-Gleichungen}
			\begin{align*}
				\partial_t u + (u\cdot \Nabla) u - \mu \Laplace u + \Nabla p &= 0, \\
				\div u &= 0
			\end{align*}
			Für $\mu = 0$ ergeben sich die \emphdef{Euler-Gleichungen} für ein nicht-viskoses, inkompressibles Fluid.
	\end{itemize}
\end{ex}


\section{Klassifikation linearer PDEs zweiter Ordnung} \label{sec:1.2}


\begin{df}[linearer Differentialoperator zweiter Ordnung] \label{1.14}
	Sei $\Omega \subset \R^d$ offen, $A = (a_{ij})_{i,j = 1}^d \in C^0 (\Omega, \R^{d\times d}), b = (b_i)_{i=1}^d \in C^0(\Omega)^d, c \in C^0(\Omega)$.
	Dann nennen wir $\scr L: C^2(\Omega) \to C^0(\Omega)$ mit
	\begin{equation} \label{eq:1.2}
		(\scr L u)(x) := - \sum_{i,j=1}^d a_{ij}(x) \partial_{x_i} \partial_{x_j} u(x) + \sum_{i=1}^d b_i(x) \partial_{x_i} u(x) + c(x) u(x)
	\end{equation}
	\emphdef[Differentialoperator!allgemein, linear, zweiter Ordnung]{allgemeiner linearer Differentialoperator zweiter Ordnung}.
	\begin{note}
		\begin{itemize}
			\item
				$\scr L$ erfasst die Differential-Operatoren in der Laplace-, Poisson-, Helmholtz-, Wärmeleitungs-, Diffusions- und in der allgemeinen Diffusions-Advektions-Reaktionsgleichung aus \ref{1.10}.
			\item
				Zu $f \in C^0(\Omega)$ lässt sich eine entsprechende PDE formulieren:
				\begin{equation} \label{eq:1.3}
					\scr L u(x) = f(x),
				\end{equation}
				für $x \in \Omega$.
			\item
				Wir nennen $-\sum_{i,j=1}^d a_{ij}(x) \partial_{x_i} \partial_{x_j} u$ \emphdef{Hauptteil} von $\scr L$.
			\item
				Ohne Einschränkung kann $A$ als symmetrisch vorausgesetzt werden, denn $\partial_{x_i} \partial_{x_j} u = \partial_{x_j} \partial_{x_i} u$.
				Falls $A$ nicht symmetrisch ist, so ergibt $A_s := \f 12 (A + A^T)$ identisches $\scr L$. \Exercise
				$A$ hat somit ohne Einschränkung nur reelle Eigenwerte.
			\item
				Auch geläufig ist die sogennante \emphdef{Divergenzform}
				\[
					(\_{\scr L} u)(x) := -\Nabla \cdot (A(x) \cdot \Nabla u(x)) + \Nabla \cdot (b(x) \cdot u(x)) + cu(x),
				\]
				welche man bei differenzierbaren $a_{ij}, b_i$ leicht in obige Form bringen kann.
				\begin{proof}
					Man erhält
					\begin{align*}
						(\_{\scr L} u)(x) &= - \Nabla \cdot (A \cdot \Nabla u) + \Nabla \cdot (b \cdot u) + c u \\
						&= - \sum_{i,j=1}^d \partial_{x_i} (a_{ij} \partial_{x_j} u) + \sum_{i=1}^d \partial_{x_i} (b_i u) + cu \\
						&= -\sum_{i,j=1}^d a_{ij} \partial_{x_i} \partial_{x_j} u - \sum_{j=1}^d \sum_{i=1}^d (\partial_{x_i} a_{ij}) \partial_{x_j} u \\
						&\qquad + \sum_{i=1}^d b_i \partial_{x_i} u + \sum_{i=1}^d (\partial_{x_i} b_i) u + cu \\
						&= - \sum_{i,j=1}^d a_{ij} \partial_{x_i} \partial_{x_j} u + \sum_{i=1}^d \tilde b_i \partial_{x_i} u + \tilde c u
					\end{align*}
					mit der Wahl
					\[
						\tilde b_i := b_i - \sum_{j=1}^d (\partial_{x_j} a_{ji}),
						\quad
						\tilde c := c + \sum_{i=1}^d \partial_{x_i} b_i.
					\]
				\end{proof}
		\end{itemize}
	\end{note}
\end{df}

\begin{df}[Klassifikation] \label{1.15}
	Der Operator $\scr L$ aus \eqref{eq:1.2} ist
	\begin{itemize}
		\item
			\emphdef{elliptisch} in $x$, falls alle Eigenwerte von $A(x)$ positiv,
		\item
			\emphdef{parabolisch} in $x$, falls $d-1$ Eigenwerte von $A(x)$ positiv, ein Eigenwert Null ist, aber $\rg([A(x),b(x)]) = d$.
		\item
			\emphdef{hyperbolisch} in $x$, falls $d-1$ Eigenwerte von $A(x)$ positiv und ein Eigenwert negativ ist.
	\end{itemize}
	$\scr L$ \emphdef{elliptisch}, \emphdef{parabolisch}, bzw. \emphdef{hyperbolisch}, wenn er es in jedem $x \in \Omega$ ist.
	Die PDE \eqref{eq:1.3} ist \emphdef{elliptisch}, \emphdef{parabolisch}, bzw. \emphdef{hyperbolisch}, wenn $\scr L$ dies ist.
	\begin{note}
		\begin{itemize}
			\item
				Die Begriffe sind motiviert aus Kegelschnitten oder Quadriken, denn
				\[
					z^T A(x) z = 1
				\]
				beschreibt unter den genannten Voraussetzungen ein Ellipsoid, Paraboloid, bzw. Hyperboloid.
		\end{itemize}
	\end{note}
\end{df}

\Timestamp{2014-10-21}

\begin{ex} \label{1.16}
	\begin{itemize}
		\item
			Die Laplace/Poisson-Gleichung ist elliptisch:
			\[
				\scr L u := - \Laplace u
				\quad \implies \quad A(x) = \Matrix{1 & 0 \\ 0 & 1}, b = c = 0.
			\]
			$A(x)$ besitzt offenbar rein positive Eigenwerte.
		\item
			Die instationäre Wärmeleitungsgleichung oder Diffusionsgleichung ist parabolisch:
			\[
				\scr L u := \partial_t u - \Laplace_x u
				\quad \implies \quad
				A(x) = \Matrix{1 &  &  &  \\ & \ddots & & \\ & & 1 & \\ & & & 0}, b = \Vector{0 & \dots & 0 & 1}, c = 0
			\]
			alle Eigenwaerte von $A$ bis auf eine sind positiv, ein Eigenwert Null, $\rg(A, b) = d$.
		\item
			Die Wellengleichung ist hyperbolisch:
			\[
				\scr L u := \partial_t^2 u - \Laplace_x u
				\qquad \implies \qquad
				A(x) = \Matrix{1 &  &  &  \\ & \ddots & & \\ & & 1 & \\ & & & -1}, b = 0, c = 0
			\]
		\item
			Tricomi-Gleichung $\Omega \subset \R^2$:
			\[
				x_2 \partial_{x_1}^2 u - \partial_{x_2}^2 u = 0
				\qquad \implies \qquad
				A = \Matrix{ x_2 & 0 \\ 0 & 1 }
			\]
			ist vom gemischten Typ: elliptisch für $x_2 > 0$, hyperbolisch für $x_2 < 0$.
	\end{itemize}
\end{ex}

Die Unterscheidung im Sinne der Charakterisierung aus \ref{1.15} ist sinnvoll wegen wesentlich unterschiedlicher Lösungseigenschaften.

\begin{itemize}
	\item
		Elliptische PDE:
		\begin{itemize}
			\item
				Es werden meist Randbedingungen vorgeschrieben
			\item
				Lösungen sind oft sehr glatt
			\item
				Lösungen erfüllen häufig ein sogenanntes „Maximumsprinzip“
		\end{itemize}
	\item
		Parabolische PDE
		\begin{itemize}
			\item
				Die ausgezeichnete Achse (zum Null-Eigenwert) ist meist die Zeit
			\item
				Die PDE kann dann oft als
				\[
					\partial_t u + \tilde{\scr L} u = \tilde f
				\]
				umgeschrieben werden, wobei $\tilde{\scr L}$ ein elliptischer Operator
			\item
				Es werden häufig Anfangswertbedingungen für $u$ vorgegeben und gegebenenfalls Randwerte
			\item
				Gleichung hat einen „regularisierenden Effekt“:
				Lösungen sind oft glatter als die Daten.
			\item
				unendliche Ausbreitungsgeschwindigkeit
		\end{itemize}
	\item
		Hyperbolische PDE:
		\begin{itemize}
			\item
				Die ausgezeichnete Achse ist meist die Zeit.
				Die PDE kann dann oft als
				\[
					\partial_t^2 u + \tilde{\scr L} u = \tilde f
				\]
				mit elliptischem $\tilde{\scr L}$ geschrieben werden.
			\item
				endliche Ausbreitungsgeschwindigkeit
			\item
				Anfangs- und gegebenenfalls Randbedingungen
			\item
				beschreiben oft Schwingungsvorgänge
			\item
				kein regularisierender Effekt
		\end{itemize}
\end{itemize}

\begin{df}[Gleichmäßig elliptisch] \label{1.17}
	$\scr L$ ist \emphdef{gleichmäßig elliptisch}, falls $\alpha > 0$ existert, sodass
	\[
		z^T A(x) z \ge \alpha \|z\|^2
	\]
	für alle $z \in \R^d, x \in \Omega$, d.h. alle Eigenwerte von $A(x)$ sind $\ge \alpha$.
	$\alpha$ nennen wir \emphdef{Elliptizitätskonstante}.
\end{df}


% 1.3
\section{Lösungskonzepte} \label{sec:1.3}

\begin{df}[Klassische Lösung] \label{1.18}
	Sei eine skalare PDE \eqref{eq:1.1} gegeben.
	Falls eine Funktion $u \in C^k(\Omega)$ die Gleichung \eqref{eq:1.1} erfüllt für alle $x \in \Omega$, so nennen wir $u$ \emphdef{klassische Lösung} der PDE.
	\begin{note}[Wohlgestelltheit]
		\begin{itemize}
			\item
				Ein Lösungsbegriff ist sinnvoll definiert, wenn man Bedingungen formulieren kann, sodass die PDE mit den Zusatzbedingungen wohlgestellt ist (im Sinne von Hadamard), d.h.
				\begin{enumerate}[i)]
					\item
						Es existiert eine Lösung,
					\item
						Lösung ist eindeutig,
					\item
						Lösung hängt stetig von den Daten ab („kleine“ Änderungen der Daten ergeben nur „kleine“ Änderungen in der Lösung).
				\end{enumerate}
			\item
				Eine PDE erfordert typischerweise Zusatzbedingungen, sonst ist keine Eindeutigkeit und damit auch keine Wohlgestelltheit zu erwarten.

				Sei $u \in C^2(\Omega)$ eine klassische Lösung von $-\Laplace u = f$.
				Sei $\_u \in \P_1(\Omega)$, dann ist $\Laplace \_u = 0$ und $u \in C^\infty$, also ist auch $u + \_u$ eine klassische Lösung von $-\Laplace u = f$:
				\[
					- \Laplace(u + \_u) = - \Laplace u - \Laplace \_u = f.
				\]
		\end{itemize}
	\end{note}
	\begin{note}[Anfangs- und Randbedingungen]
		\begin{itemize}
			\item
				Für eine PDE auf einem beschränktem Gebiet $\Omega \subset \R^d$ mit $\Gamma := \partial \Omega$ fortert man meist Randbedingungen.
				Typische Randbedingungen sind
				\begin{enumerate}[i)]
					\item
						\emphdef{Dirichlét-Randbedingungen}: $u(x) = g(x)$ auf $\Gamma$ für stationäre (zeit-unabhängige) Probleme mit vorgegebene Funktion $g$.
						Anschaulich z.B. bei Wärmeleitung: Kühlung/Heizung auf eine feste Umgebungstemperatur.
					\item
						\emphdef{Neumann-Randbedingungen}: z.B. $- \Nabla u(x) \cdot n = h(x)$ auf $\Gamma$ (für die Poisson-Gleichung)
						Allgemeiner:
						\[
							f(x,t,u(x)) \cdot n(x) = h(x,t)
						\]
						für $(x, t) \in \Gamma \times (0,T)$ für die Transport-Reaktionsgleichung.
						Dabei bezeichnet $n(x)$ die \emphdef{Einheitnormale}.
						Man gibt den \emph{Fluss} der Lösung über die Kante mittels $h$ vor.
						Beispielsweise beschreibt $h(x,t) = 0$ eine „\emphdef{isolierende Randbedingung}“.
					\item
						\emphdef{Robin'sche Randbedingung}:
						\[
							f(x, t, u(x,t)) \cdot n(x) = h_0 + u \cdot h_1.
						\]
				\end{enumerate}
				Weitere Formen:
				\begin{itemize}
					\item
						Auf verschiedenen Randteilen verschiedene Typen.
					\item
						„periodische Randbedingungen“
				\end{itemize}
			\item
				Für zeitabhängige PDE auf $\Omega_T := \Omega \times (0,T)$ fordert man meist Anfangsbedingungen.
				Gegeben $u_0: \Omega \to \R$, Forderung $u(x, 0) = u_0(x)$ für $x \in \Omega$ (wie in der Numerik 2: Anfangsbedingungen für gewöhnliche Differentialgleichungen).
			\item
				Eine PDE mit solchen Bedingungen heißt dann \emphdef{Anfangswertproblem} (AWP), \emphdef{Randwertproblem} (RWP) oder \emphdef{Anfangs-Randwert-Problem} (ARWP).
				Ein AWP wird auch oft \emphdef{Cauchy-Problem}.
		\end{itemize}
	\end{note}
\end{df}

Es folgen einige Aussagen zu klassischen Lösungen und deren Eigenschaften

\begin{df}[AWP für Diffusionsgleichung] \label{1.19}
	Für $\Omega = \R^d, \Omega_T := \Omega \times (0, T), T \in \R_+ \cup \Set \infty, u_0 \in C^0(\Omega) \cap L^\infty(\Omega)$ suchen wir eine klassische Lösung $u$ von
	\begin{align*}
		\partial_t u - \Laplace_x u &= 0  &&\text{in $\Omega_T$}\\
		u(\argdot, u) &= u_0  &&\text{in $\Omega$}
	\end{align*}
\end{df}

\begin{st}[Existenz für AWP der Diffusionsgleichung] \label{1.20}
	Wir definieren die \emphdef{Fundamentallösung} (oder \emphdef{Wärmeleitungskern}) $\Phi: \Omega_T \to \R$
	\[
		\Phi(x,t) := \frac{1}{(4\pi t)^{\frac{d}{2}}} e^{- \frac{\|x\|^2}{4t}},
		\qquad (x,t) \in \Omega_T.
	\]
	Dann ist
	\[
		u(x,t) := \big(\Phi(\argdot, t) \ast u_0\big) (x) := \int_{\R^d} \Phi(x-y, t) u_0(y) \di[y],
		\qquad (x,t) \in \Omega_T
	\]
	eine klassische Lösung des AWP.
	\begin{proof}
		Evans oder Skript PDEMAS 13/14.
	\end{proof}
	\begin{note}
		\begin{itemize}
			\item
				$u(x,t)$ ist sogar $C^\infty(\Omega_T)$, obwohl die Anfangsdaten gröber sind.
				Dies nennt man \emphdef{regularisierenden Effekt} der PDE (siehe Evans §2.3 Thm 1).
			\item
				\emphdef{Unendliche Ausbreitungsgeschwindigkeit}: Jeder Wert $u_0(x)$ geht in die Lösung $u(x + \Delta x, \Delta t)$ für beliebig kleines $\Delta t$, beliebig großes $\Delta x$.
		\end{itemize}
	\end{note}
\end{st}

\begin{df}[AWP für Wellengleichung, $d = 1$] \label{1.21}
	Für $\Omega = \R, T > 0, \Omega_T := \Omega \times (0, T), u_0 \in C^2(\Omega), v_0 \in C^1(\Omega)$ suchen wir eine klassische Lösung $u \in C^2(\Omega_T) \cap C^1(\_{\Omega_T})$ als Lösung von
	\begin{align*}
		\partial_t^2 u - c^2 \Laplace_x u &= 0 &&\text{in $\Omega_T$}, \\
		u(\argdot, 0) &= u_0  && \text{in $\Omega$}, \\
		\partial_t u(\argdot, 0) &= v_0.
	\end{align*}
\end{df}

\begin{st}[Existenz für AWP der Wellengl., d'Alembert'sche Formel, $d = 1$] \label{1.22}
	Die Klassische Lösung des AWP aus \ref{1.21} ist
	\[
		u(x,t) := \f 12 \big( u_0(x  + ct) + u_0(x-ct)\big) + \f 1{2c} \int_{x-ct}^{x+ct} v_0(s) \di[s].
	\]
	\begin{proof}
		Anfangsbedingungen sind erfüllt:
		\begin{align*}
			u(x,0) &= \f 12 \big(u_0(x) + u_0(x)\big) + \f 1{2c} \int_x^x v_0(s) \di[s] = u_0(x), \\
			\partial_t u(x,t) &= \f 12 (c_i u_0'(x+ct) -cu_0'(x-ct)) + \f 1{2c}( c v_0(x+ct) + cv_0(x-ct)), \\
			\partial_t u(x,t) &= \f 1{2c} (c v_0(x) + c v_0(x)) = v_0(x).
		\end{align*}
		Die PDE ist erfüllt:
		\begin{align*}
			\partial_t^2 u(x,t) &= \f 12 \big(c^2 u_0''(x+ct) + c^2 u_0''(x-ct)\big) + \f 1{2c} \big( c^2 v_0'(x+ct) - c^2 v_0'(x-ct) \big), \\
			\partial_x u(x,t) &= \f 12 \big(u_0'(x + ct) + u_0'(x-ct)\big) + \f 1{2c} \big( v_0(x+ct) - v_0(x-ct) \big), \\
			\partial_x^2 u(x,t) &= \f 12 \big(u_0''(x+ct) + u_0''(x-ct)\big) + \f 1{2c} \big( v_0'(x+ct) - v_0'(x-ct) \big),
		\end{align*}
		also
		\[
			\partial_t^2 u - c^2 \partial_x^2 u
			= 0.
		\]
	\end{proof}
	\begin{note}
		\begin{itemize}
			\item
				$u(x,t)$ ist nur $C^2$, nicht glatter als die Daten, kein regularisierender Effekt,
			\item
				endliche Ausbreitungsgeschwindigkeit $c$:
				$u_0(x), v_0(x)$ beeinflussen nur $u(x,t)$ für $(x,t) \in C(x_0)$, d.h. innerhalb eines \emphdef{Einflusskegels}:
				\[
					C(x_0) := \Set{ (x,t) & x_0 - ct \le x \le x_0 + ct }.
				\]
				Umgekehrte Sicht: \emphdef{Abhängigkeitskegel} $K(x,t)$:
				\[
					K(x,t) := \Set{ (\_x, \_t) & \_t \le t, x - c(t - \_t) \le \_x \le x + c(t - \_t) }
				\]
		\end{itemize}
	\end{note}
\end{st}

\begin{df}[RWP für Poisson-Gleichung] \label{1.23}
	Sei $\Omega \subset \R^d$ offen und beschränkt, $f \in C^0(\Omega), g \in C^0(\Gamma), \Gamma := \Boundary \Omega$.
	Gesucht ist $u \in C^2(\Omega) \cap C^0(\_\Omega)$ als Lösung von
	\begin{align*}
		- \Laplace u &= f  && \text{in $\Omega$}, \\
		u &= g  && \text{auf $\Gamma$}.
	\end{align*}
	\begin{note}
		\begin{itemize}
			\item
				Falls $f = 0$, ist $\Laplace u = 0$, wir nennen $u$ dann \emphdef{harmonisch}.
			\item
				Für die Poisson-Gleichung mit $\Omega = \R^d$ kann man auch durch Faltung von $f$ mit einer Fundamentallösung ein $u \in C^\infty(\R^d)$ als Lösung konstruieren (siehe Evans oder PDEMAS 13/14).
				Wir verzichten an dieser Stelle auf Details.
			\item
				Eine interessante Eigenschaft ist das \emph{Maximumsprinzip} für Lösungen des RWP.
		\end{itemize}
	\end{note}
\end{df}

\begin{st}[Maximumsprinzip für Poission-RWP] \label{1.24}
	Sei $u$ klassische Lösung des RWP aus \ref{1.23} mit $f(x) \le 0, x \in \Omega$.
	Dann nimmt $u$ sein Maximum auf dem Rand an, d.h.
	\[
		\max_{x\in \_\Omega} u(x) = \max_{x \in \Gamma} u(x) = \max_{x\in \Gamma} g(x).
	\]
\Timestamp{2014-10-24}
	\begin{proof}
		Angenommen $c := m_{\_\Omega} - m_{\Gamma} := \max_{x\in \_\Omega} u(x) - \max_{x\in\Gamma} u(x) > 0$.
		Setze $\rho := \max_{x\in\Omega} \|x\|^2$, wähle $\eps > 0$ sodass $\eps \rho < c$.
		Definiere $v(x) := u(x) + \eps \|x\|^2, x \in \_\Omega$.
		Dann gilt
		\[
			\max_{x\in\Gamma} v(x) \le m_\Gamma + \eps \rho
		\]
		und
		\[
			\max_{x\in\_\Omega} v(x) \ge m_{\_\Omega} = c + m_\Gamma > m_\Gamma + \eps \rho.
		\]
		Also existiert $x_0 \in \Omega$ mit $v(x_0) = \max_{x\in \_\Omega} v(x)$, d.h. ein lokales Maximum in $\Omega$.
		Es folgt
		\[
			\pddx[x_j^2] v(x_0)
			= \ddx[t^2] v(x_0 + te_j) \big|_{t=0}
			\le 0
		\]
		und damit
		\[
			\Laplace v(x_0) \le 0
			\quad\implies\quad
			-\Laplace v(x_0) \ge 0
		\]
		Wegen $\Laplace(\|x\|^") = \sum_{i=1}^d 2 = 2d$ folgt
		\[
			0
			\ge f(x_0)
			= - \Laplace u(x_0)
			= \underbrace{- \Laplace v(x_0)}_{\ge 0} + \eps \underbrace{\Laplace (\|x\|^2)}_{=2d}
			\ge 2\eps d
			> 0,
		\]
		ein Widerspruch.
		Somit ist $c < 0$ und $m_\Gamma \ge m_{\_\Omega}$.
	\end{proof}
	\begin{note}
		Analog gilt ein Minimumprinzip für harmonische Funktionen, falls $f \ge 0$.
	\end{note}
\end{st}

\begin{kor}[Eindeutigkeit für Poisson-RWP] \label{1.25}
	Die Klassische Lösung des RWP auf \ref{1.23} ist eindeutig.
	\begin{proof}
		Seien $u, \_u$ zwei Lösungen.
		Dann erfüllt $w := u - \_u$ das homogene RWP
		\begin{align*}
			-\Laplace w &= 0 & & \text{in $\Omega$}, \\
			w &= 0 && \text{auf $\Gamma$}.
		\end{align*}
		Das Maximumsprinzip \ref{1.24} ergibt $\max_{x\in\_\Omega} w(x) = \max_{x\in\Gamma} w(x) = 0$, also $w(x) \le 0$ in $\_\Omega$.
		Analog mit dem Minimumsprinzip $w \ge 0$ und folglich $w = 0$ in $\_\Omega$.
	\end{proof}
\end{kor}

\begin{nt*}[Motivation für andere Lösungsbegriffe]
	Klassische Lösungen sind nicht immer der passende Begriff.
	\begin{enumerate}[i)]
		\item
			Unstetiger Quellsterm in der Poisson-Gleichung $-u'' = f(x)$, $x \in \Omega := (0,1)$.
			Falls $f$ unstetig ist, so kann eine Lösung $u$ nicht in $C^2(\_\Omega)$ liegen.
		\item
			Unstetige Koeffizienten im Diffusionsproblem (z.B. geschichtete Materialien) $-\partial_x(a(x) \partial_x u) = 0, x \in \Omega := (0,1)$.
			Falls $a(x)$ unstetig, kann z.B. ein stetiges $u$ mit unstetiger Ableitung eine Lösung sein?
			Betrachte
			\begin{align*}
				a (x) &= \begin{cases}
					1 & x \le \f 12 \\
					2 & x > \f 12
				\end{cases},&
				u(x) &= \begin{cases}
					x & x \le \f 12 \\
					\f 14 + \f 12 x & x > \f 12
				\end{cases}.
			\end{align*}
			$u$ ist keine klassische Lösung, aber eine sogenannte „schwache Lösung“, in einem geeigneten Sobolev-Raum (siehe \ref{chap:3}).
		\item
			Wellengleichung mit allgemeinen Anfangsdaten.
			Die Lösungsformel aus \ref{1.22} macht auch für nicht differenzierbare, oder unstetige Funktionen Sinn.
			Bei $v_0 = 0$ und $u_0 \in L^1(\Omega) \cap L^\infty(\Omega)$
			\[
				u(x,t) := \f 12 \big( u_0(x-ct) + u_0(x+ct)\big)
			\]
			ist nicht differenzierbar/unstetig, also keine klassische Lösung, aber eine „Distributionslösung“.
		\item
			Bei nichtlinearen Erhaltungsgleichungen existieren klassische Lösungen gegebenenfalls nur für endliche Zeiten, es können trotz glatter Daten Unstetigkeiten entstehen.
	\end{enumerate}
\end{nt*}

\begin{ex}[Unstetigkeit bei nichtlinearem Transport] \label{1.26}
	Sei $\Omega = \R, \Omega_T = \Omega \times (0,T)$, $T = \infty$.
	Zu $f \in C^2(\R), u_0 \in C^1(\R)$ betrachte die Transportgleichung
	\begin{align*}
		\partial_t u + \partial_x f(u) &= 0 && \text{in $\Omega_T$}, \\
		u(\argdot, 0) &= u_0 && \text{in $\Omega$,}
	\end{align*}
	z.B. $f(u) = \f 12 u^2$, dann auch \emphdef{Burgers-Gleichung} genannt.

	Sei $u$ eine klassische Lösung, wir definieren \emphdef{Charakteristiken}, oder \emphdef{charakteristische Kurven}
	\[
		\Gamma := \Set{ (\gamma(t), t) & t \in (0,T) },
	\]
	mit $\gamma(0) = x_0, \gamma'(t) = f'(u(\gamma(t), t))$.
	Die Lösung $u$ ist konstant entlang $\Gamma$, denn für in $(\gamma(t),t)$ gilt
	\begin{align*}
		(\Nabla u) \cdot v = \Vector{\partial_x u & \partial_t u} \cdot \Vector{\gamma'(t) & 1}
		&= \partial_t u + \gamma'(t)  \partial_x u \\
		&= \partial_t u + f'(u) \partial_x u \\
		&= \partial_t u + \partial_x f(u)
		= 0
	\end{align*}
	mit Tangente $v = \Vector{\gamma'(t) & 1}$.
	Also ist $\Gamma$ eine Gerade, denn
	\[
		\gamma'(t) = f'(\underbrace{u(\gamma(t), t)}_{=\const}) = \const.
	\]
	Die Lösung $u$ ist vollständig durch Werte von $u_0$ festgelegt, falls die Charakteristiken $\Omega_T$ überdecken.
	Die Lösung ist im Allgemeinen nur bis endliche Zeiten wohldefiniert, denn Charakteristiken können sich schneiden.
	Der Begriff der „schwachen Lösung“, bzw. „Entropielösung“ ist ein geeigneter Lösungsbegriff, der auch solche Unstetigkeiten zulässt (siehe \ref{chap:5}).
\end{ex}

\begin{df}[Distributionslösung] \label{1.27}
	Sei $\Omega \subset \R^d$ offen, $\scr L: C^k(\Omega) \to C^0(\Omega)$ ein linearer Differentialoperator,
	\[
		\scr L u := \sum_{|\beta| \le k} a_\beta \partial^\beta u
	\]
	mit Koeffizienten $a_\beta \in \R$.
	Sei $f \in L^1_{\text{loc}}(\Omega)$.
	Dann heißt $u\in L^1_{\text{loc}}$ \emphdef{Distributionslösung} von $\scr L u = f$ in $\Omega$, wenn
	\begin{equation} \label{eq:1.4}
		\sum_{|\beta|\le k} (-1)^{|\beta|} a_\beta \int_\Omega u \partial^\beta \phi \di[x]
		 = \int_\Omega f \phi \di[x]
	\end{equation}
	für alle $\phi \in C_0^\infty(\Omega)$.
	\begin{note}
		\begin{itemize}
			\item
				Eine Distributionslösung macht keine Aussage über Randwerte, im Allgemeinen ist keine Eindeutigkeit zu erwarten.
			\item
				Distributionslösungen schließen klassische Lösungen mit ein, sind also eine echte Verallgemeinerung dieser.
		\end{itemize}
	\end{note}
\end{df}

\begin{st}[Klassische Lösungen und Distributionslösungen] \label{1.28}
	Sei $u$ eine Distributionslösung gemäß \eqref{eq:1.4} und $f \in C^0(\Omega), u \in C^k(\Omega)$, dann ist $u$ eine klassische Lösung.
	\begin{proof}
		Nutze partielle Integration ($k$-fach), Randterme verschwinden wegen $\partial^\beta \phi |_{\Boundary \Omega} = 0$.
		\[
			\underbrace{\sum_{|\beta|\le k} \underbrace{(-1)^{|\beta|} (-1)^{|\beta|}}_{=1} a_\beta \int_\Omega (\partial^\beta u) \phi \di[x]}_{= \int_\Omega (\scr L u) \phi \di[x]}
			= \int_\Omega f \phi \di[x].
		\]
		Der Fundamentalsatz \ref{1.7} liefert $\scr L u = f$ fast überall.
		Wegen Stetigkeit von $\scr L u, f$ folgt $\scr L u = f$ überall und $u$ ist eine klassische Lösung.
	\end{proof}
\end{st}

\begin{st}[Distributionslösung der Wellengleichung] \label{1.29}
	Sei $u_0 \in L^1(\R) \cap L^\infty(\R)$, dann ist für $\Omega_T := \R \times (0,T)$
	\[
		u(x,t) := \f 12 \big( u_0(x-ct) + u_0(x+ct) \big)
	\]
	Distributionslösung der Wellengleichung.
	\begin{proof}
		Übungsaufgabe.
	\end{proof}
\end{st}

\begin{nt*}[Numerische Lösungen]
	\begin{itemize}
		\item
			Im Allgemeinen existieren für PDPEs (wie bei gewöhnlichen ODEs in Numerik 2 auch) keine Lösungsformeln für g eine „exakte Lösung“ $u \in X$, $X$ Banachraum, $\dim(X) = \infty$.

			Daher sind numerische Methoden zur Approximation von $u$ erforderlich.
		\item
			Meistens sind hierzu \emphdef{diskrete Funktionenräume} $X_h \subset X$ gegeben, welche von einem Diskretisierungsparameter $h$ abhängen äbhängen (z.B. Gitterweite) $n := \dim X_h < \infty$.
		\item
			Approximation $u_h \in X_h$ wird durch einen Koeffizientenvektor repräsentiert.
			Sei $X_h = \Span{\phi_1, \dotsc, \phi_n}$ mit $\Set{\phi_i}_{i=1}^n$ Basis, dann lautet der Ansatz $u_h = \sum_{i=1}^n u_i \phi_i$ mit „\emphdef{Freiheitsgrade}“ (engl. “degrees of freedom”, DOF).
			$\underbar{u}_h = (u_i)_{i=1}^n \in \R^n$
		\item
			Diskretisierung der PDE und der Randbedingungen liefert im Allgemeinen ein algebraisches System zur Berechnung von $u_h$, z.B. ein LGS
			\[
				A_h \underbar{u}_h = b_h,
			\]
			$A_h \in \R^{n\times n}, b_h \in \R^n$
	\end{itemize}
\end{nt*}

\begin{nt*}[Ziele der Numerik und der Numerischen Analysis]
	Nachweis von Eigenschaften der Numerischen Approximation
	\begin{itemize}
		\item
			Existenz und Eindeutigkeit von $u_h \in X_h$
		\item
			Konvergenz gegen exakte Lösung $\lim_{h\to 0} \|u-u_h\| = 0$
		\item
			Konvergenzordnung: Für maximales $p > 0$ existiert $C > 0$, sodass
			\[
				\|u - u_h\| \le C h^p.
			\]
		\item
			Fehlerschranken:
			\begin{itemize}
				\item
					A priori Fehlerschranken $\|u-u_h\| \le C(u,h)$, $C$ unabhängig von $u_h$, also „vor der Berechnung“.
				\item
					A posteriori Fehlerschranken: $\|u-u_h\| \le C(u_h, h)$, $C$ unabhängig von $u$, aber abhängig von $u_h$, also „nach der Berechnung“.
				\item
					Mindestanforderungen für Fehlerschranken: $\lim_{h\to 0} C(\argdot ,h) = 0$
					Ideale Eigenschaft: „Effizienz“, d.h. $\|u-u_h\|$ und $C(\argdot, h)$ konvergieren mit derselben Ordnung gegen 0, d.h. $\f{C(\argdot, h)}{\|u-u_h\|} \le \_C$ mit $\_C$ unabhängig von $h$.
				\item
					Fehlerschranken erlauben Steuerung von $h$, sodass gewünschte Genauigkeit garantiert ist.
			\end{itemize}
	\end{itemize}
	Weitere Eigenschaften
	\begin{itemize}
		\item
			Beschränktheit: $\|u_h\| \le C$,
		\item
			Positivität: $u_h \ge 0$,
		\item
			Erhaltungseigenschaft: $J(u) = J(u_h)$ für geeignetes $J: X \to \R$,
		\item
			stetige Abhängigkeit von Daten,
		\item
			Stabilität,
		\item
			diskretes Maximumprinzip,
		\item
			\dots
	\end{itemize}
\Timestamp{2014-10-28}
	Algorithmische Aspekte:
	\begin{itemize}
		\item
			möglichst Dünnbesetztheit (engl. “sparsity”) des LGS $A_h u_h = b_h$, denn $n$ hat in realen Anwendungen Größenordnungen von $10^6$ bi $10^9$.
		\item
			Effizientes Aufstellen („Assemblieren“) des Systems möglichst $\LandauO(n)$ statt $\LandauO(n^2)$.
			(Es existieren auch sogenannte matrixfreie Algorithmen, welche ohne Aufstellen von $A_h$ auskommen, sondern nur die Matrix-Vektor-Multiplikation $A_h v_h$ in $\LandauO(n)$ bereitstellen.
		\item
			möglichst weitere schöne Eigenschaften von $A$:
			\begin{itemize}
				\item
					Symmetrie
				\item
					positive Definitheit
				\item
					„M-Matrix-Eigenschaft“ (siehe \ref{chap:2})
			\end{itemize}
		\item
			schnelles Lösen des LGS, z.B. CG-Verfahren mit Vorkonditionierer (siehe NLA)
		\item
			Realisierung der Algorithmen in effizienten und wiederverwertbaren Software-Paketen, Parallelisierung, Visualisierung
	\end{itemize}
\end{nt*}

