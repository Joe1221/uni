\chapter{Restringierte Optimierung}



\section{Lineare Optimierung}


\subsection{Motivation}

Zur Schweinefütterung stehen zwei Möglichkeiten zur Verfügung:
 Soja zu 1€ pro Einheit, enthält 2 Proteiene und 4 Fett; Kartoffeln zu 2€ pro Einheit, enthält 2 Proteine und 2 Fett.

Futter soll $\ge 10$ Proteine und $\le 12$ Fett besitzen.
Dies führt auf die Minimierungsaufgabe
\[
	x + 2y \to \min!
	\udN
	\begin{cases}
		2x + 2y &\ge 10 \\
		4x + 2y &\le 12 \\
		x &\ge 0 \\
		y &\ge 0
	\end{cases}.
\]

\coursetimestamp{11}{12}{2013}

Jede Ungleichung kann in die Form
\[
	\sum_{j} a_{ij} x_j \le b_i
\]
gebracht werden.
Jede Ungleichung kann in die Form
\begin{align*}
	\sum a_{ij} x_j + \xi &= b_i \\
	\xi &\ge 0
\end{align*}
gebracht werden.
Mit $x_j = x_j' - x_j'', x_j' \ge 0, x_j'' \ge 0$
kann für jede Variable $x_j \ge 0$ gefordert werden.

\begin{df} \label{3.1}
	Sei $A \in \R^{n\times n}, b\in \R^m, c \in \R^n$.
	Das Minimierungsproblem
	\[
		f(x) := c^T x \to \min!
		\quad\udN\quad
		Ax = b, x \ge 0
	\]
	heißt \emph{lineares Optimierungsproblem (engl. linear program) in Normalform}.
	$f$ heißt \emph{Zielfunktion} und
	\[
		\{x \in \R^n : Ax = b \land x \ge 0 \}
	\]
	\emph{zulässiger Bereich}.
\end{df}

\begin{conv*}
	Im Folgenden nutzen wir die Notation
	\[
		x = \begin{pmatrix}
			x_1 \\ \vdots \\ x_n
		\end{pmatrix} \in \R^n
	\]
	und setzen
	\[
		x \ge 0
		:\iff
		x_1, \dotsc, x_n \ge 0.
	\]
\end{conv*}

\begin{nt} \label{3.2}
	Der zulässige Bereich kann einelementig sein (dann ist dieses Element die Lösung) oder leer.

	Möglicherweise existiert auch für einen nicht-leeren zulässigen Bereich keine Lösung, z.B. $n=m=1, A = 0, b=0, c=-1$ (nach unten unbeschränkt).

	Ist der zulässige Bereich nicht-leer und beschränkt, dann existiert eine Lösung.
\end{nt}

\subsection{Geometrische Interpretation}

\begin{df} \label{3.3}
	\begin{enumerate}[(a)]
		\item
			Zu gegebenen Punkten $y^1, \dotsc, y^n \in \R^n$ heißt
			\[
				\sum_{i=1}^m \lambda_i y^i,
				\qquad
				\lambda_i \in [0,1], \sum_{i=1}^n \lambda_i = 1
			\]
			\emph{Konvexkombination}.
			Die Menge aller Konvexkombinationen
			\[
				S(y^1, \dotsc, y^m) := \Set{
					\sum_{i=1}^m \lambda_i y^i:
					\lambda_i \in [0,1], \sum_{i=1}^n \lambda_i = 1
				}
			\]
			heißt (der von $y^1,\dotsc, y^m$) aufgespannte Simplex.

			Damit ist $S(y^1, y^2) = [y^1, y^2]$ die Verbindungsstrecke aus \ref{2.1}.
		\item
			Für $\emptyset \neq K \subset \R^n$ nennen wir $x \in K$ eine \emph{Ecke von $K$}, falls
			\[
				\forall y^1, y^2 \in \R^n, x \in [y^1, y^2] \subset K : x = y^1 \lor x = y^2.
			\]
	\end{enumerate}
\end{df}

Betrachte stets $A \in \R^{m\times n}, b\in \R^m, c \in \R^n$ und
\[
	K:= \{ x \in \R^n : Ax = b, x \ge 0 \}.
\]
$K$ ist offenbar konvex, d.h. $\forall y^1, y^2 \in K : [y^1, y^2] \subset K$.

\begin{ex} \label{3.4}
	Es gilt $0 \in K \iff b = 0$.
	Für $0 \in K$ ist $x = 0$ Ecke von $K$, denn für alle $y^1, y^2 \in K$ mit
	\[
		0 = (1-\lambda) y^1 + \lambda y^2,
		\qquad \lambda \in [0,1]
	\]
	ist $y^1 = 0$ oder $y^2 = 0$.
\end{ex}

\begin{df} \label{3.5}
	Teilmengen $I \subset \{1, \dotsc, n\}$ nennen wir \emph{Indexmengen} und bezeichnen die Anzahl der Elemente in $I$ mit $|I|$.
	Für $I \neq \emptyset$ bilden wir für $A \in \R^{m\times n}, v \in \R^n$.
	\begin{align*}
		A_I &:= (a_{ij})_{\substack{i=1,\dotsc,m \\ j \in I}}
			\in \R^{m\times |I|}, \\
		v_I &:= (v_j)_{j\in I} \in \R^{|I|}
			\in \R^{|I|}.
	\end{align*}
	Jedem $x \in \R^n$ ordnen wir zu
	\[
		I_x = \Big\{ j \in \{1, \dotsc, n\} : x_j > 0 \Big\}
		\subset \{1, \dotsc, n\}
	\]
	Für $x \neq 0$ schreiben wir auch
	\[
		A_x := A_{I_x}
	\]
	und $v_x$ statt $v_{I_x}$.
	Es gilt offenbar für $0 \neq x \in K$
	\[
		b = Ax = A_x x_x.
	\]
	Es gilt auch
	\[
		A_x v_x = A v
	\]
	für alle $v \in \R^n$ mit $I_v \subset I_x$.
\end{df}

\begin{lem} \label{3.6}
	\begin{enumerate}[(a)]
		\item
			Ist $0 \neq x \in K$ keine Ecke von $K$, so existieren $y^1, y^2 \in K, y^1 \neq x, y^2 \neq x, y^1 \neq y^2$, so dass
			\[
				x \in [y^1, y^2], \quad I_{y^1}, I_{y^2} \subset I_x.
			\]
		\item
			$0 \neq x \in K$ ist genau dann eine Ecke von $K$, wenn $A_x$ injektiv ist, also $\rg(A_x) = |I_x|$.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Ist $x \in K$ keine Ecke, dann existieren $y^1, y^2 \in K, y^1 \neq y^2$ und für $\lambda \in (0,1)$
				\[
					x = (1-\lambda) y^1 + \lambda y^2.
				\]
				Für jedes $j$ gilt
				\[
					y_j^1 > 0 \implies x_j > 0 \qquad
					y_j^2 > 0 \implies x_j > 0
				\]
				also $I_{y^1}, I_{y^2} \subset I_x$.
			\item
				Außerdem ist
				\[
					A_x (y_x^1 - y_x^2)
					= Ay^1 - Ay^2
					= b - b = 0.
				\]
				Wegen $y^1 \neq y^2 \implies y_x^1 \neq  y_x^2$.
				Damit ist $A_x$ nicht injektiv, wenn $x$ keine Ecke ist.

				Sei $A_x$ nicht injektiv, dann existiert $0 \neq y_x \in \R^{|I_x|}$ mit $A_x y_x = 0$, den wir durch Nullen zu $y \in \R^n$ fortsetzen.
				Wähle $\eps > 0$ so klein, dass $\eps |y_j| < x_j$ für alle $j \in I_x$.
				Setze
				\[
					y^1 := x - \eps y,
					\quad
					y^2 := x + \eps y
				\]
				Offenbar ist $x \in [y^1, y^2]$ und $y^1 \neq x, y^2 \neq x$.
				Aus $Ay = A_x y_x = 0$ folgt
				\[
					Ay^1 = Ax = b = Ax = Ay^2.
				\]
				und wegen der Wahl von $\eps$ ist
				\[
					y^1, y^2 \ge 0.
				\]
		\end{enumerate}
	\end{proof}
\end{lem}

\coursetimestamp{16}{12}{2013}
\begin{kor} \label{3.7}
	Ein Punkt $x \in K$ mit nichtleerer Indexmenge $I_x \subset \{1, \dotsc, n\}$ ist eine Ecke von $K$ genau dann wenn $A_{I_x} \tilde x = b$ mit $\tilde x \in \R^{|I_x|}$ genau eine Lösung mit nicht-negativen Komponenten besitzt.

	In diesem Fall ergibt sich die Ecke $x \in \R^n$ durch Nullfortsetzung aus $\tilde x \in \R^{|I_x|}$.

	Insbesondere existieren nur endlich viele Ecken.
	\begin{proof}
		\begin{segnb}[„$\implies$“]
			Sei also $x \in K$ eine Ecke mit nichtleerer Indexmenge $I_x \subset \{1, \dotsc, n\}$.
			Dann gilt
			\[
				A_{I_x} x_{I_x} = A_x x_x = Ax = b
			\]
			und wegen \ref{3.6} b) ist $x_x$ auch die einzige Lösung von $A_{I_x} \tilde x = b$ mit nichtnegativen Komponenten.
		\end{segnb}
		\begin{segnb}[„$\impliedby$“]
			Ist nun also $A_{I_x} \tilde x = A_x \tilde x = b$ eindeutig lösbar, so ist insbesondere $A_x$ injektiv, besitzt also linear unabhängige Spalten.
			Bezeichne $x \in \R^n$ die Nullfortsetzung von $\tilde x$, dann ist $I_x \subset \{1, \dotsc, n\}$ und wenn die Komponenten von $\tilde x$ nicht-negativ sind, so ist $x \in \R^n$ ein zulässiger Punkt und nach \ref{3.6} b) eine Ecke von $K$.
		\end{segnb}
	\end{proof}
\end{kor}

\begin{lem} \label{3.8}
	\begin{enumerate}[(a)]
		\item
			Jeder Punkt $x \in K$ mit minimaler Indexmenge, d.h. $|I_x| \le |I_y|$ für alle $y \in K$, ist eine Ecke.
			Insbesondere besitzt jeder nicht-leere zulässige Bereich mindestens eine Ecke.
		\item
			Existiert auf dem zulässigen Bereich ein Minimum der Zielfunktion $f(x) = c^T x$, so ist einer der Minimierer eine Ecke.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Ist $0 = x \in K$, so ist $I_x = \emptyset$ und $x = 0$ ist wegen \ref{3.4} auch eine Ecke.

				Sei also $x \neq 0$ mit minimaler Indexmenge, aber $x$ sei \emph{keine} Ecke.
				Nach \ref{3.6} a) existieren dann paarweise von $x$ verschiedene $y^1, y^2 \in K$ mit $x \in [y^1, y^2]$ und $I_{y^1}, I_{y^2} \subset I_x$.

				Betrachte $v := y^2 - y^1$ und für ein $\lambda \in \R$ den Punkt $z_\lambda := x + \lambda v$.
				Dann gilt für alle $\lambda \in \R$
				\[
					A z_\lambda
					= A (x + \lambda v)
					= b + \lambda (b-b)
					= b.
				\]
				Wir wollen nun zeigen, dass ein $\_\lambda$ existiert, sodass $z_{\_\lambda} \in K$ ist (d.h. $z_\lambda \ge 0$) und $|I_{z_\lambda}| < |I_x|$ gilt.

				Da $y^1, y^2$ paarweise verschieden waren, gilt $\emptyset \neq I_v \subset I_x$.
				Für jedes $j \in I_v$ setzen wir
				\[
					\lambda_j
					:= - \f {x_j}{v_j}
					= - \f {x_j}{y^2_j - y^1_j}
					\neq 0
				\]
				und wählen $k \in I_v$, sodass $|\lambda_k| \le |\lambda_j|$ für alle $j \in I_v$.
				Wähle $\_\lambda := \lambda_k$ und $z := z_{\_\lambda} = x + \lambda_k v$.
				$z$ erfüllt
				\begin{itemize}
					\item
						$z_k = x_k + \lambda_k v_k = x_k - x_k = 0$
					\item
						$z_j = x_j + \lambda_k v_j \ge 0$ für $j \in I_v$, denn wäre $z_j$ negativ, so müsste die Funktion $\lambda \mapsto x_j + \lambda v_j$ eine betragskleinere Nullstelle $\lambda_j$ als $\lambda_k$ besitzen.
				\end{itemize}
				Damit ist $z \in K$ zulässig.
				Außerdem gilt für $\lambda_k > 0$ dass $x \in [y^1, z]$ und für $\lambda_k < 0$ dass $x \in [z, y^2]$.
				Da also $x$ keine Ecke von $K$ ist, existieren $y, z \in K, \lambda \in (0,1)$, sodass $x = (1-\lambda) y + \lambda z$ und es gilt $|I_z| < |I_i| \le |I_x|$, ein Widerspruch zu $|I_x| \le |I_y|$ für alle $y \in K$.
			\item
				Sei also $x \in K$ ein Minimierer mit (unter den Minimierern) minimaler Indexmenge, d.h.
				\[
					x \in \argmin_{\xi \in K} c^T \xi
					\land \forall x' \in \argmin_{\xi \in K} c^T \xi : |I_x| \le |I_{x'}|.
				\]
				Falls $x$ \emph{keine} Ecke ist, so existieren wie im a)-Teil wieder $y, z \in K, \lambda \in (0, 1)$ mit $x = (1 - \lambda)y + \lambda z$ und $|I_z| < |I_x|$.
				Noch zu zeigen ist: $z$ ist Minimierer von $f$.

				Da $x$ Minimerer von $f$ ist, gilt $c^Tx \le c^Ty, c^Tx \le c^Tz$.
				Es gilt
				\[
					c^T x = (1-\lambda)c^T y + \lambda c^T z
					\le c^Ty
				\]
				und damit auch $c^T z \le c^T y$.
				Analog zeigt man $c^T y \le c^T z$, also $c^T y = c^T z$.
				Schließlich folgt
				\[
					c^T x = (1-\lambda)c^T y + \lambda c^Tz = c^T y = c^T z.
				\]
				Damit ist auch $z$ Minimierer von $f$ auf $K$, ein Widerspruch zu $|I_z| < |I_x|$.
		\end{enumerate}
	\end{proof}
\end{lem}

\begin{nt} \label{3.9}
	\begin{itemize}
		\item
			Das betrachtete Optimierungsproblem ist damit gelöst.
			Es genügt, für jede (der endlich vielen, höchstens $m$-elementigen) Teilmengen von $\{1, \dotsc, n\}$ gemäß \ref{3.7} zu prüfen, ob es eine dazugehörige Ecke $x \in K$ gibt (für $b = 0$ muss noch $x = 0$ als Ecke hinzugenommen werden).
		\item
			Gibt es einen Minimierer, so ist dies eine der Ecken und es müssen nur noch die Werte der Zielfunktion für die endlich vielen Ecken berechnet und verglichen werden.
		\item
			Falls das Minimierungsproblem lösbar ist, erhalten wir so nach endlich vielen Schritten eine Lösung.
	\end{itemize}
\end{nt}

\coursetimestamp{13}{01}{2014}

\subsection{Das Simplexverfahren}

Im folgenden setzen wir voraus, dass alle Ecken nicht-entartet sind, d.h. dass für alle Ecken $x$ von $K$ gilt, dass $|I_x| = m$.

Wir formulieren das Verfahren direkt auf der Indexmenge.
Zu einer Ecke $x$ bezeichnen wir die Indexmenge $I_x$ mit $B \subset \{1, \dotsc, n\}$ (Basisvariablen) und $N := \{1, \dotsc, n\} \setminus B$ (Nichtbasisvariable).
Entsprechend definieren wir $A_B, A_N, v_B$ und $v_N$ zu $A \in \R^{m\times n}, v \in \R^n$.

Für einen Algorithmus, der sich von Ecke zu Ecke „hangelt“ und dabei das Zielfunktional verbessert sind folgende Dinge nötig:
\begin{enumerate}[1.]
	\item
		Bestimmung einer Startecke (genauer: ein $B$, das zu einer Ecke gehört).
	\item
		Wie kommen wir von einer Ecke zu einer neuen Ecke mit besserem Zielfunktionalswert?
	\item
		Wie erkennen wir eine optimale Ecke?
\end{enumerate}

\subsubsection{Das Stoppkriterium}

Gehöre $B \subset \{1, \dotsc, n\}$ zu einer Ecke.
Nach \ref{3.6} ist $A_B \in \R^{m\times |B|}$ injektiv und dank der vereinfachten Voraussetzung $A_B$ invertierbar.
Jedes $x \in K \subset \R^n$ ist eindeutig festgelegt durch $x_B \in \R^n$ und $x_N \in \R^{n-m}$.
Es gilt
\[
	b = Ax = A_Bx_B + A_Nx_N,
\]
also $x_B = A_B^{-1} (b - A_N x_N)$ für alle $x \in K$.

In der zu $B$ gehörigen Ecke $x \in K$ gilt $x_N = 0, x_B = A_B^{-1}b$ und
\[
	c^T x = c_B^T x_B + c_N^T x_N = c_B^T A_B^{-1}b
\]
in jedem anderen zulässigen Punkt $x \in K$ ist
\begin{align*}
	c^Tx
	&= c_B^T x_B + c_N^T x_N \\
	&= c_B^T A_B^{-1}(b - A_Nx_N) + c_N^T x_N \\
	&= c_B^T A_B^{-1}b + (c_N^T - c_B^T A_B^{-1}A_N) x_N.
\end{align*}
$c_N^T - c_B^T A_B^{-1} A_N$ heißt \emph{Vektor der reduzierten Kosten}.
Für $c_N^T c_B^T A_B^{-1} A_N \ge 0$, dann ist $c^T x \ge c_B^T A_B^{-1} b$, für alle $x \in K$ also die zu $B$ gehörige Ecke optimal.

Demnach ist das Stoppkriterium für das Simplexverfahren die Bedingung $c_N^T - c_B^T A_B^{-1} A_N \ge 0$.

\subsection{Der Pivotschritt}

Es gelte
\[
	c_N^T - c_B^T A_B^{-1} A_N \not\ge 0,
\]
etwa $(c_N^T - c_B^T A_B^{-1} A_N)_j < 0$ für ein $j \in \{1, \dotsc, n-m\}$.
Jedes $x_N = (x_k)_{k\in\N}$ mit $x_k = 0$ für $k \neq j$ und $x_j > 0$ führt mit
\[
	x_B := A_B^{-1}(b - A_N x_N)
\]
zu einem $x \in \R^n$ mit geringerem Zielfunktionalswert $c^T x$ und $Ax = b$ und $x$ ist zulässig genau dann, wenn $x_B \ge 0$.

$x_B$ hängt stetig von $x_j \ge 0$ ab.
Für $x_j = 0$ ist $x_B > 0$, d.h. es existiert $\eps > 0$ mit $x_B \ge 0$ für alle $x_j \in [0, \eps]$.

Entweder bleibt $x_B$ positiv für alle $x_j > 0$, dann ist das Zielfunktional nach unten unbeschränkt.
Ansonsten existiert ein kleinstes $\hat x_j > 0$, sodass $\hat x_B \ge 0$ und für alle $x_j > \hat x_j$ gilt $x_B \not\ge 0$.
Ersetze dann den zugehörigen Index in $B$ (der jetzt 0 geworden ist) durch $j$ und definiere so $B'$.
$B'$ ist damit eine Indexmenge einer Ecke mit geringerem Zielfunktionalswert.

