\chapter{Unrestringierte nichtlineare Optimierung}


Im Folgenden betrachten wir für hinreichend glatte Funktionen $f: \R^n \to \R$ das Minimierungsproblem
\[
	\min_{x\in \R^n} f(x)
\]
ohne Nebenbedingungen.


\section{Grundlagen und Optimalitätsbedingungen}


\begin{conv*}
	Im Folgenden sei $U \subset \R^n$ stets eine offene Menge.
\end{conv*}


\subsection{Grundlagen}

\subsubsection{Norm}

Für $x \in \R^n, A \in \R^{n\times n}$ setzen wir
\[
	\|x\| := \sqrt{x^T x}, \qquad
	\|A\| := \max_{\|x\|=1} \|Ax\|.
\]

\subsubsection{Ableitungen}

Für $F: U \to \R^m$, $F(x) = (f_1(x), \dotsc, f_m(x))^T$ nennen wir
\[
	F'(x) := \begin{pmatrix}
		\pddx[x_1]{f_1}(x) & \cdots & \pddx[x_n]{f_1}(x) \\
		\vdots & \ddots & \vdots \\
		\pddx[x_1]{f_m}(x) & \cdots & \pddx[x_n]{f_m}(x) \\
	\end{pmatrix} \in \R^{m\times n}
\]
die \emph{Jacobimatrix} der Funktion $F$.

Für $f: U \to \R$ definieren wir
\begin{align*}
	\nabla f(x)
	&:= f'(x)^T
	= \begin{pmatrix}
		\pddx[x_1]{f}(x) \\
		\vdots \\
		\pddx[x_n]{f}(x) \\
	\end{pmatrix}, \\
	\nabla^2 f(x)
	&:= \begin{pmatrix}
		\pddx[x_1^2]{f}(x) & \cdots & \f{\partial^2 f}{\partial x_1 \partial x_n}(x) \\
		\vdots & \ddots & \vdots \\
		\f{\partial^2 f}{\partial x_n \partial x_1}(x) & \cdots & \f{\partial^2 f}{\partial x_n^2}(x) \\
	\end{pmatrix} \in \R^{n\times n}
\end{align*}
den \emph{Gradienten} $\nabla f$ und die \emph{Hessematrix} $\nabla^2 f$ (die Bezeichnung $\nabla^2$ wird in der Literatur nicht einheitlich verwendet).
Desweiteren definieren wir die \emph{Richtungsableitung in Richtung $d \in \R^n$} als
\[
	\pddx[d]{f}(x)
	:= \lim_{t\to 0} \f {f(x+td) - f(x)}{t}
	= f'(x) d = \nabla f(x)^T d.
\]

\subsubsection{Verbindungsstrecke}

\begin{df} \label{2.1}
	Zu $x_0,x_1 \in \R^n$ heißt
	\[
		[x_0, x_1] := \big\{ x_0 + t(x_1-x_0) : t \in [0,1] \big\}
	\]
	die \emph{Verbindungsstrecke} zwischen $x_0, x_1$.
	In diesem Kontext benutzen wir auch die Notation $x_t := (1-t) x_0 + t x_1$.
\end{df}

\begin{st} \label{2.2}
	Sei $f: U \to \R$ stetig differenzierbar, $x_0, x_1 \in U$ und $[x_0, x_1] \subset U$.

	Dann ist die Funktion $g: t \mapsto f(x_t)$ auf einer Umgebung von $[0,1]$ stetig differenzierbar mit
	\[
		g'(t) = \nabla f(x_t)^T (x_1 - x_0).
	\]
	Ist $f$ zweimal stetetig differenzierbar, so auch $g$ und es gilt
	\[
		g''(t) = (x_1 - x_0)^T \nabla^2 f(x_t) (x_1 - x_0).
	\]
	\begin{proof}
		Siehe \coursehref{Blatt2.pdf}{Übungsaufgabe 2.1}.
	\end{proof}
\end{st}

\subsubsection{Taylor}

\begin{st}[Linearer und quadratischer Taylor] \label{2.3}
	Sei $f : U \to \R$ stetig differenzierbar, $x\in U, \eps > 0$, so dass $B_\eps(x) \subset U$.
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			Für alle $d \in B_\eps(0)$ existiert ein $s \in [0,1]$ mit
			\[
				f(x+d) = f(x) + \nabla f(x + sd)^T d.
			\]
			Außerdem gilt für alle $d \in B_\eps(0)$
			\[
				f(x+d) = f(x) + \nabla f(x)^T d + p(d)
			\]
			und das Restglied $\rho: B_\eps(0) \to \R$ erfüllt $\rho(d) = o(\|d\|)$, d.h.
			\[
				\lim_{d\to 0} \f {|\rho(d)|}{\|d\|} = 0.
			\]
		\item
			Ist $f: U \to \R$ zweimal stetig differenzierbar, dann existieren für alle $d \in B_\eps(0)$ ein $s \in [0,1]$ mit
			\[
				f(x+d)
				= f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x+sd) d.
			\]
			Außerdem gilt für alle $d \in B_\eps(0)$
			\[
				f(x+d) = f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x) d + \rho(d)
			\]
			und $p: B_\eps(0) \to \R$ gilt $\rho(d) = o(\|d\|^2)$, d.h.
			\[
				\lim_{d\to 0} \f{|\rho(d)|}{\|d\|^2} = 0.
			\]
	\end{enumerate}
	\begin{proof}
		Funktioniert mit eindimensionalem Taylor und \ref{2.2}.
	\end{proof}
\end{st}

\subsubsection{Mittelwertsatz}

\begin{lem} \label{2.4}
	Sei $F: U \to \R^m$ stetig differenzierbar, $x\in U$ und $\eps > 0$, sodass $B_\eps(x) \subset U$.

	Dann gilt für alle $d \in B_\eps(0)$
	\begin{align*}
		F(x+d)
		&= F(x) + \int_0^1 F'(x+td) d \dx[t] \\
		&= F(x) + \bigg( \int_0^1 F'(x+td) \dx[t] \bigg) d.
	\end{align*}
	Insbesondere gilt mit Integralabschätzung
	\[
		\| F(x+d) - F(x) \|
		\le \|d\| \sup_{t\in [0,1]} \|F'(x+td)\|.
	\]
	Diese Abschätzung wird oft auch \emph{mehrdimensionaler Mittelwertsatz} genannt.
\coursetimestamp{21}{10}{2013}

	Außerdem ist $F(x+d) = F(x) + F'(x)d + p(d)$ und $p: B_\eps(0) \to \R^m$ erfüllt $p(d) = o(d)$, d.h.
	$\lim_{d\to 0} \f {\|p(d)\|}{\|d\|} = 0$.

	\begin{proof}
		Da $U$ offen, existiert $\eps > 0$, so dass $[x- \eps d, x + d + \eps d] \subset U$.
		Definiere $f: (-\eps, 1 + \eps) \to \R^n$ durch
		\[
			f(t) := F(x + td) = F(g(t))
		\]
		mit $g:(-\eps, 1 + \eps) \to \R^n : t \mapsto x + td$.
		Es gilt
		\[
			f'(t)
			= F'(g(t)) g'(t)
			= F'(x + td) d.
		\]
		und damit
		\[
			F(x+d) - F(x)
			= f(1) - f(0)
			= \int_0^1 f'(t) \dx[t]
			= \int_0^1 F'(x + td) d \dx[t].
		\]

		Die zweite Behauptung ist die Definition der totalen Differenzierbarkeit.
	\end{proof}
\end{lem}

\subsubsection{Matrizen}

\begin{df} \label{2.5}
	Eine symmetrische Matrix $A = (a_{ij}) \in \R^{n\times n}$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{positiv semi-definit}, falls $x^TAx \ge 0$ für alle $x \in \R^n$,
		\item
			\emph{positiv definit}, falls $x^TAx > 0$ für alle $x \in \R^n \setminus \{0\}$.
	\end{enumerate}
	Analog definiert man \emph{negativ semi-definit} und \emph{negativ definit}.
\end{df}

\begin{st} \label{2.6}
	Zu einer symmetrischen Matrix $A \in \R^{n\times n}$ existiert eine Orthonormalbasis aus Eigenvektoren $v_1, \dotsc, v_n \in \R^n$ mit dazugehörigen Eigenwerten $\lambda_1, \dotsc, \lambda_n \in \R$:
	\[
		v_j^T v_k
		= \delta_{jk}
		= \begin{cases}
			1 & j = k \\
			0 & \text{sonst}
		\end{cases},\qquad
		Av_k = \lambda_k v_k.
	\]
	Es ist also
	\[
		A = \sum_{k=1}^n \lambda_k v_k v_k^T
	\]
	und mit $\lambda_{\text{min}}(A) := \min_{k=1,\dotsc,n} \lambda_k$, $\lambda_{\text{max}}(A) := \max_{k=1,\dotsc,n} \lambda_k$ gilt
	\[
		\lambda_{\text{min}}(A)
		= \min_{x\in\R^n} \f {x^T A x}{\|x\|^2}
		\le \f {x^T A x}{\|x\|^2}
		\le \max_{x\in\R^n} \f {x^TA x}{\|x\|^2}
		= \lambda_{\text{max}}(A)
	\]
	und
	\[
		\|A\|
		= \sup_{x\neq 0} \f{\|Ax\|}{\|x\|}
		= \max \{|\lambda_k| : k=1, \dotsc, n \}
	\]
	Insbesondere ist $A$ positiv semi-definit genau dann, wenn alle Eigenwerte $\ge 0$ und positiv definit genau dann, wenn alle Eigenwerte $>0$ sind,
	entsprechend negativ semi-definit, wenn alle Eigenwerte $\le 0$ und negativ semi-definit, wenn alle Eigenwerte $<0$ sind.
\end{st}

\begin{df} \label{2.7}
	Für eine invertierbare Matrix $A \in \R^{n\times n}$ heißt
	\[
		\kappa(A)
		:= \|A\| \|A^{-1}\|
	\]
	\emph{Kondition}.

	Für eine symmetrische, positiv definite Matrix $A \in \R^{n\times n}$ gilt offenbar
	\[
		\kappa(A)
		= \lambda_{\text{max}}(A) \lambda_{\text{max}}(A^{-1})
		= \f {\lambda_{\text{max}}(A)}{\lambda_{\text{min}}(A)}.
	\]
\end{df}

\begin{nt} \label{2.8}
	Die Kondition ist ein Maß für die Fehlerverstärkung durch $A^{-1}$ (z.B. durch Lösen eines LGS), denn der relative Ausgabefehler lässt sich durch die Kondition und dem relativen Eingabefehler abschätzen:
	\begin{align*}
		\dfrac {A^{-1}(b+\delta) - A^{-1}b}{\|A^{-1}b\|}
		&= \f {\|A^{-1}\delta\|}{\|A^{-1}b\|} \\
		&\le \|A^{-1}\| \|A\| \f {\|\delta\|}{\|A\|\|A^{-1}b\|} \\
		&\le \kappa(A) \f {\|\delta\|}{\|b\|}.
	\end{align*}
\end{nt}

\subsection{Optimalitätsbedingungen}

\begin{df} \label{2.9}
	Sei $X \subset \R^n$ und $f: X \to \R$.
	Ein Punkt $x \in X$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{globales Minimum von $f$ in $X$}, falls
			\[
				\forall y \in X: f(x) \le f(y),
			\]
		\item
			\emph{lokales Minimum von $f$}, falls
			\[
				\exists \eps > 0 \forall y \in X \cap B_\eps(x): f(x) \le f(y),
			\]
		\item
			\emph{striktes globales Minimum von $f$ in $X$}, falls
			\[
				\forall y \in X \setminus \{x\}: f(x) < f(y)
			\]
		\item
			\emph{striktes lokales Minimum von $f$}, falls
			\[
				\exists \eps > 0 \forall y \in (X \setminus \{x\}) \cap B_\eps(x): f(x) < f(y),
			\]
	\end{enumerate}
	Analog definiert man die entsprechenden Maxima.
	\begin{note}
		Jedes globale Minimum/Maximum ist mit dieser Definition insbesondere ein lokales Minimum/Maximum.
	\end{note}
\end{df}

\begin{st}[Notwendige Optimalitätsbedingung 1. Ordnung] \label{2.10} \label{st:optN1}
	Sei $U \subset \R^n$ offen und $f: U \to \R$ stetig differenzierbar.
	Ist $x \in U$ ein lokales Minimum von $f$, dann gilt $\nabla f(x) = 0$.

	Punkte $x \in U$ mit $\nabla f(x) = 0$ heißen \emph{stationäre Punkte}.
	\begin{proof}
		Für jedes $d \in \R^n$ gilt
		\[
			\nabla f(x)^T d
			= \lim_{t \to 0^+} \f {f(x+td) - f(x)}{t}
			\ge 0
		\]
		Mit der Wahl $d := - \nabla f(x)$ also $-\|\nabla f(x)\|^2 \ge 0$ und damit $\nabla f(x) = 0$.
	\end{proof}
\end{st}

\begin{st}[Notwendige Optimalitätsbedingung 2. Ordnung] \label{2.11} \label{st:optN2}
	Sei $U \subset \R^n$ offen und $f: U \to \R$ zweimal stetig differenzierbar.
	Ist $x \in U$ ein lokales Minimum von $f$, dann gilt
	\begin{enumerate}[(a)]
		\item
			$\nabla f(x) = 0$,
		\item
			$\nabla^2 f(x)$ ist positiv semi-definit ($\forall x \in \R^n : x^T \nabla^2 f(x) x \ge 0$).
	\end{enumerate}
	\begin{proof}
		Teil (a) ergibt sich aus \ref{2.10}, zeige also (b):
		Sei $d \in \R^n$ und $\eps > 0$ so klein, dass $B_\eps(x) \subset U$ und $x$ globales Minimum in $B_\eps(x)$.
		Gemäß \ref{2.3} gilt
		\[
			f(x+td)
			= f(x) + t \nabla f(x)^T d + \f {t^2}2 d^T \nabla^2 f(x) d + p(td)
		\]
		mit $p(td) = o(\|td\|^2)$ für alle $td \in B_\eps(0)$.
		Also gilt für beliebige $d \in \R^n$ und alle $|t| < \f \eps{\|d\|}$
		\begin{align*}
			d^T \nabla^2 f(x) d
			&= \f{2}{t^2} \Big( \underbrace{f(x+td) - f(x)}_{\ge 0} - \underbrace{t\nabla f(x)^T d}_{=0} - p(td) \Big) \\
			&\ge - \f 2{t^2} p(td).
		\end{align*}
		Für $t \to 0$ also $d^T \nabla^2 f(x) d \ge 0$.
	\end{proof}
\end{st}

\begin{st}[Hinreichende Optimalitätsbedingungen 2. Ordnung] \label{2.12} \label{st:optH2}
	Sei $U \subset \R^n$ offen und $f: U \to \R$ zweimal stetig differenzierbar.
	Gilt
	\begin{enumerate}[(a)]
		\item
			$\nabla f(x) = 0$,
		\item
			$\nabla^2 f(x)$ ist positiv definit ($\forall x \in \R^n \setminus \{0\} : x^T \nabla^2 f(x) x > 0$),
	\end{enumerate}
	dann ist $x$ ein striktes lokales Minimum von $f$.
	\begin{proof}
		Da $\nabla^2 f(x)$ positiv definit, setze $\my := \lambda_{\text{min}} (\nabla^2 f(x)) > 0$.
		Gemäß \ref{2.6} gilt $d^T \nabla^2 f(x) d \ge \my \|d\|^2$ für alle $d \in \R^n \setminus \{0\}$.
		Die Taylorapproximation gemäß \ref{2.3} liefert
		\[
			f(x+d)
			= f(x) + \underbrace{\nabla f(x)^T d}_{=0} + \underbrace{\f 12 d^T \nabla^2 f(x) d}_{\ge \f 12 \my \|d\|^2} + p(d)
		\]
		mit $p(d) = o(\|d\|^2)$, also $p(d) \le \f \my 4 \|d\|^2$ für hinreichend kleine $d$.

		Damit gilt
		\[
			f(x+d)
			\ge f(x) + \f \my2 \|d\|^2 - \f \my4 \|d\|^2
			= f(x) + \f \my4 \|d\|^2
		\]
		und damit $f(x+d) > f(x)$ für alle hinreichend kleinen $d \neq 0$.
	\end{proof}
\end{st}

\begin{ex} \label{2.13}
	\begin{enumerate}[(a)]
		\item
			Die Bedingung aus \ref{st:optN1} ist offenbar nicht hinreichend:
			$f(x) = -x^2$ hat im kritischen Punkt ein Maximum (und kein Minimum),
			die Funktionen $g(x) = x^3$ und
			\[
				h(x_1,x_2) = x_1^2 - x_2^2
			\]
			haben in $0$, bzw. $(0,0)$ kritische Punkte, aber dort weder Maxima, noch Minima, sondern Sattelpunkte.
		\item
			Die Bedingung aus \ref{st:optN2} ist nicht hinreichend:
			$f(x) = x^3$ erfüllt $f'(0) = 0$ und $f''(0) = 0$ ist insbesondere positiv semi-definit, besitzt aber in $x = 0$ kein lokales Minimum.
		\item
			Die Bedingung aus \ref{st:optH2} ist nicht notwendig:
			$f(x) = x^4$ besitzt in $x = 0$ ein lokales Minimum, aber $f''(0) = 0$ ist nicht positiv definit.
	\end{enumerate}
\end{ex}


\subsection{Konvexität}


\begin{df} \label{2.14}
	Eine Menge $X \subset \R^n$ heißt \emph{konvex}, wenn alle Verbindungsstrecken zweier Punkte darin enthalten sind, d.h.
	\begin{align*}
		\forall x,y \in X:
		[x,y] \subset X,
	\end{align*}
	oder ausführlicher
	\begin{align*}
		\forall x,y \in X, \lambda \in [0,1]:
		x_\lambda
		= (1-\lambda)x + \lambda y \in X.
	\end{align*}
\end{df}

\begin{df} \label{2.15}
	Sei $X \subset \R^n$ konvex.
	Eine Funktion $f: X \to \R$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{konvex}, falls für alle $x,y \in X, \lambda \in [0,1]$
			\[
				f\big((1-\lambda)x + \lambda y\big)
				\le (1-\lambda) f(x) + \lambda f(y).
			\]
		\item
			\emph{strikt konvex}, falls für alle $x,y \in X, x \neq y, \lambda \in (0,1)$
			\[
				f\big((1-\lambda)x + \lambda y\big)
				< (1-\lambda) f(x) + \lambda f(y).
			\]
		\item
			\emph{gleichmäßig konvex}, falls $\my > 0$ existiert, sodass für alle $x,y \in X, \lambda \in [0,1]$
			\[
				f\big((1-\lambda)x + \lambda y\big) + \my \lambda(1-\lambda) \|y-x\|^2
				\le (1-\lambda) f(x) + \lambda f(y).
			\]
			Zur Motivation betrachte auch \ref{2.17}.
	\end{enumerate}
\end{df}

\begin{st} \label{2.16}
	Sei $U \subset \R^n$ offen und $f: U \to \R$ stetig differenzierbar.
	$f$ ist auf einer konvexen Menge $X \subset U$
	\begin{enumerate}[(a)]
		\item
			genau dann konvex, wenn für alle $x,y \in X$
			\[
				\nabla f^T(x) (y-x)
				\le f(y) - f(x).
			\]
		\item
			genau dann strikt konvex, wenn für alle $x,y \in X, x \neq y$
			\[
				\nabla f^T(x) (y-x)
				< f(y) - f(x).
			\]
		\item
			genau dann gleichmäßig konvex, wenn ein $\my > 0$ existiert, sodass für alle $x,y \in X$.
			\[
				\nabla f(x)^T (y-x) + \my \|y-x\|
				\le f(y) - f(x)
			\]
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				\begin{segnb}[„$\implies$“]
					Ist $f$ konvex, dann ist
					\begin{align*}
						\nabla f(x)^T (y-x)
						&= \lim_{t \to 0} \f {f(x+t(y-x)) - f(x)}t \\
						&= \lim_{t \to 0} \f {f((1-t)x + ty) - f(x)}t \\
						&\le \lim_{t \to 0} \f{(1-t)f(x) + tf(y) - f(x)}t
						= f(y) - f(x).
					\end{align*}
				\end{segnb}
				\begin{segnb}[„$\impliedby$“]
					Sei $\lambda \in [0,1]$ und $x,y \in X$.
					Dann gilt
					\begin{align*}
						f(x) - f(x_\lambda)
						&\ge \nabla f(x_\lambda)^T(x-x_\lambda), \\
						f(y) - f(x_\lambda)
						&\ge \nabla f(x_\lambda)^T(y-x_\lambda)
					\end{align*}
					und somit
					\begin{align*}
						&(1-\lambda) f(x) + \lambda f(y) \\
						&\quad= (1-\lambda)(f(x) - f(x_\lambda)) + \lambda (f(y) - f(x_\lambda)) + f(x_\lambda) \\
						&\quad\ge (1-\lambda) \nabla f(x_\lambda)^T (x-x_\lambda) + \lambda \nabla f(x_\lambda)^T (y-x_\lambda) + f(x_\lambda) \\
						&\quad= \nabla f(x_\lambda)^T \big( (1-\lambda) x + \lambda y - x_\lambda \big) + f(x_\lambda) \\
						&\quad= f(x_\lambda).
					\end{align*}
				\end{segnb}
			\item
				\begin{segnb}[„$\implies$“]
					Sei $f$ strikt konvex und $x, y \in X$ mit $x\neq y$.
					Setze
					\[
						x_{\f 12} := \f {x + y}2.
					\]
					Dann gilt $y = 2 x_{\f 12} - x$, also
					\begin{align*}
						\nabla f(x)^T (y-x)
						&= 2 \nabla f(x)^T (x_{\f 12} - x) \\
						&\le 2 \big(f(x_{\f 12}) - f(x)\big) \\
						&< 2 \big(\f {f(x) + f(y)}2 - f(x)\big)
						= f(y) - f(x).
					\end{align*}
				\end{segnb}
				\begin{segnb}[„$\impliedby$“]
					Analog zu (a) „$\impliedby$“
				\end{segnb}
			\item
				\begin{segnb}[„$\implies$“]
					Es gilt
					\begin{align*}
						&\nabla f(x)^T (y-x) \\
						&\quad= \lim_{t\to 0} \f {f(x_t) - f(x)}t \\
						&\quad\le \lim_{t\to 0} \f 1t \Big( (1-t)f(x) + tf(y) - \my t(1-t)\|y-x\|^2 - f(x) \Big) \\
						&\quad= f(y) - f(x) - \my \|y-x\|^2.
					\end{align*}
				\end{segnb}
				\begin{segnb}[„$\impliedby$“]
					Gehe vor, wie in (a) $\impliedby$:
					\begin{align*}
						&(1-\lambda) f(x) + \lambda f(y) \\
						&\quad= (1-\lambda) (f(x) - f(x_\lambda)) + \lambda (f(y) - f(x_\lambda)) + f(x_\lambda) \\
						&\quad\ge (1-\lambda) \Big(\nabla f(x_\lambda)^T \underbrace{(x-x_\lambda)}_{=\lambda (x+y)} + \my \|x-x_\lambda\|^2 \Big) \\
						    &\quad\quad + \lambda \Big( \nabla f(x_\lambda)^T \underbrace{(y-x_\lambda)}_{=(1-\lambda) (x+y)} + \my \|y-x_\lambda\|^2 \Big) + f(x_\lambda) \\
						&\quad= f(x_\lambda) + (1-\lambda)\my \underbrace{\|x - x_\lambda\|^2}_{\lambda^2 \|x-y\|^2} + \lambda \my \underbrace{\|y-x_\lambda\|^2}_{(1-\lambda)^2\|y-x\|^2} \\
						&\quad=  f(x_\lambda) + (1-\lambda)\lambda \my \Big( \lambda \|y-x\|^2 + (1-\lambda) \|y-x\|^2 \Big) \\
						&\quad=  f(x_\lambda) + (1-\lambda)\lambda \my \|y-x\|^2.
					\end{align*}
				\end{segnb}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{st} \label{2.17}
	Sei $X \subset \R^n$ offen und konvex und $f: X \to \R^n$ zweimal stetig differenzierbar.
	$f$ ist auf $X$
	\begin{enumerate}[(a)]
		\item
			genau dann konvex, wenn $\nabla^2 f(x)$ für alle $x \in X$ positiv semidefinit ist, also für alle $x \in X, d \in \R^n$
			\[
				d^T \nabla^2 f(x) d \ge 0
			\]
		\item
			strikt konvex, wenn $\nabla^2 f(x)$ für alle $x \in X$ positiv definit ist, also für alle $x \in X, d \in \R^n \setminus \{0\}$
			\[
				d^T \nabla^2 f(x) d > 0.
			\]
			Die Umkehrung gilt nicht, wie man in \ref{2.18} sieht
		\item
			genau dann gleichmäßig konvex, wenn $\nabla^2 f(x)$ gleichmäßig positiv semidefinit ist, d.h. es existiert $\my > 0$, sodass für alle $x \in X, d \in \R^n \setminus \{0\}$
			\[
				d^T \nabla^2 f(x) d \ge \my \|d\|^2.
			\]
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				\begin{segnb}[„$\implies$“]
					Sei $f$ konvex und $d \in \R^n$.
					Für hinreichend kleine $t > 0$ gilt mit Taylor und Konvexitätsformulierung aus $\ref{2.16}$
					\[
						\f {t^2}2 d^T \nabla^2 f(x) d + p(td)
						= \underbrace{f(x+td) - f(x)}_{\ge \nabla f(x)^T td} - t \nabla f(x)^T d
						\ge 0,
					\]
					wobei $p(td) = o(\|td\|)$ erfüllt.
					Also gilt
					\[
						d^T \nabla^2 f(x) d
						\ge - \f {2 p(td)}{t^2} \to 0
					\]
					für $t \to 0$.
				\end{segnb}
				\begin{segnb}[„$\impliedby$“]
					Seien $x,y \in X$ und $d := y - x$.
					Mittels \ref{2.3} existiert $s \in [0,1]$ sodass
					\begin{align*}
						f(y) = f(x + d)
						&= f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x+sd)d \\
						&\ge f(x) + \nabla f(x)^T (y-x)
					\end{align*}
					und somit ist $f$ nach \ref{2.16} konvex.
				\end{segnb}
			\item
				Analog zu $\impliedby$ in (a).
				Für das Gegenbeispiel siehe \ref{2.18}.
			\item
				\begin{segnb}[„$\implies$“]
					Analog wie „$\implies$“ in (a) erhalten wir
					\[
						d^T \nabla^2 f(x) d
						\ge - \f {2 p(td)}{t^2} + \my \|d\|^2
						\to \my \|d\|^2.
					\]
				\end{segnb}
				\begin{segnb}[„$\impliedby$“]
					Analog wie in (a) existiert zu $x,y \in X$ ein $s \in [0,1]$ mit
					\begin{align*}
						f(y)
						&= f(x) + \nabla f(x)^T (y-x) + \f 12 (y-x)^T \nabla^2 f(x_s) (y-x) \\
						&\ge f(x) + \nabla f(x)^T (y-x) + \f 12 \my \|y-x\|^2,
					\end{align*}
					also ist $f$ nach \ref{2.16} gleichmäßig konvex.
				\end{segnb}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{ex} \label{2.18}
	In \ref{2.17} gilt die Rückrichtung in (b) im Allgemeinen nicht.
	Betrachte dazu $f(x) = x^4$, dann ist $f''(x)\big|_{x=0} = 0$ nicht positiv definit trotz strikter Konvexität.
\end{ex}

\coursetimestamp{28}{10}{2013}

\begin{st} \label{2.19}
	Sei $X \subset \R^n$ konvex und $f: X \to \R$ konvex.
	Dann gelten folgende Aussagen
	\begin{enumerate}[(a)]
		\item
			Jedes lokale Minimum von $f$ ist auch globales Minimum von $f$.
		\item
			Ist $f$ strikt konvex, dann besitzt $f$ höchstens ein lokales Minimum.
			Dieses ist nach Teil (a) das eindeutige, strikte globale Minimum.
		\item
			Ist $f$ stetig differenzierbar auf einer offenen Menge $O \supset X$ offen, dann ist jeder stationäre Punkt in $X$ ein globales Minimum.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Sei $x \in X$ kein globales Minimum von $f$.
				Dann existiert $y \in X$ mit $f(y) < f(x)$.
				Mit der Konvexität folgt für alle $f \in (0,1]$
				\[
					f(x+t(y-x))
					\le (1-t)f(x) + t f(y)
					< f(x).
				\]
				Mit hinreichend kleinem $t$ finden wir also in jeder Umgebung von $x$ ein $\xi$ mit $f(\xi) < f(x)$, also ist $x$ kein lokales Minimum.
			\item
				Seien $x,y \in X$ zwei lokale Minima von $f$.
				Nach (a) sind $x,y$ globale Minima, also $f(x) = f(y)$.
				Angenommen $x \neq y$, dann wäre wegen der strikten Konvexität
				\[
					f(\f {x+y}2)
					< \f{f(x) + f(y)}2
					= f(x)
					= f(y),
				\]
				ein Widerspruch dazu, dass $x,y$ globale Minima waren.
			\item
				Ist $x \in X$ ein stationärer Punkt, dann ist nach \ref{2.16} für alle $y\in X$
				\[
					f(y) - f(x)
					\ge \nabla f(x)^T (y-x)
					= 0,
				\]
				also $f(y) \ge f(x)$ und somit $x$ globales Minimum.
		\end{enumerate}
	\end{proof}
\end{st}


\section{Das Gradientenverfahren}


\begin{conv*}
	In diesem Abschnitt sei $f: \R^n \to \R$ eine stetig differenzierbare Funktion.

	Im folgenden schreiben wir für eine Folge von Vektoren in $\R^n$ teilweise auch
	\[
		x^{(0)} = \begin{pmatrix}
			x_1^{(0)} \\ \vdots \\ x_n^{(0)}
		\end{pmatrix},
		x^{(1)} = \begin{pmatrix}
			x_1^{(1)} \\ \vdots \\ x_n^{(1)}
		\end{pmatrix},
		\dotsc \in \R^n.
	\]
\end{conv*}

\subsection{Richtung des steilsten Abstiegs}

In der Umgebung eines Punktes $x_0 \in \R^n$ gilt nach Taylor die lineare Approximation
\[
	f(x) \approx f(x_0) + \nabla f(x_0)^T (x-x_0).
\]
Nach \coursehref{Blatt3.pdf}{Übungsaufgabe 3.1}
ist das Minimum der linearen Approximation innerhalb einer Kugel um $x_0$
\[
	\min_{\|x-x_0\|=1} \Big( f(x_0) + \nabla f(x_0)^T (x-x_0) \Big)
	= f(x_0) - \nabla f(x_0)^T \f {\nabla f(x_0)}{\|\nabla f(x_0)\|}.
\]
% fixme folgende zeile ist etwas unklar
In der linearen Approximation ist $x-x_0 = -s \nabla f(x_0)$ mit $s > 0$, also die Richtung des steilsten Abstiegs von $f$.

Ein naiver Ansatz für einen Algorithmus wäre folgender:
Beginne mit $x_0 \in \R^n$ und iteriere
\[
	x_{k+1} := x_k - s_k \nabla f(x_k),
\]
mit noch zu bestimmenden Schrittweiten $s_k > 0$.
Solche Verfahren werden \emph{Gradientenverfahren} genannt.

\subsection{Armijo-Schrittweitenregel}

In der linearen Approximation erwarten wir, dass für $s_k > 0$ und $d_k \in \R^n$ (hier z.B. $d_k = -\nabla f(x_k)$)
\[
	f(x_{k+1})
	= f(x_k + s_k d_k)
	\approx f(x_k) + s_k \nabla f(x_k)^T d_k.
\]
Die Armijo-Regel besagt:
vergleiche die tatsächlie Abnahme der Zielfunktion $f(x_k) - f(x_k + s_kd_k)$ mit der aus der linearen Approximation erwarteten Abnahme $-s_k \nabla f(x_k)^T d_k$.
Nur wenn die tatsächliche Abnahme mindestens einen voregegebenen Bruchteil (z.B. $\gamma = 1\%$) der erwarteten Abnahme erreicht, also wenn die sogenannte \emph{Armijo-Regel}
\[
	f(x_{k+1})
	\le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k
\]
erfüllt ist, dann wird die Schrittweite akzeptiert, sonst verkürzt (z.B. auf $\beta s_k$ mit $\beta = \f 12 < 1$).

Für in jedem Schritt an der Stelle $x_k$ vorgegebener Abstiegsrichtung $d_k$ lässt sich die Schrittweitenwahl folgendermaßen beschreiben.
\begin{alg}[Armijo-Schrittweitenregel]
	\begin{algorithmic}
		\Require{Parameter $\beta \in (0,1), \gamma \in (0,1)$}
		\Require{Aktuelle Iterierte $x_k$ und Abstiegsrichtung $d_k$}
		\State $s_k \gets \f 1{\beta}$
		\Repeat
			\State $s_k \gets \beta s_k$
			\State $x_{k+1} \gets x_k + s_k d_k$
		\Until $f(x_{k+1}) \le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k$
		\Return $s_k$
	\end{algorithmic}
\end{alg}

Verbindet man das Gradientenverfahren (d.h. die Wahl $d_k = -\nabla f(x_k)$ für die Abstiegsrichtung) mit der Armijo-Schrittweitenregel, so erhält man den folgenden Algorithmus.

\begin{alg}[Gradientenverfahren mit Armijo-Schrittweitenregel] \label{alg:gradient_descent_armijo}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Armijo-Parameter $\beta \in (0,1), \gamma \in (0,1)$}

		\State{$k \gets 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\State{$s_k \gets \f 1\beta$}
			\Repeat
				\State{$s_k \gets \beta s_k$}
				\State{$x_{k+1} \gets x_k - s_k \nabla f(x_k)$}
			\Until{$f(x_{k+1}) \le f(x_k) - \gamma s_k \|\nabla f(x_k)\|^2$}
			\State{$k \gets k + 1$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{df} \label{2.20}
	Ein Vektor $0 \neq d \in \R^n$ heißt \emph{Abstiegsrichtung} von $f$ im Punkt $x$, falls
	\[
		\nabla f(x)^T d < 0.
	\]
\end{df}

\begin{st} \label{2.21}
	Ist $d$ eine Abstiegsrichtung von $f$ im Punkt $x$, so existiert für jedes $\gamma \in (0,1)$ ein $t > 0$ sodass
	\[
		f(x+sd)
		\le f(x) + \gamma s \nabla f(x)^T d
	\]
	für alle $s \in [0,t]$.
	Insbesondere terminiert die Armijo-Schrittweitenregel nach endlich vielen Schritten.
	\begin{proof}
		Es gilt
		\[
			\lim_{s\to 0} \big( \f{f(x_k+sd)-f(x_k)}{s} \big) - \gamma \nabla f(x)^T d
			= (1 - \gamma) \underbrace{\nabla f(x_k)^T d}_{<0}
			< 0,
		\]
		also ist für hinreichend kleine $s>0$
		\[
			\f{f(x_k+sd)-f(x_k)}{s} - \gamma \nabla f(x)^T d
			\le 0,
		\]
		also die Armijo-Bedingung erfüllt.
	\end{proof}
\end{st}

\begin{nt} \label{2.22}
	\ref{2.21} besagt insbesondere für hinreichend kleine $s > 0$ (solche, die Armijo erfüllen)
	\[
		f(x+sd)
		\le f(x) + \underbrace{\gamma s}_{> 0} \underbrace{\nabla f(x)^T d}_{<0}
		< f(x),
	\]
	d.h. die Funktion $f$ nimmt in Richtung ihrer Abstiegsrichtung lokal ab.

	%fixme: klarer machen: welche umkehrung?
	Die Umkehrung hingegen gilt nicht.
	Betrachte dazu $f(x) = -x^2$ an der Stelle $x = 0$: in Richtung $d=\pm 1$ nimmt die Funktion ab, aber beides sind keine Abstiegsrichtungen gemäß \ref{2.20}.
\end{nt}

\begin{nt}[“Trust-Region”] \label{2.23}
	Die Armijo-Regel ist ein spezieller, einfacher Fall für ein sogenanntes “Trust-Region”-Verfahren.
	Bei einem Trust-Region-Verfahren wird $f$ dabei durch eine Näherung, beispielsweise einer linearen ersetzt:
	\[
		f(x)
		\approx f(x_k) + \nabla f(x_k)^T (x-x_k).
	\]
	Um den Fehlerterm in der Taylorapproximation gering zu halten, vertrauen dieser Näherung jedoch nur für $x$ mit
	\[
		\|x - x_k\| \le \Delta_k,
	\]
	der sogenannten “Trust-Region”.
	Wir lösen also das restringierte Optimierungsproblem
	\[
		f(x_k) + \nabla f(x_k)^T (x-x_k) \to \min!
		\udN
		x \in B_{\Delta_k}(x_k)
	\]
	und erhalten $x_{k+1} = x_k - s_k \nabla f(x_k)$ ($s_k = \f {\Delta_k}{\|\nabla f(x_k)\|}$).
	Vergleiche anschließend die vorhergesagte Abnahme (\pred, “predicted reduction”) mit tatsächlicher Abnahme (\ared, “actual reduction”)
	\begin{align*}
		\pred_k &:= -s_k \nabla f(x_k) d_k, &
		\ared_k &:= f(x_k) - f(x_{k+1}).
	\end{align*}
	Falls $\f {\ared_k}{\pred_k} < \gamma$, so wird der Schritt mit verkleinertem $\Delta_k$ wiederholt.
\end{nt}

\coursetimestamp{30}{10}{2013}

% 2.2.3
\subsection{Konvergenz des Gradientenverfahrens}

Das Gradientenverfahren hat zwei Probleme:
\begin{itemize}
	\item
		es könnte ein lokales Maximum gefunden werden (da $\nabla f(x_k) = 0$ Abbruchkriterium ist),
	\item
		oder das Gradientenverfahren könnte nicht konvergieren (man stelle sich $f(x) = e^{-x}$ vor).
\end{itemize}
Trotzdem können wir eine schwache Aussage zum Konvergenzverhalten machen.

\begin{st}[Präkonvergenz des Gradientenverfahrens] \label{2.24}
	Das Gradientenverfahren % fixme: algorithm reference
	terminiert entweder nach endlich vielen Schritten an einem stationären Punkt $x_k$, oder erzeugt eine Folge $(x_k)_{k\in\N}$ mit
	\begin{enumerate}[(a)]
		\item
			$f(x_{k+1}) < f(x_k)$,
		\item
			jeder Haufungspunkt von $(x_k)$ ist ein stationärer Punkt von $f$.
	\end{enumerate}
	\begin{proof}
		Terminiert der Algorithmus
		nach endlich vielen Schritten an einem $x_k$, so gilt gemäß Abbruchkriterium $\nabla f(x_k) = 0$.
		Betrachte also jetzt den Fall, dass der Algorithmus nicht konvergiert.
		\begin{enumerate}[a)]
			\item
				Siehe \ref{2.22}.
			\item
				Sei $x \in \R^n$ ein Häufungspunkt von $(x_k)_{k\in\N}$, d.h. es existiert eine unendliche Indexmenge $L \subset \N$, so dass
				\[
					\lim_{L \ni l \to \infty} x_l = x.
				\]
				Da $f$ stetig, gilt auch $\lim_{L \ni l \to \infty} f(x_l) = f(x)$.
				Nach Teil (a) ist $(f(x_k))_{k\in\N}$ streng monoton fallend und damit $f(x_k) \ge f(x)$ für alle $k \in \N$.
				Also konvergiert $(f(x_k))_{k\in\N}$ und $\lim_{k\to \infty} f(x_k) = f(x)$.

				Nach der Armijo-Regel gilt
				\[
					f(x_0) - f(x)
					= \sum_{k=0}^\infty (f(x_k) - f(x_{k+1}))
					\ge \sum_{k=0}^\infty \gamma s_k \| \nabla f(x_k) \|^2,
				\]
				also ist $\lim_{k\to\infty} s_k \|\nabla f(x_k)\|^2 = 0$ und insbesondere auch für die Teilfolge mit der Indexmenge $L$:
				\[
					\lim_{L \ni l \to \infty} s_l \|\nabla f(x_l)\|^2 = 0.
				\]
				Es gilt also $\lim_{L \ni l \to \infty} s_l = 0$ oder wegen Stetigkeit $\nabla f(x) = \lim_{L \ni l \to\infty} \nabla f(x_l) = 0$.
				Im letzteren Fall ist die Behauptung beweisen, betrachte also $\lim_{L \ni l \to \infty} s_l = 0$.

				In fast allen (o.B.d.A in allen) Schritten $l \in L$ hat durch die Armijo-Regel eine Schrittweitenverkürzung stattgefunden, d.h. $\f {s_l}{\beta}$ erfüllte die Armijo-Bedingung noch nicht.
				Für alle $l \in L$ gilt demnach
				\[
					f\big(x_l - \f {s_l}\beta \nabla f(x_l)\big)
					> f(x_l) - \gamma \f {s_l}{\beta} \| \nabla f(x_l) \|^2.
				\]
				Nach \ref{2.3} gilt:
				Für alle $l \in L$ existiert $\sigma_l \in [0, \f {s_l}{\beta}]$, sodass
				\[
					f\big(x_l - \f {s_l}\beta \nabla f(x_l)\big)
					= f(x_l) - \f {s_l}\beta \nabla f\big(x_l - \sigma_l \nabla f(x_l)\big)^T \nabla f(x_l).
				\]
				Also
				\begin{align*}
					-\gamma \f {s_l}\beta \|\nabla f(x_l)\|^2
					&< f\big(x_l - \f{s_l}\beta \nabla f(x_l)\big) - f(x_l) \\
					&= -\f {s_l}\beta \nabla f\big(\underbrace{x_l - \sigma_l \nabla f(x_l)}_{\to x}\big)^T \nabla f(\underbrace{x_l}_{\to x})
				\end{align*}
				und somit für $L \ni l \to \infty$ (also $x_l \to x$ und $\sigma_l \to 0$)
				\[
					- \gamma \|\nabla f(x)\|^2 \le - \| \nabla f(x)\|^2.
				\]
				Aus $\gamma < 1$ folgt damit $\nabla f(x) = 0$.
		\end{enumerate}
	\end{proof}
\end{st}

\begin{lem} \label{2.25}
	Sei $x \in \R^n$ und $(x_k)_{k\in\N}$ eine Folge in $\R^n$.
	Besitzt jede Teilfolge von $(x_k)_{k\in\N}$ wiederum eine (Teil-)Teilfolge, die gegen $x$ konvergiert, so konvergiert die ganze Folge $(x_k)_{k\in\N}$ gegen $x$.
	\begin{proof}
		Angenommen $(x_k)_{k\in\N}$ konvergiert nicht gegen $x$.
		Dann gibt es eine Umgebung von $x$, außerhalb derer unendlich viele Folgenglieder liegen.
		Diese bilden dann aber eine Teilfolge, die keine gegen $x$ konvergente Teilfolge besitzen kann.
	\end{proof}
\end{lem}

\begin{kor} \label{2.26}
	\begin{enumerate}[(a)]
		\item
			Sei $c > 0$, so dass die \emph{Niveaumenge}
			\[
				f^{-1}((-\infty, c])
				:= \{ x \in \R^n : f(x) \le c \}
			\]
			beschränkt ist und in ihr nur ein stationärer Punkt liegt.

			Dann ist dieser stationäre Punkt das globale Minimum von $f$ und das Gradientenverfahren konvergiert für jeden Startwert $x_0$ mit $f(x_0) \le c$ gegen dieses Minimum.
		\item
			Ist $f$ konvex, dann terminiert \ref{alg:gradient_descent_armijo}
			entweder nach endlich vielen Schritten an einem globalen Minimum, oder erzeugt eine Folge, deren Häufungspunkte globale Minima sind.
		\item
			Sei $f$ strikt konvex und besitze ein eindeutiges Minimum, dann konvergiert die Folge aus \ref{alg:gradient_descent_armijo}
			für jedes $x_0$ mit $f(x_0) \le c$ gegen das globale Minimum.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				%fixme: rewrite
				$N_c := f^{-1}((-\infty,c])$ ist abgeschlossen, also kompakt, also wird das Minimum auf $N_c$ angenommen, $f(x) \le f(y)$ für alle $y \in \R^n$ und somit $\nabla f(x) = 0$.
			\item
				Folgt aus \ref{2.19} (a), (c).
			\item
				Siehe \ref{2.27}.
		\end{enumerate}
	\end{proof}
\end{kor}

\coursetimestamp{04}{11}{2013}

\begin{st}[Röhm] \label{2.27}
	Ist $f: \R^n \to \R$ konvex und besitzt ein eindeutiges Minimum, so sind alle Niveaumengen beschränkt.

	Insbesondere konvergiert das Gradientenverfahren für solche Funktionen mit jeder Wahl des Startwertes gegen das Minimum.
	\begin{proof}
		Sei $f$ konvex und $\hat x \in \R^n$ der Minimierer von $f$.
		Zu jedem Radius $r > 0$ definiere
		\[
			C_r := \min \{ f(x) : x \in \boundary B_r (\hat x) \}.
		\]
		Wir zeigen, dass
		\begin{enumerate}[(a)]
			\item
				$f^{-1}(]-\infty, C_r) \subset \_{B_r(\hat x)}$,
			\item
				$C_r \to \infty$ für $r \to \infty$.
		\end{enumerate}
		Sei $r > 0$ und $x \not\in \_{B_r(\hat x)}$.
		Für $t := \f r{\|x - \hat x\|}$ gilt $0 < t < 1$ und
		\[
			\hat x + t(x-\hat x) \in \boundary B_r(\hat x).
		\]
		Also
		\begin{align*}
			C_r
			\le f(\hat x + t(x-\hat x))
			&\le (1-t) f(\hat x) + tf(x) \\
			&< (1-t) f(x) + t f(x)
			= f(x)
		\end{align*}
		und somit (a) gezeigt.
		Es folgt daraus außerdem
		\[
			f(x)
			\ge \f 1t C_R - \f 1t f(\hat x) + f(\hat x)
			= \f {\|x-\hat x\|}r (C_r - f(\hat x)) + f(\hat x).
		\]
		Für alle $R > r$ gilt also
		\[
			C_R = \min \{ f(x) : x \in \boundary B_R(\hat x) \}
			\ge \f Rr \underbrace{(C_r - f(\hat x))}_{\ge 0} + f(\hat x)
			\to \infty
		\]
		für $R \to \infty$.
	\end{proof}
\end{st}

\subsection{Nachteile des Gradientenverfahrens}

Für $f(x) = x^T A x$ mit $A = \Id$ liefert die Gradientenrichtung die „perfekte Suchrichtung“, mit der Minimierungsregel (“line search”, d.h. suche globales Minimierung in Richtung der Suchrichtung) findet das Gradientenverfahren das Minimimum in einem Schritt.

Für $f(x) = x^T A x$ mit $A = \begin{psmallmatrix}1 & 0 \\ 0 & 4\end{psmallmatrix}$ kann sich dagegen sogenanntes “zig-zagging” ergeben, was zu langsamer Konvergenz führt (siehe \coursehref{Blatt4.pdf}{Übungsaufgabe 4.4}).


\section{Allgemeine Abstiegsverfahren}


Es sei hier weiterhin stets $f: \R^n \to \R$ stetig differenzierbar.

\begin{alg}[Allgemeines Abstiegsverfahren] \label{alg:3}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Suchrichtungen und Schrittweiten $d_k, s_k$}

		\State{$k \gets 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\State{$x_{k+1} \gets x_k + s_k d_k$}
			\State{$k \gets k + 1$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\subsection{Ein allgemeines Konvergenzresultat}

Wenn wir in \ref{alg:3} für alle $k \in \N$ fordern, dass
\[
	\nabla f(x_k)^T d_k < 0
	\qquad\text{und}\qquad
	f(x_k + s_k d_k) < f(x_k),
\]
dann können wir interessante Konvergenzresultate zeigen.
Im Beweis von \ref{2.24} folgte aus dieser Bedingung sofort, dass (falls es eine konvergente Teilfolge der $x_k$ gibt) $f(x_k)$ konvergiert, also insbesondere
\[
	f(x_k) - f(x_{k+1}) \to 0.
\]

\begin{df} \label{2.28}
	Das allgemeine Abstiegsverfahren in \ref{alg:3} besitzt
	\begin{enumerate}[(a)]
		\item
			\emph{zulässige Schrittweiten}, falls
			\[
				f(x_k + s_k d_k) < f(x_k)
			\]
			und für jede konvergente Teilfolge $(x_l)_{l\in L}$ der Iterierten gilt
			\[
				%fixme: linke seite stets erfüllt? siehe beweis 2.26
				f(x_k) - f(x_{k+1}) \to 0
				\quad\implies\quad
				\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
			\]
		\item
			\emph{zulässige Suchrichtungen}, falls
			\[
				\nabla f(x_k)^T d_k < 0
			\]
			und für jede konvergente Teilfolge $(x_l)_{l\in L}$ der Iterierten gilt
			\[
				\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
				\quad\implies\quad
				\lim_{L \ni l \to \infty} \nabla f(x_l) = 0.
			\]
	\end{enumerate}
\end{df}

\begin{st}[Präkonvergenz allgemeiner Abstiegsverfahren] \label{2.29}
	Das allgemeine Abstiegsverfahren in \ref{alg:3} besitze zulässige Schrittweiten und zulässige Suchrichtungen.
	Dann terminiert das Verfahren nach endlich vielen Schritten an einem stationären Punkt $x_k$ oder es erzeugt eine Folge $(x_k)_{k\in\N}$ mit
	\begin{enumerate}[(a)]
		\item
			$f(x_{k+1}) < f(x_k)$,
		\item
			jeder Häufungspunkt von $(x_k)$ ist ein stationärer Punkt von $f$.
	\end{enumerate}
	\begin{proof}
		Aussage (a) geht direkt aus der Definition zulässiger Schrittweiten hervor.

		Konvergiert eine Teilfolge $(x_l)_{l\in L}$ der Iterierten gegen ein $x \in \R^n$, so folgt wie in \ref{2.24}, dass
		\[
			f(x) = \lim_{L \ni l \to \infty} f(x_l) = \lim_{k \to \infty} f(x_k),
		\]
		also $f(x_k) - f(x_{k+1}) \to 0$.
		Daraus folgt mit den Definitionen der zulässigen Schrittweiten/Suchrichtungen die Aussage (b).
	\end{proof}
\end{st}

\subsection{Interpretation der Zulassungsbedingungen}

\subsubsection{Zulässigkeit der Suchrichtungen:}

\[
	0 <
	-\nabla f(x_k)^T d_k
	= \|\nabla f(x_k)\|\|d_k\| \cos \angle(-\nabla f(x_k), d_k),
\]
also genau dann, wenn
\[
	\cos \angle(-\nabla f(x_k), d_k) > 0.
\]
Suchrichtungen sollen zur Richtung des steilsten Abstiegs also einen Winkel betragsmäßig $< \f \pi2$ besitzen.
Eine naheliegende Forderung wäre, dass der Winkel „gleichmäßig“ unter $\f \pi 2$ liegt, also
\[
	\exists \alpha > 0 \forall k\in \N : \underbrace{\cos \angle(-\nabla f(x_k), d_k)}_{= \f {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|}} \ge \alpha.
\]
Solche Bedingungen werden auch \emph{Winkelbedingungen} genannt.

\begin{st} \label{2.30}
	Seien $(d_k)_{k\in\N}$  die Suchrichtungen eines allgemeine Abstiegsverfahren.
	Gilt die \emph{Winkelbedingung}
	\[
		\exists \alpha > 0 \forall k \in \N:
		\dfrac {-\nabla  f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|} \ge \alpha,
	\]
	so sind die Suchrichtungen zulässig.
	\begin{proof}
		Aus der Winkelbedingung folgt $\nabla f(x_k)^T d_k < 0$ und
		\[
			\|\nabla f(x_k)\|
			\le \f 1\alpha \f {-\nabla f(x_k)^T d_k}{\|d_k\|}.
		\]
		Falls $\f{\nabla f(x_l)^T d}{\|d_l\|} \to 0$, dann auch $\nabla f(x_l) \to 0$, also sind die Suchrichtungen zulässig.
	\end{proof}
\end{st}

\coursetimestamp{06}{11}{2013}

% Betrachtet man \ref{2.30}, so sieht man, dass für $-\f{\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$ für eine konvergente Teilfolge $(x_l)_{l\in L}$ auch $\nabla f(x_l) \to 0$
% fixme: Erläuterung

\begin{nt} \label{2.31}
	Die Suchrichtungen sind schon dann zulässig, wenn sie \emph{verallgemeinerte Winkelbedingungen} erfüllen, z.B.
	\[
		\exists \alpha > 0, p > -1 \forall k \in \N
		: \dfrac {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\| \|d_k\|}
		\ge \alpha \|\nabla f(x_k)\|^p,
	\]
	oder
	\[
		\exists \alpha_1, \alpha_2 > 0, p > -1 \forall k \in \N
		: \dfrac {-\nabla f(x_k)^Td_k}{\|\nabla f(x_k)\|\|d_k\|} \ge \min\{ \alpha_1, \alpha_2 \|\nabla f(x_k)\|^p \}.
	\]
	\begin{proof}
		 Siehe \coursehref{Blatt5.pdf}{Übungsaufgabe 5.2}.
	\end{proof}
\end{nt}

\begin{ex} \label{2.32}
	\begin{enumerate}[(a)]
		\item
			Die Suchrichtungen $d_k = -\nabla f(x_k)$ erfüllen offensichtlich die Winkelbedingungen mit $\alpha = 1$.
		\item
			Seien $A_k \in \R^{n\times n}$ symmetrische, positiv definite Matrizen mit
			\[
				0
				< c
				< \lambda_{\text{min}}(A_k)
				\le \lambda_{\text{max}}(A_k)
				\le C
				< \infty
			\]
			für alle $k \in \N$.
			Die Suchrichtungen
			\[
				d_k := - A_k^{-1} \nabla f(x_k).
			\]
			sind zulässig, denn sie erfüllen die Winkelbedingung:
			\begin{align*}
				\dfrac {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|}
				&= \dfrac {\nabla f(x_k)^T A_k^{-1} \nabla f(x_k)}{\|\nabla f(x_k)\|\|A^{-1} \nabla f(x_k)\|} \\
				&\ge \dfrac {\lambda_{\text{min}} (A_k^{-1}) \|\nabla f(x_k)\|^2}{\|A_k^{-1}\| \|\nabla f(x_k)\|^2} \\
				&= \dfrac {\lambda_{\text{min}}(A^{-1})}{\lambda_{\text{max}}(A_k^{-1})}
				= \dfrac {\lambda_{\text{min}}(A_k)}{\lambda_{\text{max}}(A_k)}
				\ge \f cC
				> 0.
			\end{align*}
	\end{enumerate}
\end{ex}

\subsubsection{Zulässigkeit der Schrittweiten}

Für $f \in C^2(\R^n)$ folgt aus \ref{2.3}, dass ein $\sigma \in [0,s]$ existiert mit
\begin{align*}
	f(x+sd)
	&= f(x) + s\nabla f(x)^T d + \f {s^2}2 d^T \nabla^2 f(x + \sigma d)d \\
	&\le f(x) + s\nabla f(x)^T d + \f {s^2}2 C \|d\|^2,
\end{align*}
wobei $C := \max_{\sigma\in[0,s]} \|\nabla^2 f(x + \sigma d) \|$.
Die rechte Seite ist dabei minimal für
\[
	s = s^* := \f{-f(x)^T d}{C\|d\|^2}.
\]
Dann ist
\[
	f(x+s^*d)
	\le f(x) - \f{|\nabla f(x)^T d|^2}{2C\|d\|^2},
\]
also ist in Suchrichtung $d$ mit Schrittweite $s^*$ eine Verkleinerung von $f$ um mindestens $\f 1{2C} \f {|\nabla f(x)^T d|^2}{\|d\|^2}$ möglich.

\begin{df} \label{2.33}
	Seien $(d_k)_{k\in \N}$ und $(s_k)_{k\in\N}$ Suchrichtungen und Schrittweiten eines allgemeinen Abstiegsverfahren.
	Die Schrittweiten heißen \emph{effizient}, falls
	\[
		\exists \theta > 0 \forall k \in \N
		: f(x_k + s_k d_k) \le f(x_k) - \theta \f {|\nabla f(x_k)^T d_k|^2}{\|d_k\|^2}.
	\]
\end{df}

\begin{st} \label{2.34}
	Seien $(d_k)_{k\in\N}$ und $(s_k)_{k\in\N}$ die Suchrichtungen und Schrittweiten eines allgemeinen Abstiegsverfahrens, das $f(x_k + s_k d_k) < f(x_k)$ erfüllt.
	Sind die Schrittweiten effizient, dann sind sie auch zulässig.
	\begin{proof}
		$f(x_k+s_kd_k) < f(x_k)$ ist klar.
		Es gilt
		\[
			\theta \f {|\nabla f(x_k)^T d_k|^2}{\|d_k\|^2}
			\le f(x_k) - f(x_{k+1}),
		\]
		also
		\[
			\f{|\nabla f(x_k)^T d_k|}{\|d_k\|} \to 0,
		\]
		falls $f(x_k) - f(x_{k+1}) \to 0$.
	\end{proof}
\end{st}

\begin{nt*}
	Die Armijo-Schrittweiten sind nicht effizient (siehe \ref{2.35}).

	Die Armijo-Regel akzeptiert Abnahmen in der Größenordnung $\|\nabla f(x_k)\|$, während die Effizienz der Schrittweiten aber eine Abnahme der Größenordnung $\|\nabla f(x_k)\|^2$ fordert.
\end{nt*}

\subsection{Zulässigkeit der Armijo-Schrittweitenregel}

Für $f(x) = -x$ ist $d_k = - \nabla f(x) = 1$ und Armijo akzeptiert stets $s_k = 1$.
Für $d_k' = - \f{\nabla f(x_k)}{2^k} = \f 1{2^k}$ akzeptiert Armijo ebenfalls stets $s_k' = 1$.
Die Winkelbedingungen sind in beiden Fällen erfüllt, aber im zweiten Fall konvergiert zwar $(x_k)$, aber nicht gegen einen stationären Punkt.
Also sind Armijo-Schrittweiten im Allgemeinen nicht zulässig.

\begin{ex} \label{2.35}
	Ein Abstiegsverfahren mit Armijo-Regel und Suchrrichtungen
	\[
		d_k := -2^{-k} \nabla f(x)
	\]
	konvergiert für $f(x) = -x$ gegen einen nicht-stationären Punkt.

	Armijo-Schrittweiten können also nicht zulässig sein.
\end{ex}

\begin{st} \label{2.36}
	Seien $(d_k)_{k\in\N}$ Abstiegsrichtungen.
	Existiert für jede konvergente Folge $(x_l)_{l\in L}$ eine streng monoton wachsende Funktion $\phi: [0,\infty) \to [0,\infty)$ mit
	\[
		\|d_l\|
		\ge \phi \big( \f{-\nabla f(x_l)^T d_l}{\|d_l\|} \big)
	\]
	für alle $l \in L$,
	dann sind die Armijo-Schrittweiten zulässig.
	\begin{proof}
		Zeige gemäß \ref{2.28}
		\begin{enumerate}[a)]
			\item
				$\forall k\in\N : f(x_k + s_k d_k) < f(x_k)$
			\item
				und für jede konvergente Teilfolge $(x_l)_{l\in L}$:
				\[
					\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0
					\quad \implies\quad
					\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
				\]
		\end{enumerate}
		\begin{enumerate}[a)]
			\item
				Nach \ref{2.21} liefert die Armijo-Regel stets eine Schrittweite $s_k$ mit
				\[
					f(x_k + s_k d_k)
					\le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k
					< f(x_k).
				\]
			\item
				Sei $f(x_k) - f(x_{k+1}) \to 0$ und sei $(x_l)_{l\in L}$ eine konvergente Teilfolge der Iterierten.
				Angenommen $\f {\nabla f(x_l)^T d_l}{\|d_l\|} \not\to 0$ für $L \ni l \to \infty$, d.h.
				\[
					\exists \eps > 0 \forall l \in L' \subset L : \f{\nabla f(x_l)^T d_l}{\|d_l\|} < - \eps
				\]
				mit $|L'| = \infty$.
				Die Armijo-Regel liefert
				\[
					-\gamma \f {\nabla f(x_k)^T d_k}{\|d_k\|} s_k \|d_k\|
					= - \gamma s_k \nabla f(x_k)^T d_k
					\le	f(x_k) - f(x_{k+1})
					\to 0.
				\]
				Also
				\[
					\lim_{L' \ni l \to \infty} s_l \|d_l\| = 0.
				\]
				Außerdem folgt für alle $l \in L'$
				\[
					\|d_l\|
					\ge \phi(\f{-\nabla f(x_l)^T d_l}{\|d_l\|})
					> \phi(\eps)
					> \phi(0)
					\ge 0.
				\]
				und somit $s_l \to 0$ für $L' \ni l \to \infty$.
				Der Rest funktioniert wie im Beweis von \ref{2.24} und man erhält
				%fixme: prüfen und ausführen
				\[
					0
					\le (1-\gamma) \f {-\nabla f(x_l)^T d_l}{\|d_l\|}
					< \f {\nabla f(x_l+ \sigma_l d_l) - \nabla f(x_l)^Td_l}{\|d_l\|}
					\le \|\nabla f(x_l + \sigma_l d_l) - \nabla f(x_l)\|.
				\]
				Aus $s_l \to 0$ folgt $\sigma_l d_l \to 0$.
				Da auch $(x_l)$ konvergiert, existiert ein $r > 0$ sodass
				\[
					x_l, x_l + \sigma_l d_l \in \_{B_r(0)}
				\]
				für fast alle $l \in L'$.
				Auf $\_{B_r(0)}$ ist $\nabla f$ also gleichmäßig stetig und damit
				\[
					\nabla f(x_l + \sigma_l d_l) - \nabla f(x_l) \to 0
				\]
				und somit $\f{-\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$, ein Widerspruch zur annahme.
		\end{enumerate}
	\end{proof}
\end{st}

\begin{ex} \label{2.37}
	Für das Gradientenverfahren mit $d_k := -\nabla f(x_k)$ ist
	\[
		\|d_k\|
		=\|\nabla f(x_k)\|
		=\phi(\f{-\nabla f(x_k)^T d_k}{\|d_k\|})
	\]
	mit $\phi(x) = x$.
	Mit \ref{2.36} und \ref{2.29} folgt also noch einmal die Aussage aus \ref{2.24}.
\end{ex}

\subsection{Die Powell-Wolfe-Schrittweitenregel}

Es gibt Varianten der Armijo-Regel, die zulässig sind:
% fixme: varianten genauer ausführen
\begin{itemize}
	\item
		z.B. Armijo mit Aufweitung,
	\item
		Armijo-Bedingung als Schranke in beide Richtungen,
	\item
		% fixme: reference
		Goldstein-Regel (siehe Übungsaufgabe).
\end{itemize}

In den Beweisen von \ref{2.24} und \ref{2.36} wurde verwendet
\[
	\gamma \nabla f(x_l)^T d_l
	< \nabla f(x_l + \sigma_l d_l)^T d_l
\]
mit einer Zwischenstelle $\sigma_l \in [0, s_l]$.
Naheliegend ist jetzt ein Algorithmus, der einen solchen Zusammenhang explizit fordert.
Es wird also zur aktuellen Iterierten $x$ und Suchrichtung $d$ eine Schrittweite $s$ gesucht, welche die bekannte Armijo-Bedingung und die sogenannte \emph{Powell-Wolfe-Bedingung} erfüllt:
\begin{align}
	f(x+sd) - f(x)
	&\le \gamma s \nabla f(x)^T d \label{eq:pw_armijo} \tag{Armijo}\\
	\nabla f(x+sd)^T d
	&\ge \eta \nabla f(x)^T d \label{eq:pw_pw} \tag{PW}
\end{align}
mit $0 < \gamma < 1$ und $\gamma < \eta < 1$ erfüllt.

\begin{alg} \label{alg:4}
	\begin{algorithmic}
		\Require{$0 < \gamma < \eta < 1$}
		\Require{aktuelle Iterierte $x$, Richtung $d\in\R^n$}
		\State{$s^- \gets 1$}
		\While{$s^-$ verletzt \eqref{eq:pw_armijo}}
			\State{$s^- \gets \f {s^-}2$}
		\EndWhile
		\State{$s^+ \gets s^-$}
		\While{$s^+$ erfüllt \eqref{eq:pw_armijo}}
			\State{$s^+ \gets 2s^+$}
		\EndWhile
		\While{$s^-$ verletzt \eqref{eq:pw_pw}}
			\State{$s^{(0)} \gets \f {s^+ + s^-}2$}
			\If{$s^{(0)}$ erfüllt \eqref{eq:pw_armijo}}
				\State{$s^- \gets s^{(0)}$} \Comment{$s^-$ erfüllt Armijo}
			\Else
				\State{$s^+ \gets s^{(0)}$} \Comment{$s^+$ verletzt Armijo}
			\EndIf
		\EndWhile
		\Return{$s \gets s^-$}
	\end{algorithmic}
\end{alg}

\begin{st} \label{2.38}
	Seien $0<\gamma<1$ und $\gamma<\eta<1$.
	Sei $d$ eine Abstiegsrichtung für $f$ im Punkt $x$.
	Weiter sei $f$ in Richtung $d$ nach unten beschränkt: $\inf_{t\ge 0}f(x+td) > -\infty$.

	Dann terminiert \ref{alg:4} nach endlich vielen Schritten und liefert eine Schrittweite $s$, die \eqref{eq:pw_armijo}, \eqref{eq:pw_pw} erfüllt.
	\begin{proof}
		Die erste Repeat-Schleife terminiert wegen \ref{2.21} (für $s$ klein genug ist die Armijo-Bedingung erfüllt).

		Für die zweite Repeat-Schleife betrachte
		\begin{align*}
			-\infty
			< \inf_{s\ge 0} f(x+sd)
			&\le f(x+s^+ d) \\
			&\stack{\text{\eqref{eq:pw_armijo}}}{\le} f(x) + \gamma s^+ \underbrace{\nabla f(x)^T d}_{< 0}
			\xrightarrow{s^+\to\infty} -\infty.
		\end{align*}
		Also kann $s^+$ nicht beliebig groß werden und die Schleife terminiert nach endlich vielen Schritten mit einem $s^+$, welches \eqref{eq:pw_armijo} verletzt.

		Für die While-Schleife betrachte die stetige Funktion
		\[
			g(s) := f(x+sd) - f(x) - \gamma s \nabla f(x)^T d,
		\]
		welche in $s^*$ eine Nullstelle hat.
		Zeige:
		\begin{enumerate}[(i)]
			\item
				In $s^*$ ist \eqref{eq:pw_armijo} erfüllt.
			\item
				Für $s \in \R$ mit $g(s) > 0$ ist \eqref{eq:pw_armijo} nicht erfüllt.
			\item
				Für $s \in \R$ mit $g(s) \le 0$ ist \eqref{eq:pw_armijo} erfüllt.
		\end{enumerate}
		Dann terminiert \ref{alg:4} nach endlich vielen Schritten und liefert eine Schrittweite $s$, die \eqref{eq:pw_armijo} und \eqref{eq:pw_pw} erfüllt.

		Die Intervallhalbierung sucht nach einem $s^*$ an dem \eqref{eq:pw_armijo} noch erfüllt ist und erzeugt dabei eie Folge von $s^-$, die monoton steigend gegen $s^*$ konvergiert und für alle Folgenglieder gilt $g(s^-) \le 0$.
		Genauso wird eine Folge von $s^+$ erzeugt, die monoton fallend gegen $s^*$ konvergiert und es gilt $g(s^+) > 0$.

		An $s^*$ gilt also
		\[
			0
			\le g'(s^*)
			= \nabla f(x+sd)^T d - \gamma \nabla f(x)^T d.
		\]

		Da $g$ stetig ist, liegt zu jedem $\eps > 0$ nach hinreichend viele Schleifendurchgänge $s^-$ nahe genug an $s^*$, sodass gilt
		\[
			g'(s^-) > - \eps.
		\]
		Mit $\eps := (\gamma - \eta) \nabla f(x)^T d$ folgt, dass nach endlich vielen Schleifendurchgängen gilt
		\[
			\nabla f(x+s^- d)^T d - \gamma \nabla f(x)^T d
			= g'(s^-)
			> - \eps
			= (\eta - \gamma) \nabla f(x)^T d,
		\]
		also gilt $\nabla f(x+s^- d)^T d > \eta \nabla f(x)^T d$, was \eqref{eq:pw_pw} entspricht.
	\end{proof}
\end{st}

\begin{st} \label{2.39}
	Sei $f$ nach unten beschränkt, $(d_k)_{k\in\N}$ Abstiegsrichtungen.
	Dann sind die durch die Powell-Wolfe-Regel erzeugten Schrittweiten zulässig.
	\begin{proof}
		Zeige $f(x_{k+1}) < f(x_k)$ und für jede konvergente Teilfolge $(x_l)_{l\in L}$
		\[
			\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0.
			\quad\implies\quad
			\lim_{L\ni l \to\infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0
		\]
		Da $f$ nach unten beschränkt ist, erzeugt \ref{alg:4} nach \ref{2.38} für jedes $k \in \N$ eine Schrittweite $s_k > 0$, die \eqref{eq:pw_armijo}, \eqref{eq:pw_pw} erfüllen.
		Damit gilt
		\[
			f(x_{k+1})
			= f(x_k + s_k d_k)
			\le f(x_k) + \gamma s_k \underbrace{\nabla f(x_k)^T d_k}_{< 0}
			< f(x_k).
		\]
		Sei jetzt $\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0$ und $(x_l)_{l\in L}$ eine konvergente Teilfolge der Iterierten $(x_k)_{k\in\N}$.
		Angenommen
		\[
			\lim_{L\ni l\to\infty} \f{\nabla f(x_l)^T d}{\|d_l\|} < 0,
		\]
		d.h. \oBdA existiert $\eps > 0$, sodass für alle $l \in L$
		\[
			- \f {\nabla f(x_l)^T d_l}{\|d_l\|} > \eps.
		\]
		Es gilt
		\[
			0 \leftarrow
			f(x_k) - f(x_{k+1})
			\ge -\gamma s_k \nabla f(x_k)^T d_k
			= s_k \gamma \|d_k\| \underbrace{\f{-\nabla f(x_k)^T d_k}{\|d_k\|}}_{> \eps},
		\]
		also $\lim_{L\ni l\to\infty} s_l \|d_l\| = 0$.

		Es gilt
		\[
			\nabla f(x_l + s_l d_l)^T d_l \ge \underbrace{\eta}_{<1} \underbrace{\nabla f(x_l)^T d_l}_{<0},
		\]
		also
		\begin{align*}
			0
			&\le -(1-\eta)\nabla f(x_l)^T d_l \f 1{\|d_l\|} \\
			&= \f 1{\|d_l\|}\big( \eta \nabla f(x)^T d_l - \nabla f(x_l)^T d_l \big) \\
			&\le \f 1{\|d_l\|} \big( \nabla f(x_l + s_l d_l)) - \nabla f(x_l) \big)^T d_l \\
			&\le \big\|\nabla f(x_l + s_l d_l) -\nabla f(x_l) \big\|
		\end{align*}
		Es genügt also $\|\nabla f(x_l + s_l d_l) -\nabla f(x_l)\| \to 0$ zu zeigen, denn dann gilt auch $- \f{\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$, was ein Widerspruch wäre.

		Wegen $\lim_{L\ni l\to\infty} s_l d_l = 0$ existiert eine kompakte Menge, die fast alle $x_l, x_l + s_l d_l$ enthält.
		$\nabla f$ ist auf dieser kompakten Menge gleichmäßig stetig, also
		\[
			\lim_{L\ni l\to\infty} \big\|\nabla f(x_l + s_l d_l) -\nabla f(x_l) \big\| \to 0.
		\]
	\end{proof}
\end{st}


\section{Das Newton-Verfahren}


In diesem Abschnittt sei $f: \R^n \to \R$ stets zweimal stetig differenzierbar.
Wenn $\hat x$ Minimum von $f$ ist, dann auch Nullstelle von $F := \nabla f : \R^n \to \R^n$.
Wir verfolgen jetzt die Idee, das Minimum zu bestimmen, indem wir mit dem Newton-Verfahren die Nullstellle von $F = \nabla f$ finden.

\subsection{Das Newton-Verfahren für Gleichungsysteme}

Sei $F: \R^n \to \R^n$ stetig differenzierbar.
Betrachte das nicht-lineare Gleichungsystem
\[
	F(x) \stack != 0.
\]
Approximiere $F$ durch seine lineare Näherung in der aktuellen Iterierten $x_k$:
\[
	0
	= F(x)
	\approx F(x_k) + F'(x_k)(x-x_k).
\]
Es ergibt sich damit die Iteration
\[
	x_{k+1}
	:= x_k - F'(x_k)^{-1} F(x_k).
\]

\begin{alg}[Newton-Verfahren] \label{alg:5}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\State{$k \gets 0$}
		\While{$F(x_k) \neq 0$}
			\State{$d_k \gets -F'(x_k)^{-1} F(x_k)$}
			\State{$x_{k+1} \gets x_k + d_k$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{nt*}
	Das Newton-Verfahren konvergiert nicht für jeden Startwert, es gibt Beispiele für alternierende Iterierte und für strikte Divergenz.
	% fixme: Beispiele für Nicht-Konvergenz
\end{nt*}

Für $q \in \R, |q| < 1$ gilt
\[
	\sum_{n=0}^\infty = \f 1{1-q}.
\]
Dies lässt sich auch für Matrizen verallgemeinern.

\begin{lem}[Neumannsche Reihe] \label{2.40}
	Für alle $A \in \R^{n\times n}$ mit $\|A\| < 1$ ist $(I-A)$ invertierbar und es konvergiert die \emph{Neumannsche Reihe}
	\[
		\sum_{k=0}^\infty A^k
		= (I-A)^{-1}
	\]
	Insbesondere gilt
	\[
		\|(I-A)^{-1}\|
		\le \f 1{1-\|A\|}.
	\]
	\begin{proof}
		Sei $S_l = \sum_{k=0}^l A^k$.
		Dann gilt für $m \ge l$
		\begin{align*}
			\|S_m - S_l\|
			&= \bigg\| \sum_{k=l+1}^m A^k \bigg\| \\
			&\le \sum_{k=l+1}^m \|A\|^k
			= \|A\|^{l+1} \sum_{k=0}^{m-l-1} \|A\|^k
			\le \f{\|A\|^{l+1}}{1-\|A\|}
			< \eps
		\end{align*}
		für genügend großes $l$.
		Also ist $(S_l)_{l\in\N}$ ein Cauchy-Folge in $\R^{n\times m}$ und der Grenzwert existiert.
		Es gilt
		\[
			(I-A) \sum_{k=0}^\infty A^k
			= \sum_{k=0}^\infty A^k - \sum_{k=0}^\infty A^{k+1}
			= I.
		\]
		Damit ist $(I-A)$ invertierbar mit $(I-A)^{-1} = \sum_{k=0}^\infty A^k$ und
		\[
			\Big\| \sum_{k=0}^\infty A^k \Big\|
			\le \sum_{k=0}^\infty \|A\|^k
			= \f 1{1-\|A\|}.
		\]
	\end{proof}
\end{lem}

\begin{lem}[Lemma von Banach] \label{2.41}
	Sei $A \in \R^{n\times n}$ invertierbar und $B \in \R^{n\times n}$ erfülle $\|A^{-1} B\| < 1$.
	Dann ist $A + B$ invertierbar und es gilt
	\begin{align*}
		\|(A + B)^{-1}\|\
		&\le \f {\|A^{-1}\|}{1-\|A^{-1}B\|} \\
		\|(A+B)^{-1} - A^{-1}\|
		&\le \f {\|A^{-1}\|\|A^{-1}B\|}{1-\|A^{-1}B\|}
	\end{align*}
	\begin{proof}
		Wende \ref{2.40} auf $-A^{-1}B$ an, also ist $I + A^{-1}B$ invertierbar und
		\[
			A + B
			= A(I + A^{-1}B)
		\]
		als Produkt invertierbarer Matrizen auch invertierbar.
		Außerdem ist
		\[
			\|(A+B)^{-1}\|
			\le \|A^{-1}\| \|(I+A^{-1}B)^{-1}\|
			\stack{\ref{2.40}}\le \f {\|A^{-1}\|}{1-\|A^{-1}B\|}
		\]
		und
		\begin{align*}
			(A+B)^{-1} - A^{-1}
			&= (I + A^{-1}B)^{-1}A^{-1} - A^{-1} \\
			&= (I + A^{-1}B)^{-1} - I) A^{-1} \\
			&= \bigg(\sum_{k=0}^\infty (-A^{-1}B)^k - I\bigg) A^{-1} \\
			&= \sum_{k=1}^\infty (-A^{-1}B)^k A^{-1} \\
			&= (-A^{-1}B) \sum_{k=0}^\infty (-A^{-1}B)^k A^{-1} \\
			&= (-A^{-1}B) (I + A^{-1}B)^{-1} A^{-1},
		\end{align*}
		also in der Norm
		\[
			\|(A+B)^{-1} - A^{-1}\|
			\le \f {\|A^{-1}\| \|A^{-1}B\|}{1-\|A^{-1}B\|}.
		\]
	\end{proof}
\end{lem}

\begin{kor} \label{2.42}
	Aus \ref{2.41} folgt, dass jedes invertierbare $A \in \R^{n\times n}$ eine Umgebung invertierbarer Matrizen
	\[
		\scr U_\delta
		:= \Set{ \tilde A \in \R^{n\times n} | \|\tilde A - A\| < \delta }
	\]
	besitzt, wobei z.B. $\delta := \f 1{\|A\|^{-1}}$.
	Außerdem gilt für jede konvergente Folge $(A_k)_{k\in\N} \to A$ invertierbarer Matrizen mit invertierbarem Grenzwert $A$, auch
	\[
		A_k^{-1} \to A^{-1}
	\]
	für $k \to \infty$.
	Die Menge der invertierbaren Matrizen ist also offen und die Inversion eine stetige Abbildung auf dieser Menge.
\end{kor}

\begin{lem} \label{2.43}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $\hat x$ sei eine Nullstelle von $F$ mit invertierbarer Jacobi-Matrix $F'(\hat x)$.
	Dann existieren $\delta, \gamma > 0$, mit
	\[
		\|F(x)\|
		\ge \gamma \|x-\hat x\|
	\]
	für alle $x \in B_\delta(\hat x)$.
	Insbesondere ist $\hat x$ die einzige Nullstelle von $F$ in $B_\delta(\hat x)$.
	\begin{proof}
		Es gilt
		\[
			\|x-\hat x\| \le \|F'(\hat x)^{-1}\| \|F'(\hat x)(x-\hat x)\|,
		\]
		also gilt für $\gamma := \f 1{2\|F'(\hat x)^{-1}\|}$
		\[
			\|F'(\hat x)(x-\hat x)\|
			\ge 2\gamma \|x - \hat x\|.
		\]
		Für hinreichend nah an $\hat x$ liegende $x$ liefert die Taylorapproximation eine Approximation mit
		\[
			\|F(x) - \underbrace{F(\hat x)}_{=0} - F'(\hat x)(x-\hat x) \|
			\le \gamma \|x-\hat x\|,
		\]
		also
		\begin{align*}
			2\gamma \|x-\hat x\|
			\le \|F'(\hat x)(x-\hat x)\|
			&\le \|F(x) - F'(\hat x)(x-\hat x) \| + \|F(x)\| \\
			&\le \gamma \|x-\hat x\| + \| F(x) \|.
		\end{align*}
		und somit $\|F(x)\| \ge \gamma \|x - \hat x\|$.
	\end{proof}
\end{lem}

\begin{df} \label{2.44}
	Eine Folge $(x_k)_{k\in\N} \subset \R^n$ konvergiert
	\begin{enumerate}[(a)]
		\item
			\emph{linear} mit Rate $0 < \gamma < 1$ gegen $x \in \R^n$, falls
			\[
				\|x_{k+1} - x\| \le \gamma \|x_k - x\|
			\]
			für fast alle $k \in \N$.
		\item
			\emph{superlinear} gegen $x \in \R^n$, falls $x_k \to x$ und
			\[
				x_{k+1} - x
				= o(x_k - x),
			\]
			d.h.
			\[
				\lim_{k\to\infty} \f {\|x_{k+1}-x\|}{\|x_k - x\|} \to 0.
			\]
		\item
			\emph{quadratisch} gegen $x\in \R^n$, falls $x_k \to x$ und
			\[
				x_{k+1} - x
				= \landauO (\|x_k - x\|^2),
			\]
			d.h.
			\[
				\exists C > 0 \forall k\in \N : \|x_{k+1} - x \| \le C \|x_k - x\|^2.
			\]
	\end{enumerate}
\end{df}

\begin{nt} \label{2.45}
	Bei linearer Konvergenz wächst die Anzahl der richtigen Nachkommastellen pro Schritt um eine konstante Anzahl.
	Bei quadratischer Konvergenz verdoppelt sich die Anzahl der richtigen Nachkommastellen pro Schritt.
\end{nt}

\coursetimestamp{20}{11}{2013}

\begin{st}[Lokale Konvergenz des Newton-Verfahrens für Gleichungssysteme] \label{2.46}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $\hat x$ sei Nullstelle von $F$ mit invertierbarer $F'(\hat x) \in \R^{n\times n}$.
	Dann existieren $\delta, C > 0$ so dass
	\begin{enumerate}[(a)]
		\item
			$\hat x$ ist die einzige Nullstelle von $F$ auf $B_\delta(\hat x)$,
		\item
			$F'(x)$ ist invertierbar und $\|F'(x)^{-1}\| \le C$ für alle $x \in B_\delta(\hat x)$.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ liegen alle von \ref{alg:5} erzeugten Iterierten in $B_\delta(\hat x)$.
			Insbesondere ist \ref{alg:5} durchführbar.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ terminiert \ref{alg:5} entweder nach endlich vielen Schritten an $\hat x$ oder erzeugt eine Folge $(x_k)_{k\in\N}$, die superlinear gegen $\hat x$ konvergiert.
		\item
			Ist $F'$ zusätlich in $B_\delta(\hat x)$ Lipschitz-stetig mit Lipschitz-Konstante $L$, d.h.
			\[
				\forall x,y \in B_\delta(\hat x) : \|F'(x) - F'(y)\| \le L \|x-y\|,
			\]
			dann ist die Konvergenz in (d) sogar quadratisch und es gilt
			\[
				\|x_{k+1} - \hat x \| \le \f {CL}2 \|x_k - \hat x\|^2
			\]
			für alle $k \in \N$
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Dies ist gerade \ref{2.43}.
			\item
				Folgt aus \ref{2.42} und Stetigkeit von $F'^{-1}$.
			\item[(c), (d)]
				Für jedes $x_k$ in dem $F'(x_k)$ invertierbar ist, gilt
				\begin{align*}
					x_{k+1} - \hat x
					&= x_k - F'(x_k)^{-1}F(x_k) - \hat x \\
					&= F'(x_k)^{-1}\Big( F'(x_k) (x_k-\hat x) - F(x_k) + F(\hat x) \Big) \\
					&= F'(x_k)^{-1}\bigg( F'(x_k) (x_k-\hat x) \\
					& \qquad\qquad\qquad\qquad - \int_0^1 F'(\hat x + t(x_k-\hat x))(x_k - \hat x) \dx[t] \bigg) \\
					&=F'(x_k)^{-1}\int_0^1 \Big( F'(x_k) - F'\big(\hat x + t(x_k - \hat x)\big) \Big)(x_k - \hat x) \dx[t],
				\end{align*}
				also
				\begin{align*}
					&\|x_{k+1} - \hat x\| \\
					&\quad \le \|x_k-\hat x\|\underbrace{\|F'(x_k)^{-1}\|}_{=:C} \underbrace{\sup_{t\in [0,1]} \Big\| F'(x_k) - F'(\hat x + t(x_k-\hat x)) \Big\|}_{\to 0 (x_k \to \hat x)}.
				\end{align*}
				Sei $\delta$ hinreichend klein (siehe (a) und (b)), dass für $x_k \in B_\delta(\hat x)$ gilt
				\[
					\sup_{t\in[0,1]} \|F'(x_k) - F'(\hat x + t(x_k - \hat x))\|
					\le \f 1{2C}.
				\]
				Es folgt für alle $x_k \in B_\delta(\hat x)$
				\[
					\|x_{k+1} - \hat x\| \le \f 12 \| x_k - \hat x\|
				\]
				und damit insbesondere für $x_0 \in B_\delta(\hat x)$ auch $x_k \in B_\delta(\hat x)$ für alle $k \in \N$ und $x_k \to \hat x$.

				Es gilt sogar
				\[
					\f {\|x_{k+1} - \hat x\|}{\|x_k - \hat x\|} \le C \sup_{t\in [0,1]} \| F'(x_k) - F'(\hat x  + t(x_k + \hat x)) \| \to 0.
				\]
			\item[(e)]
				Für (auf $B_\delta(\hat x)$) Lipschitz-stetige $F'$ erhalten wir sogar
				\begin{align*}
					\|x_{k+1} - \hat x\|
					&\le C \|x_k - \hat x\| \int_0^1 L \| \underbrace{x_k - (\hat x + t(x_k - \hat x))}_{=(1-t)x_k -(1-t)\hat x} \| \dx[t] \\
					&\le C \|x_k - \hat x\|^2 L \int_0^1 1-t \dx[t]
					= \f {CL}2 \|x_k - \hat x\|^2.
				\end{align*}
		\end{enumerate}
	\end{proof}
\end{st}

\subsection{Das Newton-Verfahren für Optimierungsprobleme}

Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
Wir wenden das Newton-Verfahren auf das Nullstellenproblem
\[
	F(x) := \nabla f(x) = 0
\]
an.
Offenbar ist $F'(x) = \nabla^2 f(x)$ die Hesse-Matrix von $f$ und es ergibt sich folgender Algorithmus

\begin{alg}[Newton-Verfahren für Optimierungsprobleme] \label{alg:6}
	\begin{algorithmic}
		\Require{Startwert $x_0$}
		\State{$k \gets 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\State{$d_k \gets -\big(\nabla^2 f(x_k)\big)^{-1} \nabla f(x_k)$}
			\State{$x_{k+1} \gets x_k + d_k$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{lem} \label{2.47}
	Für alle symmetrische Matrizen $A, B \in \R^{n\times n}$ gilt
	\[
		\lambda_{\text{min}}(A + B) \ge \lambda_{\text{min}}(A) - \|B\|.
	\]
	Insbesondere besitzt jede symmetrische, positiv definite Matrix eine Umgebung in $\R^{n\times n}$, in der alle symmetrischen Matrizen positiv definit sind.
	\begin{proof}
		Es gilt
		\[
			\f {x^T A x}{\|x\|^2}
			= \f {x^T (A+B) x}{\|x\|^2} - \f {x^T B x}{\|x\|^2}
			\le \f {x^T (A+B) x}{\|x\|^2} + \max_{x\in\R^n} \f {|x^T B x|}{\|x\|^2}
			\le \f {x^T (A+B) x}{\|x\|^2} + \|B\|.
		\]
		Also
		\[
			\lambda_{\text{min}}(A+B)
			\stack{\ref{2.6}}= \min_{x\in \R^n} \f {x^T(A+B)x}{\|x\|^2}
			\ge \min_{x\in\R^n} \Big( \f {x^T A x}{\|x\|^2} - \|B\| \Big)
			= \lambda_{\text{min}}(A) - \|B\|.
		\]
	\end{proof}
\end{lem}

\begin{st}[Lokale Konvergenz des Newton-Verfahrens für Optimierungsprobleme] \label{2.48}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar und $\hat x$ ein lokales Minimum von $f$ mit positiv definiter Hesse-Matrix $\nabla^2 f(\hat x)$.
	Dann existieren $\delta, \my > 0$ so dass
	\begin{enumerate}[(a)]
		\item
			$\hat x$ ist der einzige stationäre Punkt auf $B_\delta(\hat x)$,
		\item
			$\lambda_{\text{min}}(\nabla^2 f(x)) \ge \my$ für alle $x \in B_\delta(\hat x)$, insbesondere ist $\nabla^2(f(x))$ invertierbar und $\|\nabla^2 f(x)^{-1}\| \le \f 1\my$.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ liegen alle durch \ref{alg:6} erzeugten Iterierten in $B_\delta(\hat x)$.
			Insbesondere ist \ref{alg:6} durchführbar.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ terminiert \ref{alg:6} entweder an $\hat x$ oder erzeugt eine Folge $(x_k)_{k\in\N}$, die superlinear gegen $\hat x$ konvergiert.
		\item
			Ist $\nabla^2 f$ zusätzlich Lipschitz-stetig in $B_\delta(\hat x)$, d.h.
			\[
				\forall x,y \in B_\delta(\hat x) : \| \nabla^2 f(x) - \nabla^2 f(y) \|
				\le L \|x-y\|,
			\]
			dann ist die Konvergenz sogar quadratisch durch
			\[
				\|x_{k+1} - \hat x\| \le \f {L}{2\my} \|x_k - \hat x\|^2
			\]
			gegeben.
	\end{enumerate}
	\begin{proof}
		Für jedes $0 < \my < \lambda_{\text{min}}(\nabla^2 f(\hat x))$ folgt aus \ref{2.47}, dass ein $\delta > 0$ existiert mit $\lambda_{\text{min}}(\nabla^2 f(x)) \ge \my$ für alle $x \in B_\delta(\hat x)$.

		Der Rest funktioniert wie im Beweis von \ref{2.46}.
	\end{proof}
\end{st}

\begin{ex} \label{2.49}
	Betrachte $f: \R \to \R, f(x) = \sqrt{x^2 + 1}$.
	Offenbar ist $\hat x=0$ das einzige Minimum von $f$.
	$f$ erfüllt die Voraussetzungen von \ref{2.48}, denn
	\begin{align*}
		\nabla f(x) &= \f {x}{\sqrt{x^2 + 1}} \\
		\nabla^2 f(x) &= \f {1}{(x^2 + 1)^{\f 32}}.
	\end{align*}
	Die Newton-Iteration ergibt sich dann als
	\begin{align*}
		x_{k+1}
		&= x_k - (\nabla^2 f(x_k))^{-1} \nabla f(x_k) \\
		&= x_k - (x_k^2 + 1)^{\f 32} \f {x_k}{\sqrt{x_k^2 + 1}} \\
		&= - x_k^3.
	\end{align*}
	Konvergenz findet sich also nur lokal für $|x_0| < 1$.
\end{ex}

\begin{nt} \label{2.50}
	Eine Alternative Motivation des Newton-Verfahrens für Optimierungsprobleme wäre, $f(x)$ durch die quadratische Näherung in $x_k$
	\[
		f(x) \approx
		f(x_k) + \nabla f(x_k)^T (x-x_k) + \f 12 (x-x_k)^T \nabla^2 f(x_k) (x-x_k)
	\]
	zu ersetzen.
	Das Minimum dieser quadratischen Näherung liegt in (siehe Übungen) % fixme: ref
	\[
		x = x_k - \nabla^2 f(x_k)^{-1} \nabla f(x_k).
	\]
	Dies führt wieder auf die Newton-Iteration.
\end{nt}

\subsection{Newton-artige Verfahren}

Das Newton-Verfahren hat gewisse Nachteile (z.B. gegenüber dem Gradienten-Verfahren)
\begin{itemize}
	\item
		Nur lokale Konvergenz,
	\item
		Hessematrix wird benötigt,
	\item
		benötigt LGS-Lösung mit $\nabla^2 f(x_k)$.
\end{itemize}
Trotzdem hat das Newton-Verfahren Vorteile, die es nützlich machen
\begin{itemize}
	\item
		superlineare Konvergenz (dies rechtfertig asymptotisch jeden $N$-fachen Aufwand (für beliebig großes, festes $N$) gegenüber einem linear-konvergenten Verfahren)
\end{itemize}
Mit $d_k := - \nabla^2 f(x_k)^{-1} \nabla f(x_k)$ wird nur eine Approximation $x_{k+1}$ an das Optimum berechnet.
Es ist also vielleicht nicht nötig, $d_k$ exakt zu berechnen.
Dies liefert die Motivation für zwei Verfahren
\begin{itemize}
	\item
		Inexakte Newton-Verfahren:
		$d_k$ wird nur näherungsweie z.B. durch Anwendung einiger Schritte eines iterativen Verfahrens auf das lineare Gleichungsystem $\nabla^2 f(x_k) d_k = - \nabla f(x_k)$ bestimmt.
	\item
		Newton-artige Verfahren:
		Ersetze $\nabla^2 f(x_k)$ durch invertierbare Matrix $H_k \in \R^{n\times n}$ (die einfacher zu berechenen oder einfacher zu invertieren ist) und wähle $d_k$ stattdessen als Lösung von $H_k d_k = - \nabla f(x_k)$.
\end{itemize}

\begin{lem} \label{2.51}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $K \subset \R^n$ kompakt und konvex.

	Dann ist $F$ auf $K$ Lipschitz-stetig mit $L := \max_{x\in K} \|F'(x)\|$, also
	\[
		\|F(y) - F(x)\|
		\le L \|y-x\|
	\]
	für alle $x,y \in K$.
	\begin{proof}
		Nach dem Mittelwertsatz \ref{2.4} gilt
		\begin{align*}
			\|F(y) - F(x)\|
			&= \Big\| \int_0^1 F'\big(x + t(y-x)\big) \dx[t] (y-x) \Big\| \\
			&\le \max_{x\in K} \|F'(x)\| \|y-x\|.
		\end{align*}
	\end{proof}
\end{lem}

\begin{st}[Dennis-Moré-Bedingungen] \label{2.52}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar und $\hat x \in \R^n$ besitze eine invertierbare Hessematrix $\nabla^2 f(\hat x)$.
	Sei $(x_k)_{k\in\N}$ eine Folge in $\R^n$ mit $x_k \neq \hat x$ für alle $k \in \N$ und $x_k \to \hat x$.

	Dann sind folgende Aussagen äquivalent:
	\begin{enumerate}[(a)]
		\item
			$(x_k)$ konvergiert superlinear gegen $\hat x$  und $\hat x$ ist stationärer Punkt.
		\item
			$\nabla f(x_{k+1}) = o(x_{k+1} - x_k)$
		\item
			$\nabla f(x_k) + \nabla^2 f(\hat x)(x_{k+1} - x_k) = o(x_{k+1} - x_k)$
		\item
			$\nabla f(x_k) + \nabla^2 f(x_{k+1})(x_{k+1} - x_k) = o(x_{k+1} - x_k)$
	\end{enumerate}
	\begin{proof}
		\begin{segnb}[„(a)$\implies$(b)“]
			$(x_k)_{k\in\N}$ konvergiere superlinear, d.h. $\|x_{k+1} - \hat x\| \le \f 12 \|x_k - \hat x\|$ für hinreichend große $k \in \N$.
			Es gilt
			\begin{align*}
				\|x_k - \hat x\|
				&\le \|x_{k+1} - x_k\| + \|x_{k+1} - \hat x\| \\
				&\le \|x_{k+1} - x_k\| + \f 12 \|x_k - \hat x\|
			\end{align*}
			und damit
			\[
				\|x_k - \hat x\|
				\le 2 \|x_{k+1} - x_k\|
			\]
			für hinreichend große $k$.

			Da $(x_k)_{k\in\N}$ beschränkt ist, existiert eine abgeschlossene Kugel $K$ mit $x_k, \hat x \in K$ für alle $k \in \N$.
			Nach \ref{2.51} existiert $L > 0$ mit
			\begin{align*}
				\|\nabla f(x_{k+1}) \|
				&= \| \nabla f(x_{k+1}) - \nabla f(\hat x) \| \\
				&\le L \|x_{k+1} - \hat x\|
				= o(x_k - \hat x)
				= o(x_{k+1} - x_k)
			\end{align*}
		\end{segnb}
		\begin{segnb}[„(b)$\implies$(a)“]
			Sei $\nabla f(x_{k+1}) = o(x_{k+1} - x_k)$, d.h.
			\[
				\eps_k := \f {\|\nabla f(x_{k+1})\|}{\|x_{k+1} - x_k\|}
				\to 0.
			\]
			Insbesondere $\nabla f(\hat x) = \lim_{x_k \to \hat x} \nabla f(x_k) = 0$.
			$\nabla^2 f(\hat x)$ ist invertierbar, also existiert nach \ref{2.43} $\gamma > 0$ mit
			\[
				\|\nabla f(x_{k+1}) \|
				\ge \gamma \|x_{k+1} - \hat x\|
			\]
			für hinreichend große $k$.
			Es gilt
			\begin{align*}
				\|x_{k+1} - \hat x\|
				&\le \f 1\gamma \|\nabla f(x_{k+1})\| \\
				&= \f {\eps_k}{\gamma} \|x_{k+1} - x_k\| \\
				&\le \f{\eps_k}{\gamma} \|x_{k+1} - \hat x\| + \f{\eps_k}{\gamma} \|x_k - \hat x\|
			\end{align*}
			Für hinreichend große $k \in \N$ ist $\f {\eps_k}{\gamma} < \f 12$ und damit
			\[
				\|x_{k+1} - \hat x\|
				\le 2 \f {\eps_k}{\gamma} \|x_k - \hat x\|
				= o(x_k - \hat x).
			\]
		\end{segnb}
		\begin{segnb}[„(b)$\iff$(c)“]
			Der Mittelwertsatz \ref{2.4} für $F(x) := \nabla f(x)$ liefert
			\begin{align*}
				&\nabla f(x_{k+1}) \\
				&\quad= \nabla f(x_k) + \int_0^1 \nabla^2 f(x_k + t(x_{k+1} - x_k)) (x_{k+1} - x_k) \dx[t] \\
				&\quad= \nabla f(x_k) \\
					&\qquad + \int_0^1 \Big(\nabla^2 f\big(x_k + t(x_{k+1} - x_k)\big) - \nabla^2 f(\hat x) \Big) \dx[t] (x_{k+1} - x_k) \\
					&\qquad + \nabla^2 f(\hat x) (x_{k+1} - x_k)
			\end{align*}
			$\nabla^2 f$ ist stetig, also $\nabla^2 f$ gleichmäßig stetig auf einer kompakten Menge $K$ mit $x_k, \hat x \in K$ und somit wegen $x_n \to \hat x$
			\[
				\int_0^1 \Big( \nabla^2 f(x_k + t(x_{k+1} - x_k)) - \nabla^2 f(\hat x) \Big) \dx[t] \to 0.
			\]
			Also gilt
			\[
				\nabla f(x_{k+1})
				= \nabla f(x_k) + \nabla^2 f(\hat x) (x_{k+1} - x_k) + o(x_{k+1} - x_k)
			\]
			Hieran lässt sich die Äquivalenz ablesen.
		\end{segnb}
		\begin{segnb}[„(c)$\iff$(d)“]
			Wegen $\nabla^2 f(x_k) \to \nabla^2 f(\hat x)$ ist
			\[
				\nabla f(x_k) + \underbrace{\nabla^2 f(\hat x) (x_{k+1} - x_k)}_{=\nabla^2 f(x_k)(x_{k+1} - x_k) + o(x_{k+1} - x_k)}
				= o(x_{k+1} - x_k)
			\]
			äquivalent zu
			\[
				\nabla f(x_k) + \nabla^2 f(x_k) (x_{k+1} - x_k) = o(x_{k+1} - x_k).
			\]
		\end{segnb}
	\end{proof}
\end{st}

\begin{st} \label{2.53}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
	$(x_k)_{k\in\N}$ sei erzeugt durch $x_{k+1} := x_{k} + d_k$ und konvergiere gegen $\hat x \in \R^n$ mit positiv definiter Hessematrix $\nabla^2 f(\hat x)$.
	Außerdem gelte $x_k \neq \hat x$ für alle $k \in \N$.

	Dann gelten folgende Aussagen
	\begin{enumerate}[(a)]
		\item
			Newton-Verfahren:
			Sind die $d_k$ exakte Lösungen von
			\[
				\nabla^2 f(x_k) d_k = - \nabla f(x_k),
			\]
			dann ist $\hat x$ ein Minimum von $f$ und $(x_k)_{k\in\N}$ konvergiert superlinear gegen $\hat x$ (sogar quadratisch, falls $\nabla^2 f$ lokal Lipschitz-stetig).
		\item
			Inexakte Newton-Verfahren:
			Sind die $d_k$ approximative Lösungen von
			\[
				\nabla^2 f(x_k) d_k = - \nabla f(x_k),
			\]
			die
			\[
				\|\nabla f(x_k) + \nabla^2 f(x_k) d_k\| = \eta_k \|\nabla f(x_k)\|
			\]
			mit einer Nullfolge $(\eta_k)_{k\in\N}$ erfüllen, so ist $\hat x$ ein Minimum und $x_k \to \hat x$ konvergiert superlinear.
		\item
			Newton-artige Verfahren:
			Sind die $d_k$ Lösungen von
			\[
				H_k d_k = - \nabla f(x_k)
			\]
			mit $H_k \in \R^{n\times n}$ invertierbar und $H_k \to \nabla^2 f(\hat x)$, dann ist $\hat x$ Minimum und die Konvergenz ist superlinear.
	\end{enumerate}
\coursetimestamp{27}{11}{2013}
	\begin{proof}
		Teil (a) ist klar nach \ref{2.52} (d), quadratische nach \ref{2.48}.
		\begin{enumerate}[(a)]
			\item[(c)]
				Es gilt
				\begin{align*}
					- \nabla f(x_k) - \nabla^2 f(\hat x) (x_{k+1} - x_k)
					&= \underbrace{\big(H_k - \nabla^2 f(\hat x)\big)}_{\to 0} (x_{k+1} - x_k) \\
					&= o(x_{k+1} - x_k).
				\end{align*}
				Nach \ref{2.52} (c) ist $\hat x$ Minimum und die Folge konvergiert superlinear.
			\item[(b)]
				$d_k = x_{k+1} - x_k$ erfülle $\|\nabla f(x_k) + \nabla^2 f(x_k) d_k\| = \eta_k \|\nabla f(x_k)\|$ mit einer Nullfolge $(\eta_k)_{k\in\N}$.
				Dann gilt
				\begin{align*}
					\|\nabla f(x_k)\|
					&\le \|\nabla f(x_k) + \nabla^2 f(x_k) (x_{k+1} - x_k)\| \\
					&\qquad + \| \nabla^2 f(x_k){x_{k+1} - x_k} \| \\
					&= \eta_k \|\nabla f(x_k)\| + \| \nabla^2 f(x_k) d_k \|,
				\end{align*}
				also
				\[
					\|\nabla f(x_k) \|
					\le \f 1{1 - \eta_k} \|\nabla^2 f(x_k) d_k\|
				\]
				und somit
				\begin{align*}
					\|\nabla f(x_k) + \nabla^2 f(x_k) d_k \|
					&\le \eta_k \|\nabla f(x_k)\| \\
					&\le \f {\eta_k}{1-\eta_k} \underbrace{\|\nabla^2 f(x_k)\|}_{\le \const}\|x_{k+1} - x_k\| \\
					&= o(x_{k+1} - x_k).
				\end{align*}
				Nach \ref{2.52} (d) ist $\hat x$ Minimum und die Folge konvergiert superlinear.
		\end{enumerate}
	\end{proof}
\end{st}

\subsection{Quasi-Newton-Verfahren}

\paragraph{Motivation:}

Betrachte das Newton-Verfahren für eindimensionale Nullstellenprobleme, d.h
\[
	F: \R \to \R, F(\hat x) \stack != 0.
\]
Die Iteration lautet dann
\[
	x_{k+1} := x_k - F'(x_k)^{-1} F(x_k).
\]
Approximiere $F'(x_k)$ durch die Sekantensteigung der aktuellen Iterierten zur vorigen:
\[
	F'(x_k) \approx \dfrac {F(x_k) - F(x_{k-1})}{x_k - x_{k-1}} =: H_k.
\]
Konvergiert die Iteriertenfolge werden also auch unsere Approximationen an $F'(x_k)$ immer besser.
Es ergibt sich die Iteration
\[
	x_{k+1} = x_k - \bigg(\dfrac{F(x_k) - F(x_{k-1})}{x_k - x_{k-1}} \bigg)^{-1} F(x_k),
\]
das sogenannte \emph{Sekantenverfahren}.

Für Optimierungsprobleme approximiere analog
\[
	f''(x_k) \approx \f {f'(x_k) - f'(x_{k-1})}{x_k - x_{k-1}} =: H_k
\]
und iteriere $x_{k+1} := x_k - H_k^{-1} f'(x_k)$.

Im eindimensionalen ist $H_k$ eindeutige, skalare Lösung von
\[
	f'(x_k) - f'(x_{k-1})
	= H_k (x_k - x_{k-1}).
\]
Das Analogon in $\R^n$ wäre die Bedingung
\[
	\nabla f(x_k) - \nabla f(x_{k-1})
	= H_k (x_k -x_{k-1})
\]
zu fordern.
Das führt auf die folgende Definition.

\begin{df*}[Quasi-Newton-Verfahren]
	Ein Newton-artiges Verfahren, bei dem $H_k$ in jeder Iteration die \emph{Quasi-Newton-Bedingung}
	\begin{equation} \label{eq:qn}
		\nabla f(x_k) - \nabla f(x_{k-1})
		= H_k (x_k -x_{k-1})
		\tag{QN}
	\end{equation}
	erfüllt, heißt \emph{Quasi-Newton-Verfahren}.
\end{df*}

\begin{nt} \label{2.54}
	\begin{enumerate}[(a)]
		\item
			$H_k := \nabla^2 f(x_k)$ erfüllt \eqref{eq:qn} im Allgemeinen nicht
		\item
			Es gilt
			\[
				\nabla f(x_k) - \nabla f(x_{k-1})
				= \underbrace{\int_0^1 \nabla^2 f(x_{k-1} + t (x_k - x_{k-1})) \dx[t]}_{= H_k} (x_k - x_{k-1}).
			\]
			Mit diesem $H_k$ ergäbe sich in jedem Fall ein Quasi-Newton-Verfahren, wenn auch mit sehr aufwändig zu berechnendem $H_k$.
		\item
			Es gilt
			\begin{align*}
				\nabla f(x_{k+1})
				&= \underbrace{\nabla f(x_k)}_{=H_k(x_k - x_{k+1})} + \underbrace{( \nabla f(x_{k+1}) - \nabla f(x_k) )}_{=H_{k+1} (x_{k+1} - x_k)} \\
				&= (H_{k+1} - H_k)(x_{k+1} - x_k).
			\end{align*}
			Nach \ref{2.52} (b) konvergiert das Quasi-Newton-Verfahren unter der Voraussetzung $x_k \to \hat x$ also bereits dann superlinear, wenn $H_k - H_{k-1} \to 0$.
	\end{enumerate}
\end{nt}

Dementsprechend liegt es nahe, $H_{k+1}$ so zu wählen, dass sie sich möglichst wenig von $H_k$ unterscheidet, \eqref{eq:qn} erfüllt und möglichst leicht zu invertieren ist.

Dies motiviert das Prinzip der \emph{Aufdatierung}, welches uns $H_{k+1}$ durch kleine Änderung von $H_k$ liefert.

\subsubsection{Rang 1 Modifikationen}

Sei $e_k \in \R^n$ der $k$-te Einheitsvektor, dann ist
\[
	e_j e_k^T = \big( \delta_{ij}\delta_{lk} \big)_{i,l = 1, \dotsc, n}.
\]
Für $A \in \R^{n\times n}$ ist $A + e_j e_k^T$ die im $(j,k)$-ten Eintrag abgeänderte Matrix.
Genauso ergibt sich $A + uv^T$ (sofern die Matrix in einer Basis gegeben ist, die $v$ und $w$ enthält) durch Abänderung eines Eintrags aus $A$.

Für Newton-artige Verfahren müssen wir im $k$-ten Schritt $H_k$ invertieren, also müssen wir sicherstellen, dass durch Aufdatierung die Matrix invertierbar bleibt.
Das folgende Lemma liefert die Aussage für Aufdatierungen der Form $A + uv^T$.

\begin{lem}[Sherman-Morrison-Woodberry-Formel] \label{2.55}
	Sei $A \in \R^n$ invertierbar und $u, v \in \R^n \setminus \{0\}$.
	$A + uv^T \in \R^{n\times n}$ ist genau dann invertierbar, wenn $1 + v^T A^{-1} u \neq 0$.
	In diesem Fall ist die Inverse explizit gegeben durch
	\[
		\big(A + uv^T\big)^{-1} = A^{-1} - \dfrac {A^{-1} u v^T A^{-1}}{1 + v^T A^{-1} u}.
	\]
	\begin{proof}
		Ist $1 + v^T A^{-1} u \neq 0$, dann ist
		\[
			(A + uv^T)(A^{-1} - \f {A^{-1} uv^T A^{-1}}{1 + v^T A^{-1} u} ) = I.
		\]
		Ist $1 + v^T A^{-1} u = 0$, dann ist
		\begin{align*}
			(A + uv^T) A^{-1} uv^Tv
			&= uv^Tv + uv^TA^{-1} uv^Tv \\
			&= u \underbrace{(1 + v^TA^{-1}u)}_{=0} (v^Tv)
			= 0
		\end{align*}
		und $A^{-1} uv^Tv = \|v\|^2 A^{-1} u \neq 0$, also $\dim \ker (A + uv^T) > 0$ und somit $A$ nicht invertierbar.
	\end{proof}
\end{lem}

Das einfachste Quasi-Newton-Verfahren wäre damit
\[
	H_{k+1} := H_k + \gamma_k u_k u_k^T,
\]
wobei $\gamma_k \in \R, u_k \in \R^n \setminus \{0\}$ so zu bestimmen sind, dass $H_{k+1}$ \eqref{eq:qn} erfüllt.

Sei $y_k := \nabla f(x_{k+1}) - \nabla f(x_k)$.
Wenn wir $(y_k - H_k d_k)^T d_k \neq 0$ voraussetzen, dann ergibt sich (siehe \coursehref{Blatt8.pdf}{Übungsaufgabe 8.1}) die eindeutige Aufdatierungsformel
\[
	H_{k+1} := H_k + \dfrac{(y_k - H_k d_k)(y_k - H_k d_k)^T}{(y_k - H_k d_k)^T d_k}.
\]
Diese Aufdatierung nennen wir \emph{symmetrische Rang-1-Modifikation}, oder kurz \emph{SR1-Aufdatierung}.

%fixme: something missing?

\coursetimestamp{02}{12}{2013}

Quasi-Newton-Verfahren benötigen keine Hesse-Matrizen mehr und keine LGS-Lösung.

\subsubsection{Broyden-Fletcher-Goldfarb-Shanno-Formel (BFGS)}

\[
	H_{k+1} := H_k + \dfrac {y_ky_k^T}{y_k^T d_k} - \dfrac {H_k d_k d_k^T H_k^T}{d_k^T H_k d_k}.
\]
$H_k$ erfüllt \eqref{eq:qn} nach \coursehref{Blatt9.pdf}{Übungsaufgabe 8.1} und es gilt mit \coursehref{Blatt9.pdf}{Übungsaufgabe 8.2 c)}
\begin{align*}
	B_{k+1} &:= H_{k+1}^{-1} \\
	&= B_k + \dfrac {(d_k-B_ky_k)d_k^T + d_k(d_k-B_ky_k)^T}{d_k^T y_k} - \dfrac {(d_k-B_ky_k)^T y_k}{(d_k^T y_k)^2} d_k d_k^T.
\end{align*}

\begin{alg} \label{alg:7}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{symmetrisch, positiv definite Startmatrix $B_0 \in \R^{n\times n}$}
		\State{$k \gets 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\State{$d_k \gets - B_k \nabla f(x)$}
			\State{$x_{k+1} \gets x_k + d_k$}
			\State{$B_{k+1} \gets B_k + \f {(d_k-B_ky_k)d_k^T + d_k(d_k-B_ky_k)^T}{d_k^T y_k} - \f {(d_k-B_ky_k)^T y_k}{(d_k^T y_k)^2} d_k d_k^T$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{st} \label{2.56}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar, $\nabla^2 f$ lokal Lipschitz-stetig und $\hat x$ ein lokales Minimum von $f$ mit positiv definitem $\nabla^2 f(\hat x)$.

	Dann existiert $\delta, \eps > 0$ so dass für
	\begin{enumerate}[(a)]
		\item
			jeden Startwert $x_0 \in B_\delta(\hat x)$
		\item
			jede symmetrische, positiv definite Startmatrix $B_0$ mit $\|B_0 - \nabla^2 f(\hat x)^{-1}\| < \eps$
	\end{enumerate}
	\ref{alg:7} durchführbar ist und entweder nach endlich vielen Schritten $x_k = \hat x$ liefert oder eine Folge $(x_k)_{k\in \N}$, die superlinear gegen $\hat x$ konvergiert.
	\begin{proof}
		siehe \cite[Satz 11.33]{geigerkanzow99}.
	\end{proof}
\end{st}

\subsection{Das globalisierte Newton-Verfahren}

\begin{itemize}
	\item
		Das Gradientenverfahren konvergiert global (gegen ein lokales Minimum), aber „langsam“ (linear).
	\item
		Das Newtonverfahren und seine Derivate konvergieren nur lokal, aber „schnell“ (superlinear).
\end{itemize}
Wünschenswert wäre ein Verfahren, das global und schnell konvergiert.
Eine Herangehensweise wäre, das Gradientenverfahren so lange anzuwenden, bis man nah genug am Minimum ist, um dann das lokale Newton-Verfahren anzuwenden.

Wie finden wir die Iterierte, ab der wir das Newton-Verfahren starten sollen?
Prüfe, ob ein Newton-Schritt die Voraussetzungen des allgemeinen Konvergenzresultats erfüllt.
Wenn nicht, mache einen Gradientenschritt, sonst einen Newton-Schritt.

Wir interpretieren das Newton-Verfahren als Abstiegsverfahren mit Suchrichtung $d_k = - \nabla^2 f(x_k)^{-1} \nabla f(x_k)$ und Schrittweiten $s_k = 1$.

Überprüfe, ob $d_k := -\nabla^2 f(x_k)^{-1} \nabla f(x_k)$ die verallgemeinerte Winkelbedingung
\[
	\f{-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\| \|d_k\|} \ge \alpha \|\nabla f(x_k)\|^p
\]
für $\alpha, p > 0$ erfüllen.
Für die Schrittweite verwende die Armijo-Regel.
Wir erwarten
\begin{itemize}
	\item
		globale (Prä-)Konvergenz, da Suchrichtungen und Schrittweiten zulässig gewählt wurden,
	\item
		Der Algorithmus kann irgendwann einen Newton-Schritt durchführen.
\end{itemize}

\begin{alg}[Globalisiertes Newton-Verfahren] \label{alg:8}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Armijo-Parameter $\beta \in (0,1), \gamma \in (0,\f 12)$, siehe \ref{2.59}}
		\Require{Winkelbedingungs-Parameter $\alpha,p > 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\If{$\det(\nabla^2 f(x_k)) \neq 0$}
				\State{$d_k \gets -\nabla^2 f(x_k)^{-1} \nabla f(x_k)$}
				\If{$-\nabla f(x_k)^T d_k < \alpha \|\nabla f(x_k)\|^{1+p}\, \|d_k\|$}
					\State{$d_k \gets -\nabla f(x_k)$}
				\EndIf
			\Else
				\State{$d_k \gets -\nabla f(x_k)$}
			\EndIf
			\State{$s_k \gets \f 1\beta$} \Comment{ab hier: Armijo-Regel}
			\Repeat
				\State{$s_k \gets \beta s_k$}
				\State{$x_{k+1} \gets x_k + s_k d_k$}
			\Until{$f(x_{k+1}) \le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{st}[Präkonvergenz des globalisierten Newton-Verfahrens] \label{2.57}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
	\ref{alg:8} terminiert entweder nach endlich vielen Schritten an einem stationärem Punkt, oder er erzeugt eine Folge $(x_k)_{k\in\N}$ mit
	\begin{enumerate}[(a)]
		\item
			$f(x_{k+1}) < f(x_k)$,
		\item
			jeder Häufungspunkt von $x_k$ ist stationärer Punkt von $f$.
	\end{enumerate}
	\begin{proof}
		Wir zeigen die Zulässigkeit von Suchrichtungen und Schrittweiten (die Aussage folgt dann mit \ref{2.29}).
		\begin{seg}[Zulässigkeit der Suchrichtungen]
		Wird im Algorithmus die Newton-Suchrichtung verwendet, dann ist
		\[
			-\nabla f(x_k)^T d_k \ge \alpha \|\nabla f(x_k)\|^{1+p}\, \|d_k\|,
		\]
		ansonsten ist $d_k := -\nabla f(x_k)$.

		Also gilt die verallgemeinerte Winkelbedingung
		\[
			- \f {\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|}
			\ge \min \{ 1, \alpha \|\nabla f(x_k)\|^p \}.
		\]
		Nach \ref{2.31} sind die Suchrichtungen $d_k$ somit zulässig.
		\end{seg}
		\begin{seg}[Zulässigkeit der Schrittweiten]
		Verwende \ref{2.36}:
		Sei $(x_l)$ eine konvergente Folge, also
		\[
			\exists C > 0 : \|\nabla^2 f(x_l)\| \le C.
		\]
		Für Newton-Suchrichtungen gilt
		\begin{align*}
			- \f {\nabla f(x_l)^T d_l}{\|d_l\|}
			\le \|\nabla f(x_l)\|
			= \|\nabla^2 f(x_l) d_l\|
			\le C \|d_l\|,
		\end{align*}
		und für Gradientensuchrichtungen
		\[
			\|\nabla f(x_l)\|
			= \|d_l\|
			= \f {-\nabla f(x_l)^T d_l}{\|d_l\|}.
		\]
		Also ist
		\[
			\|d_l\|
			\ge \min \{1, \f 1C \} \f {-\nabla f(x_l)^T d_l}{\|d_l\|}.
		\]
		Die Armijo-Regel liefert also zulässige Schrittweiten.
		\end{seg}
	\end{proof}
\end{st}

\begin{lem} \label{2.58}
	Sei $\hat x \in \R^n$ und $(x_k)_{k\in\N} \subset \R^n$, dann gelten folgende Aussagen
	\begin{enumerate}[(a)]
		\item
			Besitzt jede konvergente Teilfolge von $(x_k)_{k\in\N}$ eine gegen $\hat x$ konvergente Teilfolge, so konvergiert $(x_k)_{k\in\N}$ gegen $\hat x$.
		\item
			Ist $(x_k)_{k\in\N}$ beschränkt und $\hat x$ ihr einziger Häufungspunkt, so konvergiert $(x_k)_{k\in\N}$ gegen $\hat x$.
		\item
			Ist $\hat x$ ein isolierter Häufungspunkt von $(x_k)_{k\in\N}$ (d.h. es existiert eine Umgebung um $\hat x$, in der $\hat x$ einziger Häufungspunkt ist) und gilt für jede gegen $\hat x$ konvergente Teilfolge $(x_l)_{l\in L}$
			\[
				x_l - x_{l+1} \to 0,
			\]
			so konvergiert $(x_k)_{k\in\N}$ gegen $\hat x$.
			\begin{note}
				Mit $l+1$ ist nicht der nächstgrößere Index nach $l$ in $L$ gemeint, im Allgemeinen gilt nicht $l+1 \in L$.
			\end{note}
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				siehe \ref{2.25}.
			\item
				triviale Folgerung aus (a).
			\item
\coursetimestamp{04}{12}{2013}
				Angenommen $(x_k) \not\to \hat x$, dann existiert $B_\eps(\hat x)$, so dass unendlich viele $x_k$ außerhalb $B_\eps (\hat x)$ liegen.
				Wähle $\eps > 0$ so klein, dass außerdem $\hat x$ einziger Häufungspunkt in $B_\eps(\hat x)$ ist.
				Nach Konstruktion liegen innerhalb und außerhalb $B_\eps(\hat x)$ jeweils unendlich viele $x_k$.

				Es existiert $L \subset \N$, $|L| = \infty$, so dass $x_l \in B_\eps(\hat x)$ und $x_{l+1} \not\in B_\eps(\hat x)$ für alle $l \in L$.
				$(x_l)_{l\in L}$ ist beschränkt (da $\forall l \in L: x_l \in B_\eps(\hat x)$) mit einzigem Häufungspunkt $\hat x$, also $\lim_{L\ni l\to \infty} x_l = \hat x$, ein Widerspruch zu $x_l - x_{l+1} \to 0$.
		\end{enumerate}
	\end{proof}
\end{lem}

\begin{st}[Schnelle Konvergenz des globalisierten Newton-Verfahrens] \label{2.59}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
	Falls \ref{alg:8} nicht terminiert, die erzeugte Folge $(x_k)_{k\in\N} \subset \R^n$ einen Häufungspunkt besitzt und $\nabla^2 f(\hat x)$ positiv definit ist, so gilt
	\begin{enumerate}[(a)]
		\item
			$\hat x$ ist isoliertes Minimum von $f$,
		\item
			$x_k \to \hat x$,
		\item
			Nach endlich vielen Iterationsschritten geht das Verfahren in das Newton-Verfahren über.
	\end{enumerate}
	Insbesondere konvergiert $(x_k)_{k\in \N}$ superlinear (und für $\nabla^2 f$ lokal Lipschitz-stetig sogar quadratisch) gegen $\hat x$.
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Nach \ref{2.57} ist $\hat x$ ein stationärer Punkt und da $\nabla^2 f(\hat x)$ positiv definit auch lokales Minimum.

				Nach \ref{2.48} (a), (b) existiert $\delta, \my > 0$ sodass $\hat x \in \R^n$ der einzige stationäre Punkt in $B_\delta(\hat x)$ ist und $\lambda_{\text{min}}(\nabla^2(f(x))) \ge \my$ für alle $x \in B_\delta(\hat x)$ gilt.
			\item
				$\hat x$ ist nach \ref{2.57} (b) einziger Häufungspunkt von $(x_k)_{k\in\N}$ in $B_\delta(\hat x)$.
				Sei $(x_l)_{l\in L}$ eine gegen $\hat x$ konvergente Teilfolge.
				Wegen $\nabla f(x_l) \to 0$ gilt
				\begin{align*}
					\|x_l - x_{l+1}\|
					&= s_l \|d_l\|
					\le \|d_l\| \\
					&\le \max \Big\{ \underbrace{\|\nabla f(x_l)\|}_{\to 0}, \underbrace{\|\nabla^2 f(x_l)^{-1} \nabla f(x_l)\|}_{\le \|\nabla^2 f(x_l)^{-1} \| \|\nabla f(x_l)\|} \Big\}
				\end{align*}
				Wegen $\|\nabla^2 f(x_l)^{-1}\| = \f 1{\lambda_{\text{min}}(\nabla^2 f(x_l))} \le \f 1\my$ gilt also
				\[
					\|x_l - x_{l+1}\| \to 0.
				\]
				Nach \ref{2.58} konvergiert also $x_k \to \hat x$ für $k\to \infty$.
			\item
				Zeige, dass für hinreichend große $k \in \N$
				\begin{enumerate}[(i)]
					\item
						$\nabla^2 f(x_k)$ invertierbar ist,
					\item
						die Newtonsuchrichtung $d_k := - \nabla^2 f(x_k)^{-1} \nabla f(x_k)$ die verallgemeinerte Winkelbedingung erfüllt, d.h.
						\[
							-\nabla f(x_k)^T d_k
							\ge \alpha \|\nabla f(x_k)\|^{1 + p} \|d_k\|
						\]
						mit $\alpha, p > 0$,
					\item
						die Armijo-Regel die Schrittweite $s_k = 1$ akzeptiert, d.h.
						\[
							f(x_k + d_k)
							\le f(x_k) + \gamma \nabla f(x_k)^T d_k.
						\]
				\end{enumerate}
				\begin{enumerate}[(i)]
					\item
						Da $x_k \to \hat x$ ist $x_k \in B_\delta (\hat x)$ für fast alle $k \in \N$ und damit $\nabla^2 f(x_k)$ invertierbar für fast alle $k \in \N$.
					\item
						Da $f \in C^2$, existiert $C > 0$ mit
						\[
							\|\nabla^2 f(x) \| \le C
						\]
						für alle $x \in B_\delta(\hat x)$.
						Wegen $\nabla f(x_k) \to 0$ gilt für hinreichend große $k$
						\[
							\alpha \|\nabla f(x_k)\|^p
							\le \f \my C,
						\]
						wobei $\alpha, p > 0$ frei gewählte Parameter des Verfahrens waren.
						Daraus folgt schließlich die gewünschte Winkelbedingung
						\begin{align*}
							-\nabla f(x_k)^T d_k
							&= d_k^T \nabla^2 f(x_k) d_k \\
							&\ge \my \|d_k\|^2 \\
							&= \my \|\nabla^2 f(x_k)^{-1} \nabla f(x_k)\| \|d_k\| \\
							&\ge \my \f{\|\nabla f(x_k)\|}{\|\nabla^2 f(x_k)\|} \|d_k\| \\
							&\ge \f{\my}C \|\nabla f(x_k) \| \|d_k\| \\
							&\ge \alpha \|\nabla f(x_k)\|^{1+ p} \|d_k\|.
						\end{align*}
					\item
						Nach \ref{2.3} existiert $s \in [0,1]$ mit
						\begin{align*}
							f(x_k + d_k)
							&= f(x_k) + \nabla f(x_k)^T d_k + \f 12 d_k^T \nabla f(x_k + s d_k)
						\end{align*}
						Also ist
						\begin{align*}
							&f(x_k + d_k) - f(x_k) - \gamma \nabla f(x_k)^T d_k \\
							&\quad= (1-\gamma) \nabla f(x_k)^T d_k + \f 12 d_k^T \nabla f(x_k + sd_k) d_k \\
							&\quad= (\gamma-1) d_k^T \nabla^2 f(x_k) d_k + \f 12 d_k^T \nabla^2 f(x_k + sd_k) d_k \\
							&\quad= \underbrace{(\gamma-\f 12)}_{<0} \underbrace{d_k^T \nabla^2 f(x_k) d_k}_{\ge \my \|d_k\|^2} \\
							&\qquad\qquad\qquad + \f 12 d_k^T \Big(\nabla f(x_k + sd_k) - \nabla^2 f(x_k)\Big) d_k \\
							&\quad\le \Big(\underbrace{\my (\gamma - \f 12)}_{<0} + \underbrace{\f 12 \Big\|\nabla^2 f(x_k + sd_k) - \nabla^2 f(x_k)\Big\|}_{\to 0} \Big) \|d_k\|^2 \\
							&\quad\le 0
						\end{align*}
						für hinreichend große $k \in \N$ und die Armijo-Regel akzeptiert $s_k = 1$.
				\end{enumerate}
		\end{enumerate}
	\end{proof}
\end{st}

\subsubsection{Globalisierte BFGS-Verfahren}

Analog zum globalisierten Newton-Verfahren lässt sich auch das BFGS-Verfahren globalisieren, siehe dazu \cite{geigerkanzow99}.


\section{Nichtlineare Ausgleichsprobleme}


Betrachte für hinreichend oft differenzierbares $F: \R^n \to \R^m$ die Gleichung
\[
	F(x) = 0.
\]
Wenn wir $m > n$ zulassen, so ist das System im Allgemeinen garnicht exakt lösbar.
Stattdessen suchen wir als Approximation an die Lösung das Minimum
\[
	\|F(x)\| \to \min!,
\]
oder äquivalent das Minimum von
\[
	\Phi(x)
	:= \f 12 \| F(x) \|^2
	= \f 12 \sum_{i = 1}^m F_i(x)^2.
\]

\coursetimestamp{09}{12}{2013}

\begin{lem} \label{2.60}
	Sei $F \in C^1$ (bzw. $F \in C^2$), dann ist $\Phi \in C^1$ (bzw. $\Phi \in C^2$) mit
	\begin{align*}
		\nabla \Phi(x) &= F'(x)^T F(x) \\
		\nabla^2 \Phi(x) &= F'(x)^T F'(x) + \sum_{i=1}^m F_i(x) \nabla^2 F_i(x)
	\end{align*}
	\begin{proof}
		siehe Übungsaufgabe.
		% fixme: ref
	\end{proof}
\end{lem}

\subsection{Das Gauß-Newton-Verfahren}

Newton angewandt auf das nichtlineare Ausgleichsproblem ergibt
\begin{align*}
	x_{k+1}
	&:= x_k - \nabla^2 \Phi(x_k)^{-1} \nabla \Phi(x_k) \\
	&= x_k - \Big(F'(x_k)^T F'(x_k) + \sum_{i=1}^m F_i(x_k) \nabla^2 F_i(x_k) \Big)^{-1} F'(x_k)^T F(x_k).
\end{align*}

Der Newton-Algorithmus minimiert in jedem Schritt die quadratische Approximation
\[
	\Phi(x) \approx \Phi(x_k) + \nabla \Phi(x_k)^T (x-x_k) + \f 12 (x-x_k) \nabla^2 \Phi(x_k) (x-x_k)
\]
Nun hat $\Phi$ aber eine gewisse Gestalt, die wir ausnutzen könnten.

Minimiere stattdessen
\[
	\Phi(x)
	= \f 12 \|F(x)\|^2
	\approx \f 12 \|F(x_k) + F'(x_k) (x-x_k) \|^2,
\]
d.h. suche eine bestmögliche Lösung für $F'(x_k)(x - x_k) = -F(x_k)$.
Die Gaußschen Normalengleichungen liefern, dass das gesuchte Minimum genau
\[
	F'(x_k)^T F'(x_k) (x-x_k) = - F'(x_k)F(x_k)
\]
löst.
Dies liefert die Iteration
\[
	x_{k+1}
	:= x_k - \big(F'(x_k)^T F'(x_k)\big)^{-1} F'(x_k)^T F(x_k)
\]
Für $F: \R^n \to \R^n$ und $F'(x_k)$ invertierbar, ist dies genau das bisherige Newton-Verfahren.

\begin{alg}[Gauß-Newton-Verfahren] \label{alg:9}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\State{$k \gets 0$}
		\While{$F'(x_k)^T F(x_k) \neq 0$}
			\State{$d_k \gets - \big(F'(x_k)^T F'(x_k)\big)^{-1} F'(x_k)^T F(x_k)$}
			\State{$x_{k+1} \gets x_k + d_k$}
			\State{$k \gets k + 1$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{nt*}
	Gauß-Newton-Verfahren konvergieren (für nicht exakt lösbare nichtlineare Ausgleichprobleme) im Allgemeinen nur linear (siehe Übungsaufgabe).
	% fixme: ref
\end{nt*}

\subsection{Levenberg-Marquardt-Verfahren}

Betrachte die Approximation aus dem Gauß-Newton-Verfahren:
\[
	\Phi(x)
	= \f 12 \|F(x)\|^2
	\approx \f 12 \|F(x_k) + F'(x_k) (x-x_k) \|^2.
\]
Da diese Approximation nur in der Nähe von $x_k$ gilt, wäre es naheliegend, die Minimierung unter einer Nebenbedingung durchzuführen, welche die Schrittweite nicht zu groß werden lässt.

Wir minimieren deshalb
\[
	\| F(x_k) + F'(x_k)(x-x_k) \|^2 + \my \|x-x_k\|^2 \to \min!
\]
mit einem Parameter $\my > 0$, der bestimmt, wie der jeweilige Ausdruck gewichtet wird:
\begin{align*}
	\my = 0 &: \text{ nur $\|F(x_k) + F'(x_k)(x-x_k)\|$ wird minimiert, Gauß-Newton} \\
	\my \to \infty &: \text{ nur $\|x-x_k\|$ wird minimiert, $x = x_k$}.
\end{align*}
Folgendes Minimierungsproblem ist eine äquivalente Formulierung:
\[
	\left\|
	\begin{pmatrix}
		F'(x_k) \\
		\sqrt{\my} I
	\end{pmatrix}
	(x-x_k)
	+ \begin{pmatrix}
		F(x_k) \\
		0
	\end{pmatrix}
	\right\|^2 \to \min!
\]
Die Gaußsche Normalengleichung liefert
\[
	\Big( F'(x_k)^T \sqrt{\my} I \Big)
	\begin{pmatrix}
		F'(x_k) \\
		\sqrt{\my} I
	\end{pmatrix}
	(x-x_k)
	=
	- \Big(F'(x_k)^T \sqrt{\my} I \Big)
	\begin{pmatrix}
		F(x_k) \\
		0
	\end{pmatrix}.
\]
Dies liefert die Iteration $x_{k+1} := x_k + d_k$, wobei $d_k$ folgende Gleichung löst:
\[
	\Big( F'(x_k)^T F'(x_k) + \my I \Big) d_k
	= - F'(x_k)^T F(x_k).
\]
Dabei ist $F'(x_k)^T F'(x_k) + \my I$ stets positiv definit (siehe \ref{2.61}), also invertierbar.

\begin{lem} \label{2.61}
	Sei $x_k \in \R^n$.
	\begin{enumerate}[(a)]
		\item
			Für jedes $\my > 0$ ist $F'(x_k)^T F'(x_k) + \my I$ positiv definit und damit invertierbar.
		\item
			Die Abbildung $r: (0,\infty) \to \R: \my \mapsto \|d_k\|$, wobei
			\[
				d_k := -\Big( F'(x_k)^T F'(x_k) + \my I \Big)^{-1} F'(x_k)^T F(x_k),
			\]
			ist stetig und monoton fallend.
			Es gilt
			\[
				\lim_{\my\to\infty} d_k = 0
			\]
			und falls $F'(x_k)^T F'(x_k)$ invertierbar ist
			\[
				\lim_{\my\to 0} d_k = -(F'(x_k)^T F'(x_k))^{-1} F'(x_k)^T F(x_k).
			\]
		\item
			Die Wahl
			\[
				d_k := -\Big( F'(x_k)^T F'(x_k) + \my I \Big)^{-1} F'(x_k)^T F(x_k),
			\]
			ist ein globales Minimum von
			\[
				\| F(x_k) + F'(x_k) d \| \to \min!
				\udN
				\|d\| \le r(\my).
			\]
			\begin{note}
				Mit diesem Ansatz können wir ein Trust-Region-Verfahren (siehe \ref{2.23}) erhalten.
				$\my$ steuert die Größe der Trust-Region $B_{r(\my)}(x_k)$.
			\end{note}
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				klar, da $F'(x_k)^T F'(x_k)$ symmetrisch und positiv semidefinit.
			\item
				Sei $(v_l)_{l=1}^n \subset \R^n$ eine ONB aus Eigenvektoren von $F'(x_k)^T F'(x_k)$ mit zugehörigen Eigenwerten $\lambda_l \ge 0$.

				Wir zerlegen hiermit
				\[
					F'(x_k)^T F(x_k)
					= \sum_{l=1}^n a_l v_l,
				\]
				wobei $a_l = \<v_l, F'(x_k)^T F(x_k)\> = v_l^T F'(x_k)^T F(x_k)$.
				Da $v_l$ Eigenvektor von $(F'(x_k)^T F'(x_k) + \my I)^{-1}$ zum Eigenwert $\f 1{\lambda_l + \my}$ ist, folgt
				\[
					d_k = -\sum_{l=1}^n \f {a_l}{\lambda_l + \my} v_l
				\]
				und mit Pythagoras
				\[
					\|d_k\|^2 = \sum_{l=1}^n \big( \f {a_l}{\lambda_l + \my} \big)^2.
				\]
				Damit ist $r: (0, \infty) \to \R: \my \to \|d_k\|$ stetig und monoton fallend.
				Außerdem erkennt man $\lim_{\my \to \infty} d_k = 0$ und
				\begin{align*}
					\lim_{\my \to 0} d_k
					= -\sum_{l=1}^n \f {a_l}{\lambda_l} v_l
					&= -\sum_{l=1}^n a_l (F'(x_k)^T F'(x_k))^{-1} v_l \\
					&= -\big( F'(x_k)^T F'(x_k) \big)^{-1} F'(x_k)^T F(x_k).
				\end{align*}
			\item
				$d_k$ ist per Konstruktion (durch die Gaußschen Normalengleichungen) globales Minimum von
				\[
					\| F(x_k) + F'(x_k) d_k \|^2 + \my \|d_k\|^2 \to \min!
				\]
				Angenommen $\hat d_k \neq d_k$ sei ein globales Minimum von $\|F(x_k) + F'(x_k) d\| \to \min!$ unter der Nebenbedingung $\|d\| \le r(\my) = \|d_k\|$ und $d_k$ sei dies nicht, dann wäre
				\[
					\underbrace{\| F(x_k) + F'(x_k) \hat d_k \|^2}_{< \| F(x_k) + F'(x_k) d_k \|^2} + \my \underbrace{\|\hat d_k\|^2}_{\le \|d_k\|^2}
					< \| F(x_k) + F'(x_k) d_k \|^2 + \my \|d_k\|^2
				\]
				ein kleineres Minimum von $\| F(x_k) + F'(x_k) d_k \|^2 + \my \|d_k\|^2 \to \min!$, ein Widerspruch.
		\end{enumerate}
	\end{proof}
\end{lem}

Wie passen wir $\my$ im Laufe des Algorithmus an?
Definiere nach dem Prinzip der Trust-Region
\begin{align*}
	\eps
	&:= \dfrac {\mathrm{ared}_k}{\mathrm{pred}_k}
	:= \dfrac {\|F(x_k)\|^2 - \|F(x_{k+1})\|^2}{\|F(x_k)\|^2 - \|F(x_k) + F'(x_k) (x_{k+1} - x_k)\|^2}.
\end{align*}
Ein sehr kleines $\eps$ (beispielsweise $\eps < 0.3$) bedeutet, der Schritt ist zu groß: verwerfe den Schritt und vergrößere $\my$ (und verkleinere damit die Trust-Region $B_{r(\my)}(x_k)$).

Ein großes $\eps$ (beispielsweise $\eps > 0.9$) bedeutet, der Schritt war in Ordnung, vielleicht sogar zu klein: verkleinere $\my$, oder behalte den aktuellen Wert bei.

Wir erhalten folgenden Algorithmus:

\begin{alg} \label{alg:10}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Initiales $\my$ und Parameter $0 < \beta_0 < \beta_1 < 1$ zur Steuerung von $\my$}
		\State{$k \gets 0$}
		\While{$F'(x_k)^T F(x_k) \neq 0$}
			\State{$d_k \gets - \big(F'(x_k)^T F'(x_k) + \my I \big)^{-1} F'(x_k)^T F(x_k)$}
			\State{$\eps \gets \frac {\|F(x_k)\|^2 - \|F(x_{k+1})\|^2}{\|F(x_k)\|^2 - \|F(x_k) + F'(x_k) d_k\|^2}$}
			\While{$\eps < \beta_0$} \Comment{verkleinere die Trust-Region, falls nötig}
				\State{$\my \gets 2 \my$}
				\State{$d_k \gets - \big(F'(x_k)^T F'(x_k) + \my I \big)^{-1} F'(x_k)^T F(x_k)$}
				\State{$\eps \gets \frac {\|F(x_k)\|^2 - \|F(x_{k+1})\|^2}{\|F(x_k)\|^2 - \|F(x_k) + F'(x_k) d_k\|^2}$}
			\EndWhile
			\State{$x_{k+1} \gets x_k + d_k$}
			\If{$\eps > \beta_1$} \Comment{wenn gewünscht, vergrößere die Trust-Region}
				\State{$\my \gets \f 12 \my$}
			\EndIf
			\State{$k \gets k + 1$}
		\EndWhile
	\end{algorithmic}
\end{alg}

Für Konvergenztheorie (einer Variante dieses Verfahrens) siehe \cite[Satz 21.3]{hanke02}
