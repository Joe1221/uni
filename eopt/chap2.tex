\chapter{Unrestringierte nichtlineare Optimierung}


Im Folgenden betrachten wir für (hinreichend glatte) $f: \R^n \to \R$ das Minimierungsproblem
\[
	\min_{x\in \R^n} f(x)
\]
ohne Nebenbedingungen.


\section{Grundlagen und Optimalitätsbedingungen}


$U \subset \R^n$ sei im Folgenden stets eine offene Menge.


\subsection{Grundlagen}

Für $x \in \R^n, A \in \R^{n\times n}$ setzen wir
\[
	\|x\| := \sqrt{x^T x}, \qquad
	\|A\| := \max_{\|x\|=1} \|Ax\|.
\]

Für $F: U \to \R^m$, $F(x) = (f_1(x), \dotsc, f_m(x))^T$ sei
\[
	F'(x) := \begin{pmatrix}
		\pddx[x_1]{f_1}(x) & \cdots & \pddx[x_n]{f_1}(x) \\
		\vdots & \ddots & \vdots \\
		\pddx[x_1]{f_m}(x) & \cdots & \pddx[x_n]{f_m}(x) \\
	\end{pmatrix} \in \R^{m\times n}
\]
die \emph{Jacobimatrix} der Funktion $F$.

Für $f: U \to \R$ bezeichnen
\begin{align*}
	\nabla f(x)
	&:= f'(x)^T
	= \begin{pmatrix}
		\pddx[x_1]{f}(x) \\
		\vdots \\
		\pddx[x_n]{f}(x) \\
	\end{pmatrix}, \\
	\nabla^2 f(x)
	&:= \begin{pmatrix}
		\pddx[x_1^2]{f}(x) & \cdots & \f{\partial^2 f}{\partial x_1 \partial x_n}(x) \\
		\vdots & \ddots & \vdots \\
		\f{\partial^2 f}{\partial x_n \partial x_1}(x) & \cdots & \f{\partial^2 f}{\partial x_n^2}(x) \\
	\end{pmatrix} \in \R^{n\times n}
\end{align*}
den Gradienten $\nabla f$ und die Hessematrix $\nabla^2 f$ die Hesse-Matrix
(die Bezeichnung $\nabla^2$ wird in der Literatur nicht einheitlich verwendet).
Bezeichne außerdem für $d \in \R^n$ die \emph{Richtungsableitung} mit
\[
	\pddx[d]{f}(x)
	:= \lim_{t\to 0} \f {f(x+td) - f(x)}{t}
	= f'(x) d = \nabla f(x)^T d.
\]

\begin{df} \label{2.1}
	Zu $x_0,x_1 \in \R^n$ heißt
	\[
		[x_0, x_1] := \big\{ x_0 + t(x_1-x_0) : t \in [0,1] \big\}
	\]
	die \emph{Verbindungsstrecke} zwischen $x_0, x_1$.
\end{df}

\begin{st} \label{2.2}
	Sei $f: U \to \R$ stetig differenzierbar, $x_0, x_1 \in U$ und $[x_0, x_1] \subset U$.

	Dann ist die Funktion $g: t \mapsto f(x_t)$ (wobei $x_t := x_0 + t(x_1 - x_0) = (1-t) x_0 + tx_1$) auf einer Umgebung von $[0,1]$ stetig differenzierbar und
	\[
		g'(t) = \nabla f(x_t)^T (x_1 - x_0).
	\]
	Ist $f$ zweimal stetetig differenzierbar, so auch $g$ und es gilt
	\[
		g''(t) = (x_1 - x_0)^T \nabla^2 f(x_t) (x_1 - x_0).
	\]
	\begin{proof}
		Siehe \coursehref{Blatt2.pdf}{Übungsaufgabe 2.1}.
	\end{proof}
\end{st}

\begin{st}[Linearer und quadratischer Taylor] \label{2.3}
	Sei $f : U \to \R$ stetig differenzierbar, $x\in U, \eps > 0$, so dass $B_\eps(x) \subset U$.
	Dann gilt
	\begin{enumerate}[(a)]
		\item
			Für alle $d \in B_\eps(0)$ existiert ein $s \in [0,1]$ mit
			\[
				f(x+d) = f(x) + \nabla f(x + sd)^T d.
			\]
			Außerdem gilt für alle $d \in B_\eps(0)$
			\[
				f(x+d) = f(x) + \nabla f(x)^T d + p(d)
			\]
			und das Restglied $p: B_\eps(0) \to \R$ erfüllt $p(d) = o(d)$, d.h.
			\[
				\lim_{d\to 0} \f {p(d)}{\|d\|} = 0.
			\]
		\item
			Ist $f: U \to \R$ zweimal stetig differenzierbar, dann existieren für alle $d \in B_\eps(0)$ ein $s \in [0,1]$mit
			\[
				f(x+d)
				= f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x+sd) d.
			\]
			Außerdem gilt für alle $d \in B_\eps(0)$
			\[
				f(x+d) = f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x) d + p(d)
			\]
			und $p: B_\eps(0) \to \R$ gilt $p = o(\|d\|^2)$, d.h.
			\[
				\lim_{d\to 0} \f{|p(d)|}{\|d\|^2} = 0.
			\]
	\end{enumerate}
	\begin{proof}
		Funktioniert mit eindimensionalem Taylor und \ref{2.2}.
	\end{proof}
\end{st}

\begin{lem} \label{2.4}
	Sei $F: U \to \R^m$ stetig differenzierbar, $x\in U$ und $\eps > 0$, sodass $B_\eps(x) \subset U$.

	Dann gilt für alle $d \in B_\eps(0)$
	\begin{align*}
		F(x+d)
		&= F(x) + \int_0^1 F'(x+td) d \dx[t] \\
		&= F(x) + \bigg( \int_0^1 F'(x+td) \dx[t] \bigg) d.
	\end{align*}
	Insbesondere gilt
	\[
		\| F(x+d) - F(x) \|
		\le \|d\| \sup_{t\in [0,1]} \|F'(x+td)\|.
	\]
	Diese Abschätzung wird oft auch \emph{mehrdimensionaler Mittelwertsatz} genannt.
\coursetimestamp{21}{10}{2013}

	Außerdem ist $F(x+d) = F(x) + F'(x)d + p(d)$ und $p: B_\eps(0) \to \R^m$ erfüllt $p(d) = o(d)$, d.h.
	$\lim_{d\to 0} \f {\|p(d)\|}{\|d\|} = 0$.

	\begin{proof}
		Da $U$ offen, existiert $\eps > 0$, so dass $[x- \eps d, x + d + \eps d] \subset U$.
		Definiere $f: (-\eps, 1 + \eps) \to \R^n$ durch
		\[
			f(t) := F(x + td) = F(g(t))
		\]
		mit $g:(-\eps, 1 + \eps) \to \R^n : t \mapsto x + td$.
		Es gilt
		\[
			f'(t)
			= F'(g(t)) g'(t)
			= F'(x + td) d.
		\]
		und damit
		\[
			F(x+d) - F(x)
			= f(1) - f(0)
			= \int_0^1 f'(t) \dx[t]
			= \int_0^1 F'(x + td) d \dx[t].
		\]

		Die zweite Behauptung ist die Definition der totalen Differenzierbarkeit.
	\end{proof}
\end{lem}

\begin{df} \label{2.5}
	Eine symmetrische Matrix $A = (a_{ij}) \in \R^{n\times m}$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{positiv semi-definit}, falls $x^TAx \ge 0$ für alle $x \in \R^n$,
		\item
			\emph{positiv definit}, falls $x^TAx > 0$ für alle $x \in \R^n \setminus \{0\}$.
	\end{enumerate}
	Analog definiert man \emph{negativ semi-definit} und \emph{negativ definit}.
\end{df}

\begin{st} \label{2.6}
	Zu einer symmetrischen Matrix $A \in \R^{n\times n}$ existiert eine Orthonormalbasis aus Eigenvektoren $v_1, \dotsc, v_n \in \R^n$ mit dazugehörigen Eigenwerten $\lambda_1, \dotsc, \lambda_n \in \R$, als
	\[
		v_j^T v_k
		= \delta_{jk}
		= \begin{cases}
			1 & j = k \\
			0 & \text{sonst}
		\end{cases},\qquad
		Av_k = \lambda_k v_k
	\]
	Es ist also
	\[
		A = \sum_{k=1}^n \lambda_k v_k v_k^T
	\]
	und mit $\lambda_{\text{min}}(A) := \min_{k=1,\dotsc,n} \lambda_k$, $\lambda_{\text{max}}(A) := \max_{k=1,\dotsc,n} \lambda_k$ gilt
	\[
		\lambda_{\text{min}}(A)
		= \min_{x\in\R^n} \f {x^T A x}{\|x\|^2}
		\le \f {x^T A x}{\|x\|^2}
		\le \max_{x\in\R^n} \f {x^TA x}{\|x\|^2}
		= \lambda_{\text{max}}(A)
	\]
	und
	\[
		\|A\|
		= \sup_{x\neq 0} \f{\|Ax\|}{\|x\|}
		= \max \{|\lambda_k| : k=1, \dotsc, n \}
	\]
	Insbesondere ist $A$ positiv semi-definit genau dann, wenn alle Eigenwerte $\ge 0$ und positiv definit genau dann, wenn alle Eigenwerte $>0$ sind,
	entsprechend negativ semi-definit, wenn alle Eigenwerte $\le 0$ und negativ semi-definit, wenn alle Eigenwerte $<0$ sind.
\end{st}

\begin{df} \label{2.7}
	Für eine invertierbare Matrix $A \in \R^{n\times n}$ heißt
	\[
		\kappa(A)
		:= \|A\| \|A^{-1}\|
	\]
	\emph{Kondition}.

	Für eine symmetrische, positiv definite Matrix $A \in \R^{n\times n}$ gilt offenbar
	\[
		\kappa(A)
		= \lambda_{\text{max}}(A) \lambda_{\text{max}}(A^{-1})
		= \f {\lambda_{\text{max}}(A)}{\lambda_{\text{min}}(A)}.
	\]
\end{df}

\begin{nt} \label{2.8}
	Die Kondition ist ein Maß für die Fehlerverstärkung durch $A^{-1}$ (d.h. durch Lösen eines LGS), denn
	\begin{align*}
		\dfrac {A^{-1}(b+\delta) - A^{-1}b}{\|A^{-1}b\|}
		&= \f {\|A^{-1}\delta\|}{\|A^{-1}b\|} \\
		&\le \|A^{-1}\| \|A\| \f {\|\delta\|}{\|A\|\|A^{-1}b\|} \\
		&\le \kappa(A) \f {\|\delta\|}{\|b\|}.
	\end{align*}
\end{nt}

\subsection{Optimalitätsbedingungen}

\begin{df} \label{2.9}
	Sei $X \subset \R^n$ und $f: X \to \R$.
	Ein Punkt $x \in X$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{globales Minimum von $f$ in $X$}, falls
			\[
				\forall y \in X: f(x) \le f(y),
			\]
		\item
			\emph{lokales Minimum von $f$}, falls
			\[
				\exists \eps > 0 \forall y \in X \cap B_\eps(x): f(x) \le f(y),
			\]
		\item
			\emph{striktes globales Minimum von $f$ in $X$}, falls
			\[
				\forall y \in X \setminus \{x\}: f(x) < f(y)
			\]
		\item
			\emph{striktes lokales Minimum von $f$}, falls
			\[
				\exists \eps > 0 \forall y \in (X \setminus \{x\}) \cap B_\eps(x): f(x) < f(y),
			\]
	\end{enumerate}
	Analog definiert man die entpsrechenden Maxima.
\end{df}

\begin{st}[Notwendige Optimalitätsbedingung 1. Ordnung] \label{2.10}
	Sei $U \subset \R^n$ offen, $f: U \to \R$ stetig differenzierbar.
	Ist $x \in U$ ein lokales Minimum von $f$, dann gilt $\nabla f(x) = 0$.

	Punkte mit $\nabla f(x) = 0$ heißen \emph{stationäre Punkte}
	\begin{proof}
		Für jedes $d \in \R^n$ gilt
		\[
			\nabla f(x)^T d
			= \lim_{t \to 0^+} \f {f(x+td) - f(x)}{t}
			\ge 0
		\]
		Für $d := - \nabla f(x)$ folgt $-\|\nabla f(x)\|^2 \ge 0$ und damit $\nabla f(x) = 0$.
	\end{proof}
\end{st}

\begin{st}[Notwendige Optimalitätsbedingung 2. Ordnung] \label{2.11}
	Sei $U \subset \R^n$ offen, $f: U \to \R$ zweimal stetig differenzierbar.
	Ist $x \in U$ ein lokales Minimum von $f$, dann ist $x$ ein stationärer Puunkt von $f$ und $\nabla^2 f$ ist positiv semi-definit, also
	\begin{enumerate}[(a)]
		\item
			$\nabla f(x) = 0$,
		\item
			$x^T \nabla^2 f(x) x \ge 0$ für alle $x \in \R^n$.
	\end{enumerate}
	\begin{proof}
		Teil (a) ergibt sich aus \ref{2.10}, zeige also (b):
		Sei $d \in \R^n$ und $\eps > 0$ so klein, dass $B_\eps(x) \subset U$ und $x$ globales Minimum in $B_\eps(x)$.
		Verwende \ref{2.3} mit $td$ anstelle von $d$:
		\[
			f(x+td)
			= f(x) + t \nabla f(x)^T d + \f {t^2}2 d^T \nabla^2 f(x) d + p(td
		\]
		für alle $td \in B_\eps(0)$.
		Also gilt für alle $|t| < \f \eps{\|d\|}$
		\[
			\nabla^2 f(x) d
			\ge - \f 2{t^2} p(td)
			\to 0
		\]
		für $t \to 0$.
	\end{proof}
\end{st}

\begin{st}[Hinreichende Optimalitätsbedingungen 2. Ordnung]
	Sei $U \subset \R^n$ offen, $f: U \to \R$ zweimal stetig differenzierbar.
	Ist $x \in U$ ein stationärer Punkt mit positiv definiter Hesse-Matrix, d.h.
	\begin{enumerate}[(a)]
		\item
			$\nabla f(x) = 0$,
		\item
			$d^T \nabla^2 f(x) d > 0$ für alle $d \in \R^n \setminus \{0\}$.
	\end{enumerate}
	Dann ist $x$ ein striktes lokales Minimum von $f$.
	\begin{proof}
		Nach \ref{2.6} ist mit (b) $\my := \lambda_{\text{min}} (\nabla^2 f(x)) > 0$ und
		\[
			d^T \nabla^2 f(x) d \ge \my \|d\|^2.
		\]
		Wie in \ref{2.11} ist
		\[
			f(x+d)
			= f(x) + \nabla f(x)^T d + \f 12 d^T \nabla^2 f(x) d + p(d)
		\]
		und $p(d) \le \f \my4 \|d\|^2$ für hinreichend kleine $d$.

		Also
		\[
			f(x+d)
			\ge f(x) + \f \my2 \|d\|^2 - \f \my4 \|d\|^2
			= f(x) + \f \my4 \|d\|^2
		\]
		und damit $f(x+d) > f(x)$ für alle hinreichend kleinen $d \neq 0$.
	\end{proof}
\end{st}

\begin{ex} \label{2.13}
	\begin{enumerate}[(a)]
		\item
			N1 ist nicht hinreichend.
			$f(x) = -x^2$ hat im kritischen Punkt ein Maximum,
			$f(x) = x^3$ hat in $x=0$ weder ein Maximum, noch ein Minimum.
			Zum Namen „Sattelpunkt“
			\[
				f(x_1,x_2) = x_1^2 - x_2^2
			\]
			bildet einen „Sattel“ in $(0,0)$.
		\item
			N2 ist nicht hinreichend, betrachte $f(x) = x^3$.
		\item
			H2 ist nicht notwendig, betrachte $f(x) = x^4$.
	\end{enumerate}
\end{ex}


\subsection{Konvexität}


\begin{df} \label{2.14}
	Eine Menge $X \subset \R^n$ heißt \emph{konvex}, wenn alle Verbindungsstrecken zweier Punkte darin enthalten sind, also für alle $x,y \in X, \lambda \in [0,1]$
	\[
		x_\lambda
		:= (1-\lambda)x + \lambda y \in X.
	\]
\end{df}

\begin{df} \label{2.15}
	Sei $X \subset \R^n$ konvex.
	$f: X \to \R$ heißt
	\begin{enumerate}[(a)]
		\item
			\emph{konvex}, falls für alle $x,y \in X, \lambda \in [0,1]$.
			\[
				f((1-\lambda)x + \lambda y)
				\le (1-\lambda) f(x) + \lambda f(y).
			\]
		\item
			\emph{strikt konvex}, falls für alle $x,y \in X, x \neq y, \lambda \in (0,1)$.
			\[
				f((1-\lambda)x + \lambda y)
				< (1-\lambda) f(x) + \lambda f(y).
			\]
		\item
			\emph{gleichmäßig konvex}, falls $\my > 0$ existiert, sodass für alle $x,y \in X, \lambda \in [0,1]$.
			\[
				f((1-\lambda)x + \lambda y) + \my \lambda(1-\lambda) \|y-x\|^2
				< (1-\lambda) f(x) + \lambda f(y).
			\]
			Zur Motivation betrachte auch \ref{2.17}.
	\end{enumerate}
\end{df}

\begin{st} \label{2.16}
	Sei $U \subset \R^n$ offen und $f: U \to \R$ stetig differenzierbar.
	$f$ ist auf einer konvexen Menge $X \subset U$
	\begin{enumerate}[(a)]
		\item
			genau dann konvex, wenn für alle $x,y \in X$
			\[
				\nabla f^T(x) (y-x)
				\le f(y) - f(x).
			\]
		\item
			genau dann strikt konvex, wenn für alle $x,y \in X, x \neq y$
			\[
				\nabla f^T(x) (y-x)
				< f(y) - f(x).
			\]
		\item
			genau dann gleichmäßig konvex, wenn ein $\my > 0$ existiert, sodass für alle $x,y \in X$.
			\[
				\nabla f(x)^T (y-x) + \my \|y-x\|
				\le f(y) - f(x)
			\]
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				\begin{seg}[„$\implies$“]
					Ist $f$ konvex, dann ist
					\begin{align*}
						\nabla f(x)^T (y-x)
						&= \lim_{t \to 0} \f {f(x+t(y-x)) - f(x)}t \\
						&= \lim_{t \to 0} \f {f((1-t)x + ty) - f(x)}t \\
						&\le \lim_{t \to 0} \f{(1-t)f(x) + tf(y) - f(x)}t
						= f(y) - f(x).
					\end{align*}
				\end{seg}
				\begin{seg}[„$\impliedby$“]
					Sei $\lambda \in [0,1]$ und $x,y \in X$.
					Dann gilt
					\begin{align*}
						f(x) - f(x_\lambda)
						&\ge \nabla f(x_\lambda)^T(x-x_\lambda) \\
						f(y) - f(x_\lambda)
						&\ge \nabla f(x_\lambda)^T(y-x_\lambda)
					\end{align*}
					Damit ist
					\begin{align*}
						(1-\lambda) f(x) + \lambda f(y)
						&= (1-\lambda)(f(x) - f(x_\lambda)) + \lambda (f(y) - f(x_\lambda)) + f(x_\lambda) \\
						&\ge (1-\lambda) \nabla f(x_\lambda)^T (x-x_\lambda) + \lambda \nabla f(x_\lambda)^T (y-x_\lambda) + f(x_\lambda) \\
						&= \nabla f(x_\lambda)^T \big( (1-\lambda) x + \lambda y - x_\lambda \big) + f(x_\lambda) \\
						&= f(x_\lambda)
					\end{align*}
				\end{seg}
			\item
				\begin{seg}[„$\implies$“]
					Sei $f$ strikt konvex, $x, y \in X, x\neq y$, setze
					\[
						x_{\f 12} := \f {f(x) + f(y)}2.
					\]
					Es gilt
					\begin{align*}
						\nabla f(x)^T (y-x)
						&= 2 \nabla f(x)^T (x_{\f 12} - x) \\
						&\le 2 (f(x_{\f 12}) - f(x)) \\
						&< 2 (\f {f(x) + f(y)}2 - f(x))
						= f(y) - f(x).
					\end{align*}
				\end{seg}
				\begin{seg}[„$\impliedby$“]
					Analog zu (a) „$\impliedby$“
				\end{seg}
			\item
				\begin{seg}[„$\implies$“]
					Es gilt
					\begin{align*}
						\nabla f(x)^T (y-x)
						&= \lim_{t\to 0} \f {f(x_t) - f(x)}t \\
						&\le \lim_{t\to 0} \f 1t \Big( (1-t)f(x) + tf(y) - \my t(1-t)\|y-x\|^2 - f(x) \Big) \\
						&= f(y) - f(x) - \my \|y-x\|^2.
					\end{align*}
				\end{seg}
				\begin{seg}[„$\impliedby$“]
					Gehe vor, wie in (a) $\impliedby$:
					\begin{align*}
						(1-\lambda) f(x) + \lambda f(y)
						&= (1-\lambda) (f(x) - f(x_\lambda)) + \lambda (f(y) - f(x_\lambda)) + f(x_\lambda) \\
						&\ge (1-\lambda) \Big(\nabla f(x_\lambda)^T (x-x_\lambda) + \my \|x-x_\lambda\|^2 \Big) \\
							&\quad + \lambda \Big( \nabla f(x_\lambda)^T (y-x_\lambda) + \my \|y-x_\lambda\|^2 \Big) + f(x_\lambda) \\
						&= f(x_\lambda) + (1-\lambda)\my \underbrace{\|x - x_\lambda\|^2}_{\lambda^2 \|y-x\|^2} + \lambda \my \underbrace{\|y-x_\lambda\|^2}_{(1-\lambda)^2\|y-x\|^2} \\
						&=  f(x_\lambda) + (1-\lambda)\lambda \my \|y-x\|^2.
					\end{align*}
				\end{seg}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{st} \label{2.17}
	Sei $X \subset \R^n$ offen und kovex und $f: X \to \R^n$ zweimal stetig differenzierbar.
	$f$ ist auf $X$
	\begin{enumerate}[(a)]
		\item
			genau dann konvex, wenn $\nabla^2 f(x)$ für alle $x \in X$ positiv semidefinit ist, also für alle $x \in X, d \in \R^n$
			\[
				d^T \nabla^2 f(x) d \ge 0
			\]
		\item
			strikt konvex, wenn $\nabla^2 f(x)$ für alle $x \in X$ positiv semidefinit ist, also für alle $x \in X, d \in \R^n \setminus \{0\}$
			\[
				d^T \nabla^2 f(x) d > 0.
			\]
			Die Umkehrung gilt nicht.
		\item
			genau dann gleichmäßig konvex, wenn $\nabla^2 f(x)$ gleichmäßig positiv semidefinit ist, d.h. es existiert $\my > 0$, sodass für alle $x \in X, d \in \R^n \setminus \{0\}$
			\[
				d^T \nabla^2 f(x) d \ge \my \|d\|^2.
			\]
			Die Umkehrung gilt nicht.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				\begin{seg}[„$\implies$“]
					Sei $f$ konvex und $d \in \R^n$.
					Für hinreichend kleine $t > 0$ gilt mit Taylor und $\ref{2.16}$
					\[
						\f {t^2}2 d^T \nabla^2 f(x) d + p(td)
						= f(x+td) - f(x) - t \nabla f(x)^T d
						\ge 0,
					\]
					also
					\[
						d^T \nabla^2 f(x) d
						\ge - \f {2 p(td)}{t^2} \to 0
					\]
					für $t \to 0$.
				\end{seg}
				\begin{seg}[$\impliedby$]
					Seien $x,y \in X$, dann gilt nach \ref{2.3}, dass $s \in [0,1]$ existiert mit
					\begin{align*}
						f(y)
						&= f(x) + \nabla f(x)^T d  + \f 12 (y-x)^T \nabla^2 f(x+s(y-x))(y-x) \\
						&\ge f(x) + \nabla f(x)^T (y-x)
					\end{align*}
					und somit ist $f$ nach \ref{2.16} konvex.
				\end{seg}
			\item
				Analog zu $\impliedby$ in (a).
			\item
				\begin{seg}[„$\implies$“]
					Analog wie „$\implies$“ in (a) erhalten wir
					\[
						d^T \nabla^2 f(x) d
						\ge - \f {2 p(td)}{t^2} + \my \|d\|^2
						\to \my \|d\|^2.
					\]
				\end{seg}
				\begin{seg}[„$\impliedby$“]
					Analog wie in (a) existiert zu $x,y \in X$ ein $s \in [0,1]$ mit
					\begin{align*}
						f(x)
						&= f(x) + \nabla f(x)^T (y-x) + \f 12 (y-x)^T \nabla^2 f(x_s) (y-x) \\
						&\ge f(x) + \nabla f(x)^T (y-x) + \f 12 \my \|y-x\|^2,
					\end{align*}
					also ist $f$ nach \ref{2.16} gleichmäßig konvex.
				\end{seg}
		\end{enumerate}
	\end{proof}
\end{st}

\begin{ex} \label{2.18}
	In \ref{2.17} gilt die Rückrichtung in (b) im Allgemeinen nicht.
	Betrachte dazu $f(x) = x^4$, dann ist $f''(x)\big|_{x=0} = 0$, trotz Minimum in $x=0$.
\end{ex}

\coursetimestamp{28}{10}{2013}

\begin{st} \label{2.19}
	Sei $X \subset \R^n$ konvex, $f: X \to \R$ konvex.
	Dann gelten folgende Aussagen
	\begin{enumerate}[(a)]
		\item
			Jedes lokale Minimum von $f$ ist auch globales Minimum von $f$ von $x$.
		\item
			Ist $f$ strikt konvex, dann besitzt $f$ höchstens ein lokales Minimum.
			Nach (a) ist jedes lokale Minimum das eindeutige, strikte globale Minimum.
		\item
			Ist $f$ stetig differenzierbar auf $O \subset X$ offen, dann ist jeder stationäre Punkt in $X$ ein globales Minimum.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
				Sei $x \in X$ kein globales Minimum von $f$.
				Dann existiert $y \in X$ mit $f(y) < f(x)$.
				Mit der Konvexität folgt für alle $f \in (0,1]$
				\[
					f(x+t(y-x))
					\le (1-t)f(x) + t f(y)
					< f(x).
				\]
				mit entsprechend kleinem $t$ finden wir damit in jeder Umgebung von $x$ ein $\xi$ mit $f(\xi) < f(x)$, also ist $x$ kein lokales Minimum.
			\item
				Seien $x,y \in X$ zwei lokale Minima von $f$.
				Nach (a) sind $x,y$ globale Minima, also $f(x) = f(y)$.
				Angenommen $x \neq y$, dann wäre wegen der strikten Konvexität
				\[
					f(\f {x+y}2)
					< \f{f(x) + f(y)}2
					= f(x)
					= f(y),
				\]
				ein Widerspruch dazu, dass $x,y$ globale Minima waren.
			\item
				Ist $x \in X$ ein stationärer Punkt, dann ist nach \ref{2.16} für alle $y\in X$
				\[
					f(y) - f(x)
					\ge \nabla f(x)^T (y-x)
					= 0,
				\]
				also $f(y) \ge f(x)$ und somit $x$ globales Minimum.
		\end{enumerate}
	\end{proof}
\end{st}


\section{Das Gradientenverfahren}


In diesem Abschnitt sei $f: \R^n \to \R$ eine stetig differenzierbare Funktion.

\begin{conv*}
	Im folgenden schreiben wir für eine Folge von Vektoren in $\R^n$,
	\[
		x_0, x_1, x_2, \dotsc \in \R^n.
	\]
	teilweise auch
	\[
		x^{(0)} = \begin{pmatrix}
			x_1^{(0)} \\ \vdots \\ x_n^{(0)}
		\end{pmatrix},
		x^{(1)} = \begin{pmatrix}
			x_1^{(1)} \\ \vdots \\ x_n^{(1)}
		\end{pmatrix},
		\dotsc \in \R^n.
	\]
\end{conv*}

\subsection{Richtung des steilsten Abstiegs}

In der Umgebung eines Punktes $x_0 \in \R^n$ ist (gemäß Taylorapproximation)
\[
	f(x) \approx f(x_0) + \nabla f(x_0)^T (x-x_0).
\]
Nach \coursehref{Blatt3.pdf}{Übungsaufgabe 3.1}
ist das Minimum der linearen Approximation innerhalb einer Kugel um $x_0$
\[
	\min_{\|x-x_0\|=1} \Big( f(x_0) + \nabla f(x_0)^T (x-x_0) \Big)
	= f(x_0) - \nabla f(x_0)^T \f {\nabla f(x_0)}{\|\nabla f(x_0)\|}.
\]
In der linearen Approximation ist $x-x_0 = -s \nabla f(x_0)$ mit $s > 0$, also die Richtung des steilsten Abstiegs von $f$.

Ein naiver Ansatz für einen Algorithmus wäre folgender:
Beginne mit $x_0 \in \R^n$ und iteriere
\[
	x_{k+1} := x_k - s_k \nabla f(x_k),
\]
mit noch zu bestimmenden Schrittweiten $s_k > 0$.
Solche Verfahren werden \emph{Gradientenverfahren} genannt.

\subsection{Armijo-Schrittweitenregel}

In der linearen Approximation erwarten wir, dass für $s_k > 0$ und $d_k \in \R^n$ (hier z.B. $d_k = -\nabla f(x_k)$)
\[
	f(x_{k+1})
	= f(x_k + s_k d_k)
	\approx f(x_k) + s_k \nabla f(x_k)^T d_k.
\]
Die Armijo-Regel besagt:
vergleiche die tatsächlie Abnahme der Zielfunktion $f(x_k) - f(x_k + s_kd_k)$ mit der aus der linearen Approximation erwarteten Abnahme $-s_k \nabla f(x_k)^T d_k$.
Nur wenn die tatsächliche Abnahme einen voregegebenen Bruchteil (z.B. $\gamma = 1\%$) der erwarteten Abnahme erreicht, also wenn die sogenannte \emph{Armijo-Regel}
\[
	f(x_{k+1})
	\le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k
\]
erfüllt ist, dann wird die Schrittweite akzeptiert, sonst verkürzt (z.B. auf $\beta s_k$ mit $\beta = \f 12 < 1$).

Für in jedem Schritt an der Stelle $x_k$ vorgegebene Abstiegsrichtungen $d_k$ lässt sich das folgende Abstiegsverfahren beschreiben.
\begin{alg}[Armijo-Schrittweitenregel]
	\begin{algorithmic}
		\Require{Parameter $\beta \in (0,1), \gamma \in (0,1)$}
		\Require{Aktuelle Iterierte $x_k$ und Abstiegsrichtung $d_k$}
		\State $s_k \gets \f 1{\beta}$
		\Repeat
			\State $s_k \gets \beta s_k$
			\State $x_{k+1} \gets x_k + s_k d_k$
		\Until $f(x_{k+1}) \le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k$
	\end{algorithmic}
\end{alg}

Verbindet man das Gradientenverfahren (d.h. die Wahl $d_k = -\nabla f(x_k)$ für die Abstiegsrichtung) mit der Armijo-Schrittweitenregel, so erhält man den folgenden Algorithmus.

\begin{alg}[Gradientenverfahren mit Armijo-Schrittweitenregel]
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Armijo-Parameter $\beta \in (0,1), \gamma \in (0,1)$}
		\For{$k \gets 0, 1, 2, \dotsc$}
			\If{$\nabla f(x_k) = 0$}
			\State{\Return{$x_k$}}
			\EndIf
			\State{$s_k \gets \f 1\beta$}
			\Repeat
				\State{$s_k \gets \beta s_k$}
				\State{$x_{k+1} \gets x_k - s_k \nabla f(x_k)$}
			\Until{$f(x_{k+1}) \le f(x_k) - \gamma s_k \|\nabla f(x_k)\|^2$}
		\EndFor
	\end{algorithmic}
\end{alg}

\begin{df} \label{2.20}
	Ein Vektor $0 \neq d \in \R^n$ heißt \emph{Abstiegsrichtung} von $f$ im Punkt $x$, falls
	\[
		\nabla f(x)^T d < 0.
	\]
\end{df}

\begin{st} \label{2.21}
	Ist $d$ eine Abstiegsrichtung für $f$ im Punkt $x$, so existiert für jedes $\gamma \in (0,1)$ ein $t > 0$ mit
	\[
		f(x+sd)
		\le f(x) + \gamma s \nabla f(x)^T d
	\]
	für alle $s \in [0,t]$, d.h. die Armijo-Schrittweitenregel terminiert nach endlich vielen Schritten.
	\begin{proof}
		Für $s \to 0$ ist
		\[
			\f{f(x_k+sd)-f(x_k)}{s} - \gamma \nabla f(x)^T d
			\to (1 - \gamma) \underbrace{\nabla f(x_k)^T d}_{<0}
			< 0,
		\]
		also ist für hinreichend kleine $s>0$
		\[
			\f{f(x_k+sd)-f(x_k)}{s} - \gamma \nabla f(x)^T d
			\le 0,
		\]
		d.h. die Armijo-Bedingung ist erfüllt.
	\end{proof}
\end{st}

\begin{nt} \label{2.22}
	Mit \ref{2.21} gilt insbesondere für hinreichend kleine $s > 0$
	\[
		f(x+sd)
		\le f(x) + \underbrace{\gamma s}_{> 0} \underbrace{\nabla f(x)^T d}_{<0}
		< f(x),
	\]
	d.h. die Funktion $f$ nimmt in Richtung ihrer Abstiegsrichtung lokal ab.

	Die Umkehrung hingegen gilt nicht.
	Betrachte dazu $f(x) = -x^2$ an der Stelle $x = 0$: in Richtung $d=\pm 1$ nimmt die Funktion ab, aber beides sind keine Abstiegsrichtungen gemäß \ref{2.20}.
\end{nt}

\begin{nt}[“Trust-Region”] \label{2.23}
	Die Armijo-Regel ist ein spezieller, einfacher Fall für ein sogenanntes “Trust-Region”-Verfahren.
	Bei einem Trust-Region-Verfahren wird $f$ dabei durch seine lineare Näherung
	\[
		f(x)
		\approx f(x_k) + \nabla f(x_k)^T (x-x_k)
	\]
	ersetzt.
	Wir vertrauen dieser Näherung jedoch nur für $x$ mit
	\[
		\|x - x_k\| \le \Delta_k,
	\]
	der sogenannten “Trust-Region” (um den Fehlerterm in der Taylorapproximation gering zu halten).
	Wir lösen also das restringierte Optimierungsproblem
	\[
		f(x_k) + \nabla f(x_k)^T (x-x_k) \to \min!
		\quad\udN\quad
		x \in B_{\Delta_k}(x_k)
	\]
	und erhalten $x_{k+1} = x_k - s_k \nabla f(x_k)$ ($s_k = \f {\Delta_k}{\|\nabla f(x_k)\|}$).
	Vergleiche anschließend die vorhergesagte Abnahme (\pred, “predicted reduction”) mit tatsächlicher Abnahme (\ared, “actual reduction”)
	\begin{align*}
		\pred_k &:= -s_k \nabla f(x_k), &
		\ared_k &:= f(x_k) - f(x_{k+1}).
	\end{align*}
	Falls $\f {\pred_k}{\ared_k} < \gamma$, so wird der Schritt mit verkleinertem $\Delta_k$ wiederholt.
\end{nt}

\coursetimestamp{30}{10}{2013}

% 2.2.3
\subsection{Konvergenz des Gradientenverfahrens}

Das Gradientenverfahren hat zwei Probleme:
Es könnte ein lokales Maximum gefunden werden, oder das Gradientenverfahren könnte nicht konvergieren ($f(x) = e^{-x}$).

\begin{st}[Präkonvergenz des Gradientenverfahrens] \label{2.24}
	Das Gradientenverfahren % fixme: algorithm reference
	terminiert entweder nach endlich vielen Schritten an einem stationären Punkt $x_k$, oder erzeugt eine Folge $(x_k)_{k\in\N}$ mit
	\begin{enumerate}[(a)]
		\item
			$f(x_{k+1}) < f(x_k)$,
		\item
			jeder Haufungspunkt von $(x_k)$ ist ein stationärer Punkt von $f$.
	\end{enumerate}
	\begin{proof}
		Terminiert der Algorithmus
		nach endlich vielen Schritten an einem $x_k$, so gilt $\nabla f(x_k) = 0$.
		Betrachte also jetzt den Fall, dass der Algorithmus nicht konvergiert.
		\begin{enumerate}[a)]
			\item
				Nach der Armijo-Regel gilt wegen $\nabla f(x_k) \neq 0$
				\[
					f(x_{k+1})
					\le f(x_k) - \gamma s_k \nabla f(x_k)^T \nabla f(x_k)
					< f(x_k).
				\]
			\item
				Sei $x \in \R^n$ ein Häufungspunkt von $(x_k)_{k\in\N}$, d.h. es existiert eine unendlich Indexmenge $L \subset \N$, so dass
				\[
					\lim_{L \ni l \to \infty} x_l = x.
				\]
				Da $f$ stetig, gilt auch $\lim_{L \ni l \to \infty} f(x_l) = f(x)$.
				Wegen (a) ist $(f(x_k))_{k\in\N}$ streng monoton fallend und damit $f(x_k) \ge f(x)$ für alle $k \in \N$.
				Also konvergiert $(f(x_k))_{k\in\N}$ und $\lim_{k\to \infty} f(x_k) = f(x)$.

				Nach der Armijo-Regel gilt
				\[
					f(x_0) - f(x)
					= \sum_{k=0}^\infty (f(x_k) - f(x_{k+1}))
					\ge \sum_{k=0}^\infty \gamma s_k \| \nabla f(x_k) \|^2,
				\]
				also ist $\lim_{k\to\infty} s_k \|\nabla f(x_k)\|^2 = 0$ und insbesondere auch für die Teilfolge mit der Indexmenge $L$:
				\[
					\lim_{L \ni l \to \infty} s_l \|\nabla f(x_l)\|^2 = 0.
				\]
				Also $\lim_{L \ni l \to \infty} s_l = 0$ oder $\nabla f(x) = \lim_{L \ni l \to\infty} \nabla f(x_l) = 0$ ($\nabla f$ stetig).
				Im letzteren Fall ist die Behauptung beweisen, sei also $\lim_{L \ni l \to \infty} s_l = 0$.

				In fast allen (o.B.d.A in allen) Schritten $l \in L$ hat durch die Armijo-Regel eine Schrittweitenverkürzung stattgefunden, d.h. $\f {s_l}{\beta}$ erfüllte die Armijo-Bedingung noch nicht.
				Für alle $l \in L$ gilt demnach
				\[
					f\big(x_l - \f {s_l}\beta \nabla f(x_l)\big)
					> f(x_l) - \gamma \f {s_l}{\beta} \| \nabla f(x_l) \|^2.
				\]
				Nach \ref{2.3} gilt:
				Für alle $l \in L$ existiert $\sigma_l \in [0, \f {s_l}{\beta}]$, sodass
				\[
					f(x_l) - f\big(x_l - \f {s_l}\beta \nabla f(x_l)\big)
					= \f {s_l}\beta \nabla f\big(x_l - \sigma_l \nabla f(x_l)\big)^T \nabla f(x_l).
				\]
				Also
				\begin{align*}
					-\gamma \f {s_l}\beta \|\nabla f(x_l)\|^2
					&< f\big(x_l - \f{s_l}\beta \nabla f(x_l)\big) - f(x_l) \\
					&= -\f {s_l}\beta \nabla f\big(\underbrace{x_l - \sigma_l \nabla f(x_l)}_{\to x}\big)^T \nabla f(x_l)
				\end{align*}
				und somit für $L \ni l \to \infty$ (also $x_l \to x$ und $\sigma_l \to 0$)
				\[
					- \gamma \|\nabla f(x)\|^2 \le - \| \nabla f(x)\|^2.
				\]
				Aus $\gamma < 1$ folgt damit $\nabla f(x) = 0$.
		\end{enumerate}
	\end{proof}
\end{st}

\begin{lem} \label{2.25}
	Sei $(x_k)_{k\in\N} \subset \R^n, x \in \R^n$.
	Besitzt jede Teilfolge von $(x_k)_{k\in\N}$ wiederum eine (Teil-)Teilfolge, die gegen $x$ konvergiert, so konvergiert die ganze Folge $(x_k)_{k\in\N}$ gegen $x$.
	\begin{proof}
		Angenommen $(x_k)_{k\in\N}$ konvergiert nicht gegen $x$.
		Dann gibt es eine Umgebung von $x$, außerhalb derer unendlich viele Folgenglieder liegen.
		Diese bilden dann aber eine Teilfolge, die keine gegen $x$ konvergente Teilfolge besitzen kann.
	\end{proof}
\end{lem}

\begin{kor} \label{2.26}
	\begin{enumerate}[(a)]
		\item
			Sei $c > 0$, so dass die \emph{Niveaumenge}
			\[
				f^{-1}((-\infty, c))
				:= \{ x \in \R^n : f(x) \le c \}
			\]
			beschränkt ist und in ihr nur ein stationärer Punkt liegt.
			$N_c := f^{-1}((-\infty,c])$ ist abgeschlossen, also kompakt, also wird das Minimum auf $N_c$ angenommen, $f(x) \le f(y)$ für alle $y \in \R^n$ und somit $\nabla f(x) = 0$.
			%fixme: rewrite

			Dann ist dieser stationäre Punkt das globale Minimum von $f$ auf der Niveaumenge und das Gradientenverfahren konvergiert für jeden Startwert $x_0$ mit $f(x_0) \le c$ gegen dieses Minimum.
		\item
			Ist $f$ konvex, dann terminiert Algorithmus 2 % fixme: reference
			entweder nach endlich vielen Schritten an einem globalen Minimum, oder erzeugt eine Folge, deren Häufungspunkte globale Minima sind.
		\item
			Ist $f$ strikt konvex und besitzt ein Minimum und es existiert $C > 0$ mit $f^{-1}((-\infty,C])$ beschränkt, dann konvergiert die Folge aus Algorithmus 2 % fixme: reference
			für jedes $x_0$ mit $f(x_0) \le C$ gegen das globale Minimum.

			%fixme: Reicht auch nur die strikte konvexität?
			Siehe \ref{2.27}.
	\end{enumerate}
\end{kor}

\coursetimestamp{04}{11}{2013}

\begin{st}[Röhm] \label{2.27}
	Ist $f: \R^n \to \R$ konvex und besitzt ein eindeutiges Minimum, so sind alle Niveaumengen beschränkt.
	Insbesondere konvergiert das Gradientenverfahren für strikt konvexe Funktionen mit Minimum für jede Wahl des Anfangswertes gegen das Minimum.
	\begin{proof}
		Sei $f$ konvex und $\hat x \in \R^n$ der Minimierer von $f$.
		Zu jedem Radius $r > 0$ definiere
		\[
			C_r := \min \{ f(x) : x \in \boundary B_r (\hat x) \}.
		\]
		Wir zeigen, dass
		\begin{enumerate}[(a)]
			\item
				$f^{-1}(]-\infty, C_r) \subset \_{B_r(\hat x)}$,
			\item
				$C_r \to \infty$ für $r \to \infty$.
		\end{enumerate}
		Sei $r > 0$ und $x \not\in \_{B_r(\hat x)}$.
		Für $t := \f r{\|x - \hat x\|}$ gilt $0 < t < 1$ und
		\[
			\hat x + t(x-\hat x) \in \boundary B_r(\hat x).
		\]
		Also
		\begin{align*}
			C_r
			\le f(\hat x + t(x-\hat x))
			&\le (1-t) f(\hat x) + tf(x) \\
			&< (1-t) f(x) + t f(x)
			= f(x)
		\end{align*}
		und somit (a) gezeigt.
		Es folgt daraus außerdem
		\[
			f(x)
			\ge \f 1t C_R - \f 1t f(\hat x) + f(\hat x)
			= \f {\|x-\hat x\|}r (C_r - f(\hat x)) + f(\hat x).
		\]
		Für alle $R > r$ gilt
		\[
			C_R = \min \{ f(x) : x \in \boundary B_R(\hat x) \}
			\ge \f Rr (C_r - f(\hat x)) + f(\hat x)
			\to \infty
		\]
		für $R \to \infty$.
	\end{proof}
\end{st}

\subsection{Nachteile des Gradientenverfahrens}

Für $f(x) = x^T A x$ mit $A = \Id$ liefert die Gradientenrichtung die „perfekte Suchrichtung“, mit der Minimierungsregel (“line search”, d.h. suche globales Minimierung in Richtung der Suchrichtung) findet das Gradientenverfahren das Minimimum in einem Schritt.

Für $f(x) = x^T A x$ mit $A = \begin{psmallmatrix}1 & 0 \\ 0 & 4\end{psmallmatrix}$ kann sich dagegen sogenanntes “zig-zagging” ergeben, was zu langsamer Konvergenz führt (siehe \coursehref{Blatt4.pdf}{Übungsaufgabe 4.4}).


\section{Allgemeine Abstiegsverfahren}


Es sei hier weiterhin stets $f: \R^n \to \R$ stetig differenzierbar.

\begin{alg} \label{alg:3}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\Require{Suchrichtungen und Schrittweiten $d_k, s_k$}
		\For{$i \gets 1, 2, \dotsc$}
			\If{$\nabla f(x_k) = 0$}
				\Return{$x_k$}
			\EndIf
			\State{$x_{k+1} \gets x_k + s_k d_k$}
		\EndFor
	\end{algorithmic}
\end{alg}

\subsection{Ein allgemeines Konvergenzresultat}

Wenn wir in \ref{alg:3} für alle $k \in \N$ fordern, dass
\[
	\nabla f(x_k)^T d_k < 0
	\qquad\text{und}\qquad
	f(x_k + s_k d_k) < f(x_k),
\]
dann können wir interessante Konvergenzresultate zeigen.
Im Beweis von \ref{2.24} folgte aus dieser Bedingung sofort, dass (falls es eine konvergente Teilfolge der $x_k$ gibt) $f(x_k)$ konvergiert, also insbesondere
\[
	f(x_k) - f(x_{k+1}) \to 0.
\]

\begin{df} \label{2.28}
	Das allgemeine Abstiegsverfahren in \ref{alg:3} besitzt
	\begin{enumerate}[(a)]
		\item
			\emph{zulässige Schrittweiten}, falls
			\[
				f(x_k + s_k d_k) < f(x_k)
			\]
			und für jede konvergente Teilfolge $(x_l)_{l\in L}$ der Iterierten gilt
			\[
				f(x_k) - f(x_{k+1}) \to 0
				\quad\implies\quad
				\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
			\]
		\item
			\emph{zulässige Suchrichtungen}, falls
			\[
				\nabla f(x_k)^T d_k < 0
			\]
			und für jede konvergente Teilfolge $(x_l)_{l\in L}$ der Iterierten gilt
			\[
				\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
				\quad\implies\quad
				\lim_{L \ni l \to \infty} \nabla f(x_l) = 0.
			\]
	\end{enumerate}
\end{df}

\begin{st}[Präkonvergenz allgemeiner Abstiegsverfahren] \label{2.29}
	Das allgemeine Abstiegsverfahren in \ref{alg:3} besitze zulässige Schrittweiten und Suchrichtungen.
	Dann terminiert das Verfahren nach endlich vielen Schritten an einem stationären Punkt $x_k$ oder es erzeugt eine Folge $(x_k)_{k\in\N}$ mit
	\begin{enumerate}[(a)]
		\item
			$f(x_{k+1}) < f(x_k)$,
		\item
			Jeder Häufungspunkt von $(x_k)$ ist ein stationärer Punkt.
	\end{enumerate}
	\begin{proof}
		Aussage (a) geht direkt aus der Definition zulässiger Schrittweiten hervor.

		Konvergiert eine Teilfolge $(x_l)_{l\in L}$ der Iterierten gegen ein $x \in \R^n$, so folgt wie in \ref{2.24}, dass
		\[
			f(x) = \lim_{L \ni l \to \infty} f(x_l) = \lim_{k \to \infty} f(x_k),
		\]
		also $f(x_k) - f(x_{k+1}) \to 0$.
		Daraus folgt mit den Definitionen der zulässigen Schrittweiten/Suchrichtungen die Aussage (b).
	\end{proof}
\end{st}

\subsection{Interpretation der Zulassungsbedingungen}

\paragraph{Zulässigkeit der Suchrichtungen:}
\[
	0 <
	-\nabla f(x_k)^T d_k
	= \|\nabla f(x_k)\|\|d_k\| \cos \angle(-\nabla f(x_k), d_k),
\]
also genau dann, wenn
\[
	\cos \angle(-\nabla f(x_k), d_k) > 0.
\]
Suchrichtungen sollen zur Richtung des steilsten Abstiegs einen Winkel betragsmäßig $< \f \pi2$ besitzen.
Eine Naheliegende Forderung wäre, dass der Winkel „gleichmäßig“ unter $\f \pi 2$ liegt, also
\[
	\exists \alpha > 0 \forall k\in \N : \underbrace{\cos \angle(-\nabla f(x_k), d_k)}_{= \f {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|}} \ge \alpha.
\]
Solche Bedingungen werden auch \emph{Winkelbedingungen} genannt.

\begin{st} \label{2.30}
	Seien $(d_k)_{k\in\N}$  die Suchrichtungen eines allgemeine Abstiegsverfahren.
	Gilt die Winkelbedingung
	\[
		\exists \alpha > 0:
		\dfrac {-\nabla  f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|} \ge \alpha,
	\]
	so sind die Suchrichtungen zulässig.
	\begin{proof}
		Aus der Winkelbedingung folgt $\nabla f(x_k)^T d_k < 0$ und
		\[
			\|\nabla f(x_k)\|
			\le \f 1\alpha \f {-\nabla f(x_k)^T d_k}{\|d_k\|},
		\]
		also sind die Suchrichtungen zulässig.
	\end{proof}
\end{st}

\coursetimestamp{06}{11}{2013}

% Betrachtet man \ref{2.30}, so sieht man, dass für $-\f{\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$ für eine konvergente Teilfolge $(x_l)_{l\in L}$ auch $\nabla f(x_l) \to 0$
% fixme: Erläuterung

\begin{nt} \label{2.31}
	Die Suchrichtungen sind schon dann zulässig, wenn sie \emph{verallgemeinerte Winkelbedingung} erfüllen, z.B.
	\[
		\exists \alpha > 0, p > -1
		: \dfrac {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\| \|d_k\|}
		\ge \alpha \|\nabla f\|^p,
	\]
	oder
	\[
		\exists \alpha_1, \alpha_2 > 0, p > -1
		: \dfrac {-\nabla f(x_k)^Td_k}{\|\nabla f(x_k)\|\|d_k\|} \ge \min\{ \alpha_1, \alpha_2 \|\nabla f\|^p \}.
	\]
	\begin{proof}
		 \coursehref{Blatt5.pdf}{Übungsaufgabe 5.2}
	\end{proof}
\end{nt}

\begin{ex} \label{2.32}
	\begin{enumerate}[(a)]
		\item
			Die Suchrichtungen $d_k = -\nabla f(x_k)$ erfüllen offensichtlich die Winkelbedingungen.
		\item
			Seien $A_k \in \R^{n\times n}$ symmetrisch positiv definite Matrizen mit
			\[
				0
				< c
				< \lambda_{\text{min}}(A_k)
				\le \lambda_{\text{max}}(A_k)
				\le C
				< \infty
			\]
			für alle $k \in \N$.
			Betrachte
			\[
				d_k := - A_k^{-1} \nabla f(x_k).
			\]
			Es gilt
			\begin{align*}
				\dfrac {-\nabla f(x_k)^T d_k}{\|\nabla f(x_k)\|\|d_k\|}
				&= \dfrac {\nabla f(x_k)^T A_k^{-1} \nabla f(x_k)}{\|\nabla f(x_k)\|\|A^{-1} \nabla f(x_k)\|} \\
				&\ge \dfrac {\lambda_{\text{min}} (A_k^{-1}) \|\nabla f(x_k)\|^2}{\|A_k^{-1}\| \|\nabla f(x_k)\|^2} \\
				&= \dfrac {\lambda_{\text{min}}(A^{-1})}{\lambda_{\text{max}}(A_k^{-1})}
				= \dfrac {\lambda_{\text{min}}(A_k)}{\lambda_{\text{max}}(A_k)}
				\ge \f cC
				> 0.
			\end{align*}
	\end{enumerate}
\end{ex}

\paragraph{Zulässigkeit der Schrittweiten}
Für $f \in C^2(\R^n)$ folgt aus \ref{2.3}, dass ein $\sigma \in [0,s]$ existiert mit
\begin{align*}
	f(x+sd)
	&= f(x) + s\nabla f(x)^T d + \f {s^2}2 d^T \nabla^2 f(x + \sigma d)d \\
	&\le f(x) + s\nabla f(x)^T d + \f {s^2}2 C \|d\|^2,
\end{align*}
wobei $C := \max_{\sigma\in[0,s]} \|\nabla^2 f(x + \sigma d) \|$.
Die rechte Seite ist dabei minimal für
\[
	s^* = \f{-f(x)^T d}{C\|d\|^2}.
\]
Dann ist
\[
	f(x+s^*d)
	\le f(x) - \f{|\nabla f(x)^T d|^2}{2C\|d\|^2},
\]
also ist in Suchrichtung $d$ mit Schrittweite $s^*$ eine Verkleinerung von $f$ um mindestens $\f 1{2C} \f {|\nabla f(x)^T d|^2}{\|d\|^2}$ möglich.

\begin{df} \label{2.33}
	Seien $(d_k)_{k\in \N}$ und $(s_k)_{k\in\N}$ Suchrichtungen und Schrittweiten eines Abstiegsverfahren.
	Die Schrittweiten heißen \emph{effizient}, falls
	\[
		\exists \theta > 0 \forall k \in \N
		: f(x_k + s_k d_k) \le f(x_k) - \theta \f {|\nabla f(x_k)^T d_k|^2}{\|d_k\|^2}.
	\]
\end{df}

\begin{st} \label{2.34}
	Seien $(d_k)_{k\in\N}$ und $(s_k)_{k\in\N}$ die Suchrichtungen und Schrittweiten eines allgemeinen Abstiegsverfahrens, das $f(x_k + s_k d_k) < f(x_k)$ erfüllt.
	Sind die Schrittweiten effizient, dann sind sie auch zulässig.
	\begin{proof}
		$f(x_k+s_kd_k) < f(x_k)$ ist klar.
		Es gilt
		\[
			\theta \f {|\nabla f(x_k)^T d_k|^2}{\|d_k\|^2}
			\le f(x_k) - f(x_{k+1}),
		\]
		also
		\[
			\f{|\nabla f(x_k)^T d_k|}{\|d_k\|} \to 0,
		\]
		falls $f(x_k) - f(x_{k+1}) \to 0$.
	\end{proof}
\end{st}

\begin{nt*}
	Die Armijo-Schrittweiten sind nicht effizient.

	Armijo akzeptiert (für das Gradientenverfahren) Abnahmen in der Größenordnung $\|\nabla f(x_k)\|$, während die Effizienz aber eine Größenordnung von $\|\nabla f(x_k)\|^2$ fordert.

	\begin{proof}
		Armijo-Schrittweiten sind nicht effizient, da sie nicht zulässig sind (siehe \ref{2.35}).
	\end{proof}
\end{nt*}

\subsection{Zulässigkeit der Armijo-Schrittweitenregel}

Für $f(x) = -x$ ist $d_k = - \nabla f(x) = 1$ und Armijo akzeptiert stets $s_k = 1$.
Für $d_k' = - \f{\nabla f(x_k)}{2^k} = \f 1{2^k}$ akzeptiert Armijo ebenfalls stets $s_k' = 1$.
Die Winkelbedingungen sind in beiden Fällen erfüllt, aber im zweiten Fall konvergiert eine konvergente Teilfolge nicht gegen einen stationären Punkt.
Also sind Armijo-Schrittweiten im Allgemeinen nicht zulässig.

\begin{ex} \label{2.35}
	Die Armijo-Regel mit Suchrrichtungen
	\[
		d_k := -2^{-k} \nabla f(x)
	\]
	konvergiert nicht für $f(x) = -x$.
	Armijo-Schrittweiten können also nicht zulässig sein.
\end{ex}

\begin{st} \label{2.36}
	Seien $(d_k)_{k\in\N}$ Abstiegsrichtungen.
	Existiert für jede konvergente Folge $(x_l)_{l\in L}$ eine streng monoton wachsende Funktion $\phi: [0,\infty) \to [0,\infty)$ mit
	\[
		\|d_l\|
		\ge \phi \big( \f{-\nabla f(x_l)^T d_l}{\|d_l\|} \big)
	\]
	für alle $l \in L$.
	Dann sind die Armijo-Schrittweiten zulässig.
	\begin{proof}
		Zeige gemäß \ref{2.28}
		\[
			\forall k\in\N : f(x_k + s_k d_k) < f(x_k)
		\]
		und für jede konvergente Teilfolge $(x_l)_{l\in L}$:
		\[
			\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0
			\quad \implies\quad
			\lim_{L \ni l \to \infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0.
		\]
		Nach \ref{2.21} liefert die Armijo-Regel eine Schrittweite $s_k$ mit
		\[
			f(x_k + s_k d_k)
			\le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k
			< f(x_k).
		\]
		Sei $f(x_k) - f(x_{k+1}) \to 0$ und sei $(x_l)_{l\in L}$ eine konvergente Teilfolge der Iterierten.
		Angenommen $\f {\nabla f(x_l)^T d_l}{\|d_l\|} \not\to 0$ für $L \ni l \to \infty$, d.h.
		\[
			\exists \eps > 0 \forall l \in L' \subset L : \f{\nabla f(x_l)^T d_l}{\|d_l\|} < - \eps
		\]
		mit $|L'| = \infty$.
		Außerdem
		\[
			-\gamma \f {\nabla f(x_k)^T d_k}{\|d_k\|} s_k \|d_k\|
			= - \gamma s_k \nabla f(x_k)^T d_k
			\le	f(x_k) - f(x_{k+1})
			\to 0.
		\]
		Also
		\[
			\lim_{L' \ni l \to \infty} s_l \|d_l\| = 0.
		\]
		Außerdem folgt für alle $l \in L'$
		\[
			\|d_l\|
			\ge \phi(\f{-\nabla f(x_l)^T d_l}{\|d_l\|})
			> \phi(\eps)
			> \phi(0)
			\ge 0.
		\]
		und somit $s_l \to 0$.
		Der Rest funktioniert wie im Beweis von \ref{2.24} und man erhält
		%fixme: prüfen
		\[
			0
			\le (1-\gamma) \f {-\nabla f(x_l)^T d_l}{\|d_l\|}
			< \f {\nabla f(x_l+ \sigma_l d_l) - \nabla f(x_l)^Td_l}{\|d_l\|}
			\le \|\nabla f(x_l + \sigma_l d_l) - \nabla f(x_l)\|.
		\]
		Aus $s_l \|d_l\| \to 0$ folgt $\sigma_l d_l \to 0$.
		Da auch $(x_l)$ konvergiert, existiert ein $r > 0$ mit
		\[
			x_l, x_l + \sigma_l d_l \in \_{B_r(0)}.
		\]
		Auf $\_{B_r(0)}$ ist $\nabla f$ also gleichmäßig stetig und damit
		\[
			\nabla f(x_l + \sigma_le d_l) - \nabla f(x_l) \to 0
		\]
		und somit $\f{-\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$.
	\end{proof}
\end{st}

\begin{ex} \label{2.37}
	Für das Gradientvenverfahren mit $d_k := -\nabla f(x_k)$ ist
	\[
		\|d_k\|
		=\|\nabla f(x_k)\|
		=\phi(\f{-\nabla f(x_k)^T d_k}{\|d_k\|})
	\]
	mit $\phi(x) = x$.
	Mit \ref{2.36} und \ref{2.29} folgt also noch einmal die Aussage aus \ref{2.24}.
\end{ex}

\subsection{Die Powell-Wolfe-Schrittweitenregel}

Es gibt Varianten der Armijo-Regel, die zulässig sind, z.B. Armijo mit Aufweitung, Armijo-Bedingung auch als Schranken in beide Richtungen an Abstieg, Goldstein-Regel.

\paragraph{Die Idee hinter Powell-Wolfe}
In den Beweisen von \ref{2.24} und \ref{2.36} wurde verwendet
\[
	\gamma \nabla f(x_l)^T d_l
	< \nabla f(x_l + \sigma_l d_l)^T d_l
\]
mit einer Zwischenstelle $\sigma_l \in [0, s_l]$.
Naheliegend ist jetzt ein Algorithmus, der einen solchen Zusammenhang explizit fordert.
Es wird also zur aktuellen Iterierten $x$ und Suchrichtung $d$ eine Schrittweite $s$ gesucht, die
\begin{align}
	f(x+sd) - f(x)
	&\le \gamma s \nabla f(x)^T d \label{eq:pw1}\\
	\nabla f(x+sd)^T d
	&\ge \eta \nabla f(x)^T d \label{eq:pw2}
\end{align}
mit $0 < \gamma < 1$ und $\gamma < \eta < 1$ erfüllt.

\begin{alg} \label{alg:4}
	\begin{algorithmic}
		\Require{$0<\gamma < 1, \gamma < \eta < 1$}
		\Require{aktuelle Iterierte $x$, Richtung $d\in\R^n$}
		\State{$s^- \gets 2$}
		\Repeat
			\State{$s^- \gets \f {s^-}2$}
		\Until{$s^-$ erfüllt Armijo}
		\State{$s^+ \gets s^-$}
		\Repeat
			\State{$s^+ \gets 2s^+$}
		\Until{$s^+$ verletzt Armijo}
		\While{$s^-$ verletzt Powell-Wolfe}
		\State{$s^{(0)} \gets \f {s^+ + s^-}2$}
		\If{$s^{(0)}$ erfüllt Armijo}
			\State{$s^- \gets s^{(0)}$}
		\Else
			\State{$s^+ \gets s^{(0)}$}
		\EndIf
		\EndWhile
		\State{\Return $s \gets s^-$}
	\end{algorithmic}
\end{alg}

\begin{st} \label{2.38}
	Seien $0<\gamma<1$ und $\gamma<\eta<1$.
	Sei $d$ eine Abstiegsrichtung für $f$ im Punkt $x$.
	Weiter sei $f$ in Richtung $d$ nach unten beschränkt: $\inf_{t\ge 0}f(x+td) > -\infty$.

	Dann terminiert \ref{alg:4} nach endlich vielen Schritten und liefert eine Schrittweite $s$, die \ref{eq:pw1}, \ref{eq:pw2} erfüllt.
	\begin{proof}
		Die erste Repeat-Schleife terminiert wegen \ref{2.21} (für $s$ klein genug ist die Armijo-Bedingung erfüllt).

		Für die zweite Repeat-Schleife betrachte
		\[
			-\infty
			< \inf_{s\ge 0} f(x+sd)
			\le f(x+s^+ d
			\le f(x) + \gamma s^+ \nabla f(x)^T d
			\xrightarrow{s^+\to\infty} -\infty.
		\]
		Also kann $s^+$ nicht beliebig groß werden und die Schleife terminiert nach endlich vielen Schritten mit einem $s^+$, welches \ref{eq:pw1} verletzt.

		Für die While-Schleife betrachte die stetige Funktion
		\[
			g(s) := f(x+sd) - f(x) - \gamma s \nabla f(x)^T d,
		\]
		welche in $s^*$ eine Nullstelle hat.
		Zeige:
		\begin{enumerate}[(i)]
			\item
				In $s^*$ ist \ref{eq:pw1} erfüllt.
			\item
				Für $s \in \R$ mit $g(s) > 0$ ist \ref{eq:pw1} nicht erfüllt.
			\item
				Für $s \in \R$ mit $g(s) \le 0$ ist \ref{eq:pw1} erfüllt.
		\end{enumerate}
		Dann terminiert \ref{alg:4} nach endlich vielen Richtten und liefert eine Schrittweite $s$, die \ref{eq:pw1} und \ref{eq:pw2} erfüllt.

		Die Intervallhalbierung sucht nach einem $s^*$ an dem \ref{eq:pw1} noch erfüllt ist und erzeugt dabei eie Folge von $s^-$, die monoton steigend gegen $s^*$ konverrgiert und für alle Folgenglieder gilt $g(s^-) \le 0$.
		Genauso wird eine Folge von $s^+$ erzeugt, die monoton fallen gegen $s^*$ konvergiert und es gilt $g(s^+) > 0$.

		An $s^*$ gilt
		\[
			0
			\le g'(s^*)
			= \nabla f(x+sd)^T d - \gamma \nabla f(x)^T d
		\]
		(vgl. \ref{eq:pw2}).

		Da $g$ stetig ist, liegt zu jedem $\eps > 0$ für hinreichend viele Schleifendurchgänge $s^-$ nahe genug an $s^*$, sodass gilt
		\[
			g'(s^t) > - \eps.
		\]
		Mit $\eps := (\gamma - \eta) \nabla f(x)^T d$ folgt, dass nach endlich vielen Schleifendurchgängen gilt
		\[
			\nabla f(x+s^- d)^T d - \gamma \nabla f(x)^T d
			= g'(s^-)
			> - \eps
			= (\nabla - \gamma) \nabla f(x)^T d,
		\]
		also gilt $\nabla f(x+s^- d)^T d > \eta \nabla f(x)^T d$, was \ref{eq:pw2} entspricht.
	\end{proof}
\end{st}

\begin{st} \label{2.39}
	Sei $f$ nach unten beschränkt, $(d_k)_{k\in\N}$ Abstiegsrichtungen.
	Dann sind die durch die Powell-Wolfe-Regel erzeugten Schrittweiten zulässig.
	\begin{proof}
		Zeige $f(x_{k+1}) < f(x_k)$ und für jede konvergente Teilfolge $(x_l)_{l\in L}$
		\[
			\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0.
			\quad\implies\quad
			\lim_{L\ni l \to\infty} \f{\nabla f(x_l)^T d_l}{\|d_l\|} = 0
		\]
		Da $f$ nach unten beschränkt ist, erzeugt \ref{alg:4} nach \ref{2.38} für jedes $k \in \N$ eine Schrittweite $s_k > 0$, die \ref{eq:pw1}, \ref{eq:pw2} erfüllen.
		Damit gilt
		\[
			f(x_{k+1})
			= f(x_k + s_k d_k)
			\le f(x_k) + \gamma s_k \nabla f(x_k)^T d_k
			f(x_k).
		\]
		Sei jetzt $\lim_{k\to\infty} f(x_k) - f(x_{k+1}) = 0$ und $(x_l)_{l\in L}$ eine konvergente Teilfolge der Iterierten $(x_k)_{k\in\N}$.
		Angenommen
		\[
			\lim_{L\ni l\to\infty} \f{\nabla f(x_l)^T d}{\|d_l\|} \le -\eps < 0,
		\]
		d.h. \oBdA für alle $l \in L$
		\[
			- \f {\nabla f(x_l)^T d_l}{\|d_l\|} > \eps.
		\]
		Es gilt
		\[
			0 \leftarrow
			f(x_k) - f(x_{k+1})
			\ge -\gamma s_k \nabla f(x_k)^T d_k
			= s_k \gamma \|d_k\| \underbrace{\f{-\nabla f(x_k)^T d_k}{\|d_k\|}}_{> \eps},
		\]
		also $\lim_{L\ni l\to\infty} s_l \|d_l\| = 0$.

		Es gilt
		\[
			\nabla f(x_l + s_l d_l)^T d_l \ge \underbrace{\eta}_{<1} \underbrace{\nabla f(x_l)^T d_l}_{<0},
		\]
		also
		\begin{align*}
			0
			&\le -(1-\eta)\nabla f(x_l)^T d_l \f 1{\|d_l\|} \\
			&= \f 1{\|d_l\|}\big( \eta \nabla f(x)^T d_l - \nabla f(x_l)^T d_l \big) \\
			&\le \f 1{\|d_l\|} \big( \nabla f(x_l + s_l d_l)) - \nabla f(x_l) \big)^T d_l \\
			&\le \big\|\nabla f(x_l + s_l d_l) -\nabla f(x_l) \big\|
		\end{align*}
		Zeige $\|\nabla f(x_l + s_l d_l) -\nabla f(x_l)\| \to 0$, denn dann gilt auch $- \f{\nabla f(x_l)^T d_l}{\|d_l\|} \to 0$, was ein Widerspruch wäre.

		Wegen $\lim_{L\ni l\to\infty} s_l d_l = 0$ existiert eine kompakte Menge, die fast alle $x_l, x_l + s_l d_l$ enthält.
		$\nabla f$ ist auf dieser kompakten Menge gleichmäßig stetig, also
		\[
			\lim_{L\ni l\to\infty} \big\|\nabla f(x_l + s_l d_l) -\nabla f(x_l) \big\| \to 0.
		\]
	\end{proof}
\end{st}


\section{Das Newton-Verfahren}


In diesem Abschnittt sei $f: \R^n \to \R$ stets zweimal stetig differenzierbar.
Wenn $\hat x$ Minimum von $f$ ist, dann auch Nullstelle von $F := \nabla f : \R^n \to \R$.
Wir verfolgen jetzt die Idee, das Minimum zu bestimmen, indem wir mit dem Newton-Verfahren die Nullstellle von $F = \nabla f$ finden.

\subsection{Das Newton-Verfahren für Gleichungsysteme}

Sei $F: \R^n \to \R^n$ stetig differenzierbar.
Betrachte das nicht-lineare Gleichungsystem
\[
	F(x) \stack != 0.
\]
Approximiere $F$ durch seine lineare Näherung in der aktuellen Iterierten $x_k$:
\[
	0
	= F(x)
	= F(x_k) + F'(x_k)(x-x_k).
\]
Es ergibt sich damit die Iteration
\[
	x_{k+1}
	:= x_k - F'(x_k)^{-1} F(x_k).
\]

\begin{alg}[Newton-Verfahren] \label{alg:5}
	\begin{algorithmic}
		\Require{Startwert $x_0 \in \R^n$}
		\State{$k \gets 0$}
		\While{$F(x_k) \neq 0$}
			\State{$d_k \gets -F'(x_k)^{-1} F(x_k)$}
			\State{$x_{k+1} \gets x_k + d_k$}
		\EndWhile
	\end{algorithmic}
\end{alg}

Das Newton-Verfahren konvergiert nicht für jeden Startwert, es Beispiele für alternierende Iterierte und für strikte Divergenz.
% fixme: Beispiele für Nicht-Konvergenz

Für $q \in \R, |q| < 1$ gilt
\[
	\sum_{n=0}^\infty = \f 1{1-q}.
\]
Dies lässt sich auch für Matrizen verallgemeinern.

\begin{lem}[Neumannsche Reihe] \label{2.40}
	Für alle $A \in \R^{n\times n}$ mit $\|A\| < 1$ ist $(I-A)$ invertierbar und es konvergiert die \emph{Neumannsche Reihe}
	\[
		\sum_{k=0}^\infty A^k
		= (I-A)^{-1}
	\]
	Insbesondere gilt
	\[
		\|(I-A)^{-1}\|
		\le \f 1{1-\|A\|}.
	\]
	\begin{proof}
		Sei $S_l = \sum_{k=0}^l A^k$.
		Dann gilt für $m \ge l$
		\begin{align*}
			\|S_m - S_l\|
			&= \Big\| \sum_{k=l+1}^m A^k \Big\| \\
			&\le \sum_{k=l+1}^m \|A\|^k
			= \|A\|^{l+1} \sum_{k=0}^{m-l-1} \|A\|^k
			\le \f{\|A\|^{l+1}}{1-\|A\|}
			< \eps
		\end{align*}
		für genügend großes $l$.
		Also ist $(S_l)_{l\in\N}$ ein Cauchy-Folge und der Grenzwert existiert.
		Es gilt
		\[
			(I-A) \sum_{k=0}^\infty A^k
			= \sum_{k=0}^\infty A^k - \sum_{k=0}^\infty A^{k+1}
			= I.
		\]
		Damit ist $(I-A)$ invertierbar und $(I-A)^{-1} = \sum_{k=0}^\infty A^k$ und
		\[
			\Big\| \sum_{k=0}^\infty A^k \Big\|
			\le \sum_{k=0}^\infty \|A\|^k
			= \f 1{1-\|A\|}.
		\]
	\end{proof}
\end{lem}

\begin{lem}[Lemma von Banach] \label{2.41}
	Sei $A \in \R^{n\times n}$ invertierbar und $B \in \R^{n\times n}$ erfülle $\|A^{-1} B\| < 1$.
	Dann ist $A + B$ invertierbar und es gilt
	\begin{align*}
		\|(A + B)^{-1}\|\
		&\le \f {\|A^{-1}\|}{1-\|A^{-1}B\|} \\
		\|(A+B)^{-1} - A^{-1}\|
		&\le \f {\|A^{-1}\|\|A^{-1}B\|}{1-\|A^{-1}B\|}
	\end{align*}
	\begin{proof}
		Wende \ref{2.40} auf $-A^{-1}B$ an, also ist $I + A^{-1}B$ invertierbar und
		\[
			A + B
			= A(I + A^{-1}B)
		\]
		auch invertierbar (Produkt invertierbarer Matrizen.
		Außerdem ist
		\[
			\|(A+B)^{-1}\|
			\le \|A^{-1}\| \|(I+A^{-1}B)^{-1}\|
			\stack{\ref{2.40}}\le \f {\|A^{-1}\|}{1-\|A^{-1}B\|}
		\]
		und
		\begin{align*}
			(A+B)^{-1} - A^{-1}
			&= (I + A^{-1}B)^{-1}A^{-1} - A^{-1} \\
			&= (I + A^{-1}B)^{-1} - I) A^{-1} \\
			&= \bigg(\sum_{k=0}^\infty (-A^{-1}B)^k - I\bigg) A^{-1} \\
			&= \sum_{k=1}^\infty (-A^{-1}B)^k A^{-1} \\
			&= (-A^{-1}B) \sum_{k=0}^\infty (-A^{-1}B)^k A^{-1} \\
			&= (-A^{-1}B) (I + A^{-1}B)^{-1} A^{-1},
		\end{align*}
		also in der Norm
		\[
			\|(A+B)^{-1} - A^{-1}\|
			\le \f {\|A^{-1}\| \|A^{-1}\|}{1-\|A^{-1}B\|}.
		\]
	\end{proof}
\end{lem}

\begin{kor} \label{2.42}
	Aus \ref{2.41} folgt, dass jedes invertierbare $A \in \R^{n\times n}$ eine Umgebung invertierbarer Matrizen
	\[
		\scr U_\delta
		:= \Set{ \tilde A \in \R^{n\times n} | \|\tilde A - A\| < \delta },
	\]
	wobei z.B. $\delta := \f 1{\|A\|^{-1}}$.
	Außerdem gilt für jede konvergente Folge $(A_k)_{k\in\N} \to A$ invertierbarer Matrizen mit invertierbarem Grenzwert $A$, gilt auch
	\[
		A_k^{-1} \to A^{-1}
	\]
	für $k \to \infty$.
	Die Menge der invertierbaren Matrizen ist alos offen und die Inversion eine stetige Abbildung auf dieser Menge.
\end{kor}

\begin{lem} \label{2.43}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $\hat x$ sei eine Nullstelle von $F$ mit invertierbarer Jacobi-Matrix $F'(\hat x)$.
	Dann existieren $\delta, \gamma > 0$, mit
	\[
		\|F(x)\|
		\ge \gamma \|x-\hat x\|
	\]
	für alle $x \in B_\delta(\hat x)$.
	Insbesondere ist $\hat x$ die einzige Nullstelle von $F$ in $B_\delta(\hat x)$.
	\begin{proof}
		Es gilt
		\[
			\|x-\hat x\| \le \|F'(\hat x)^{-1}\| \|F'(\hat x)(x-\hat)\|,
		\]
		also
		\[
			\|F'(\hat x)(x-\hat x)\|
			\ge 2\gamma \|x - \hat x\|
		\]
		mit $\gamma := \f 1{2\|F'(\hat x)^{-1}\|}$.
		Für hinreichend nah an $\hat x$ liegende $x$ gilt nach \ref{2.4}
		\[
			\|F(x) - \underbrace{F(\hat x)}_{=0} - F'(\hat x)(x-\hat x) \|
			\le \gamma \|x-\hat x\|,
		\]
		also
		\begin{align*}
			2\gamma \|x-\hat x\|
			\le \|F'(\hat x)(x-\hat x)
			&\le \|F(x) - F'(\hat x)(x-\hat x) \| + \|F(x)\| \\
			&\le \gamma \|x-\hat x\| + \| F(x) \|.
		\end{align*}
	\end{proof}
\end{lem}

\begin{df} \label{2.44}
	Eine Folge $(x_k)_{k\in\N} \subset \R^n$ konvergiert
	\begin{enumerate}[(a)]
		\item
			\emph{linear} mit Rate $0 < \gamma < 1$ gegen $x \in \R^n$, falls
			\[
				\|x_{k+1} - x\| \le \gamma \|x_k - x\|
			\]
			für fast alle $k \in \N$.
		\item
			\emph{superlinear} gegen $x \in \R^n$, falls $x_k \to x$ und
			\[
				x_{k+1} - x
				= o(x_k - x),
			\]
			d.h.
			\[
				\lim_{k\to\infty} \f {\|x_{k+1}-x\|}{\|x_k - x\|} \to 0.
			\]
		\item
			\emph{quadratisch} gegen $x\in \R^n$, falls $x_k \to x$ und
			\[
				x_{k+1} - x
				= O(\|x_k - x\|^2),
			\]
			d.h.
			\[
				\exists C > 0 \forall k\in \N : \|x_{k+1} - x \| \le C \|x_k - x\|^2.
			\]
	\end{enumerate}
\end{df}

\begin{nt} \label{2.45}
	Bei linearer Konvergenz wächst die Anzahl der richtigen Nachkommastellen pro Schritt um eine konstante Anzahl.
	Bei quadratischer Konvergenz verdoppelt sich die Anzahl der richtigen Nachkommastellen pro Schritt.
\end{nt}

\coursetimestamp{20}{11}{2013}

\begin{st}[Lokale Konvergenz des Newton-Verfahrens für Gleichungsysteme] \label{2.46}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $\hat x$ sei Nullstelle von $F$ mit invertierbarer $F'(\hat x) \in \R^{n\times n}$.
	Dann existieren $\delta, C > 0$ so dass
	\begin{enumerate}[(a)]
		\item
			$\hat x$ ist die einzige Nullstelle von $F$ auf $B_\delta(\hat x)$,
		\item
			$F'(x)$ ist invertierbar und $\|F'(x)^{-1}\| \le C$ für alle $x \in B_\delta(\hat x)$.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ liegen alle von \ref{alg:5} erzeugten Iterierten in $B_\delta(\hat x)$.
			Insbesondere ist \ref{alg:5} durchführbar.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ terminiert \ref{alg:5} entweder nach endlich vielen Schritten an $\hat x$ oder er erzeugt eine Folge, die superlinear gegen $\hat x$ konvergiert.
		\item
			Ist $F'$ zusätlich Lipschitz-stetig mit Konstante $L$, d.h.
			\[
				\forall x,y \in B_\delta(\hat x) : \|F'(x) - F'(y)\| \le L \|x-y\|,
			\]
			dann ist die Konvergenz in (a) sogar quadratisch und es gilt
			\[
				\|x_{k+1} - \hat x \| \le \f {CL}2 \|x_k - \hat x\|^2
			\]
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}[(a)]
			\item
			\item
				Folgen aus \ref{2.43} und \ref{2.41}.
			\item
			\item
				Für jedes $x_k$ in dem $F'(x_k)$ invertierbar ist, gilt
				\begin{align*}
					x_{k+1} - \hat x
					&= x_k - F'(x_k)^{-1}F(x_k) - \hat x \\
					&= F'(x_k)^{-1}\big( F'(x_k) (x_k-\hat x) - F(x_k) + F(\hat x) \big) \\
					&= F'(x_k)^{-1}\bigg( F'(x_k) (x_k-\hat x) \\
					& \qquad\qquad\qquad\qquad - \int_0^1 F'(\hat x + t(x_k-\hat x))(x_k - \hat x) \dx[t] \bigg) \\
					&=F'(x_k)^{-1}\int_0^1 \big( F'(x_k) - F'(\hat x + t(x_k - \hat x)) \big)(x_k - \hat x) \dx[t],
				\end{align*}
				also
				\[
					\|x_{k+1} - \hat x\|
					\le \|x_k-\hat x\|\|F'(x_k)^{-1}\| \underbrace{\sup_{t\in [0,1]} \| F'(x_k) - F'(\hat x + t(x_k-\hat x)) \|}_{\to 0}
				\]
				Sei $\delta$ so klein (siehe (a) und (b)), dass
				\[
					\sup_{t\in[0,1]} \|F'(x_k) - F'(\hat x + t(x_k - \hat x))\|
					\le \f 1{2C}
				\]
				für alle $x_k \in B_\delta(\hat x)$.
				Dann gilt für alle $x_k \in B_\delta(\hat x)$
				\[
					\|x_{k+1} - \hat x\| \le \f 12 \| x_k - \hat x\|.
				\]
				Für $x_0 \in B_\delta(\hat x)$ folgt $x_k \in B_\delta(\hat x)$ für alle $k \in \N$ und $x_k \to \hat x$.
				Es gilt sogar
				\[
					\f {\|x_{k+1} - \hat x\|}{\|x_k - \hat x\|} \le C \sup_{t\in [0,1]} \| F'(x_k) - F'(\hat x  + t(x_k + \hat x)) \| \to 0.
				\]
			\item
				Für (auf $B_\delta(\hat x)$) Lipschitz-stetige $F'$ erhalten wir sogar
				\begin{align*}
					\|x_{k+1} - \hat x\|
					&\le C \|x_k - \hat x\| \int_0^1 L \| \underbrace{x_k - (\hat x + t(x_k - \hat x))}_{=(1-t)x_k -(1-t)\hat x} \| \dx[t] \\
					&\le C \|x_k - \hat x\|^2 L \int_0^1 1-t \dx[t]
					= \f {CL}2 \|x_k - \hat x\|^2.
				\end{align*}
		\end{enumerate}
	\end{proof}
\end{st}

\subsection{Das Newton-Verfahren für Optimierungsprobleme}

Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
Wir versuchen, das Newton-Verfahren auf das Nullstellenproblem
\[
	F(x) := \nabla f(x) = 0
\]
an.
Offenbar ist $F'(x) = \nabla^2 f(x)$ und es ergibt sich folgender Algorithmus

\begin{alg}[Newton-Verfahren für Optimierungsprobleme] \label{alg:6}
	\begin{algorithmic}
		\Require{Startwert $x_0$}
		\State{$k \gets 0$}
		\While{$\nabla f(x_k) \neq 0$}
			\State{$d_k \gets -(\nabla^2 f(x_k))^{-1} \nabla f(x_k)$}
			\State{$x_{k+1} \gets x_k + d_k$}
		\EndWhile
	\end{algorithmic}
\end{alg}

\begin{lem} \label{2.47}
	Für alle symmetrische Matrizen $A, B \in \R^{n\times n}$ gilt
	\[
		\lambda_{\text{min}}(A + B) \ge \lambda_{\text{min}}(A) - \|B\|.
	\]
	Insbesondere besitzt jede symmetrische, positiv definite Matrix eine Umgebung in $\R^{n\times n}$, in der alle symmetrischen Matrizen positiv definit sind.
	\begin{proof}
		Es gilt
		\[
			\f {x^T A x}{\|x\|2}
			= \f {x^T (A+B) x}{\|x\|^2} - \f {x^T B x}{\|x\|^2}
			\le \f {x^T (A+B) x}{\|x\|^2} + \max_{x\in\R^n} \f {|x^T B x|}{\|x\|^2}
			\le \f {x^T (A+B) x}{\|x\|^2} + \|B\|.
		\]
		Also
		\[
			\lambda_{\text{min}}(A+B)
			\stack{\ref{2.6}}= \min_{x\in \R^n} \f {x^T(A+B)x}{\|x\|^2}
			\ge \min_{x\in\R^n} \f {x^T A x}{\|x\|^2} - \|B\|
			= \lambda_{\text{min}}(A) - \|B\|.
		\]
	\end{proof}
\end{lem}

\begin{st}[Lokale Konvergenz des Newton-Verfahrens für Optimierungsprobleme] \label{2.48}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar, $\hat x$ ein lokales Minimum von $f$ mit positiv definiter Hesse-Matrix $\nabla^2 f(\hat x)$.
	Dann existieren $\delta, \my > 0$ so dass
	\begin{enumerate}[(a)]
		\item
			$\hat x$ ist der einzige stationäre Punkt auf $B_\delta(\hat x)$,
		\item
			$\lambda_{\text{min}}(\nabla^2 f(x)) \ge \my$ für alle $x \in B_\delta(\hat x)$, insbesondere ist $\nabla^2(f(x))$ invertierbar und $\|\nabla^2 f(x)\|^{-1} \le \f 1\my$.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ liegen alle durch \ref{alg:6} erzeugten Iterierten in $B_\delta(\hat x)$.
			Insbesondere ist \ref{alg:6} durchführbar.
		\item
			Für jedes $x_0 \in B_\delta(\hat x)$ terminiert \ref{alg:6} entweder an $\hat x$ oder erzeugt eine Folge $(x_k)_{k\in\N}$, die superlinear gegen $\hat x$ konvergiert.
		\item
			Ist $\nabla^2 f$ zusätzlich Lipschitz-stetig in $B_\delta(\hat x)$, d.h.
			\[
				\forall x,y \in B_\delta(\hat x) : \| \nabla^2 f(x) - \nabla^2 f(y) \|
				\le L \|x-y\|,
			\]
			dann ist die Konvergenz sogar quadratisch durch
			\[
				\|x_{k+1} - \hat x\| \le \f {L}{2\my} \|x_k - \hat x\|^2
			\]
			gegeben.
	\end{enumerate}
	\begin{proof}
		Für jedes $0 < \my < \lambda_{\text{min}}(\nabla^2 f(\hat x))$ folgt aus \ref{2.47}, dass ein $\delta > 0$ existiert mit $\lambda_{\text{min}}(\nabla^2 f(x)) \ge \my$ für alle $x \in B_\delta(\hat x)$.

		Der Rest funktioniert wie in \ref{2.46}.
	\end{proof}
\end{st}

\begin{ex} \label{2.49}
	Betrachte $f: \R \to \R, f(x) = \sqrt{x^2 + 1}$.
	Offenbar ist $\hat x=0$ das einzige Minimum von $f$.
	$f$ erfüllt die Voraussetzungen von \ref{2.48}, denn
	\begin{align*}
		\nabla f(x) &= \f {x}{\sqrt{x^2 + 1}} \\
		\nabla^2 f(x) &= \f {1}{(x^2 + 1)^{\f 32}}.
	\end{align*}
	Die Newton-Iteration ergibt sich dann als
	\begin{align*}
		x_{k+1}
		&= x_k - (\nabla^2 f(x_k))^{-1} \nabla f(x_k) \\
		&= x_k - (x_k^2 + 1)^{\f 32} \f {x_k}{\sqrt{x_k^2 + 1}} \\
		&= - x_k^3.
	\end{align*}
	Konvergenz findet sich also nur lokal für $|x_0| < 1$.
\end{ex}

\begin{nt} \label{2.50}
	Alternative Motivation für das Newton-Verfahren für das Optimierungsproblem wäre, $f$ durch die quadratische Näherung an $x_k$
	\[
		f(x) \approx
		f(x_k) + \nabla f(x_k)^T (x-x_k) + \f 12 (x-x_k)^T \nabla^2 f(x_k) (x-x_k)
	\]
	zu ersetzen.
	Das Minimum dieser quadratischen Näherung liegt in (siehe Übungen) % fixme: ref
	\[
		x = x_k - \nabla^2 f(x_k)^{-1} \nabla f(x_k).
	\]
	Dies führt wieder auf das Newton-Verfahren.
\end{nt}

\subsection{Newton-artige Verfahren}

Das Newton-Verfahren hat gewisse Nachteile (z.B. gegenüber dem Gradienten-Verfahren)
\begin{itemize}
	\item
		Nur lokale Konvergenz,
	\item
		Hessematrix wird benötigt,
	\item
		benötigt LGS-Lösung mit $\nabla^2 f(x_k)$.
\end{itemize}
Trotzdem hat das Newton-Verfahren Vorteile, die es nützlich machen
\begin{itemize}
	\item
		superlineare Konvergenz (rechtfertig asymptotisch jeden $N$-fachen Aufwand gegenüber einem linear-konvergenten Verfahren)
\end{itemize}
Mit $d_k := - \nabla^2 f(x_k)^{-1} \nabla f(x_k)$ wird nur eine Approximation $x_{k+1}$ an das Optimum berechnet.
Es ist also vielleicht nicht nötig, $d_k$ exakt zu berechnen.
Dies liefert die Motivation für zwei Verfahren
\begin{itemize}
	\item
		Inexakte Newton-Verfahren:
		$d_k$ wird nur näherungsweie z.B. durch Anwendung einiger Schritte eines iterativen Verfahrens auf das lineare Gleichungsystem $\nabla^2 f(x_k) = - \nabla f(x_k)$ bestimmt.
	\item
		Newton-artige Verfahren:
		Ersetze $\nabla^2 f(x_k)$ durch invertierbare Matrix $H_k \in \R^{n\times n}$ (die einfacher zu berechenen oder einfacher zu invertieren ist) und löse
		\[
			H_k d_k = - \nabla f(x_k).
		\]
\end{itemize}

\begin{lem} \label{2.51}
	Sei $F: \R^n \to \R^n$ stetig differenzierbar und $K \subset \R^n$ kompakt und konvex.

	Dann ist $F$ auf $K$ Lipschitz-stetig mit $L := \max_{x\in K} \|F'(x)\|$, also
	\[
		\|F(y) - F(x)\|
		\le L \|y-x\|
	\]
	für alle $x,y \in K$.
	\begin{proof}
		Nach dem Mittelwertsatz \ref{2.4} gilt
		\[
			\|F(y) - F(x)\| = \Big\| \int_0^1 F'(x + t(y-x)) \dx[t] (y-x) \Big\|
			\le \max_{x\in K} \|F'(x)\| \|y-x\|.
		\]
	\end{proof}
\end{lem}

\begin{st}[Dennis-Moré-Bedingungen] \label{2.52}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar, $\hat x \in \R^n$ besitze invertierbare Hessematrix $\nabla^2 ff(\hat x)$.
	Sei $(x_k)_{k\in\N} \subset \R^n$ mit
	\[
		\forall k \in \N : x_k \neq \hat x
	\]
	und $x_k \to \hat x$.

	Dann sind folgende Aussagen äquivalent:
	\begin{enumerate}[(a)]
		\item
			$(x_k)$ konvergiert superlinear gegen $\hat x$  und $\hat x$ ist stationärer Punkt.
		\item
			$\nabla f(x_{k+1}) = o(x_{k+1} - x_k)$
		\item
			$\nabla f(x_k) + \nabla^2 f(\hat x)(x_{k+1} - x_k) = o(x_{k+1} - x_k)$
		\item
			$\nabla f(x_k) + \nabla^2 f(x_{k+1})(x_{k+1} - x_k) = o(x_{k+1} - x_k)$
	\end{enumerate}
	\begin{proof}
		\begin{segnb}[„(a)$\implies$(b)“]
			$(x_k)_{k\in\N}$ konvergiere superlinear, d.h. $\|x_{k+1} - \hat x\| \le \f 12 \|x_k - \hat x\|$ für hinreichend große $k \in \N$.
			Es gilt
			\begin{align*}
				\|x_k - \hat x\|
				&\le \|x_{k+1} - x_k\| + \|x_{k+1} - \hat x\| \\
				&\le \|x_{k+1} - x_k\| + \f 12 \|x_k - \hat x\|
			\end{align*}
			und damit
			\[
				\|x_k - \hat x\|
				\le 2 \|x_{k+1} - x_k\|
			\]
			für hinreichend große $k$.
			Da $(x_k)_{k\in\N}$ beschränkt ist, existiert eine abgeschlossene Kugel $K$ mit $x_k, \hat x \in K$ für alle $k \in \N$.
			Nach \ref{2.51} existiert $L > 0$ mit
			\begin{align*}
				\|\nabla f(x_{k+1}) \|
				&= \| \nabla f(x_{k+1} - \nabla f(\hat x)) \| \\
				&\le L \|x_{k+1} - \hat x\|
				= o(x_k - \hat x)
				= o(x_{k+1} - x_k)
			\end{align*}
		\end{segnb}
		\begin{segnb}[„(b)$\implies$(a)“]
			Sei $\nabla f(x_{k+1}) = o(x_{k+1} - x_k)$, d.h.
			\[
				\eps_k := \f {\|\nabla f(x_{k+1})\|}{\|x_{k+1} - x_k\|}
				\to 0.
			\]
			Insbesondere $\nabla f(\hat x) = \lim_{x_k \to \hat x} \nabla f(x_k) = 0$.
			$\nabla^2 f(\hat x)$ ist invertierbar, also existiert nach \ref{2.43} $\gamma > 0$ mit
			\[
				\|\nabla f(x_{k+1}) \|
				\ge \gamma \|x_{k+1} - \hat x\|
			\]
			für hinreichend große $k$.
			Es gilt
			\begin{align*}
				\|x_{k+1} - \hat x\|
				&\le \f 1\gamma \|\nabla f(x_{k+1})\| \\
				&= \f {\eps_k}{\gamma} \|x_{k+1} - x_k\| \\
				&\le \f{\eps_k}{\gamma} \|x_{k+1} - \hat x\| + \f{\eps_k}{\gamma} \|x_k - \hat x\|
			\end{align*}
			Für hinreichend große $k \in \N$ ist $\f {\eps_k}{\gamma} < \f 12$ und damit
			\[
				\|x_{k+1} - \hat x\|
				\le 2 \f {\eps_k}{\gamma} \|x_k - \hat x\|
				= o(x_k - \hat x).
			\]
		\end{segnb}
		\begin{segnb}[„(b)$\iff$(c)“]
			Der Mittelwertsatz \ref{2.4} für $F(x) := \nabla f(x)$ liefert
			\begin{align*}
				&\nabla f(x_{k+1}) \\
				&\quad= \nabla f(x_k) + \int_0^1 \nabla^2 f(x_k + t(x_{k+1} - x_k)) (x_{k+1} - x_k) \dx[t] \\
				&\quad= \nabla f(x_k) \\
					&\qquad + \int_0^1 \Big(\nabla^2 f(x_k + t(x_{k+1} - x_k)) - \nabla^2 f(\hat x) \Big) (x_{k+1} - x_k) \dx[t] \\
					&\qquad + \nabla^2 f(\hat x) (x_{k+1} - x_k)
			\end{align*}
			$\nabla^2 f$ ist stetig, also $\nabla^2 f$ gleichmäßig stetig auf einer abgeschlossener Kugel mit $K \in x_k, \hat x$ und somit
			\[
				\int_0^1 \Big( \nabla^2 f(x_k + t(x_{k+1} - x_k)) - \nabla^2 f(\hat x) \Big) \dx[t] \to 0.
			\]
			Also gilt
			\[
				\nabla f(x_{k+1})
				= \nabla f(x_k) + \nabla^2 f(\hat x) (x_{k+1} - x_k) + o(x_{k+1} - x_k)
			\]
		\end{segnb}
		\begin{segnb}[„(c)$\iff$(d)“]
			Wegen $\nabla^2 f(x_k) \to \nabla^2 f(\hat x)$ ist
			\[
				\nabla f(x_k) + \underbrace{\nabla^2 f(\hat x) (x_{k+1} - x_k)}_{=\nabla^2 f(x_k)(x_{k+1} - x_k) + o(x_{k+1} - x_k)}
				= o(x_{k+1} - x_k)
			\]
			äquivalent zu
			\[
				\nabla f(x_k) + \nabla^2 f(x_k) (x_{k+1} - x_k) = o(x_{k+1} - x_k).
			\]
		\end{segnb}
	\end{proof}
\end{st}

\begin{st} \label{2.53}
	Sei $f: \R^n \to \R$ zweimal stetig differenzierbar.
	$(x_k)_{k\in\N}$ sei erzeugt durch $x_{k+1} := x_{k} + d_k$ und konvergiere gegen $\hat x \in \R^n$ mit positiv definiter Hessematrix $\nabla^2 f(\hat x)$.
	Außerdem gelte $x_k \neq \hat x$ für alle $k \in \N$.

	Dann gelten folgende Aussagen
	\begin{enumerate}[(a)]
		\item
			Newton-Verfahren:
			Sind die $d_k$ exakte Lösungen von
			\[
				\nabla^2 f(x_k) d_ke = - \nabla f(x_k),
			\]
			dann ist $\hat x$ ein Minimum von $f$ und $(x_k)_{k\in\N}$ konvergiert superlinear gegen $\hat x$ (sogar quadratisch, falls $\nabla^2 f$ lokal Lipschitz-stetig).
		\item
			Inexakte Newton-Verfahren:
			Sind die $d_k$ approximative Lösungen von
			\[
				\nabla^2 f(x_k) d_ke = - \nabla f(x_k),
			\]
			die
			\[
				\|\nabla f(x_k) + \nabla^2 f(x_k) d_k\| = \eta_k \|\nabla f(x_k)\|
			\]
			mit einer Nullfolge $(\eta_k)_{k\in\N}$ erfüllt, so ist $\hat x$ ein Minimum und $x_k \to \hat x$ konvergiert superlinear.
		\item
			Newton-artige Verfahren:
			Sind die $d_k$ Lösungen von
			\[
				H_k d_k = - \nabla f(x_k)
			\]
			mit $H_k \in \R^{n\times n}$ invertierbar und $H_k \to \nabla^2 f(\hat x)$, dann ist $\hat x$ Minimum und die Konvergenz ist superlinear.
	\end{enumerate}
\coursetimestamp{27}{11}{2013}
	\begin{proof}
		Teil (a) ist klar nach \ref{2.52} (d), quadratische nach \ref{2.48}.
		\begin{enumerate}[(a)]
			\item[(c)]
				Es gilt
				\begin{align*}
					- \nabla f(x_k) - \nabla^2 f(\hat x) (x_{k+1} - x_k)
					&= \underbrace{\big(H_k - \nabla^2 f(\hat x)\big)}_{\to 0} (x_{k+1} - x_k) \\
					&= o(x_{k+1} - x_k).
				\end{align*}
				Nach \ref{2.52} (c) ist $\hat x$ Minimum und die Folge konvergiert superlinear.
			\item[(b)]
				Es gilt
				\begin{align*}
					\|\nabla f(x_k)\|
					&\le \|\nabla f(x_k) + \nabla^2 f(x_k) (x_{k+1} - x_k)\| + \| \nabla f(x_k){x_{k+1} - x_k} \| \\
					&\le \eta_k \|\nabla f(x_k)\| + \| \nabla^2 f(x_k) d_k \|,
				\end{align*}
				also
				\[
					\|\nabla f(x_k) \|
					\le \f 1{1 - \eta_k} \|\nabla^2 f(x_k) d_k\|
				\]
				und somit
				\begin{align*}
					\|\nabla f(x_k) + \nabla^2 f(x_k) d_k \|
					&\le \eta_k \|\nabla f(x_k)\| \\
					&\le \f {\eta_k}{1-\eta_k} \|\nabla^2 f(x_k)\|\|x_{k+1} - x_k\| \\
					&= o(x_{k+1} - x_k).
				\end{align*}
				Nach \ref{2.52} (d) ist $\hat x$ Minimum und die Folge konvergiert superlinear.
		\end{enumerate}
	\end{proof}
\end{st}

\subsection{Quasi-Newton-Verfahren}

\paragraph{Motivation:}

Betrachte das Newton-Verfahren für eindimensionale Nullstellenprobleme
\[
	F: \R \to \R, F(\hat x) = 0
\]
mit der Iteration
\[
	x_{k+1} := x_k - F'(x_k)^{-1} F(x_k).
\]
Approximiere $F'(x_k)$ durch
\[
	F'(x_k) \approx \f{F(x_k) - F(x_{k-1})}{x_k - x_{k-1}} =: H_k.
\]
Es ergibt sich die Iteration
\[
	x_{k+1} = x_k - \big(\f{F(x_k) - F(x_{k-1})}{x_k - x_{k-m}} \big)^{-1} F(x_k),
\]
das sogenannte \emph{Sekantenverfahren}.

Für Optimierungsprobleme approximiere analog $f''(x_k) \approx \f {f'(x_k) - f'(x_{k-1})}{x_k - x_{k-1}} =: H_k$ und iteriere $x_{k+1} := x_k - H_k^{-1} f'(x_k)$.

Im eindimensionalen ist $H_k$ eindeutige Lösung von
\[
	f'(x_k) - f'(x_{k-1})
	= H_k (x_k - x_{k-1}).
\]
Das Analogon in $\R^n$ wäre
\[
	\nabla f(x_k) - \nabla f(x_{k-1})
	= H_k (x_k -x_{k-1}).
\]
Newton-artige Verfahren mit $H_k$, welche dieser Bedingung genügen, heißen \emph{Quasi-Newton-Verfahren}.

\begin{nt} \label{2.54}
	\begin{enumerate}[(a)]
		\item
			$H_k := \nabla^2 f(x_k)$ erfüllt \eqref{eq:qn} im Allgemeinen nicht
		\item
			Es gilt
			\[
				\nabla f(x_k) - \nabla f(x_{k-1})
				= \underbrace{\int_0^1 \nabla^2 f(x_{k-1} + t (x_k - x_{k-1})) \dx[t]}_{= H_k} (x_k - x_{k-1}).
			\]
			Mit diesem $H_k$ ergäbe sich ein Quasi-Newton-Verfahren, wenn auch sehr aufwändig zu berechnendem $H_k$.
		\item
			Es gilt
			\begin{align*}
				\nabla f(x_k)
				&= \nabla f(x_{k-1}) + ( \nabla f(x_k) - \nabla f(x_{k-1}) ) \\
				&= H_{k-1} (x_{k-1} - x_k) + H_k (x_k - x_{k-1}) \\
				&= (H_k - H_{k-1})(x_k - x_{k-1}).
			\end{align*}
			Nach \ref{2.52} (b) konvergiert das Quasi-Newton-Verfahren bereits dann superlinear, wenn $H_k - H_{k-1} \to 0$.
	\end{enumerate}
\end{nt}

Dementsprechend liegt es nahe, $H_{k+1}$ so zu wählen, dass sie sich möglichst wenig von $H_k$ unterscheidet, \eqref{eq:qn} erfüllt und möglichst leicht zu invertieren ist.

Führe eine sogenannte \emph{Aufdatierung} durch: erhalte $H_{k+1}$ durch kleine Änderung von $H_k$.

\paragraph{Rang 1 Modifikationen}

Sei $e_k \in \R^n$ der $k$-te Einheitsvektor, dann ist
\[
	e_j e_k^T = (\delta_{ij}\delta_{lk})_{i,l = 1, \dotsc, n}.
\]
Für $A \in \R^{n\times n}$ ist $A + e_j e_k^T$ die im $(j,k)$-ten Eintrag abgeänderte Matrix.
Genauso ergibt sich $A + uv^T$ (in einer Basis, die $v$ und $w$ enthält) durch Abänderung eines Eintrags aus $A$.

\begin{lem}[Sherman-Morrison-Woodberry-Formel] \label{2.55}
	Sei $A \in \R^n$ invertierbar und $u, v \/n \R^n \setminus \{0\}$.
	$A + uv^T \in \R^{n\times n}$ ist genau dann invertierbar, wenn $1 + v^T A^{-1} u \neq 0$.
	In diesem Fall gilt
	\[
		(A + uv^T)^{-1} = A^{-1}0- \f {A^{-1} u v^T A^{-1}}{1 + v^T A^{-1} u}.
	\]
	\begin{proof}
		Ist $1 + v^T A^{-1} u \neq 0$, dann ist
		\[
			(A + uv^T)(A^{-1} - \f {A^{-1} uv^T A^{-1}}{1 + v^T A^{-1} u} ) = I.
		\]
		Ist $1 + v^T A^{-1} u = 0$, dann ist
		\begin{align*}
			(A + uv^T) A^{-1} uv^Tv
			&= uv^Tv + uv^TA^{-1} uv^Tv \\
			&= u( 1 + v^TA^{-1}u) (v^Tv)
			= 0
		\end{align*}
		und $A^{-1} uv^Tv = \|v\|^2 A^{-1} u \neq 0$, also $A + uv^T$ nicht injektiv und insbesondere nicht invertierbar.
	\end{proof}
\end{lem}

Das einfachste Quasi-Newton-Verfahren wäre damit
\[
	H_{k+1} := H_k + \gamma_k u_k u_k^T,
\]
wobei $\gamma_k \in \R, u_k \in \R^n \setminus \{0\}$ so zu bestimmen sind, dass $H_{k+1}$ \eqref{eq:qn} erfüllt.

Falls $(y_k - H_k d_k)^T d_k \neq 0$ ($y_k = \nabla f(x_{k+1} - \nabla f(x_k)$), dann ergibt sich eine eindeutige Aufdatierungsformel
\[
	H_{k+1} := H_k + \dfrac{(y_k - H_k d_k)(y_k - H_k d_k)^T}{(y_k - H_k d_k)^T d_k}.
\]

