\documentclass[
	%noproofs
]{mycourse}
% Umgebungen:
\theoremstyle{mythm}
\theorempreskipamount 2.5em             % Abstand vor Theroem
\theoremindent 2ex                   % Theroem einrücken
\theoremheaderfont{\kern-1em\normalfont\bfseries}   % Überschrift wieder ausrücken
%\theoremheadertypefont{\color{green!25!black}}% Font für Theorem-Typ (Satz, Definition, etc.)
\theorembodyfont{\normalfont}             % Aufrecht statt kursiv im body-Teil

%\usepackage{psfrag}
%\usepackage{pb-diagram} 
%\usepackage{algorithm}
%\usepackage{algorithmic}
\newtheorem{theorem}{Satz}[chapter]
\newtheorem{bemerkung}[theorem]{Bemerkung}
\newtheorem{korollar}[theorem]{Folgerung}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{beispiele}[theorem]{Beispiele}
\newtheorem{beispiel}[theorem]{Beispiel}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{definitiontheorem}[theorem]{Definition und Satz}

% Beweise:

\theoremstyle{break}
\theorempreskipamount 1.5em 								% Abstand vor Theroem
\theoremheaderfont{\kern-1em\bfseries\small\itshape}% Kursiv und kleiner als oben

\theoremsymbol{\ensuremath{\square}}
\newtheorem*{beweis}{Beweis:}


% Bezeichner:
% %%%%%%%%%%%

% Abkürzungen und Symbole
% %%%%%%%%%%%%%%%%%%%%%%%%
%

\newcommand{\Range}{\mathcal{R}}
\newcommand{\Kern}{\mathcal{N}}
\newcommand{\rang}{\mathrm{rang}}

\newcommand{\DS}{\displaystyle}

\newcommand{\norm}[1]{\left\Vert#1\right\Vert}		% Norm
\newcommand{\Langle}{\left\langle}
\newcommand{\Rangle}{\right\rangle}

%\newcommand{\1}{\mathbbm{1}} 			      	% Funktion, die konstant 1 ist
\renewcommand{\im}{\ensuremath{\mathrm{i}}} 			      	% komplexe Einheit
\newcommand{\dd}{\; : \;}    			      	% ,,derart, dass''
%\newcommand{\dx}[1][x]{\ensuremath{\, \mathrm{d} #1}} 	% Integral dx

\newcommand{\labeq}[1]{\label{eq:#1}}			% Nummerierung von Gleichung
\newcommand{\req}[1]{(\ref{eq:#1})}

\newcommand{\QED}{\hfill \ensuremath{\Box}}		% Beweisende - Box

\newcommand{\kommentar}[1]{}

% Sonstiges:

%\setcounter{secnumdepth}{3}
%\setlength{\parskip}{1ex plus0.5ex minus0.2ex}
%\setlength{\parindent}{0cm}



% Trennhilfen
\hyphenation{Nor-ma-len-ab-lei-tung Grund-idee}






%%%%%%%%%%%%%%%%%%%
%
% NOTATIONEN
%
%%%%%%%%%%%%%%%%%%%

% n: Raumdimension, \R^n

% Fancy Header:
%\fancyhead{}
%\fancyhead[LE]{\leftmark}
%\fancyhead[RO]{\rightmark}
%\fancyfoot{}
%\fancyfoot[LE,RO]{\thepage}
%\pagestyle{fancy}
%
%\fancypagestyle{plain}{
%\fancyhf{}
%\fancyfoot[LE,RO]{\thepage}
%\renewcommand{\headrulewidth}{0pt}}
%\setlength{\headheight}{28pt}

\title{Numerische Mathematik 2}
\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% TITELSEITE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}

	\vspace*{\fill}

\begin{center}
    \textbf{\Huge \sc Numerische Mathematik 2 }

	\vspace{1cm}
	{\Large \textcolor{red}{Inoffizielle}, modifizierte Version des Orginals:} \\
	\url{http://www.mathematik.uni-stuttgart.de/~harrach/lehre/Numerik2.pdf}
\end{center}

\vspace{2cm}

\begin{center}

{\Large \bf Prof. Dr. Bastian von Harrach}

\vspace{1cm}

{\Large Universität Stuttgart,\\[+1ex] Fachbereich Mathematik - IMNG\\[+1ex]
Lehrstuhl für Optimierung und inverse Probleme}

\vspace{1cm}

{\Large Sommersemester 2013}

\vspace{2cm}

{\verb|http://www.mathematik.uni-stuttgart.de/oip|}

\end{center} 

	\vspace*{\fill}
\end{titlepage}


\thispagestyle{empty}
\cleardoublepage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% Inhaltsverzeichnis
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\pagenumbering{roman}
\tableofcontents

\cleardoublepage
\pagenumbering{arabic}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter[Gewöhnliche Differentialgleichungen]{Gewöhnliche Differentialgleichungen}

In diesem Kapitel beschäftigen wir uns mit der Lösung \emph{gewöhnlicher Differentialgleichungen} (engl.: ordinary differential equations, ODE) 
bzw. \emph{Anfangswertproblemen}. Wir setzen dabei keinerlei Vorkenntnisse über die Theorie gewöhnlicher Differentialgleichungen voraus.

Wir beginnen mit einigen Beispielen.

\section{Einführung und Beispiele}\label{sect:ODE_intro}

\subsection{Mathematische Beispiele gewöhnlicher DGL}

\begin{description}
\item[Differentialgleichung:] Gleichung, die eine unbekannte Funktion zusammen mit ihren Ableitungen enthält.
\end{description}

\begin{beispiel}\label{bsp:ODE_math}
Einfache mathematische Beispiele für Differentialgleichungen:

\begin{enumerate}
\item[(a)] Betrachte die Differentialgleichung 
\[
y'(x)=0 \quad \mbox{(kurz: $y'=0$)},
\]
d.h. gesucht ist eine differenzierbare Funktion 
\[
y: \R\to \R,\ y: x \mapsto y(x)\quad \mbox{ mit } \quad y'(x)=0 \quad \forall x\in \R.
\]
\begin{itemize}
\item \emph{Spezielle} Lösungen sind z.B.: 
\[
y(x)=0, \quad  y(x)=1, \quad y(x)=-37, \quad \ldots
\]
\item Die \emph{allgemeine} Lösung ist $y(x)=C$, $C\in \R$, d.h. man kann zeigen, dass jede solche Funktion
die ODE löst und jede Lösung in dieser Form geschrieben werden kann.
\end{itemize}
%
\item[(b)] Betrachte die Differentialgleichung 
\[
y'(x)= r y(x), \quad r\in \R \quad \mbox{(kurz: $y'=r y$)}.
\]
\begin{itemize}
\item \emph{Spezielle} Lösungen sind z.B.: 
\[
y(x)=0, \quad y(x)=e^{rx}, \quad y(x)=-37e^{rx}, \quad \ldots
\]
\item Die \emph{allgemeine} Lösung ist $y(x)=Ce^{rx}$, $C\in \R$.
\end{itemize}
%
\item[(c)] 
Betrachte die Differentialgleichung \emph{höherer Ordnung} 
\[
y''(x)=-y(x) \quad \mbox{(kurz: $y''=-y$)}.
\]
\begin{itemize}
\item \emph{Spezielle} Lösungen sind z.B.: 
\[
y(x)=0, \quad y(x)=\sin (x), \quad y(x)=37\cos (x), \quad \ldots
\]
\item Die \emph{allgemeine} Lösung ist $C_1 \sin(x) + C_2 \cos(x)$, \quad $C_1,C_2\in \R$.
\end{itemize}
%
\item[(d)] 
Betrachte das \emph{Differentialgleichungssystem} 
\begin{align*}
y_1''(x)& = -y_1(x)\\
y_2'(x)& = y_3(x)\\
y_3'(x)& = y_3(x)
\end{align*}
\begin{itemize}
\item Eine \emph{spezielle} Lösung ist z.B.: 
\begin{align*}
y_1(x)& = \sin(x)\\
y_2(x)& = 37\\
y_3(x)& = 0
\end{align*}
\item Die \emph{allgemeine} Lösung ist
\begin{align*}
y_1(x)& = C_1 \sin(x) + C_2 \cos(x)\\
y_2(x)& = C_3 e^x+C_4\\
y_3(x)& = C_3 e^x\\
\end{align*}
mit $C_1,\ldots,C_4\in \R.$
\end{itemize}
%
\item[(e)] Betrachte die Differentialgleichung für eine \emph{vektorwertige} Funktion:

Gesucht ist (eine differenzierbare Funktion) 
\[
y: \R \to \R^2,\quad y:\ x\mapsto y(x):=\begin{pmatrix} y_1(x)\\ y_2(x) \end{pmatrix}.
\]
mit $y'=y$, also
\[
y'(x)=y(x) \;  \Longleftrightarrow \;
\left( \begin{array}{c} y_1'(x)\\ y_2'(x) \end{array} \right)= \left( \begin{array}{c} y_1(x)\\ y_2(x) \end{array} \right)
\;  \Longleftrightarrow \;
\left\{ \begin{array}{r@{\,}  l}
y_1'(x)&=y_1(x)\\  y_2'(x)&=y_2(x)
\end{array} \right.
\]
\end{enumerate}
\end{beispiel}



\begin{description}
\item[\emph{Gewöhnliche} Differentialgleichung:] Alle Ableitung beziehen sich auf die selbe eindimensionale Variable.
\end{description}

\begin{beispiel}
Betrachte $y:\R^2 \to \R, \quad (x_1,x_2)\mapsto y(x)=y(x_1,x_2)$

Eine nicht gewöhnliche, \emph{partielle} Differentialgleichung (engl.: Partial Differential Equation, PDE) ist 
\[
\frac{\partial^2 y}{\partial x_1^2}+\frac{\partial^2 y}{\partial x_2^2}=0
\]

\emph{Spezielle} Lösungen sind z.B.:  $y(x)=0$, $y(x)=x_1+x_2$, \ldots
\end{beispiel}

PDEs sind Gegenstand der im nächsten Semester angebotenen Vorlesung \emph{Numerik partieller Differentialgleichungen}.

\subsection{Anwendungsbeispiele für gewöhnliche DGL}

Je nach Anwendung verwenden wir in diesem Abschnitt unterschiedliche Bezeichner für die Funktion und
die Variable. Für Ableitungen bezüglich der Zeit schreiben wir auch 
$\dot y(t)=y'(x)$.

\paragraph{Continuous compounding -- stetige Verzinsung} 


\begin{description}
\item[$y(t)$:] Sparguthaben zum Zeitpunkt $t$.
\end{description}

Bank zahlt Zinsen proportional zu Guthaben und Zeitspanne:
\[
\Delta y(t)=y(t+\Delta t)-y(t)= r y(t) \Delta t
\]
Gutgeschriebene (kapitalisierte) Zinsen generieren \emph{Zinseszinsen}.

Stetige Verzinsung: instantane Kapitalisierung, d.h. $\Delta t\to 0$:
\[
\dot y(t)=r y(t).
\]


\paragraph{Populationsdynamik}

\begin{description}
\item[$y(t)$:] Anzahl von Individuen einer Population
\end{description}

\begin{itemize}
\item \underline{Model 1 (Malthus):} Population wächst mit konstanter Rate $r\in \R$. 
In einem kurzen Zeitintervall $\Delta t$, wächst die Population um $\Delta y \approx r y \Delta t$.
\[
\dot y=r y.
\]

\item \underline{Model 2 (Verhulst):} Es existiert Maximalbevölkerung $M>0$, Population wächst mit von $y$ abhängiger Rate
\begin{description}
\item[$y\ll M $:] Wachstum mit Rate $r$
\item[$y\approx M$:] Wachstum mit Rate $0$
\end{description}
In Zeitintervall $\Delta t$, wächst die Population um $\Delta y \approx r (1-y/M) y \Delta t$.
\[
\dot y=r\left( 1- \frac{y}{M} \right) y=r y - \frac{r}{M} y^2.
\]
$\frac{r}{M} y^2$: Todesrate aufgrund zu hoher Population.
%
\item \underline{Model 3 (Lotka-Volterra / Räuber-Beute Modell):}

Zwei Populationen $y_1(t), y_2(t)$, Räuber und Beutetiere:
\begin{align*}
\dot y_1 &= r_1 y_1 - f_1 y_1 y_2\\
\dot y_2 &= - r_2 y_2  + f_2 y_1 y_2
\end{align*}
\end{itemize}
%
\paragraph{Chemische Reaktionen}

\begin{description}
\item[$A(t)$, $B(t)$, $C(t)$, \ldots:] Konzentration der Chemikalien $A$,$B$,$C$,\ldots 
\end{description}

\begin{itemize}
\item $A \stackrel{k}{\longrightarrow} B$

In einem kurzen Zeitintervall $\Delta t$ wandeln sich $kA(t) \Delta t$ Moleküle von $A$ in $B$ um.
\[
\dot A(t)=-kA(t), \qquad \dot B(t)=kA(t).
\]

\item $A  + B \stackrel{k}{\longrightarrow} C + 2D$
\[
\dot A=-kA B, \quad \dot B=-kAB, \quad \dot C=kAB, \quad \dot D=2kAB.
\]
\end{itemize}
%
\paragraph{Newtonsche Gesetze}

\begin{description}
\item[$x(t)=(x_1(t), x_2(t), x_3(t))^T$:] Position eines Körpers zum Zeitpunkt $t$ 
\item[$v(t)=\dot x(t)=(\dot x_1(t), \dot x_2(t), \dot x_3(t))^T$:] Geschwindigkeit
\item[$a(t)=\dot v(t)=  \ddot x(t)=(\ddot x_1(t), \ddot x_2(t), \ddot x_3(t))^T$:] Beschleunigung
\end{description}

\underline{Newtonsches Gesetz:} Wirkt eine Kraft $F(t)$ auf einen Körper der Masse $m$, so ist
\[
F(t)= m a(t) = m \ddot x(t)
\]
%
\paragraph{Elektrische Schaltkreise}

Betrachte eine \emph{RLC-Reihenschaltung}, d.h. eine Reihenschaltung von Widerstand (R), 
Induktivität (L), und Kapazität (C). 
\begin{itemize}
\item Stromstärke $I_R(t)$ durch einen Widerstand $R$ bei Anlegen einer Spannung $U_R(t)$:
\[
I_R(t)= U_R(t) / R.
\]
\item Stromstärke $I_C(t)$ durch einen Kondensator mit Kapazität $C$ bei Anlegen einer Spannung $U_C(t)$:
\[
I_C(t)= \dot U_C(t) C 
\]
\item Stromstärke $I_L(t)$ durch eine Spule mit Induktivität $L$ bei Anlegen einer Spannung
$U_L(t)$:
\[
\dot I_L(t)= U_L(t)/L.
\]
\end{itemize}

Aus den \emph{Kirchhoffschen Gesetzen} folgt
\begin{align*}
U(t)&=U_R(t)+U_C(t)+U_L(t) \quad \mbox{(Spannungsbilanz)}\\
I_L(t)&=I_C(t)=I_R(t) \quad \mbox{(Strombilanz)}
\end{align*}
Es folgt, dass $U_L(t)=C L \ddot U_C(t)$ und $U_R(t)=R C \dot U_C(t)$, und damit
\[
U(t)=U_C(t)+RC\dot U_C(t) + LC \ddot U_C(t).
\]


\subsection{Anfangswertprobleme}

Die Lösung einer gewöhnlichen DGL ist üblicherweise nicht eindeutig. Die allgemeine Lösung von $\dot y(t)=ry(t)$ 
ist $y(t)=Ce^{rt}$ mit einem Parameter $C\in \R$. In vielen Anwendungen sind die Parameter eindeutig
bestimmt durch die Anfangswerte von $y$. Bei der stetigen Verzinsung ist z.B.\ $C=y(0)$ das anfängliche
Sparguthaben.

Intuitiv erwarten wir in den anderen Beispielen, dass die Lösung durch folgende Informationen eindeutig bestimmt wird:
\begin{itemize}
\item Populationsdynamik: anfängliche Population $y(0)$, bzw., $y_1(0),y_2(0)$
\item Chemische Reaktionen: anfängliche Konzentrationen $A(0)$, $B(0)$, \ldots
\item Newtonsche Gesetze: anfängliche Position $x_1(0),x_2(0),x_3(0)$ und Geschwindigkeit $v_1(0),v_2(0),v_3(0)$
\item Elektrische Schaltkreise: Anfängliche Strom- und Spannungswerte am Kondensator $U_C(0)$ and $\dot U_C(0)$
\end{itemize}

Eine gewöhnliche DGL zusammen mit Anfangsbedingungen heißt auch \emph{Anfangswertproblem} (AWP).

\subsection{Elementare Lösungsmethoden}

Ähnlich wie Integrale lassen sich manche (aber nicht alle) gewöhnliche
Differentialgleichungen analytisch, d.h. in geschlossener Form lösen. Wir geben hier nur Beispiele 
besonders einfacher Lösungsmethoden an. Es existieren noch einige weitere wichtige Lösungsmethoden,
aber im Allgemeinen lassen sich gewöhnliche Differentialgleichungen nur numerisch lösen.



\paragraph{Raten/Wissen der Lösung}

siehe Beispiel~\ref{bsp:ODE_math}.

\paragraph{Separation der Variablen}

Gewöhnliche DGL der Form 
\[
y'(x)=g(x) h(y(x))
\]
lassen sich formal(!) schreiben als
\begin{align}
\frac{\dx[y]}{h(y)}=g(x)\dx
\end{align}
und durch Integration lösen
\begin{align}
\int \frac{1}{h(y)} \dx[y]=\int g(x)\dx.
\end{align}
Formal bedeutet dabei, dass dies keine mathematisch rigorosen Umformulierungen sind.
Die Ausdrücke $\dx$ sind nicht definiert! 

Man kann diese Methode rigoros formulieren und rechtfertigen. % (siehe ??). 
Aber auch ohne rigorose Rechtfertigung haben formale Methoden einen großen Nutzen
(nicht nur im Bereich gewöhnlicher DGL). Oft lässt sich nämlich durch formales Vorgehen ein Lösungskandidat bestimmen und für diesen dann rigoros überprüfen, ob er tatsächlich eine Lösung ist. 


\begin{beispiel}
Betrachte Modell 2 aus der Populationsdynamik ($M=r=1$):
\begin{align*}
\frac{\dx[y]}{\dx[t]} = \left(1-y\right) y
\end{align*}
mit Anfangwert $y(0)>1$. 

Obiges formales Vorgehen liefert
\[
\int \frac{1}{\left(1-y\right)y} \dx[y]  =\int 1 \dx[t].
\]
Wir erwarten anschaulich, dass die Population von oben gegen ihren Maximalwert $M=1$ konvergieren 
diesen aber nicht unterschreiten wird. Wir lösen also die Integrale auf beiden Seiten unter der
Annahme $y>1$:
\begin{align*}
\int 1 \dx[t] &= t + \mbox{const.}\\
\int \frac{1}{\left(1-y\right)y} \dx[y] 
&= - \int \frac{1}{y-1} \dx[y] + \int \frac{1}{y} \dx[y]\\
&= - \ln (y-1) + \ln (y) + \mbox{const.}=\ln \frac{y}{y-1} + \mbox{const.}
\end{align*}
Wir erhalten
\begin{align*}
\ln \frac{y}{y-1} &= t + \mbox{const.} \quad 
\Longrightarrow \quad \frac{y}{y-1} = C e^t\\
\Longrightarrow \quad y &= \frac{Ce^t}{Ce^t-1}.\\
\end{align*}
$C$ kann aus dem Anfangswert $y(0)=y_0$ bestimmt werden:
\begin{align*}
y_0 &= \frac{C}{C-1} \quad \Longrightarrow \quad  C=\frac{y_0}{y_0-1}.
\end{align*}

Man prüft leicht (und mathematisch rigoros) nach, dass der so bestimmte Lösungskandidat für $y_0>1$ tatsächlich
das AWP
\[
\frac{\dx[y]}{\dx[t]} =\left(1-y\right) y,  \quad y(0)=y_0
\]
löst. 
\end{beispiel}

\paragraph{Variation der Konstanten}

Betrachte $y'(x)=r y(x) + z(x)$.

Allgemeine Lösung der \emph{homogenen} Gleichung $y'(x)=r y(x)$ ist $y(x)=C e^{rx}$ mit einer Konstante $C\in \R$.

\emph{Ansatz:} Ersetze zur Lösung der inhomogenen Gleichung die Konstante durch eine Funktion $C(x)$:
\begin{align*}
C'(x) e^{rx} + C(x) r e^{rx}& =y'(x)= r y(x) + z(x)= r C(x) e^{rx} + z(x)\\
\quad \Longrightarrow \quad C'(x)= z(x) e^{-rx} 
\end{align*}
Durch Integration erhalten wir $C(x)$ und damit die Lösung $y(x)=C(x)e^{rx}$.



\section{Theorie gewöhnlicher DGL}

\subsection{Eine allgemeine Form}

Von nun an betrachten wir stets Anfangswertprobleme in der folgenden allgemeinen Form
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0
\]
wobei $x\in [x_0,\infty)\subset \R$, $y(x)=(y_1(x),\ldots, y_d(x))^T\in \R^d$ vektorwertig ist, $d\in \N$, und
\[
f:\ \R^{d+1}\to \R^d, \quad f(x,y)=\left( \begin{array}{c} f_1(x,y_1,\ldots,y_d)\\ \vdots \\ f_d(x,y_1,\ldots,y_d) \end{array} \right).
\]

Die Differentialgleichung $y'=f(x,y(x))$ ist äquivalent zum Differentialgleichungssystem
\[
\left. \begin{array}{r@{\,} l} 
y'_1(x) &= f_1(x,y_1(x),\ldots,y_d(x))\\ 
&\vdots\\
y'_d(x) &= f_d(x,y_1(x),\ldots,y_d(x))
\end{array}\right.
\]
 
Gleichungen höherer Ordnung (d.h. solche, die höhere Ableitungen von $y$ enthalten) können 
in diese Form transformiert werden, indem $y$ und seine Ableitungen (bis zur zweithöchsten) in
einer vektorwertigen Hilfsfunktion  $u=(u_1,u_2,\ldots)$ zusammengefasst werden
\[
u_1(x):=y(x), \quad u_2(x):=y'(x), \quad u_3(x)=y''(x), usw.
\]

\begin{beispiel}
$y''=-y$ kann in obige Form transformiert werden durch
\[
u=\left( \begin{array}{c} u_1(x)\\ u_2(x) \end{array}\right) := \left( \begin{array}{c} y(x)\\ y'(x) \end{array}\right).
\]
Damit ist $y''=-y$ äquivalent zu
\[
u'=\left( \begin{array}{c} u_1'(x)\\ u_2'(x) \end{array}\right)
= \left( \begin{array}{c} y'(x)\\ y''(x) \end{array}\right)
= \left( \begin{array}{c} y'(x)\\ -y(x) \end{array}\right)
= \left( \begin{array}{c} u_2(x)\\ -u_1(x) \end{array}\right)
=:f(x,u(x)).
\]
\end{beispiel}

\subsection{Existenz, Eindeutigkeit und Stabilität}\label{subsec:wohlgestellt}

Ein Problem heißt \emph{wohlgestellt} (nach Hadamard) wenn
\begin{enumerate}[(a)]
\item eine Lösung existiert (\emph{Existenz}),
\item die Lösung eindeutig ist (\emph{Eindeutigkeit}),
\item die Lösung stetig von den Eingabeparametern abhängt (\emph{Stabilität}).
\end{enumerate}

Für das Anfangswertproblem 
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0.
\]
bedeutet Wohlgestelltheit, dass eine eindeutige Lösung $y(x)$ existiert und diese Lösung 
stetig von den Anfangswerten $y_0$ (und ggf. weiteren in $f$ vorhandenen Parametern) abhängt.
Dies werden wir in diesem Abschnitt untersuchen.

\paragraph{Existenz und Eindeutigkeit.} 
In diesem Abschnitt beweisen wir den Exis\-tenz- und Eindeutigkeitssatz von Picard-Lindel\"of in seiner einfachsten Form
\begin{theorem}[Picard-Lindel\"of]\label{thm:PL}
Seien $x_0,x_\mathrm{end}\in \R$, $x_0<x_\mathrm{end}$, $y_0\in \R^d$. Für 
\[
f:\ [x_0,x_\mathrm{end}]\times \R^{d}\to \R^d,  \quad f:\ (x,y)\mapsto f(x,y)
\]
gelte
\begin{enumerate}[(a)]
\item $f$ ist stetig
\item $f$ ist (global und bzgl. $x$ gleichmäßig) Lipschitz-stetig in $y$, d.h.
es existiert ein $L>0$ so dass
\[
\norm{f(x,y)-f(x,z)}\leq L \norm{y-z} \quad \forall x\in [x_0,x_\mathrm{end}],\ y,z\in \R^d.
\]
\end{enumerate}

Dann existiert genau eine stetig differenzierbare Funktion
$y: [x_0,x_\mathrm{end}]\to \R^d$ mit 
\[
y'(x)=f(x,y(x)) \quad \forall x\in (x_0,x_\mathrm{end}) \quad \mbox{ und } \quad y(x_0)=y_0.
\]
%$y$ ist stetig differenzierbar. Insbesondere erfüllt $y$ die DGL (im Sinne einseitiger
%Ableitungen) auch für $x=x_0$ und $x=x_\mathrm{end}$. 
\end{theorem}

Wir werden Satz \ref{thm:PL} mit Hilfe des Banachschen Fixpunktsatz und einigen Hilfssätzen beweisen. 
\begin{theorem}[Banachscher Fixpunktsatz]
Sei $(X,d)$ ein vollständiger metrischer Raum und $\Phi$ eine 
\emph{kontrahierende Selbstabbildung} von $X$, d.h. es existiere ein $q<1$ mit
\[
\Phi: X\to X  \quad \mbox{ und } \quad d(\Phi(x), \Phi(y))\leq q\,  d(x,y)  \quad \forall x,y\in X.
\]
Dann besitzt $\Phi$ genau einen \emph{Fixpunkt} $\hat x$, d.h. genau ein $\hat x\in K$ mit $\Phi(\hat x)=\hat x$.

Für jeden Startwert $x^{(0)}\in X$ konvergiert die durch \emph{Fixpunktiteration} definierte Folge 
\[
(x^{(k)})_{k\in \N_0}, \qquad x^{(k+1)}:=\Phi(x^{(k)}) \quad \forall k\in \N_0.
\]
(in der Metrik $d$) gegen $\hat x$, d.h.
\[
d(x^{(k)}, \hat x)\to 0.
\]
\end{theorem}
\begin{beweis}
aus der Numerik I bekannt.
\end{beweis}

Als vollständigen metrischen Raum werden wir den Raum stetiger Funktionen betrachten:
\begin{lemma}
Die Menge der auf $[x_0,x_\mathrm{end}]$ stetigen Funktionen
\[
C([x_0,x_\mathrm{end}])^d:=\{ y: \ [x_0,x_\mathrm{end}]\to \R^d \ \mathrm{stetig} \} 
\]
ist bezüglich der \emph{Supremums-} (auch: \emph{Maximumsnorm})
\[
\norm{y}_\infty:= \max_{x\in [x_0,x_\mathrm{end}]} \norm{y(x)}
\]
ein \emph{Banachraum}, d.h. ein vollständiger normierter Vektorraum
(und damit insbesondere bzgl. der induzierten Metrik $d(y_1,y_2):=\norm{y_1-y_2}_\infty$ ein 
vollständiger normierter Raum).
\end{lemma}
\begin{beweis}
Die Vektorraum- und Normeigenschaften lassen sich einfach nachrechnen (siehe Übungsaufgabe 2.2).

Zum Beweis der Vollständigkeit müssen wir zeigen, dass (bzgl. $\norm{\cdot}_\infty$) jede Cauchy-Folge
konvergiert. Sei also $(y^ {(n)})_{n\in \N}\subset C([x_0,x_\mathrm{end}])$ eine Cauchy-Folge bzgl. $\norm{\cdot}_\infty$, d.h. für jedes $\epsilon>0$ existiert $N\in \N$, so dass
\[
\epsilon>  \norm{y^{(n)}-y^{(m)}}=  \max_{x\in [x_0,x_\mathrm{end}]}  \norm{y^{(n)}(x)-y^{(m)}(x)} \quad \forall n,m\geq N.
\]
Für jedes feste $x\in [x_0,x_\mathrm{end}]$ ist dann
\[
\epsilon>  \norm{y^{(n)}(x)-y^{(m)}(x)}  \quad \forall n,m\geq N,
\]
also $(y^{(n)}(x))_{n\in \N}\subset \R^d$ eine Cauchy-Folge. Diese besitzt einen Grenzwert,
so dass wir 
\[
y:\ [x_0,x_\mathrm{end}]\to \R^d \quad \mbox{ durch } \quad y(x):=\lim_{n\to \infty} y^{(n)}(x).
\]
definieren können.

Aus 
\[
\epsilon>  \norm{y^{(n)}(x)-y^{(m)}(x)}  \quad \forall n,m\geq N
\]
folgt dass
\[
\epsilon\geq \norm{y^{(n)}(x)-y(x)} \quad \forall n\geq N
\]
und so gibt es also zu jedem $\epsilon>0$ ein $N\in \N$, so dass
\[
\epsilon\geq \max_{x\in [x_0,x_\mathrm{end}]}  \norm{y^{(n)}(x)-y(x)}.
\]
Die Funktionenfolge $y^{(n)}$ konvergiert also gleichmäßig gegen $y$, womit die Stetigkeit von 
$y$ folgt, also $y\in C([x_0,x_\mathrm{end}])^d$. Damit gilt also
\[
\norm{y^{(n)}-y}_\infty = \max_{x\in [x_0,x_\mathrm{end}]}  \norm{y^{(n)}(x)-y(x)}\to 0,
\]
d.h. $y^{(n)}\to y$ bzgl. der Supremumsnorm.
\end{beweis}

Wir benötigen aber noch eine etwas abgewandelte Norm:
\begin{korollar}\label{kor:gewSupNorm}
Für eine Funktion $w\in C([x_0,x_\mathrm{end}])$ gelte
\[
\exists c,C>0:\ c\leq w(x)\leq C \quad \forall x\in [x_0,x_\mathrm{end}].
\]

Dann ist $C([x_0,x_\mathrm{end}])^d$ auch bzgl. der 
\emph{gewichteten Supremumsnorm} 
\[
\norm{y}_w:= \max_{x\in [x_0,x_\mathrm{end}]} \left( w(x) \norm{y(x)}\right)
\]
ein Banachraum.
\end{korollar}
\begin{beweis}
Offenbar ist $\norm{\cdot}_w$ tatsächlich eine Norm und es gilt 
\[
c\norm{y}_\infty \leq \norm{y}_w\leq C\norm{y}_\infty \quad \forall y\in C([x_0,x_\mathrm{end}])^d.
\]
Insbesondere ist jede Cauchy-Folge bzgl. $\norm{\cdot}_w$ auch eine bzgl. $\norm{\cdot}_\infty$ und
der Grenzwert bzgl. $\norm{\cdot}_\infty$ ist auch der Grenzwert bzgl. $\norm{\cdot}_w$.
\end{beweis}

Wir formulieren noch die Anfangswertaufgabe in eine Fixpunktgleichung um.
\begin{lemma}\label{lemma:PL_hilf}
Es gelten die Voraussetzungen von  Satz \ref{thm:PL}. Eine 
%in $[x_0,x_\mathrm{end}]$ stetige und in $(x_0,x_\mathrm{end})$ 
stetig differenzierbare Funktion $y:\ [x_0,x_\mathrm{end}]\to \R^d$ erfüllt genau dann das AWP
\[
y'(x)=f(x,y(x)) \quad \forall x\in (x_0,x_\mathrm{end}) \quad \mbox{ und } \quad y(x_0)=y_0,
\]
wenn $y$ stetig ist und die folgende Fixpunktgleichung löst:
\[
y(x)=y_0+ \int_{x_0}^x f(t,y(t))\dx[t] \quad \forall x\in  [x_0,x_\mathrm{end}].
\]
\end{lemma}
\begin{beweis}
Ist $y$ stetig differenzierbar und erfüllt das AWP, so ist 
\[
y(x)=y(x_0)+\int_{x_0}^x y'(t) \dx[t]=y_0+ \int_{x_0}^x f(t,y(t))\dx[t] \quad \forall x\in  [x_0,x_\mathrm{end}].
\]

Ist umgekehrt $y$ stetig und erfüllt die Fixpunktgleichung,
so ist auch $t\mapsto f(t,y(t))$ stetig und
\[
y(x)=y_0+ \int_{x_0}^x f(t,y(t))\dx[t]
\]
ist differenzierbar, $y'(x)=f(x,y(x))$ und $y(x_0)=y_0$.
\end{beweis}

Jetzt können wir Satz \ref{thm:PL} beweisen:

\textbf{Beweis von Satz \ref{thm:PL}:} Nach unserer Vorarbeit genügt es zu zeigen, 
dass durch
\[
y \mapsto \Phi(y), \quad \Phi(y): x\mapsto y_0+ \int_{x_0}^x f(t,y(t))\dx[t]
\]
eine bzgl. einer gewichteten Supremumsnorm kontrahierende Selbstabbildung von 
$C([x_0,x_\mathrm{end}])^d$ ist.

Die Selbstabbildungseigenschaft ist klar. Für die Kontraktionseigenschaft betrachten wir
für zwei Funktionen $y^{(1)},y^{(2)}\in C([x_0,x_\mathrm{end}])^d$
\begin{align*}
\lefteqn{\norm{\Phi(y^{(1)})(x)-\Phi(y^{(2)})(x)}}\\
&=\norm{ \int_{x_0}^x \left( f(t,y^{(1)}(t)) - f(t,y^{(2)}(t)) \right)\dx[t]}\\
&\leq \int_{x_0}^x \norm{ f(t,y^{(1)}(t)) - f(t,y^{(2)}(t)) } \dx[t]
\leq \int_{x_0}^x L \norm{ y^{(1)}(t) - y^{(2)}(t) } \dx[t]
\end{align*}
Hieraus folgt 
\[
\norm{\Phi(y^{(1)}) - \Phi(y^{(2)}) }_\infty  \leq L (x_\mathrm{end}-x_0) \norm{y^{(1)} - y^{(2)}}_\infty,
\]
so dass $\Phi$ nur für kleine $L$ oder nah an $x_0$ liegendes $x_\mathrm{end}$ eine Kontraktion ist.

Durch Einfügen einer Gewichtsfunktion $w(x)$ (mit den in Folgerung \ref{kor:gewSupNorm} genannten Eigenschaften) erhalten wir jedoch
\begin{align*}
\lefteqn{w(x) \norm{\Phi(y^{(1)})(x)-\Phi(y^{(2)})(x)}}\\
&\leq w(x) \int_{x_0}^x L \frac{1}{w(t)} w(t) \norm{ y^{(1)}(t) - y^{(2)}(t) } \dx[t]\\
&\leq w(x) L \norm{y^{(1)} - y^{(2)}}_w \int_{x_0}^x \frac{1}{w(t)} \dx[t]
\end{align*}
und damit
\begin{align*}
\norm{\Phi(y^{(1)}) - \Phi(y^{(2)}) }_w&\leq \norm{y^{(1)} - y^{(2)}}_w
L \max_{x\in [x_0,x_\mathrm{end}]} \left(w(x) \int_{x_0}^x \frac{1}{w(t)} \dx[t]\right).
\end{align*}
$\Phi$ ist also eine Kontraktion bzgl. $\norm{\cdot}_w$ wenn wir eine Gewichtsfunktion 
$w$ finden mit
\[
L\left(w(x) \int_{x_0}^x \frac{1}{w(t)} \dx[t]\right)<1 \quad \forall x\in [x_0,x_\mathrm{end}].
\]
Offenbar gilt dass 
\[
e^{-a(x-x_0)} \int_{x_0}^x \frac{1}{e^{-a(t-x_0)}} \dx[t]\leq\frac{1}{a}.
\]
Mit $w(x)=e^{- L/2(x-x_0)}$ ist also $\Phi$ eine Kontraktion (mit Kontraktionskonstante $1/2$) 
bzgl. $\norm{\cdot}_w$, womit Satz \ref{thm:PL} bewiesen ist. \hfill $\Box$

\begin{beispiel}\label{bsp:PL}
Auf die Voraussetzung der Lipschitz-Stetigkeit kann nicht verzichtet werden, wie die folgenden
Beispiele zeigen:
\begin{enumerate}[(a)]
\item  Betrachte das AWP
\[
y'=\sqrt{y}, \quad y(0)=0.
\]
Die rechte Seite $f(x,y):=\sqrt{y}$ ist nicht Lipschitz-stetig. Tatsächlich ist die Lösung des AWP nicht eindeutig. Zwei Lösungen sind z.B.
\[
y(x)=0 \quad \mbox{ und } \quad y(x)=\left\{ \begin{array}{l l} 0 & \mbox{ für } 0\leq x\leq 1,\\ \frac{1}{4}(x-1)^2 & \mbox{ für } x>1.
\end{array} \right. 
\]
%
\item Betrachte das AWP
\[
y'=y^2,\quad y(0)=1.
\]
Die rechte Seite $f(x,y)=y^2$ ist nur lokal aber nicht global Lipschitz stetig. Man kann zeigen, dass nur 
\[
y(x)=\frac{1}{1-x}
\]
das AWP lösen kann. Die Lösung existiert also nur auf dem Intervall $[0,1)$.
\end{enumerate}
\end{beispiel}

\begin{bemerkung}
Beispiel~\ref{bsp:PL}(b) zeigt in gewisser Weise das Schlimmste, was für eine nur lokal Lipschitz-stetige rechte Seite passieren kann. 
$f$ erfülle die Lipschitz-Bedingung
\[
\norm{f(x,y^{(1)})-f(x,y^{(2)})}\leq L \norm{y^{(1)}-y^{(2)}} \quad \forall x\in [x_0,x_\mathrm{end}],\ y^{(1)},y^{(2)}\in \overline Q.
\]
nur in einem Rechteck $Q:=(a_1,b_1)\times \dots \times (a_d,b_d)$.
Dann kann man zeigen, dass für jeden Anfangswert $y_0\in Q$, ein nichtleeres Teilintervall $[x_0,x_1]$ existiert auf dem genau eine Lösung existiert.
Darüber hinaus kann man zeigen, dass sich die Lösungskurve $(x,y(x))$ bis zum Rand des Rechtecks eindeutig fortsetzen lässt.
\end{bemerkung}

\paragraph{Stabilität}

Nun untersuchen wir wie sich eine Störung der Anfangswerte auf die Lösung auswirkt.

\begin{theorem}\label{thm:stability}
Es gelten weiterhin die Voraussetzungen von Satz \ref{thm:PL}.
$y$ und $z$ seien zwei Lösungen der gleichen DGL, aber mit verschiedenen Anfangswerten, also
\begin{align*}
y'(x)&=f(x,y(x)), \qquad y(x_0)=y_0,\\
z'(x)&=f(x,z(x)), \qquad z(x_0)=z_0.
\end{align*}
Dann gilt
\[
\norm{y(x)-z(x)} \leq e^{L (x-x_0)} \norm{y_0-z_0} \quad \forall x\in [x_0,x_\mathrm{end}].
\]
\end{theorem}
\begin{beweis}
Betrachte die Differenz
\[
s(x):=\norm{y(x)-z(x)}^2=(y(x)-z(x))^T (y(x)-z(x)).
\]
Es ist
\begin{align*}
s'(x) &= 2 (y'(x)-z'(x))^T (y(x)-z(x))\\
 &= 2 (f(x,y(x))-f(x,z(x)))^T (y(x)-z(x))\\
&\leq 2 \norm{ f(x,y(x))-f(x,z(x)) }\, \norm{y(x)-z(x)}\\
&\leq 2 L \norm{y(x)-z(x)}^2=2L s(x).
\end{align*}

Im Fall $y_0=z_0$ gilt nach Satz~\ref{thm:PL} $y(x)=z(x)$ für alle $x\geq x_0$ und die Behauptung ist bewiesen. Ansonsten existiert ein größtmögliches Intervall $[x_0,x_0+\delta)$ auf dem 
$s(x)\neq 0$ gilt und im Falle $x_0+\delta<x_\mathrm{end}$ ist $s(x_0+\delta)=0$
(siehe Übungsaufgabe 2.5). Es genügt die Behauptung in diesem Intervall zu zeigen,
da für $s(x_0+\delta)=0$ nach Satz~\ref{thm:PL} $y(x)$ und $z(x)$
ab $x\geq x_0+\delta$ übereinstimmen.

Tatsächlich gilt für alle $x\in [x_0,x_0+\delta)$
\[
\frac{d}{d x} \ln s(x)=\frac{s'(x)}{s(x)}\leq 2L
\]
also
\[
\ln s(x)=\int_{x_0}^x \frac{d}{d t} \ln s(t) \dx[t] + \ln s(x_0) \leq 2L (x-x_0) + \ln s(x_0)
\]
d.h.
\[
\norm{y(x)-z(x)}^2=s(x)\leq e^{2L(x-x_0)} s(x_0)=e^{2L(x-x_0)} \norm{y_0-z_0}^2,
\]
womit die Behauptung gezeigt ist.
\end{beweis}
%

\begin{bemerkung}
\begin{enumerate}[(a)]
\item Auch wenn $f$ nur lokal Lipschitz-stetig, gilt das Stabilitätsresultat in Satz \ref{thm:stability} noch dort, wo die eindeutige Existenz der Lösungen gesichert ist.

\item 
Wir werden in dieser Vorlesung im Folgenden annehmen, dass $f$ beliebig oft stetig differenzierbar (und damit inbesondere in jeder kompakten Menge Lipschitz-stetig) ist, so dass das AWP
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0.
\]
zumindest in einem hinreichend kleinen Intervall $[x_0,x_\mathrm{end}]$ wohlgestellt ist, also 
eine eindeutige Lösung existiert und diese (im Sinne von Satz \ref{thm:stability}) stabil vom
Anfangswert abhängt.

Außerdem kann man zeigen, dass die Lösung des AWP dann ebenfalls unendlich oft stetig 
differenzierbar ist.
\end{enumerate}
\end{bemerkung}

\section{Erste Lösungsmethoden}\label{Sect:NumODE_Motivation}

\subsection{Das Richtungsfeld}

Zur anschaulichen Herleitung einfacher erster Lösungsmethoden betrachten wir ein skalares AWP, 
in dem wir die Lösung $y: [x_0,\infty)\to \R$ von
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0\in \R
\]
suchen.

Wir können uns die DGL $y'(x)=f(x,y(x))$ durch das dazugehörige Richtungsfeld veranschaulichen: Zu jedem Punkt
$(x,y)\in \R^2$ zeichnen wir einen Richtungspfeil mit Steigung $f(x,y)$, z.B. den Vektor $(1,f(x,y))^T$ (\fixme[Bild: Richtungsfeld $f(x,y(x))=x$]). Eine Funktion löst die DGL genau dann, wenn an jedem
Punkt durch den die Funktion geht, die Steigung der Funktion und die Steigung des Richtungspfeils übereinstimmen.
Wir können die DGL zeichnerisch lösen, indem wir ausgehend vom Startwert $(x,y_0)$ die Funktion passend 
zu den Richtungspfeilen zeichnen.

\subsection{Explizites Euler-Verfahren}

Basierend auf dieser zeichnerischen Idee gehen wir nun systematischer vor und entwickeln ein erstes numerisches Lösungsverfahren.
Betrachte das allgemeine (vektorwertige) AWP
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0\in \R^d
\]
auf dem Intervall $x\in [a,b]$, $a:=x_0$. Wir diskretisieren das Intervall durch $n+1$ Punkte
\[
a=x_0 < x_1 < \ldots < x_n=b,
\]
also unter Verwendung der \emph{Schrittweite}
$h_i:=x_{i+1}-x_i$, $i=0,\ldots,n-1$.
Beginnend mit $x_0$ (wo wir die Lösung kennen, $y(x_0)=y_0$) berechnen wir 
nun sukzessiv Approximationen $y_i\approx y(x_i)$. 

Der einfachste Möglichkeit ist die \emph{explizite Eulermethode}, bei der wie die Steigung im aktuellen
Punkt verwenden, um die Approximation im nächsten Punkt zu berechnen:\footnote{Hier und im Folgenden bezeichen wir mit $y_0, y_1,\ldots, y_n\in \R^d$ $d$-dimensionale Vektoren und nicht die Einträge eines Vektors.}

\begin{align*}
y_1 & :=y_0+h_0 f(x_0,y_0)\\
y_2 & :=y_1+h_1 f(x_1,y_1)\\
\vdots \;&\qquad\qquad \vdots\\
y_{i+1} & :=y_i+h_i f(x_i,y_i)\\
\vdots \;&\qquad\qquad \vdots\\
y_n & :=y_{n-1}+h_{n-1} f(x_{n-1},y_{n-1})
\end{align*}

Dies entspricht dem zeichnerischen Lösen der DGL im Richtungsfeld durch eine stückweise lineare Funktion,
bei der die Steigung der Liniensegmente im \emph{linken Punkt} mit dem Richtungsfeld übereinstimmt.

Das gleiche Verfahren erhalten wir auch durch Diskretisierung der DGL mit finiten Differenzen (Vorwärtsdifferenzenquotient):
\begin{align*}
\frac{y_{i+1}-y_i}{x_{i+1}-x_i}
\approx \frac{y(x_{i+1})-y(x_{i})}{x_{i+1}-x_i} \approx y'(x_i)= f(x_i,y(x_i))\approx f(x_i,y_i).
\end{align*}
Man erhält die Iteration
\[
	y_{i+1} \approx y_i + \underbrace{(x_{i+1} - x_{i})}_{h_i} f(x_i, y_i)
\]
in Übereinstimmung mit der grafischen Lösungsmethode.

Das explizite Eulerverfahren heißt auch Vorwärts-Euler-Verfahren (engl.: \emph{forward Euler}).


\subsection{Implizites Euler-Verfahren}

Bei der zeichnerischen Lösung der DGL im Richtungsfeld durch eine stückweise lineare Funktion,
könnten wir auch versuchen die Funktion so zu wählen, dass die Steigung der Liniensegmente
im \emph{rechten Punkt} mit dem Richtungsfeld übereinstimmt.

Dann haben wir keine explizite Formel für die Berechnung von $y_{i+1}$ aus $y_i$.
Statt dessen ist $y_{i+1}$ \emph{implizit} gegeben als Lösung von 
\[
y_{i+1} = y_i+h_i f(x_{i+1},y_{i+1}).
\]

Bei diesem \emph{impliziten Euler-Verfahren} müssen wir also für jedes $y_i\in \R^d$, $i=2,\ldots,n$,
ein (üblicherweise nicht-lineares) $d$-dimensionales Gleichungssytem lösen.

Wieder erhalten wir das Verfahren auch durch Diskretisierung der DGL mit finiten Differenzen, diesmal mit 
dem Rückwärtsdifferenzenquotienten:
\begin{align*}
\frac{y_{i+1}-y_i}{x_{i+1}-x_i}
\approx \frac{y(x_{i+1})-y(x_{i})}{x_{i+1}-x_i} \approx y'(x_{i+1})= f(x_{i+1},y(x_{i+1}))\approx f(x_{i+1},y_{i+1}).
\end{align*}
Enstprechend heißt das implizite Euler-Verfahren auch Rückwärts-Euler-Ver\-fah\-ren (engl.: \emph{backward} Euler).

\begin{bemerkung}
Wie wir noch sehen werden, besitzen implizite Verfahren für manche (die sogenannten \emph{steifen}) Differentialgleichungen so große Vorteile, dass sie den erhöhten Aufwand wert sind.
\end{bemerkung}

\subsection{Weitere explizite und implizite Methoden}\label{subsect:More_ex_and_im_methods}

Die anschauliche Idee, stückweise lineare Funktion ins Richtungsfeld zu zeichnen, führt auf 
viele weitere explizite und implizite Methoden:

\paragraph{Implizite Mittelpunktsregel.}

Zuerst zeichnen wir die Liniensegmente so, dass die Steigung der Segmente in ihrem \emph{Mittelpunkt}
mit dem Richtungsfeld übereinstimmt.

Wir bestimmen also erst $y_{i+1/2}$ durch Lösung der Gleichung
\[
y_{i+1/2}  =y_i+\frac{h_i}{2} f\left( \frac{x_{i+1}+x_i}{2},y_{i+1/2} \right)
\]
und setzen dann
\[
y_{i+1}:=y_i+ h_i  f\left( \frac{x_{i+1}+x_i}{2},y_{i+1/2} \right)
\]
Dies ist die sogenannte \emph{implizite Mittelpunktsregel}, die auch als Kombination eines
halben impliziten Eulerschrittes mit einem halben expliziten Eulerschritt interpretiert (und implementiert) 
werden kann.

\paragraph{Verfahren von Runge.}
Wir können auch versuchen, eine explizite Formel für $y_{i+1/2}$ zu finden. Dafür setzen wir
\[
y_{i+1/2}  :=y_i+\frac{h_i}{2} f(x_i,y_i)
\]
und wählen dann wie in der impliziten Mittelpunktsregel
\[
y_{i+1}:=y_i+ h_i  f\left( \frac{x_{i+1}+x_i}{2},y_{i+1/2} \right).
\]
Dies ist das \emph{Verfahren von Runge}. Beachte dass dies nicht nur die Kombination 
zweier Halbschritte des expliziten Eulerverfahrens ist.

\paragraph{Crank-Nicolson Methode.}
Die nächste Methode erhalten wir durch die Forderung, dass die Steigung der Liniensegmente mit dem Mittelwert
der Steigungen im Richtungsfeld im linken und rechten Randpunkt des Segments übereinstimmen soll:
\[
y_{i+1} = y_i+h_i \frac{f(x_{i},y_{i})+f(x_{i+1},y_{i+1})}{2}.
\]
Dies ist die \emph{Crank-Nicolson Methode}.

\paragraph{Verfahren von Heun.}
Eine explizite Alternative zur Crank-Nicolson Methode erhalten wir, indem wir $y_{i+1}$ auf der rechten Seite 
der Crank-Nicolson-Formel durch einen Schritt mit dem expliziten Euler-Verfahren approximieren:
\begin{align*}
\eta & :=y_i+h_i f(x_i,y_i)\\
y_{i+1} &:= y_i+h_i \frac{f(x_{i},y_{i})+f(x_{i+1},\eta)}{2}.
\end{align*}






\section{Einschrittmethoden höherer Ordnung}

\paragraph{Generalvoraussetzung:} 

In diesem Abschnitt sei $[a,b]\subset \R$, $b>a$ stets ein festes Intervall. Wir werden im Folgenden nur Differentialgleichungen
\[
y'(x)=f(x,y(x))
\]
mit unendlich oft differenzierbarer rechter Seite $f$ betrachten. Insbesondere ist $f$ also lokal Lipschitz stetig.

Der Einfachheit halber fordern wir zusätzlich dass \textbf{alle partiellen Ableitungen (jeder Ordnung)} von $f$ in $[a,b]\times \R^d$ beschränkt sind.
\begin{note}
	Im Folgenden bezeichnet $\|\cdot\|$ auf $\R^d$ immer die Euklidische Norm und auf $\R^{d\times d}$ die davon induzierte Form.
\end{note}
Insbesondere existiert ein $L>0$ so dass
\[
\norm{f_y(x,y)}\leq L \quad \forall (x,y)\in [a,b]\times \R^d,
\]
wobei 
\[
f_y(x,y):=\frac{\partial f}{\partial y} (x,y)= \left( \frac{\partial f_i}{\partial y_j}(x,y) \right)_{i,j=1}^d\in \R^{d\times d}.
\]
Damit gilt also für alle $x\in [a,b]$ und $y,z\in \R^d$ 
\[
\norm{f(x,y)-f(x,z)}=\norm{\int_0^1 f_y(x,y+t(z-y)) (z-y) \dx[t]}\leq L \norm{y-z}
\]
und nach Abschnitt \ref{subsec:wohlgestellt} ist somit für jede Wahl der Anfangswerte $x_0\in [a,b]$ und $y_0\in \R^d$ die eindeutige Existenz von Lösungen und ihre stetige Abhängigkeit von den Anfangswerten garantiert.

Außerdem kann man zeigen, dass dann alle Ableitungen jeder Lösung eines AWP mit rechter 
Seite $f$ beschränkt sind. Präzise ausgedrückt: Zu jeder solchen rechten Seite $f$ existieren Konstanten $C_k>0$ ($k\in \N_0$), so dass für jede Wahl der Anfangswerte $x_0\in [a,b]$ und $y_0\in \R^d$ die zugehörige 
Lösung von 
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0\in \R^d
\]
erfüllt, dass
\[
\sup_{x\in [x_0,b]} \norm{y^{(k)}(x)} \leq C_k.
\]

Auf diese globale Zusatzvoraussetzung kann verzichtet werden, wenn die Lösbarkeit sichergestellt ist und die Approximationen an die Lösung beschränkt bleiben (z.B. auf einem beschränkten Gebiet).


\subsection{Konsistenz und Konvergenz}\label{subsect:ConsitencyOrder}

Zur Lösung des AWP
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0\in \R^d
\]
diskretisieren wir das Intervall in $n+1$ Punkte
\[
a=x_0 < x_1 < \ldots < x_n=b.
\]
Beginnend mit $x_0$ (wo wir die Lösung $y(x_0)=y_0$ kennen) versuchen wir sukzessive Approximationen $y_i\approx y(x_i)\in \R^d$ zu bestimmen.

Wir unterscheiden zwei verschiedene Approximationsmethoden:
\begin{description}
\item[Einschrittmethoden:] Nur der vorherige Punkt $y_i$ (und $x_i$, $x_{i+1}$, $h_i:=x_{i+1}-x_i$) wird zur Berechnung von $y_{i+1}$ verwendet.
\item[Mehrschrittmethoden:] Mehrere vorherige Punkte $y_i$, $y_{i-1}$, \ldots $y_{i-m}$ (und $x_{i+1}$, $x_{i}$, \ldots, $x_{i-m}$ ) 
werden zur Berechnung von $y_{i+1}$ verwendet.
($m+1$-Schritt Methode benötigt \emph{Startprozedur} zur Berechnung der ersten $m$ Werte $y_1$,\ldots, $y_m$).
\end{description}

Die Methoden in Abschnitt \ref{Sect:NumODE_Motivation} sind allesamt Einschrittmethoden. 

\begin{definition}\label{def:Konsistenz}
Eine Einschrittmethode heißt \emph{konsistent}, falls für jede (unsere Generalvoraussetzung erfüllende) rechte Seite
$f$ gilt, dass
\[
\lim_{h\to 0} \sup_{\substack{x_i\in [a,b]\\ y_i\in \R^d}} \frac{\left| y_{i+1}- y(x_i+h) \right|}{h} = 0
\]
wobei $y$ die Lösung des AWP
\[
y'(x)=f(x,y(x)), \qquad y(x_i)=y_i
\]
ist, und $y_{i+1}$ durch Anwendung der Methode auf $y_i$ mit Schrittweite $h$ erzeugt wurde.

Die Methode besitzt \emph{Konsistenzordnung} $p\in \N$, falls 
für jede (unsere Generalvoraussetzung erfüllende) rechte Seite
$f$ 
\[
\limsup_{h\to 0} \sup_{\substack{x_i\in [a,b]\\ y_i\in \R^d}} \frac{\left| y_{i+1}- y(x_i+h) \right|}{h^{p+1}}<\infty,
\]
d.h. Konstanten $C>0$, $h_0>0$ existieren, so dass für alle $0<h<h_0$:
\[
\sup_{\substack{x_i\in [a,b]\\ y_i\in \R^d}} \left| y_{i+1}- y(x_i+h) \right| \leq C h^{p+1}.
\]
\end{definition}


Eine Methode der Konsistenzordnung $p$ macht in jedem Intervall $[x_i,x_{i+1}]$ einen \emph{lokalen Fehler} 
der Größenordnung $\mathcal{O}(h^{p+1})$. Da es $n=\frac{b-a}{h}=\mathcal{O}(h^{-1})$ solche Intervalle gibt, erwarten wir dass der \emph{globale Fehler}
in der Größenordnung $\mathcal{O}(h^p)$ liegen wird. Der folgende Satz zeigt, dass dies tatsächlich der Fall ist.


\begin{theorem}\label{satz:konv_Einschritt}
Sei $y:\ [a,b]\to \R^d$ die Lösung des AWP
\[
y'(x)=f(x,y(x)), \qquad y(x_0)=y_0\in \R^d
\]

Wir betrachten die Anwendung einer Einschrittmethode mit
äquidistanter Diskretisierung, d.h. mit Schrittweite $h:=\frac{b-a}{n}>0$,
\[
a=x_0 < x_1 < \ldots < x_n=b, \qquad x_i=x_0+ih \quad (i=1,\ldots,n).
\]
%
\begin{enumerate}[(a)]
\item Ist die Methode konsistent, so gilt
\[
\max_{i=1,\ldots,n} \norm{y_i-y(x_i)}\to 0 \quad \mbox{ für $n\to \infty$}.
\]
%
\item Besitzt die Methode Konsistenzordnung $p$, so gilt
\[
\max_{i=1,\ldots,n} \norm{y_i-y(x_i)}\leq \frac{e^{L(b-a)}-1}{L} C h^p \quad \forall 0<h<h_0.
\]
wobei $C,h_0>0$ die Konstanten aus der Definition der Konsistenzordnung und $L$ die Lipschitz-Konstante
aus der Generalvoraussetzung ist.
\end{enumerate}
\end{theorem}
\begin{beweis}
Wir beginnen mit (b). Für die Schrittweite gelte $h=\frac{b-a}{n}<h_0$.
Da wir mit dem korrekten Startwert $y_0=y(x_0)$ beginnen, gilt für den Fehler nach dem ersten Schritt
\[
\norm{y_1-y(x_1)}\leq C h^{p+1}.
\]
Im nächsten Schritt, bei dem wir $y_2$ aus $y_1$ berechnen, gibt es zwei Fehlerquellen:
\begin{enumerate}[(i)]
\item Die Berechnung von $y_2$ aus $y_1$ mit dem Einschrittverfahren entspricht der Anwendung des 
Verfahrens auf das (wegen unserer Generalvoraussetzung eindeutig lösbare) AWP 
\begin{align}\labeq{Kons_AWPz}
z'(x)=f(x,z(x)), \qquad z(x_1)=y_1\in \R^d
\end{align}
Dabei macht das Verfahren den Fehler
\[
\norm{z(x_2)-y_2}\leq C h^{p+1}.
\]

\item Da $y_1$ nur eine Approximation an $y(x_1)$ ist, stimmt die Lösung $z(x)$ von \req{Kons_AWPz}
nicht mit $y(x)$ überein. Nach Satz \ref{thm:stability} gilt aber
\[
\norm{y(x_2)-z(x_2)} \leq e^{L (x_2-x_1)} \norm{y(x_1)-y_1}.
\]
\end{enumerate}

Insgesamt erhalten wir also
\begin{align*}
\norm{y_2-y(x_2)} &\leq \norm{y_2-z(x_2)} + \norm{z(x_2)-y(x_2)}\\
&\leq  C h^{p+1} + e^{Lh} \norm{y_1-y(x_1)}\\
&\leq  (1 + e^{Lh}) C h^{p+1}.
\end{align*}

Mit trivialer Induktion erhalten wir für alle $i=1,\ldots,n$:
\begin{align*}
\norm{y_i-y(x_i)} &\leq C h^{p+1} + e^{Lh} \norm{|y_{i-1}-y(x_{i-1})|} \\
&\leq C h^{p+1} + e^{Lh} \left( C h^{p+1} + e^{Lh} \norm{y_{i-2}-y(x_{i-2})} \right)  \\
&\leq \ldots \leq  \left( 1+ e^{Lh} + e^{2Lh} + e^{(i-1) Lh} \right) C h^{p+1}\\
& \leq \sum_{j=0}^{n-1} \left(e^{Lh}\right)^{j}  C h^{p+1}
= \frac{(e^{Lh})^n-1}{e^{Lh}-1} C h^{p+1}.
\end{align*}
und mit $e^{Lh}\geq 1+Lh$ folgt 
\begin{align*}
\max_{i=1,\ldots,n} \norm{y_i-y(x_i)}&\leq  \frac{e^{nhL}-1}{Lh} C h^{p+1}= \frac{e^{L(b-a)}-1}{L} C h^{p}.
\end{align*}

Der Beweis von (a) geht analog.
\end{beweis}

\medskip
\textbf{Bemerkung}\\
Im Folgenden verwenden wir im Zusammenhang mit Anfangswertproblemen
die Landau-Notation $\mathcal{O}(h^p)$, $o(h)$, etc., mit der Konvention, dass
die darin vorkommenden Konstanten von der rechten Seite $f$ nicht jedoch von dem Anfangswert $x_0\in [a,b]$, $y_0\in \R^d$
abhängen dürfen. Mit dieser Konvention ist ein Einzelschrittverfahren
\begin{itemize}
\item konsistent, falls aus $y_i=y(x_i)$ folgt, dass 
\[
y(x_{i+1})-y_{i+1}=o(h).
\]
\item konsistent mit Ordnung $p$, falls aus $y_i=y(x_i)$ folgt, dass 
\[
y(x_{i+1})-y_{i+1}=\mathcal{O}(h^{p+1}).
\]
\end{itemize}
%\end{bemerkung*}

\medskip

\begin{beispiele}
\begin{enumerate}[(a)]
\item \textbf{Explizites Euler-Verfahren:} Für $y(x_i)=y_i$ erhalten wir durch Taylorentwicklung
\begin{align*}
\norm{y(x_{i+1}) - y(x_i)+h y'(x_i)}
\leq \frac{h^2}{2} \max_{\xi\in [x_i,x_{i+1}]} \norm{y''(\xi)}\leq \frac{h^2}{2} C_2
\end{align*}
mit einer (aufgrund unserer Generalvoraussetzung nur von der rechten Seite $f$ abhängigen) Konstante $C_2$. Es ist also mit obiger Konvention
\begin{align*}
y(x_{i+1}) &= y(x_i)+h y'(x_i) + \mathcal{O}(h^2)\\
&= y(x_i)+h f(x_i,y_i) + \mathcal{O}(h^2) = y_{i+1} + \mathcal{O}(h^2)
\end{align*}
und das explizite Euler-Verfahren besitzt somit Konsistenzordnung $1$.
%
\item \textbf{Implizites Euler-Verfahren:} Für $y(x_i)=y_i$ erhalten wir wiederum durch Taylorentwicklung
\begin{align*}
y(x_i) &=y(x_{i+1})- h y'(x_{i+1}) + \mathcal{O}(h^2)\\
       &=y(x_{i+1})- h f(x_{i+1},y(x_{i+1})) + \mathcal{O}(h^2)
\end{align*}
Zusammen mit $y_{i+1}=y_i+hf(x_{i+1},y_{i+1})$ erhalten wir
\begin{align*}
\norm{y_{i+1}-y(x_{i+1})} &= \norm{ y_i+h f(x_{i+1},y_{i+1}) - y(x_{i+1})}\\
&= h \norm{ f(x_{i+1},y_{i+1})-f(x_{i+1},y(x_{i+1})) } + \mathcal{O}(h^2)\\
& \leq h L \norm{ y_{i+1}-y(x_{i+1})}+ \mathcal{O}(h^2).
\end{align*}
Für hinreichend kleine $h$ gilt also
\begin{align*}
\norm{y_{i+1}-y(x_{i+1})} &= \frac{1}{1-hL} \mathcal{O}(h^2)=\mathcal{O}(h^2),
\end{align*}
da $ 1 \leq \frac{1}{1-hL} $ ist für $hL < 1$ und für $hL \leq \frac{1}{2}$ ist $ \frac{1}{1-hL} \leq 2$.
Das implizite Euler-Verfahren besitzt also Konsistenzordnung 1.
\end{enumerate}
\end{beispiele}


\subsection{Runge Kutta Methoden}

Wir betrachten nun einen allgemeinen Ansatz um Einschrittmethoden hoher Konsistenzordnung zu konstruieren. 
Im ersten Schritt (mit $h=x_1-x_0$) soll gelten 
\[
y_{1}\approx y(x_{1})=y_0 + \int_{x_0}^{x_{1}} y'(t)\dx[t]=y_0 + \int_{x_0}^{x_{1}} f(t,y(t))\dx[t]
% h \sum_{j=1}^s b_j f(x_i+c_j h,\eta_j), \quad \sum_{j=1}^s b_j=1,
\]
Durch Approximation des Integrals auf der rechten Seite durch eine Quadraturformel erhalten wir 
\[
\int_{x_0}^{x_{1}} f(t,y(t))\dx[t] \approx h \sum_{j=1}^s b_j f(x_0+c_j h, y(x_0 + c_j h)) \approx h \sum_{j=1}^s b_j f(x_0+c_j h,\eta_j).
\]
Die Quadraturformel sollte zumindest konstante Funktion exakt integrieren, deshalb fordern wir
\[
\sum_{j=1}^s b_j=1.
\]
Die $c_j$ heißen \emph{Knoten}, $b_j$ \emph{Gewichte} und $s$ heißt \emph{Stufenzahl} des Verfahrens.

Dieser Ansatz verallgemeinert die Ideen aus Abschnitt \ref{subsect:More_ex_and_im_methods},
indem nun eine gewichtetes Mittel aus $s$ unterschiedlichen Steigungnen im Richtungsfeld an 
den Punkten $(x_0+c_j h,\eta_j)$, $j=1,\ldots,s$ verwendet werden.
Für das explizite Eulerverfahren ist $s=1$, $c_1=0$, and $\eta_1=y_0$.

$b_j$ und $c_j$ sollten aus den Knoten und Gewichten eines möglichst guten Quadraturverfahren bestimmt werden.
Zur Wahl der $\eta_j$ fordern wir dass 
\[
\eta_j \approx y(x_0+c_j h)=y_0 + \int_{x_0}^{x_0 + c_j h} y'(t)\dx[t]=y_0 + \int_{x_0}^{x_0 + c_j h} f(t,y(t))\dx[t].
\]
Wir wenden wiederum ein Quadraturverfahren für die Integrale auf der rechten Seite an und verwenden 
dabei die gleichen Quadraturpunkte wie für das erste Integral, d.h. für $j=1,\ldots, s$ verwenden wir
\[
\int_{x_0}^{x_0 + c_j h} f(t,y(t))\dx[t].\approx h \sum_{l=1}^s a_{jl} f(x_0 + c_l h,\eta_l).
\]
Wiederum sollten die Quadraturformeln zumindest konstante Funktionen exakt integrieren, deshalb fordern wir
\[
\sum_{l=1}^s a_{jl}=c_j.
\]

So erhalten wir die allgemeinen \emph{Runge-Kutta Methoden}:

\begin{alg}[Runge-Kutta Methoden]
	\begin{algorithmic}
		\Assume{$a_{jl}, b_j, c_j\in \R$, $j=1,\ldots, s$, $l=1,\ldots,s$ mit
			\[
				\sum_{j=1}^s b_j=1 \quad \mbox{ und } \quad \sum_{l=1}^s a_{jl}=c_j.
			\]
		}
		\State{Bestimme $\eta_j\in \R^d$, $j=1,\ldots,s$ aus 
			\begin{align}\labeq{RK_eta}
				\eta_j = y_i + h_i \sum_{l=1}^s a_{jl} f\Big(x_i + c_l h_i,\eta_l\Big), \quad j=1,\ldots,s.
			\end{align}
		}
		\State{Setze
			\[
				y_{i+1}:=y_i +  h_i \sum_{j=1}^s b_j f\Big(x_i+c_j h_i,\eta_j\Big).
			\]
		}
	\end{algorithmic}
\end{alg}

Runge-Kutta Methoden können explizit oder implizit sein. Ist
\[
a_{jl}=0 \quad \mbox{ für } l\geq j,
\]
dann ist $\eta_1=y_1$, $\eta_2$ kann aus $\eta_1$ berechnet werden, usw. (explizite Runge-Kutta Methoden).
Ansonsten ist \req{RK_eta} ein System aus $sd$ Gleichungen für die $sd$ unbekannten Einträge der $d$-dimensionalen Vektoren
$\eta_j\in \R^d$, $j=1,\ldots,s$ (implizite Runge-Kutta Methoden).

Eine äquivalente Formulierung erhalten wir durch
\[
k_j:=f(x_i+c_j h,\eta_j)
\]
\begin{alg}[Runge-Kutta Methoden (Alternative Formulierung)]
	\begin{algorithmic}
		\Assume{$a_{jl}, b_j, c_j\in \R$, $j=1,\ldots, s$, $l=1,\ldots,s$ mit
			\[
				\sum_{j=1}^s b_j=1 \quad \mbox{ und } \quad \sum_{l=1}^s a_{jl}=c_j.
			\]
		}
		\State{Bestimme $k_j\in \R^d$, $j=1,\ldots,s$ aus
			\[
				k_j=f\bigg(x_i+c_j h,\; y_i + h \sum_{l=1}^s a_{jl} k_l\bigg), \quad j=1,\ldots,s.
			\]
		}
		\State{Setze
			\[
				y_{i+1}:=y_i +  h \sum_{j=1}^s b_j k_j.
			\]
		}
	\end{algorithmic}
\end{alg}
Die Koeffizienten $A=(a_{jl})\in \R^{s\times s}$, $b=(b_j)\in \R^s$ und $c=(c_j)\in \R^s$
einer Runge-Kutta Methode lassen sich im sogenannten \emph{Butcher Tableau} zusammenfassen:
\[
\begin{array}{c | c}
c & A \\ \hline 
& b^T
\end{array} \qquad \qquad
%
\begin{array}{c | c c c c}
c_1 & a_{11} & a_{12} & \hdots & a_{1s}\\
c_2 & a_{21} & a_{22} & \ldots&  a_{2s}\\
\vdots & \vdots & \vdots & & \vdots\\
c_s & a_{s1} & a_{s2} & \hdots & a_{ss}\\ \hline
 & b_1 & b_2 & \hdots & b_s
\end{array}
\]

Mit dieser Notation erhalten wir für das explizite und implizite Euler Verfahren
\[
\begin{array}{c | c}
0 & 0 \\ \hline 
& 1
\end{array} \qquad \qquad
\begin{array}{c | c}
1 & 1 \\ \hline 
& 1
\end{array}
\]


\subsection{Wohldefiniertheit impliziter Methoden}

Die Vorteile impliziter Runge-Kutta Methoden werden wir erst in Abschnitt \ref{sect:steif} kennenlernen. 
Wir zeigen aber an dieser Stelle schon, dass das nicht-lineare Gleichungssystem \req{RK_eta} für hinreichend kleine Schrittweiten eindeutig lösbar ist.

\begin{theorem}
Zu jeder rechten Seite $f$ (die die Generalvoraussetzung erfüllt)
und jedem Runge-Kutta Verfahren $(A,b,c)$ existiert eine Schrittweite $h_0>0$,
so dass für jedes $x\in [a,b]$, $y\in \R^d$ und $0<h\leq h_0$ das 
Gleichungsystem für die $\eta_j$:
\begin{align*}%\labeq{RK_eta}
\eta_j = y + h \sum_{l=1}^s a_{jl} f(x + c_l h,\eta_l), \quad j=1,\ldots,s
\end{align*}
eindeutig lösbar ist.
\end{theorem}
\begin{beweis}
Wir schreiben das Gleichungssystem als Fixpunktgleichung 
\[
\eta=\Phi(\eta)
\]
mit 
\[
\eta:=\begin{pmatrix} \eta_1\\ \vdots \\ \eta_s \end{pmatrix}\in \R^{ds}, \quad
\Phi(\eta):=\begin{pmatrix} \Phi_1(\eta)\\ \vdots \\ \Phi_s(\eta) \end{pmatrix}\in \R^{ds}
\]
wobei
\[
\Phi_j(\eta):=y + h \sum_{l=1}^s a_{jl} f(x + c_l h,\eta_l)\in \R^d.
\]

Es ist
\begin{align*}
\Phi'(\eta)&=\begin{pmatrix} \Phi_1'(\eta)\\ \vdots \\ \Phi_s'(\eta) \end{pmatrix}\in \R^{ds\times ds}\\
\Phi_j'(\eta)&= \begin{pmatrix} \frac{\partial \Phi_j}{\partial \eta_1} & \cdots & \frac{\partial \Phi_j}{\partial \eta_s} \end{pmatrix}\in \R^{d\times ds}\\
\frac{\partial \Phi_j}{\partial \eta_l} &=  h a_{jl} \f{\partial}{\partial \eta_l}f\Big(x + c_l h,\eta_l\Big) \in \R^{d\times d}.
\end{align*}
Aufgrund unserer Generalvoraussetzung und der Äquivalenz aller Normen auf dem $\R^{d\times d}$ existiert ein $C>0$, so
dass für alle $j,l=1,\ldots,d$ jeder Eintrag der Matrix $\frac{\partial \Phi_j}{\partial \eta_l}$ durch $Ch$ beschränkt ist.
Damit ist jeder Eintrag von $\Phi'(\eta)$ durch $Ch$ beschränkt und (wegen der Äquivalenz aller Normen auf dem $\R^{ds\times ds}$) existiert ein $C'>0$ mit
\[
\norm{\Phi'(\eta)}\leq C'h.
\]
Für hinreichend kleine $h$ ist $\Phi$ also eine Kontraktion, denn
\[
	\Big\| \Phi(\eta^{(2)}) - \Phi(\eta^{(1)}) \Big\|
	= \bigg\| \int_0^1 \Phi'\Big(\eta^{(1)} + t (\eta^{(2)}-\eta^{(1)})\Big)(\eta^{(2)}-\eta^{(1)}) \dx[t] \bigg\|
	\le C'h \| \eta^{(2)} - \eta^{(1)} \|
\]
und damit folgte die Behauptung aus dem Banachschen Fixpunktsatz.
\end{beweis}




\subsection{Runge-Kutta Ordnungsbedingungen}

Im letzten Abschnitt haben wir gesehen, dass jede Wahl der Runge-Kutta Koeffizienten $(A,b,c)$ auf 
lösbare implizite (oder sogar explizite) Gleichung führt, das Verfahren also für jede Wahl der Koeffizienten durchführbar ist.
Jetzt wenden wir uns der Frage zu, wie die Koeffizienten gewählt werden müssen, um ein Verfahren möglichst hoher Ordnung zu erhalten.


\begin{theorem}\label{thm:RungeKuttaOrderCond}
Seien $A=(a_{ij})_{i,j=1,\ldots,s}$, $b=(b_i)_{i=1,\ldots,s}$ und $c=(c_i)_{i=1,\ldots,s}$ die Koeffizienten eines Runge-Kutta-Verfahrens.
%
\begin{enumerate}[(a)]
\item Aus
\[
\sum_{j=1}^s b_j=1 \quad \mbox{ und } \quad \sum_{k=1}^s a_{jk}=c_j  
\]
folgt dass das Verfahren (mindestens) Konsistenzordnung $1$ besitzt.
\item Das Verfahren hat genau dann mindestens Konsistenzordnung $2$, wenn
zusätzlich gilt, dass
\[
\sum_{j=1}^s b_jc_j=\frac{1}{2}.
\]
\item Das Verfahren hat genau dann mindestens Konsistenzordnung $3$, wenn
zusätzlich gilt, dass
\[
\sum_{j=1}^s b_j c_j^2 = \frac{1}{3}  \quad \mbox{ und } \quad  
\sum_{j=1}^s b_j \sum_{k=1}^s a_{jk} c_k = \frac{1}{6}.
\]
\end{enumerate}
\end{theorem}
\begin{beweis}
Wegen Übungsaufgabe 4.2 genügt es, die Behauptung für \emph{autonome} Differentialgleichungen
\[
y'=f(y), \quad f:\R^d \to \R^d
\]
zu beweisen.

Sei $y$ eine Lösung der DGL, $x_i\in [a,b]$, $y_i=y(x_i)$, $h=x_{i+1}-x_i$ und $y_{i+1}$ die durch das Runge-Kutta Verfahren 
erzielte Näherung. Nach Übungsaufgabe 3.2 gilt
\begin{align*}
y(x_{i+1})=y_i+h f+\f 12 h^2 f' f + \f 16 h^3 \Big( f^T f'' f + (f')^2 f \Big) + \mathcal{O}(h^4)
\end{align*}
wobei wir das Argument $(y_i)$ bei $f$ und seinen Ableitungen zur Vereinfachung der Schreibweise weglassen und folgende abkürzende Notation verwenden:
\begin{align*}
	u^T f'' v &= \begin{pmatrix}
		u^T H_{f_1}(y_i) v \\
		\vdots \\
		u^T H_{f_1}(y_i) v
	\end{pmatrix}
	= \Bigg( \sum_{j,k=1}^d \f{\partial^2 f_l(y_i)}{\partial y^{(j)}\partial y^{(k)}} u_jv_k \Bigg)_{l=1}^d
\end{align*}
Genauso entwickeln wir die Näherung $y_{i+1}$. Dabei verwenden wir immer wieder
\begin{align}\labeq{RK_opt_cond}
\eta_j = y_i + h \sum_{k=1}^s a_{jk} f(\eta_k), \qquad  \sum_{k=1}^s a_{jk}=c_j 
\end{align}
Zuerst erhalten wir damit (da $f$ insbesondere Lipschitzstetig)
\[
\eta_j=y_i + \mathcal{O}(h) \quad \Longrightarrow \quad f(\eta_j)=f(y_i) + \mathcal{O}(h) \quad \forall j=1,\ldots,s.
\]
Nochmalige Anwendung von \req{RK_opt_cond} führt zu
\[
\eta_j - y_i = h \sum_{k=1}^s a_{jk} f(\eta_k) = h \sum_{k=1}^s a_{jk} f(y_i) + \mathcal{O}(h^2)= h c_j f(y_i) + \mathcal{O}(h^2).
\]
Ein weiteres Mal verwenden wir \req{RK_opt_cond} und kombinieren es mit
\[
f(\eta_k)=f(y_i)+f'(y_i)(\eta_k-y_i) + \mathcal{O}(h^2).
\]
So erhalten wir
\begin{align*}
\eta_j &=  y_i + h \sum_{k=1}^s a_{jk} f(\eta_k) 
= y_i + h \sum_{k=1}^s a_{jk} \Big(f(y_i) + f'(y_i) (\eta_k-y_i) + \mathcal{O}(h^2)\Big)\\
&= y_i + h \sum_{k=1}^s a_{jk} \bigg(f(y_i) + f'(y_i) \left(h c_k f(y_i) + \mathcal{O}(h^2) \right) + \mathcal{O}(h^2)\bigg)\\
&= y_i + h c_j f(y_i)
+ h^2 f'(y_i) f(y_i) \sum_{k=1}^s a_{jk} c_k  
+ \mathcal{O}(h^3)
\end{align*}

Mit 
\[
y_{i+1}:=y_i +  h \sum_{j=1}^s b_j f(\eta_j), \quad \sum_{j=1}^s b_j=1
\]
folgt (wobei wir das Argument $(y_i)$ bei $f$ und seinen Ableitungen weglassen)
\begin{align*}
y_{i+1} &= y_i +  h \sum_{j=1}^s b_j f(\eta_j)\\
&=  y_i + h  \sum_{j=1}^s b_j \left( f + f' (\eta_j-y_i) + \frac{1}{2} (\eta_j-y_i)^T f'' (\eta_j-y_i)  + \mathcal{O}(h^3) \right)\\
&= y_i + h f + h f'  \sum_{j=1}^s b_j  (\eta_j-y_i) + \frac{1}{2} h \sum_{j=1}^s b_j (\eta_j-y_i)^T f'' (\eta_j-y_i) + \mathcal{O}(h^4)\\
&= y_i + h f + h f'  \sum_{j=1}^s b_j  \left( h c_j f + h^2 f' f \sum_{k=1}^s a_{jk} c_k + \mathcal{O}(h^3)\right)\\
& \quad {}   + \frac{1}{2} h \sum_{j=1}^s b_j \left( h c_j f + \mathcal{O}(h^2)\right)^T f'' \left( h c_j f + \mathcal{O}(h^2) \right) + \mathcal{O}(h^4)\\
&= y_i + h f + h^2 f' f  \sum_{j=1}^s b_j  c_j + h^3 (f')^2 f \sum_{j=1}^s b_j \sum_{k=1}^s a_{jk} c_k\\
& \quad {} + \frac{1}{2} h^3 f^T f'' f \sum_{j=1}^s b_j c_j^2 + \mathcal{O}(h^4)
\end{align*}

Die Behauptung folgt nun aus dem Vergleich der Entwicklungen von $y(x_{i+1})$ und $y_{i+1}$.
\end{beweis}

\begin{bemerkung}\label{remark:after_ordercond}
\begin{enumerate}[(a)]
\item Mit Satz~\ref{thm:RungeKuttaOrderCond} lässt sich die Ordnung der Verfahren in \ref{subsect:More_ex_and_im_methods} bestimmen.
\item Mit einem systematischeren \emph{symbolischen} Ansatz können Methoden beliebig hoher Ordnung konstruiert werden.
\item Man kann zeigen, dass die Ordnung eines $s$-stufigen Runge-Kutta Verfahrens höchstens $2s$ ist. Explizite Runge-Kutta
Verfahren können höchstens Ordnung $s$ haben (siehe Abschnitt \ref{subsect:limit_expl}).
\item Die in der Praxis wohl am häufigsten verwendete explizite Runge-Kutta Methode ist eine Methode 5. Ordnung von \emph{Dormand und Prince},
die durch folgendes Tableau gegeben ist:
\[
%
\begin{array}{c | c c c c c c}
0\\[+1ex]
\frac{1}{5} & \frac{1}{5}\\[+1ex]
\frac{3}{10} & \frac{3}{40} & \frac{9}{40}\\[+1ex]
\frac{4}{5} & \frac{44}{45} & -\frac{56}{15} & \frac{32}{9}\\[+1ex]
\frac{8}{9} & \frac{19372}{6561} & -\frac{25360}{2187} & \frac{64448}{6561} & -\frac{212}{729}\\[+1ex]
1 & \frac{9017}{3168} & -\frac{355}{33} & \frac{46732}{5247} & \frac{49}{176} & -\frac{5103}{18656}\\[+1ex] \hline 
\phantom{\frac{3}{3}^{\frac{3}{3}}}
& \frac{35}{384} & 0 & \frac{500}{1113} & \frac{125}{192} & -\frac{2187}{6784} & \frac{11}{84}
\end{array}
\]

Dieses Verfahren ist (in Kombination mit einer zur adaptiven Schrittweitensteuerung verwendeten Methode 4. Ordnung) unter dem Namen \texttt{dopri5} oder \texttt{ode45} in vielen Programmpaketen der Standardlöser für Anfangswertprobleme.
\end{enumerate}
\end{bemerkung}




\section{Numerik steifer Differentialgleichungen}\label{sect:steif}

\subsection{Steife Differentialgleichungen}\label{subsect:stiffness}

Bei dem Pendel aus Übungsaufgabe 3.4 waren implizite Verfahren (trotz gleicher Konsistenzordnung) den expliziten weit überlegen. 
Differentialgleichungen, in denen dieser Effekt auftritt, werden \emph{steif} genannt. Steif ist dabei kein mathematisch präzise definierter Begriff, sondern wird anschaulich für solche Differentialgleichungen verwendet, bei denen naheliegende Standardverfahren (z.B. explizite Runge-Kutta-Verfahren) keine (oder nur für extrem kleine Schrittweiten) zufriedenstellenden Ergebnisse liefern. 

Betrachten wir das einfache Beispiel 
\[
y'(x)=\lambda y,\quad y(0)=1, \quad \lambda<0.
\]
Offenbar ist die Lösung $y(x)=e^{\lambda x}$. Aufgrund der Annahme $\lambda<0$ konvergiert die
Lösung mit exponentieller Geschwindigkeit gegen Null.

Durch Anwendung des expliziten Euler-Verfahrens mit Schrittweite $h$ auf dieses AWP erhalten wir
\begin{align*}
	y_0 &= 1,\\
y_1 &= y_0 + h \lambda y_0=(1+h\lambda),\\
y_2 &= y_1 + h \lambda y_1=(1+h\lambda)y_1=(1+h\lambda)^2,\\
\vdots \; &= \qquad \vdots\\
y_n&= (1+h\lambda)^n.
\end{align*}

Da $\lambda<0$ folgt für $n\to \infty$ 
\[
\left\{ \begin{array}{l l} \mbox{$y_n\ge 0$ und $y_n\to 0$} & \mbox{ für $1+h\lambda \geq 0$}\\
\mbox{$y_n$ alterniert im Vorzeichen, $y_n\to 0$} & \mbox{ für $0>1+h\lambda>-1$}\\
\mbox{$y_n$ alterniert zwischen $+1$ und $-1$} & \mbox{ für $1+h\lambda=-1$}\\
\mbox{$y_n$ alterniert im Vorzeichen, $|y_n|\to \infty$} & \mbox{ für $1+h\lambda<-1$}
\end{array}\right.
\] 

Nur für $1+h\lambda \geq -1$ (d.h. $h\leq -\frac 2\lambda$) zeigen die Approximationen also das korrekte Langzeitverhalten und 
konvergieren gegen Null, und für $h> -\frac 1\lambda$ oszillieren die Approximationen.
Für dieses AWP mit stark negativem $\lambda$ liefert die explizite Euler Methode also nur
für extrem kleine Schrittweiten brauchbare Ergebnisse.

Betrachten wir zum Vergleich die implizite Euler-Methode:
\begin{alignat*}{2}
y_1 &= y_0 + h \lambda y_1 &\implies y_1&= (1-h\lambda)^{-1}\\
y_2 &= y_1 + h \lambda y_2 &\implies y_2&= (1-h\lambda)^{-1} y_1= (1-h\lambda)^{-2}\\ 
&&\vdots \qquad & \\
&&\implies y_n&=  (1-h\lambda)^{-n}
\end{alignat*}
Für jede Schrittweite $h>0$ ist $1-h\lambda>1$. $y_n$ bleibt also stets positiv und konvergiert gegen Null für $n\to \infty$.

Implizites und explizites Euler-Verfahren besitzen die gleiche Konsistenzordnung. Für $h\to 0$ konvergieren sie gleich schnell gegen die wahre Lösung. Jedoch gibt es zwei Eigenschaften der wahren Lösung, Positivität und Abfallverhalten, 
die nur die Iterierten des impliziten Euler-Verfahren für alle Schrittweiten zeigen. Die Iterierten des expliziten Euler-Verfahrens haben diese Eigenschaften erst für extrem kleine Schrittweiten $h$ (in unserem Beispiel für $\lambda \ll 0$).

Das betrachtete AWP ist also \emph{steif} in dem Sinne, dass die wahre Lösung gewisse Eigenschaften besitzt, die 
so wichtig sind, dass man nur solche numerischen Approximationen akzeptieren wird, die diese Eigenschaften auch besitzen.

\subsection{Die Testgleichung}

Wir motivieren nun heuristisch, dass sich das im letzten Abschnitt beobachtete Verhalten
auch in allgemeinen Anfangswertproblemen wiederfinden lässt.


Betrachten wir das allgemeine AWP
\[
y'(x)=f(x,y), \quad y(x_0)=y_0\in \R^d
\]
Gemäß Übungsaufgabe 4.2 können wir es in eine autonome Gleichung umformen. Außerdem können wir durch Verschiebung annehmen, 
dass $x_0=0$ ist.
\[
y'(x)=f(y),  \quad y(0)=y_0\in \R^d
\]
Für kleine $x$ wird sich die Lösung nur wenig verändern. Wir erwarten also, dass sich 
$y$ \emph{lokal} wie die Lösung der linearisierten Gleichung
\[
y'(x)=f(y)\approx f(y_0)+f'(y_0)(y-y_0), \quad y(0)=y_0\in \R^d
\]
verhält. 

Wir nehmen noch an, dass sich die Shifts $f(y_0)$ und $y_0$ durch geeignete Transformationen eliminieren lassen. 
%Uebungsaufgabe dazu?
Lokal lässt sich das AWP dann durch die Lösung der Gleichung 
\[
y'(x)=M y
\]
mit einer Matrix $M\in \R^{d\times d}$ approximieren. Ist $M$ diagonalisierbar mit Eigenwerten $\lambda_1,\ldots,\lambda_d$, dann ist dies äquivalent zu $d$ skalaren Testgleichungen
\[
y_j'=\lambda_j y_j, \quad j=1,\ldots,d.
\] 
Die Eigenwerte $\lambda_j$ werden im Allgemeinen komplex sein. Offenbar gelten aber alle Ergebnisse dieses Kapitels auch genauso für komplexwertige Gleichungen.

Insgesamt scheint es also erstrebenswert, Methoden zu konstruieren, die nicht nur möglichst schnell konvergieren, sondern auch
qualitativ richtiges Verhalten zeigen für die komplexe skalare Testgleichung
\[
y'=\lambda y, \quad \lambda\in \C.
\] 
Aufgrund der Linearität der Gleichung können wir dabei den Anfangswert auf $y(0)=1$ setzen.



\subsection{Die Stabilitätsfunktion}

Nach Abschnitt \ref{subsect:stiffness} gilt für die Iterierten des expliziten und impliziten Euler-Verfahrens
bei Anwendung auf die Testgleichung (mit $\lambda<0$)
\begin{align*}
y_i^{\mbox{\scriptsize (expl)}}&=(1+h\lambda )^i y_0=R^{\mbox{\scriptsize (expl)}}(h\lambda)^i y_0,\\
y_i^{\mbox{\scriptsize (impl)}}&=(1-h\lambda )^{-i} y_0=R^{\mbox{\scriptsize (impl)}}(h\lambda)^i y_0,
\end{align*}
wobei
\[
R^{\mbox{\scriptsize (expl)}}(\zeta):=(1+\zeta ), \quad \mbox{ und } \quad R^{\mbox{\scriptsize (impl)}}(\zeta)=(1-\zeta )^{-1}.
\]
Offenbar gilt das auch für $\lambda\in \C$. Wie gut die Verfahren für die Testgleichung funktionieren, lässt sich also
vollständig mit der Funktion $R(\zeta)$ beschreiben. Gleiches gilt für allgemeine Runge Kutta Methoden.

\begin{definition}[Stabilitätsfunktion]
Seien
\[
A=(a_{ij})_{i,j=1,\ldots,s}\in \R^{s\times s},\quad b=(b_i)_{i=1,\ldots,s}\in \R^s, \mbox{ und } c=(c_i)_{i=1,\ldots,s}\in \R^s
\]
die Koeffizienten einer Runge-Kutta-Methode. Sei
 $\1:=(1,\ldots,1)^T\in \R^s$ und $I\in \R^{s\times s}$ die Einheitsmatrix. Für $\zeta\in \C$ definieren wir
\[
R(\zeta):=1+\zeta b^T (I-\zeta A)^{-1} \1\in \C
\]
falls $I-\zeta A$ invertierbar ist. Ansonsten schreiben wir formal $R(\zeta)=\infty$.
(Offenbar ist dies genau dann der Fall, wenn $\frac{1}{\zeta}$ ein Eigenwert von $A$ ist,
also für höchstens $s$ komplexe Zahlen).
\end{definition}

\begin{theorem}\label{thm:R_for_RK}
Betrachte die Anwendung des Runge-Kutta Verfahrens mit Koeffizienten $A\in \R^{s\times s}$, $b,c\in \R^s$ 
auf die Testgleichung
\[
y'(x)=\lambda y(x), \quad y_0=1. 
\]
mit $\lambda\in \C$ und Schrittweite $h>0$.

Ist die Matrix $I-h \lambda A\in \C^{s\times s}$ invertierbar, so ist die Runge Kutta Methode 
anwendbar (d.h. die möglicherweise impliziten Gleichungen lösbar) und ihre Iterierten sind gegeben durch
\[
y_i=(R(h\lambda))^i.
\]
\end{theorem}
\begin{beweis}
Anwendung der Runge-Kutta Methode liefert das (möglicherweise implizite) Gleichungssystem
\[
\eta_j = y_i + h \sum_{l=1}^s a_{jl} \lambda \eta_l, \quad j=1,\ldots,s.
\]
Mit $\eta:=(\eta_1,\ldots,\eta_s)\in \C^s$ ist das äquivalent zu 
\[
\eta = y_i \1 + h\lambda A \eta \quad \Longleftrightarrow \quad (I-h\lambda A )\eta = y_i \1
\]
Ist $I-h \lambda A$ invertierbar, so existiert eine eindeutige Lösung $\eta$ und wir erhalten
\begin{align*}
y_{i}&:=y_{i-1} +  h \sum_{j=1}^s b_j \lambda \eta_j= y_{i-1} + h \lambda b^T \eta\\
&= y_{i-1} + h \lambda b^T (I-h\lambda A )^{-1} y_{i-1} \1 
= (1+h \lambda b^T (I-h\lambda A )^{-1} \1)y_{i-1}\\
&= (1+\zeta b^T (I- \zeta A )^{-1} \1)^{i} y_0=(R(\zeta))^i, \quad \zeta:=h\lambda\qquad \Box
\end{align*}
\end{beweis}


\begin{beispiel}
\begin{enumerate}[(a)]
\item Die Stabilitätsfunktion des expliziten Eulerverfahrens ist
$R(\zeta)=1+\zeta$.
\item Die Stabilitätsfunktion des impliziten Eulerverfahrens ist $R(\zeta)=(1-\zeta )^{-1}$.
\item Das Butcher Tableau für die implizite Mittelpunktsformel aus Abschnitt \ref{subsect:More_ex_and_im_methods} 
ist (vgl. Übungsaufgabe 4.1)
\[
\begin{array}{c | c}
1/2 & 1/2\\ \hline
 & 1
\end{array}
\]
Die Stabilitätsfunktion ist also
\begin{align*}
R(\zeta) &= 1+\zeta b^T (I-\zeta A)^{-1} \1= 1+\zeta 1 (1-\zeta\, 1/2)^{-1} 1
= \frac{1+\zeta/2}{1-\zeta/2}.
\end{align*}
% Übungsaufgabe:
% \item For the classical Runge-Kutta method (cf.\ Example \ref{ex:dopri45}(a))
% \[
% \begin{array}{c | c c c c}
% 0\\
% 1/2 & 1/2 \\
% 1/2 & 0 & 1/2\\
% 1 & 0 & 0 & 1\\ \hline
%  & 1/6 & 2/6 & 2/6 & 1/6
% \end{array}
% \]
% the stability function is
% \begin{align*}
% R(\zeta) &= 1+\zeta b^T (I-\zeta A)^{-1} \1\\
% &= 1+ \zeta \left( \begin{array}{c c c c}1/6 & 2/6 & 2/6 & 1/6\end{array} \right)
% \left( \begin{array}{c c c c}
% 1 & 0 & 0 & 0\\
% -\zeta/2 & 1 & 0 & 0\\
% 0 & -\zeta/2 & 1 & 0\\
% 0 & 0 & -\zeta & 1\end{array} \right)^{-1} 
% \left( \begin{array}{c}1\\ 1 \\ 1 \\ 1\end{array} \right)\\
% &= 1+ \zeta \left( \begin{array}{c c c c}1/6 & 2/6 & 2/6 & 1/6\end{array} \right)
% \left( \begin{array}{c c c c}
% 1 & 0 & 0 & 0\\
% \zeta/2 & 1 & 0 & 0\\
% \zeta^2/4 & \zeta/2 & 1 & 0\\
% \zeta^3/4 & \zeta^2/2 & \zeta & 1\end{array} \right)
% \left( \begin{array}{c}1\\ 1 \\ 1 \\ 1\end{array} \right)\\
% &= 1+ \zeta \left( \begin{array}{c c c c}1/6 & 2/6 & 2/6 & 1/6\end{array} \right)
% \left( \begin{array}{c}1\\ \zeta/2 + 1 \\ \zeta^2/4+\zeta/2 + 1 \\ \zeta^3/4 + \zeta^2/2 + \zeta + 1\end{array} \right)\\
% &= 1+ \zeta + \zeta^2/2 + \zeta^3/6 + \zeta^4/24.
% \end{align*}
\end{enumerate}
\end{beispiel}


\subsection{Stabilität}

Die exakte Lösung der Testgleichung $y'=\lambda y$, $y(0)=1$ ist 
\[
y(x)=e^{\lambda x}%=e^{\Re(\lambda) x} e^{\im \Im(\lambda)x}.
\]
Es gilt also
\[
|y(x)| \left\{ \begin{array}{l l l} \to \infty & \mbox{ für $x\to \infty$} & \mbox{ wenn } \Re(\lambda)>0 \\
\to 0 & \mbox{ für $x\to \infty$} & \mbox{ wenn } \Re(\lambda)<0 \\
=1 & \mbox{ für alle $x\geq 0$} & \mbox{ wenn } \Re(\lambda)=0
\end{array}\right.
\]
und außerdem ist, für alle $x>0$,
\[
|y(x)|\to 0, \quad \mbox{ wenn } \Re(\lambda)\to -\infty.
\]

Dies motiviert die folgende Definition.
\begin{definitiontheorem}[Stabilitätskriterien] \label{defthm:stability}
$y_i\approx y(hi)$ seien die Approximationen einer Einschrittmethode auf die Testgleichung $y'=\lambda y$, $y(0)=1$.
Die Methode heißt
\begin{itemize}
\item \emph{A-stabil} falls für $\Re(\lambda)\leq 0$ stets gilt, dass
\[
|y_{i+1}|\leq |y_i| \quad \mbox{ für alle $i$ und alle Schrittweiten $h$}
\]
\item \emph{Isometrie-erhaltend} wenn für $\Re(\lambda)=0$ stets gilt, dass
\[
|y_{i+1}|=|y_i|\quad \quad \mbox{ für alle $i$ und alle Schrittweiten $h$}
\]
\item \emph{L-stabil}, wenn sie A-stabil ist und (für alle $h>0$) 
\[
|y_1|\to 0 \quad \mbox{ für } |\lambda|\to \infty.
\]
\end{itemize}
Eine Runge-Kutta Methode ist genau dann
\begin{itemize}
\item A-stabil, wenn $|R(\zeta)|\leq 1$ für alle $\zeta\in \C$ mit $\Re(\zeta)\leq 0$,
\item Isometrie-erhaltend, wenn $|R(\zeta)|=1$ für alle $\zeta\in \C$ mit $\Re(\zeta)= 0$,
\item L-stabil, wenn A-stabil und $|R(\zeta)|\to 0$ für $|\zeta|\to \infty$.
\end{itemize}
\end{definitiontheorem}
\begin{beweis}
Die Äquivalenzen folgen aus $y_i=(R(h\lambda))^i$.
\end{beweis}

Man kann zeigen, dass die Stabilitätsfunktion eines Runge-Kutta Verfahrens stets eine rationale Funktion ist, so
dass (bei der Definition der L-Stabilität) das Verhalten für $|\zeta|\to \infty$ mit dem für $\Re(\zeta)\to -\infty$ übereinstimmt.

\begin{beispiel}
\begin{enumerate}[(a)]
\item Explizites Euler-Verfahren:
\[
|R(\im)|=|1+\im|=\sqrt{2}>1.
\]
Das explizite Euler-Verfahren ist also weder A-stabil noch Isometrie-erhaltend.
%
\item Implizites Euler-Verfahren:

Für alle $\zeta\in \C$ mit $\Re(\zeta)\leq 0$ ist
\[
|R(\zeta)|=\frac{1}{|1-\zeta|}=\frac{1}{(1-\Re(\zeta))^2+\Im(\zeta)^2}\leq 1.
\]
Das implizite Euler-Verfahren ist also A-stabil. Außerdem ist $|R(\zeta)|\to 0$ für $|\zeta|\to \infty$, das Verfahren ist also auch L-stabil.

Es ist jedoch $R(\im)=1/|1-\im|=1/\sqrt{2}< 1$, das Verfahren ist also nicht Isometrie-erhaltende.
\item Die implizite Mittelpunktsformel ist A-stabil (jedoch nicht L-stabil) und Isometrie-erhaltend (siehe Übungsaufgabe ??).
\end{enumerate}
\end{beispiel}

Betrachten wir noch einmal die Testgleichung mit $\Re(\lambda)<0$. A-Stabilität bedeutet, dass die Approximationen das 
korrekte qualitative Verhalten 
$|y_{i+1}|\leq |y_i|$ für jede Schrittweite $h>0$ zeigen. Auch wenn eine Methode nicht A-stabil ist, kann sie dennoch dieses
korrekte Verhalten zeigen, wenn nur die Schrittweite klein genug gewählt ist (so dass $|R(h\lambda)|\leq 1$).
Dies motiviert die folgende Definition.

\begin{definition}
Zu einer Runge-Kutta Methode mit Stabilitätsfunktion $R(\zeta)$ definieren wir 
das \emph{Stabilitätsgebiet} durch 
\[
\mathcal S:=\left\{ \zeta\in \C\ : \ |R(\zeta)|\leq 1\right\}\subseteq \C.
\]
\end{definition}

Beispielsweise besteht das Stabilitätsgebiet des expliziten Euler-Verfahrens 
aus allen $\zeta\in \C$ mit
\begin{align*}
1\geq |R(\zeta)|^2=|1+\zeta|^2=(1+\Re(\zeta))^2+\Im(\zeta)^2,
\end{align*}
d.h. dem abgeschlossenen Kreis mit Radius 1 um $z=-1$ in der komplexen Ebene. 


\subsection{Nachteile expliziter Verfahren}\label{subsect:limit_expl}

In unseren Beispielen waren nur implizite Verfahren A-stabil oder Isometrie-erhaltend. Tatsächlich
gibt es keine expliziten Verfahren diesen Eigenschaften, wie wir in diesem Abschnitt zeigen.

\begin{theorem}\label{thm:expl_RK_polynomial}
Die Stabilitätsfunktion einer expliziten Runge-Kutta Methode mit $s$ Stufen ist ein Polynom der Ordnung $s$.
\end{theorem}
\begin{beweis}
Seien $A\in \R^{s\times s}$, $b\in \R^s$, $c\in \R^s$ die Koeffizienten der Methode. 
Da die Methode explizit ist, ist $A$ eine strikte untere Dreiecksmatrix. Man zeigt leicht, 
dass in höheren Potenzen von $A$ immer mehr Diagonalen durch Nullen aufgefüllt werden, und
schließlich $A^s=0$ gilt:
\begin{align*}
A&=\left( \begin{array}{c c c c c c}
0 & 0 & 0 & 0 & \dots & 0\\
* & 0 & 0 & 0 & \dots & 0\\
* & * & 0 & 0 & \dots & 0\\
* & * & * & 0 & \dots & 0\\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
* & * & * & * &  \dots & 0\\
\end{array}\right), \quad
A^2=\left( \begin{array}{c c c c c c}
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
* & 0 & 0 & 0 & \dots & 0\\
* & * & 0 & 0 & \dots & 0\\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
* & * & * & * &  \dots & 0\\
\end{array}\right),\\
A^3&=\left( \begin{array}{c c c c c c}
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
* & 0 & 0 & 0 & \dots & 0\\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
* & * & * & * &  \dots & 0\\
\end{array}\right), \quad
A^s=\left( \begin{array}{c c c c c c}
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
0 & 0 & 0 & 0 & \dots & 0\\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & 0 &  \dots & 0\\
\end{array}\right)
\end{align*}

Aus $A^s=0$ folgt dass
\[
(I-\zeta A) ( I+\zeta A + \ldots \zeta^{s-1} A^{s-1}) = I
\]
also $(I-\zeta A)^{-1}=I+\zeta A + \ldots \zeta^{s-1} A^{s-1}$.

$R(\zeta):=1+\zeta b^T (I-\zeta A)^{-1} \1$ ist also ein Polynom der Ordnung $s$. $\quad \Box$
\end{beweis}

\begin{theorem}
Explizite Runge-Kutta Methode sind weder A-stabil noch Isometrie-erhaltend.
\end{theorem}
\begin{beweis}
Für jedes Polynom $R(\zeta)$ gilt $|R(\zeta)|\to \infty$ für $|\zeta|\to \infty$. 
\end{beweis}

Außerdem erhalten wir noch die schon in Bemerkung \ref{remark:after_ordercond} angesprochene 
Höchstgrenze in der Ordnung expliziter Verfahren:
\begin{theorem}
Die Konsistenzordnung einer expliziten Runge-Kutta Methode mit $s$ Stufen ist höchstens $s$.
\end{theorem}
\begin{beweis}
Nach Satz \ref{thm:expl_RK_polynomial} ist die Stabilitätsfunktion ein Polynom der Ordnung $s$:
\[
R(\zeta)=r_0+r_1\zeta+\ldots+r_s \zeta^s,\quad r_0,\ldots,r_s\in \R.
\]

Betrachte die Anwendung der Methode auf die Testgleichung mit $\lambda=1$, also $y'=y$, $y(0)=1$:
\begin{align*}
y_1&=R(h)=r_0+r_1 h+\ldots+r_s h^s.\\
y(x_1)&=e^{h}=1+h+\frac{1}{2}h^2+\ldots +\frac{1}{s!} h^s + \frac{1}{(s+1)!} h^{s+1} + \mathcal{O}(h^{s+2})
\end{align*}
Höchstens die ersten $s$ Terme der Entwicklungen können übereinstimmen, so dass der lokale Fehler einer
expliziten Methode bestenfalls in $\mathcal{O}(h^{s+1})$ liegt, also die Ordnung höchstens $s$ sein kann.
\end{beweis}



\section{Linear implizite Methoden}

Wir haben gesehen, dass steife Differentialgleichungen implizite Methoden erfordern. Im Allgemeinen
erfordert die Anwendung eines impliziten Runge-Kutta Verfahrens aber die Lösung
von $s$ gekoppelten $d$-dimensionalen nicht-linearen Gleichungen 
\[
k_j=f(x_i+c_j h, y_i + h \sum_{l=1}^s a_{jl} k_l), \quad j=1,\ldots,s,
\]
nach den $sd$ unbekannten Einträgen der $k_j$, $j=1,\ldots,s$. Ziel dieses Abschnitts 
ist die Herleitung von einfacheren und weniger Rechenaufwand erfordernden, aber dennoch stabilen Methoden.

Wir beschränken uns dabei auf autonome AWP
\[
y'=f(y), \quad y(x_0)=y_0
\]
(nach Aufgabe 4.2 kann jedes AWP in diese Form gebracht werden).

Die erste Vereinfachung ist, dass wir eine explizite Runge-Kutta Methode verwenden, für die $A$ eine linke untere Dreiecksmatrix ist, also  $a_{jl}=0$ für $l>j$. Dann können die Gleichungen für die $k_j$,
\[
k_j=f(y_i + h \sum_{l=1}^{j-1} a_{jl} k_l +  a_{jj} h k_j), \quad j=1,\ldots,s,
\]
beginnend mit $k_1$ eine nach der anderen gelöst werden. Statt eines $sd$-dimensionalen nicht-linearen
Gleichungssystems müssen wir so nur $s$ mal ein $d$-dimensionales nicht-lineares Gleichungssystem lösen.
Diese bringen wir auf Nullstellenform, also gegeben $k_1,\ldots,k_{j-1}$ ist $k_j$ so zu bestimmen, dass
\[
0\stackrel !=F_j(k_j):=k_j - f(y_i + h \sum_{l=1}^{j-1} a_{jl} k_l +  a_{jj} h k_j).
\]
Anwendung des Newton-Verfahrens ergibt ausgehend von einer Startnäherung $k_j^{(0)}$ die 
Iterationen
\[
k_j^{(n+1)}:=k_j^{(n)}-F_j'(k_j^{(n)})^{-1}F_j(k_j^{(n)}),
\]
wobei
\[
F_j'(k_j)=I- f'(y_i + h \sum_{l=1}^{j-1} a_{jl} k_l +  a_{jj} h k_j)a_{jj} h.
\]

Als weitere Vereinfachung ersetzen wir für alle $j$ die wahre Jacobi-Matrix $F_j'(k_j)$ durch 
\[
F_j'(k_j)\approx I- a_{jj} h J, \quad  J:=f'(y_i).
\] 
Außerdem führen wir nur einen einzelnen Newton-Schritt durch, d.h. für alle $j=1,\ldots, s$ setzen wir
\begin{align*}
 k_j & :=k_j^{(0)}-(I- a_{jj} h J)^{-1} F_j(k_j^{(0)})\\
&= k_j^{(0)}-(I- a_{jj} h J)^{-1} \left( k^{(0)}_j - f(y_i + h \sum_{l=1}^{j-1} a_{jl} k_l +  a_{jj} h k_j^{(0)}) \right)\\
&= (I- a_{jj} h J)^{-1} \left( f(y_i + h \sum_{l=1}^{j-1} a_{jl} k_l +  a_{jj} h k_j^{(0)}) - a_{jj} h J k_j^{(0)} \right)
\end{align*}

Es bleibt noch die Wahl des Startwerte $k_j^{(0)}$ zu klären. Hierzu verwenden wir eine 
lineare Kombination der bereits berechneten $k_l$, $l=1,\ldots,j-1$:
\[
k_j^{(0)}:=\sum_{l=1}^{j-1} \dfrac {d_{jl}}{a_{jj}} k_l
\]
mit noch zu bestimmenden Koeffizienten $d_{jl}$. Insgesamt erhalten wir so die \emph{linear impliziten} (auch: \emph{Rosenbrock}-) Runge Kutta Methoden.

\begin{center}
\fbox{\begin{minipage}{0.9\textwidth}

Gegeben $a_{jl}, d_{jl}, b_j, c_j\in \R$, $j=1,\ldots, s$, $l=1,\ldots,s$.
\begin{itemize}
\item Setze $J:=f'(y_i)$ und bestimme $k_j$, $j=1,\ldots,s$ nacheinander aus
\[
k_j:=  (I- a_{jj} h J)^{-1} \left( f\Big(y_i + h \sum_{l=1}^{j-1} (a_{jl}+d_{jl}) k_l \Big) - h J \sum_{l=1}^{j-1} d_{jl} k_l \right)
\]
\item Setze
\[
y_{i+1}:=y_i +  h \sum_{j=1}^s b_j k_j.
\]
\end{itemize}
\end{minipage}}\end{center}

\begin{bemerkung}\label{rem:LinImpl_invertible}
$I-a_{jj} hJ$ ist offenbar invertierbar für $0<h<\frac{1}{|a_{jj}|\, \norm{J}}$.
\end{bemerkung}

\begin{theorem}\label{thm:lin_impl_stab}
Seien $(A,b,c)$ die Koeffizienten einer Runge-Kutta Methode, wobei $A$ eine linke untere Dreiecksmatrix und $a_{jj}\neq 0$ sei. Dann hat die dazugehörige linear implizite Runge-Kutta Methode im folgenden Sinne die gleichen Stabilitätseigenschaften wie die ursprüngliche Methode:

Ist $R(\zeta)$ die Stabilitätsfunktion der ursprünglichen Methode, dann ergeben sich für jede Wahl der $d_{jl}$ bei Anwendung der linear impliziten Methode auf die Testgleichung
\[
y'=\lambda y, \quad y(0)=1
\]
die Approximationen
\[
y_i=R(h\lambda)^i,
\]
wenn $I-h\lambda A$ invertierbar ist (also $\frac{1}{h\lambda}\neq a_{jj}$ für alle $j$).
\end{theorem}
\begin{beweis}
Wir wenden die linear implizite Methode auf die Testgleichung an
\[
y'=\lambda y=:f(y), \quad y(0)=1.
\]
Für alle $y$ ist $J=f'(y)=\lambda$ und damit
\begin{align*}
k_j &:=  (1- a_{jj} h \lambda)^{-1} \left( \lambda(y_i + h \sum_{l=1}^{j-1} (a_{jl}+d_{jl}) k_l ) - h \lambda \sum_{l=1}^{j-1} d_{jl} k_l \right)\\
&= (1- a_{jj} h \lambda)^{-1} \left( \lambda y_i + h \lambda \sum_{l=1}^{j-1} a_{jl} k_l  \right).
\end{align*}
Mit $k:=(k_1,\ldots,k_s)^T$ ist das äquivalent zu
\[
\left( \begin{array}{c c c c}
1-a_{11}h\lambda & 0 & \dots & 0\\
-a_{21} h\lambda & 1-a_{22}h\lambda & \dots & 0\\
\vdots & \vdots & \ddots \\
-a_{s1} h\lambda & -a_{s2} h\lambda &  \dots & 1-a_{ss}h\lambda
\end{array}\right)
\left( \begin{array}{c} k_1\\ k_2\\ \vdots \\ k_s \end{array} \right)
= \left( \begin{array}{c} \lambda y_i\\ \lambda y_i\\ \vdots \\ \lambda y_i \end{array} \right).
\]
Wenn $I-h\lambda A$ invertierbar ist, dann ist also
\[
k=\lambda y_i (I-h\lambda A)^{-1}  \1
\]
und damit
\[
y_{i+1}=y_i+h b^T k=(1+ h \lambda b^T(I-h\lambda A)^{-1} \1)y_i=R(h\lambda)y_i.\quad \Box
\]
\end{beweis}

\begin{beispiel}\label{bsp:lin_impl}
\begin{enumerate}[(a)]
\item {\bf Linear-implizites Euler-Verfahren}

Für das implizite Euler-Verfahren
\[
\begin{array}{c | c}
1 & 1 \\ \hline 
& 1
\end{array}
\]
ist $A$ eine linke untere Dreiecksmatrix und keine $d$-Koeffizienten nötig. Das dazugehörige \emph{linear-implizite Euler Verfahren} lautet
\[
y_{i+1}:=y_i+hk, \quad \mbox{ mit } \quad k:=(I-hf'(y_i))^{-1} f(y_i).
\]
\item {\bf Linear-implizites Mittelpunktsverfahren}

Genauso erhalten wir das \emph{linear-implizite Mittelpunktsverfahren}:
\[
y_{i+1}:=y_i+hk, \quad \mbox{ mit } \quad k:=(I-h/2 f'(y_i))^{-1} f(y_i).
\]
 
\item  {\bf\tt ode23s} 

Das wohl am häufigsten verwendete linear-implizite Verfahren besteht aus der folgenden Kombination 
einer zweistufigen ($y$) und einer dreistufigen ($\hat y$) Methode:
\begin{align*}
k_1&:=(I-ahJ)^{-1} f(y_i)\\
k_2&:=(I-ahJ)^{-1} \left( f(y_i+h/2\, k_1)-ahJk_1\right)\\
k_3&:=(I-ahJ)^{-1} \left( f(y_i+h k_2)-d_{31}hJk_1 - d_{32} hJk_2 \right)\\[+1ex]
y_{i+1}&:=y_i+hk_2\\
\hat y_{i+1}&:=y_i+\frac{h}{6} (k_1+4 k_2 + k_3),
\end{align*}
mit
\[
J:=f'(y_i), \quad a:=\frac{1}{2+\sqrt{2}}, \quad d_{31}:=-\frac{4+\sqrt{2}}{2+\sqrt{2}}, \quad d_{32}:=\frac{6+\sqrt{2}}{2+\sqrt{2}}.
\]
$y$ und $\hat y$ werden wir in Übungsaufgabe ?? zur adaptiven Schrittweitensteuerung kombiniert. 
Das Verfahren ist in Matlab unter dem Namen {\tt ode23s} eines der zur Lösung steifer DGL empfohlenen Verfahren.
\end{enumerate}
\end{beispiel}


\begin{lemma}\label{lemma:stab_lin_impl}
Das linear implizite Euler Verfahren ist L-stabil, das linear implizite Mittelpunktsverfahren ist A-stabil und
Isometrie-erhaltend.
\end{lemma}
\begin{beweis}
Dies folgt aus Satz ~\ref{thm:lin_impl_stab} und den Stabilitätseigenschaften des impliziten Eulerverfahrens und
des impliziten Mittelpunktsverfahrens.
\end{beweis}

\textbf{Bemerkung}\\
{\it Gemäß Satz~\ref{thm:lin_impl_stab} definieren wir die Stabilitätsfunktion eines
linear impliziten Verfahrens durch die des zugrundeliegenden Runge-Kutta-Verfahrens. Entsprechend nennen wir (wie in Lemma~\ref{lemma:stab_lin_impl} schon praktiziert) 
ein linear implizites Verfahren A-stabil, L-stabil oder Isometrie-erhaltend, wenn das 
zugrundeliegende Runge-Kutta-Verfahren diese Eigenschaften hat.}

Eine linear implizite Methode besitzt die gleichen Stabilitätseigenschaften wie die ursprüngliche Methode aber (je nach Wahl der $d_{jl}$) kann sich die Konsistenzordnung unterscheiden. Wie in Satz \ref{thm:RungeKuttaOrderCond}, lassen sich Ordnungsbedingungen für die Koeffizienten von linear impliziten Verfahren herleiten. 
Wir zeigen nur exemplarisch am Beispiel \verb.ode23s. die Berechnung der Ordnung eines linear impliziten Verfahrens.

\begin{theorem}
Die in Beispiel \ref{bsp:lin_impl} beschriebene zweistufige Methode zur Berechnung von $y$ in \verb.ode23s. besitzt Konsistenzordnung 2.
\end{theorem}

\begin{beweis}
Für jedes $k\in \R^d$ ist 
\[
\norm{(I-ahJ)k}\geq \norm{k}-ah\norm{J}\norm{k}
\]
und $J=f'(y_i)$ ist aufgrund unserer Generalvoraussetzung unabhängig vom Anfangswert $x_i$, $y_i$ beschränkt.

Für hinreichend kleine $h>0$ ist die Matrix $I-ahJ$ also invertierbar und es gilt (mit unserer Konvention bzgl. der Landau-Notation aus Abschnitt~\ref{subsect:ConsitencyOrder})
\[
\norm{(I-ahJ)^{-1}}\leq \frac{1}{1-ah\norm{J}}=\frac{1}{1+\mathcal{O}(h)}=\mathcal{O}(1).
\]

Wir gehen nun wie im Beweis von Satz~\ref{thm:RungeKuttaOrderCond} vor. Nach Übungsaufabe ?? gilt 
für die Lösung von $y'=f(y)$, $y(x_i)=y_i$ 
\[
y(x_{i+1})=y_i+h f+1/2 h^2 f' f + \mathcal{O}(h^3)
\]
wobei wir wieder das Argument $(y_i)$ von $f$ und $f'$ weglassen.

Wir wollen dies mit 
\[
y_{i+1}=y_i+hk_2,
\]
vergleichen und müssen dazu also $k_2$ bis zur Ordnung $\mathcal{O}(h^2)$ entwickeln. Dazu benötigen wie die Entwicklung von $k_1$.
Aus 
\[
k_1=(I-ahJ)^{-1} f\quad \mbox{ und } \quad \norm{(I-ahJ)^{-1}}=\mathcal{O}(1)
\]
folgt $k_1=\mathcal{O}(1)$. Wir verwenden die Definition von $k_1$ nocheinmal und erhalten 
\begin{align*}
k_1&=f + ahJ k_1=f+\mathcal{O}(h).        %=f+ahJ (f+ahJ k_1) %=f+ahJ (f+ahJ (f+ahJ k_1))
\end{align*}

Für $k_2$ folgt zuerst
\begin{align*}
k_2&= (I-ahJ)^{-1} \left(f(y_0+ h/2\, k_1) - ahJk_1 \right)=\mathcal{O}(1).
\end{align*}
und dann durch nochmalige Anwendung der Definition von $k_2$
\begin{align*}
k_2&=f(y_0+ h/2\, k_1) - ahJk_1 + ahJ k_2\\
&=  f + h/2 k_1 f' +\mathcal{O}(h^2) - ahJ k_1 + ahJ k_2= f + \mathcal{O}(h).
\end{align*}
Noch ein weiteres Mal verwenden wir die Definition von $k_2$ und erhalten zusammen mit $k_1=f+\mathcal{O}(h)$, dass
\begin{align*}
k_2&=  f + h/2\, k_1 f' +\mathcal{O}(h^2) - ahJ k_1 + ahJ k_2\\
&= f+ h/2\, f f' - ahJ f + ahJ f  +\mathcal{O}(h^2)= f+ h/2 f f' +\mathcal{O}(h^2).
\end{align*}

Insgesamt ist also
\[
y_{i+1}=y_i+hk_2=y_i+hf+h^2/2\, f f' + \mathcal{O}(h^3)=y(x_i)+\mathcal{O}(h^3),
\]
die Methode besitzt also Konsistenzordnung 2. 
\end{beweis}


\section{Mehrschrittverfahren}

Wir beschreiben nun noch kurz die wesentliche Idee der Mehrschrittverfahren. 
Dabei beschränken wir uns in diesem Abschnitt auf äquidistant gewählte Gitterpunkte 
\[
x_i=x_0+ih, \quad h>0. 
\]
In einem $m$-Schritt Verfahren verwenden wir die letzten $m$ Approximationen
\[
y_{i-m+1}\approx y(x_{i-m+1}),\ldots, y_{i}\approx y(x_{i})
\]
zur Bestimmung der nächsten Approximation $y_{i+1}\approx y(x_{i+1})$.
Für die Bestimmung der dafür nötigen ersten Werte $y_1,\ldots, y_{m-1}$ 
können dabei Einzelschrittverfahrens oder Mehrschrittverahren mit weniger Schritten 
verwendet werden

\subsection{Adams-Bashforth Methoden}\label{subsect:adam_bashforth}
Zur Bestimmung von $y_{i+1}\approx y(x_{i+1})$ aus $y_{i-m+1},\ldots,y_i$ 
verwenden wir zuerst wie bei der
Herleitung der Runge Kutta Methoden
\[
y_{i+1}-y_i\approx y(x_{i+1})-y(x_i)=\int_{x_i}^{x_{i+1}} y'(x) \dx
=\int_{x_i}^{x_{i+1}} f(x,y(x)) \dx[x]
\]
Die Funktion 
\[
x\mapsto f(x,y(x))
\]
ist (zumindest näherungsweise) an den Stellen 
\[
f_j:=f(x_j,y_j)\approx f(x_j,y(x_j)), \quad j=i-m+1,\ldots,i
\]
bekannt. Es liegt daher nahe, die unbekannte Funktion $x\mapsto f(x,y(x))$ durch ihr 
Interpolationspolynom $f(x,y(x))\approx p(x)$, $p\in \Pi_{m-1}$ durch die Stützstellen $(x_j,f_j)$, $j=i-m+1,\ldots,i$ zu ersetzen. 
Mit Hilfe der (aus der Numerik I bekannten) Lagrange-Grundpo\-ly\-no\-me
\[
l_k(x)=\prod_{l=i-m+1,\dots,i \atop l\neq j} \frac{x-x_l}{x_k-x_l}, \quad k=i-m+1,\ldots,i
\]
können wir das Interpolationspolynom schreiben als
\[
p(x)=\sum_{k=i-m+1}^i f_k l_k(x).
\]
So erhalten wir
\begin{align*}
y_{i+1}-y_i&= \int_{x_{i}}^{x_{i+1}} p(t) \dx
=\sum_{k=i-m+1}^i f_k \int_{x_{i}}^{x_{i+1}} l_k(x)\dx\\
&=h \sum_{k=i-m+1}^i f_k \int_0^1 l_k(x_i+th)\dx[t]\\
&= h \sum_{k=i-m+1}^i f_k \int_0^1 \prod_{l=i-m+1,\dots,i \atop l\neq k} \frac{x_i+th - x_l}{x_k-x_l}\dx[t]\\
&= h \sum_{k=i-m+1}^i f_k \int_0^1 \prod_{l=i-m+1,\dots,i \atop l\neq k}
 \frac{i-l+t}{k-l}\dx[t]
\end{align*}
Mit der Umnummerierung $k=i-m+j$ und $l=i-m+j'$ können wir das schreiben als
\begin{align*}
y_{i+1}-y_i&= h \sum_{j=1}^m f_{i-m+j} \underbrace{\int_0^1 \prod_{j'=1,\ldots,m \atop j'\neq j}
 \frac{m-j'+t}{j-j'}\dx[t]}_{=:\beta_j}
=h\sum_{j=1}^m\beta_j f_{i-m + j},
\end{align*}
mit (von $h$ und $i$ unabhängigen!) Konstanten $\beta_j\in \R$.

Die so erhaltenen Methoden heißen \emph{explizite Adams Methoden} oder \emph{Adams-Bashforth Methoden}. 
\begin{beispiel}
Für den Spezialfall $m=1$ ergibt sich die explizite Euler-Methode.
Für $m=2$ ist
\begin{align*}
\beta_1&:= \int_0^1 \frac{2-2+t}{1-2}\dx[t]=-\int_0^1 t\dx[t]=-\frac{1}{2}\\
\beta_2&:= \int_0^1 \frac{2-1+t}{1-2}\dx[t]=\int_0^1 (t+1)\dx[t]=\frac{3}{2},
\end{align*}
also $y_{i+1}:=y_i + h (\frac{3}{2}f_i-\frac{1}{2}f_{i-1})$.
\end{beispiel}

\subsection{Weitere auf Integration basierende Methoden}\label{subsect:multistep_int}

Analog lassen sich implizite Adams Methoden (die \emph{Adams-Moulton-Methoden}) aufstellen,
indem das Interpolationspolynom durch die Stützstellen $(x_j,f_j)$ für $j=i-m+1,\ldots,i+1$,
also inklusive der noch zu bestimmenden Stützstelle gewählt wird. Dies führt auf Formeln 
der Form 
\begin{align}\labeq{Impl_Adam}
y_{i+1}=y_i+h\sum_{j=1}^{m+1}\beta_j f_{i-m + j}
=y_i+h\sum_{j=1}^{m+1}\beta_j f(x_{i-m+j},y_{i-m+j})
\end{align}

Eine verbreitete Methode diese impliziten Gleichungen zu lösen, ist es zuerst eine Näherung an
$y_{i+1}$ (und damit an $f_{i+1}$) durch die explizite Adams Methode zu bestimmen. Diese Näherung
wird dann als Startwert für eine Fixpunktiteration der Gleichung \req{Impl_Adam} verwendet
(üblich sind ein oder zwei Iterationsschritte).
Dieses Vorgehen heißt \emph{Predictor-Corrector-Verfahren}.

Das Integrationsintervall bei der Herleitung der Methoden könnte auch vor $x_i$ liegende
Bereiche umfassen, z.B.
\[
y_{i+1}-y_{i-1}\approx y(x_{i+1})-y(x_{i-1})=\int_{x_{i-1}}^{x_{i+1}} y'(x) \dx
=\int_{x_{i-1}}^{x_{i+1}} f(x,y(x)) \dx[x]
\]
Analag zum Adams-Verfahren können wir $f$ durch sein Interpolationspolynom (mit oder ohne
Verwendung der unbekannten Stützstelle $x_{i+1},f_{i+1}$) annähern und erhalten 
(implizite bzw. explizite) bzw. Formeln der Form
\begin{align*}
y_{i+1}=y_{i-1}+h\sum_{j=1}^{m+1}\beta_j f_{i-m + j} \quad \mbox{ bzw. } \quad
y_{i+1}:=y_{i-1}+h\sum_{j=1}^{m}\beta_j f_{i-m + j}.
\end{align*}
Diese Formeln heißen \emph{Nyström-Methoden} (die explizite Variante) oder \emph{Milne-Simpson}
(die implizite Variante).

\subsection{Auf Differentiation basierende Methoden}

Die bisher betrachteten Mehrschrittverfahren beruhten auf der Idee die Funktion $x\mapsto f(x,y(x))=y'(x)$
durch ein Interpolationspolynom zu approximieren und dieses zu integrieren. 
Statt dessen können wir auch die (Approximationen an die) Funktionswerte
$y_{i-m+1},\ldots,y_{i+1}$ durch ein Polynom interpolieren. 
Wie bei der Herleitung der Adams-Bashforth Methode lässt sich das Interpolationspolynom 
$q\in \Pi_m$
schreiben als
\[
q(x)=\sum_{k=i+1-m}^{i+1} y_k l_k(x), \quad l_k(x)=\prod_{l=i+1-m,\ldots,i+1 \atop l\neq k} \frac{x-x_l}{x_k-x_l}
\]
also
\begin{align*}
q(x_i+th)& =\sum_{k=i+1-m}^{i+1} y_k \prod_{l=i+1-m,\ldots,i+1 \atop l\neq k} \frac{x_i + th -x_l}{x_k-x_l}\\
&=\sum_{k=i+1-m}^{i+1} y_k \prod_{l=i+1-m,\ldots,i+1 \atop l\neq k} \frac{i-l+t}{k-l}\\
&=\sum_{j=1}^{m+1} y_{i-m+j} \prod_{j'=1,\ldots,m+1 \atop j'\neq j} \frac{m-j'+t}{j-j'}
\end{align*}

Wir können nun versuchen, den unbekannten Wert $y_{i+1}$ so zu bestimmen, 
dass das Interpolationspolynom $q$ im aktuellen Gitterpunkt $x_i$ 
die Differentialgleichung erfüllt, also
\[
q'(x_i)=f(x_i,y_i).
\]
Wegen
\begin{align*}
q'(x_i)&=\frac{1}{h} \frac{\partial}{\partial t} q(x_i+th)|_{t=0}\\
&=\frac{1}{h} \sum_{j=1}^{m+1} y_{i-m+j} \underbrace{\left( \frac{\partial}{\partial t}  \prod_{j'=1,\ldots,m+1 \atop j'\neq j}
 \frac{m-j'+t}{j-j'}\right)\Big|_{t=0}}_{=:\alpha_j}
\end{align*}
führt dies auf Formeln der Form
\[
\sum_{j=1}^{m+1} \alpha_j  y_{i-m+j} = h f(x_i,y_i),
\]
die sich (für $\alpha_{m+1}\neq 0$) explizit nach $y_{i+1}$ auflösen lassen.

Genauso führt die Forderung, dass das Interpolationspolynom $q$ im nächsten Gitterpunkt $x_{i+1}$ 
die Differentialgleichung erfüllt, mittels
\begin{align*}
q'(x_{i+1})&=\frac{1}{h} \frac{\partial}{\partial t} q(x_{i+1}+th)|_{t=0}\\
&=\frac{1}{h} \sum_{j=1}^{m+1} y_{i-m+j} \underbrace{\left( \frac{\partial}{\partial t}  \prod_{j'=1,\ldots,m+1 \atop j'\neq j}
 \frac{m+1-j'+t}{j-j'}\right)\Big|_{t=0}}_{=:\alpha_j}
\end{align*}
auf implizite Methoden der Form
\[
\sum_{j=1}^{m+1} \alpha_j  y_{i-m+j} = h f(x_{i+1},y_{i+1}).
\]
Die so entstandenen impliziten Formeln heißen auch \emph{BDF-Methoden} (Backward differentiation formula).

\begin{beispiel}
Für die implizite BDF-Methode mit $m=1$ ergibt sich
\begin{align*}
\alpha_1 &=  \frac{\partial}{\partial t}  
 \frac{1+1-2+t}{1-2}\Big|_{t=0}=-1,\\
\alpha_2 &=\frac{\partial}{\partial t}  
 \frac{1+1-1+t}{2-1}\Big|_{t=0}=1,
\end{align*}
also 
\[
-1 y_i + 1y_{i+1} = hf(x_{i+1},y_{i+1}),
\]
und damit gerade die implizite Euler-Methode.
\end{beispiel}

\subsection{Konvergenz linearer Mehrschrittmethoden}

Alle bisher kennengelernten Mehrschrittmethoden können wir in der allgemeinen Form
\[
\sum_{j=1}^{m+1} \alpha_j  y_{i-m+j} = h \sum_{j=1}^{m+1} \beta_j  f_{i-m+j}
\]
mit Konstanten $\alpha_1,\ldots,\alpha_{m+1},\beta_1,\ldots,\beta_{m+1}\in \R$ schreiben.

Wir geben in dieser Vorlesung nur eine ganz kurze Zusammenfassung der Theorie dieser Methoden.
Eine ausführlichere Darstellung findet sich z.B. in \cite{HairerNorsettWanner}.

Analog zu Einschrittmethoden wird die \emph{Konsistenzordnung} eines Mehrschrittverfahren
durch Betrachtung des \emph{lokalen Fehlers} $\norm{y_{i+1}-y(x_{i+1})}$
definiert, der sich ergibt, wenn die Methode
auf $m$ exakte Werte 
\[
y_{i-m+1}=y(x_{i-m+1}),\ldots,y_{i}=y(x_i)
\]
angewendet wird.

Satz \ref{satz:konv_Einschritt} lässt sich jedoch nicht unmittelbar auf Mehrschrittverfahren
übertragen. Im Gegensatz zu Einschrittverfahren folgt aus der Konsistenz eines Mehrschrittverfahrens
nicht automatisch Konvergenz, sondern dies erfordert eine zusätzliche Stabilitätseigenschaft.
Die in Abschnitt \ref{subsect:adam_bashforth} und \ref{subsect:multistep_int} vorgestellten
Adam-Varianten erfüllen diese zusätzliche Eigenschaften, die BDF-Formeln jedoch nur für
$m\leq 6$.


\section{Randwertprobleme}

\subsection{Motivation: Diffusionsprozesse}
Neben Anfangswertproblemen treten in der Praxis auch \emph{Randwertprobleme} für gewöhnliche Differentialgleichungen auf. Die Theorie und Numerik dieser Probleme ist eng mit der für partielle Differentialgleichung verwandt, da (wie in der folgenden Motivation)  Randwertprobleme für gewöhnliche Differentialgleichungen oft als eindimensionale stationäre Spezialfälle von Randwertproblemen für PDGL auftreten. Die folgende Modellierung
von Diffusionsprozessen folgt dem sehr lesenswerten Buch \cite{FulfordBroadbridge}.

Wir betrachten ein Rohr mit Querschnitt $A$, das von einer Lösung durchflossen wird. Wir bezeichnen mit
\begin{description}
\item[$x$:] die Position innerhalb des Rohres, etwa $x\in [0,1]$
\item[$C(x,t)$:] die Konzentration des gelösten Stoffes 
am Ort $x$ zur Zeit $t$
\item[$J(x,t)$:] Flussdichte der Lösung, d.h. welche Masse des Stoffes
einen Einheitsquerschnitt pro Zeiteinheit durchquert.
\end{description}

Wir betrachten den Rohrabschnitt zwischen $x$ und $x+\delta x$. Dabei nehmen wir an, dass
$\delta x$ so klein ist, dass die Konzentration in diesem Abschnitt
räumlich konstant ist. Die Gesamtmasse innerhalb des Abschnitts ist also
\[
A \delta x C(x,t).
\]

Nun nehmen wir an, dass $\delta t$ so klein ist, dass der Fluss im Zeitabschnitt zwischen $t$ und $t+\delta t$ zeitlich konstant ist. Aufgrund des Flusses wird sich im betrachteten Abschnitt des Rohres die Gesamtmasse in diesem Zeitabschnitt ändern um
\[
J(x,t)A \delta t - J(x+\delta x,t) A \delta t,
\]
vgl.\ die in der Vorlesung gemalten Skizzen.

Wenn es keine anderen die Masse ändernden Phänomene gibt, so gilt also
\[
A\delta x C(x,t+\delta t)=A\delta x C(x,t) + J(x,t)A \delta t - J(x+\delta x,t) A \delta t
\]
also
\[
\frac{C(x,t+\delta t)-C(x,t)}{\delta t}=-\frac{J(x+\delta x,t)-J(x,t)}{\delta x}
\]
und mit $\delta x\to 0$, $\delta t\to 0$ erhalten wir die \emph{Bilanzgleichung}
\[
\frac{\partial C(x,t)}{\partial t}=-\frac{\partial J(x,t)}{\partial x}.
\]

Die einfachste Model für Diffusion ist \emph{Fick's Gesetz}, das besagt, dass die
Flussdichte proportional ist zum Konzentrationsgefälle
\[
J(x,t)=- D(x,t) \frac{\partial C(x,t)}{\partial x}.
\]
($D(x,t)$ heißt Diffusionskonstante). %For simplicity, let $D=1$.

So erhalten wir eine partielle Differentialgleichung, die sogenannte
\emph{Diffusionsgleichung} oder auch \emph{Wärmeleitungsgleichung}
\[
\frac{\partial C(x,t)}{\partial t}=\frac{\partial}{\partial x} \left(D(x,t) \frac{\partial  C(x,t)}{\partial x}\right).
\]

Konvektion und Absorption können ähnlich modelliert werden. Wenn die Flüssigkeit sich
mit der Geschwindigkeit $v(x,t)$ bewegt, dann muss der Term $v(x,t)C(x,t)$ zum Fluss addiert werden. Wenn pro Zeiteinheit und Raumeinheit die Masse $M(x,t)$ hinzugegeben wird oder $a(x,t)C(x,t)$ z.B. aufgrund einer chemischen Reaktion verbraucht wird, so müssen diese
Änderungen in der Massenbilanz berücksichtigt werden.
Insgesamt erhalten wir 
\[
\frac{\partial C}{\partial t}(x,t) =   \frac{\partial}{\partial x} \left( D(x,t) \frac{\partial}{\partial x} C(x,t)\right) - \frac{\partial}{\partial x} \Big(v(x,t) C(x,t)\Big) - a(x,t)C(x,t) + M(x,t). 
\]

Es erscheint natürlich, dass diese partielle Differentialgleichung Anfangsbedingungen 
$C(x,0)$ für alle $x\in (0,1)$ und Randbedingungen für $x=0$ und $x=1$ benötigt. 
Als Randbedingungen können wir z.B.\ die Konzentration $C(0,t)$ and $C(1,t)$ für alle $t>0$
(Dirichlet Randbedingungen) oder den Fluss  $-D(0)\frac{\partial C(0,t)}{\partial x}$ und $-D(1)\frac{\partial C(1,t)}{\partial x}$ (Neumann Randbedingungen) vorschreiben.

Sind alle Koeffizienten der Gleichung von der Zeit unabhängig, so stellt sich oft 
mit der Zeit ein Gleichgewichtszustand ein, d.h. die Konzentration ändert sich nicht mehr.
Für diesen muss also gelten 
\[
\frac{\partial}{\partial x} \left( D(x) \frac{\partial}{\partial x} C(x)\right) - \frac{\partial}{\partial x} \Big(v(x) C(x)\Big) - a(x)C(x) + M(x)=0
\]
Dies ist wieder eine \emph{gewöhnliche Differentialgleichung}, für die wir jedoch 
(Dirichlet- oder Neumann-) Randwerte anstelle von Anfangswerten kennen.

\subsection{Differenzenverfahren}\label{subsect:FD_1D_BVP}

Motiviert durch den letzten Abschnitt betrachten wir nun
die leicht vereinfachte Diffusionsgleichung
\[
L[u]:=-u''(x) + b(x)u'(x) + c(x)u(x)=f(x) \quad x\in (0,1)
\]
und zwar zuerst mit \emph{homogenen} Dirichlet-Randbedingungen $u(0)=u(1)=0$. 

Es ist naheliegend, dass Randwertproblem zu lösen, indem wir die Funktion
$u$ diskretisieren durch ein äquidistantes Gitter $x_i=ih$, $i=0,\ldots n+1$, $h:=1/(n+1)$. 
Es bezeichne
\[
U:=(u(x_1),\ldots,u(x_{n}))^T\quad \mbox{ und } \quad F:=(f(x_1),\ldots,f(x_{n}))^T
\]
die Auswertungen von $u$ und $f$ auf diesem Gitter.

Wir ersetzen die Ableitungen durch \emph{zentrale finite Differenzen}
\begin{align*}
u'(x) &\approx D_h[U](x):=\frac{u(x+h)-u(x-h)}{2h}\\
u''(x)& \approx D^2_h[U](x):= \frac{u(x+h)-2u(x)+u(x-h)}{h^2}
\end{align*}
(wobei wir am Rand $u(0)=0=u(1)$ verwenden).

Aus der Gleichung $L[u]=f$ ergibt sich so das LGS
\[
L_h U_h = F
\]
mit einer Matrix $L_h\in \R^{n \times n}$. Durch Lösung des LGS erhalten wir einen Vektor
\[
U_h:=(u_1,\ldots, u_{n})^T\in \R^n
\]
von Approximationen an $(u(x_1),\ldots,u(x_{n}))^T$.

\paragraph{Finite Differenzen für ein einfaches Beispiel.}
Mit diesem Ansatz ergibt sich für das einfache Beispiel $-u''=f$ 
\[
\underbrace{\left( \begin{array}{c} f(x_1)\\ f(x_2)\\ \vdots \\ f(x_{n}) \end{array}\right)}_{=:F}
= \left( \begin{array}{c} u''(x_1)\\ u''(x_2)\\ \vdots \\ u''(x_{n}) \end{array}\right)
\approx \underbrace{h^{-2} \left( \begin{array}{c c c c} 2 & -1 &  & 0\\ -1 & 2 & -1 \\ & \ddots & \ddots & -1\\ 0 & & -1 & 2\end{array}\right)}_{=:L_h}
\left( \begin{array}{c} u(x_1)\\ u(x_2)\\ \vdots \\ u(x_{n}) \end{array}\right).
\]
Wir können daher erwarten, dass wir durch Lösung von $F=L_h U_h$ einen
Vektor $U_h=(u_1,\ldots,u_{n})^T$ aus Approximationen an $(u(x_1),\ldots,u(x_{n}))^T$
erhalten.

\paragraph{FD für die Diffusionsgleichung.}
Genauso diskretisieren wir
\[
-u''(x) + b(x)u'(x) + c(x)u(x)=f(x), \quad u(0)=u(1)=0
\]
und erhalten
\[
\left( \begin{array}{c} f(x_1)\\ f(x_2)\\ \vdots \\ f(x_{n}) \end{array}\right)
\approx h^{-2} \left( \begin{array}{c c c c} d_1 & s_1 &  & 0\\ r_2 & d_2 & s_2 \\ & \ddots & \ddots & s_{n-1}\\ 0  &  & r_{n} & d_{n}\end{array}\right) 
\left( \begin{array}{c} u(x_1)\\ u(x_2)\\ \vdots \\ u(x_{n}) \end{array}\right)
\]
mit
\begin{align*}
d_i&=2+h^2 c(x_i),\\
r_i&=-1-\frac 12 hb(x_i),\\
s_i&=-1+\frac 12 hb(x_i).
\end{align*}
Wiederum ergibt sich ein LGS $F\approx L_h U$, und wir können erwarten, dass die
Lösung $U_h:=L_h^{-1} F$ die wahren Lösungswerte in $U$ approximiert.

\paragraph{Inhomogene Dirichlet-Bedingungen.} 
Im Falle inhomogener Dirichlet-Bedingungen $u(0)=\alpha\in \R$, $u(1)=\beta\in \R$ ergibt sich
\[
\left( \begin{array}{c} f(x_1)\\ f(x_2)\\ \vdots \\ f(x_{n-1}) \end{array}\right)
\approx h^{-2} \left( \begin{array}{c c c c} d_1 & s_1 &  & 0\\ r_2 & d_2 & s_2 \\ & \ddots & \ddots & s_{n-1}\\ 0  &  & r_{n} & d_{n}\end{array}\right) 
\left( \begin{array}{c} u(x_1)\\ u(x_2)\\ \vdots \\ u(x_{n}) \end{array}\right)
+ h^{-2}
\left( \begin{array}{c} r_1 \alpha\\ 0 \\ \vdots \\ s_{n} \beta \end{array}\right).
\]
Wir erhalten das LGS $F\approx L_h U+B_h$ und können erwarten, dass \[
U_h:=L_h^{-1} (F-B_h)\approx U.
\]

\paragraph{Neumann Randbedingungen.} 
Neumann Randbedingungen $u'(0)=\alpha$, $u'(1)=\beta$ können behandelt werden, in dem 
wir die unbekannten Auswertungen an den Randwerten $x_0$ und $x_{n+1}$ zu den Vektoren hinzufügen
\[
\left( \begin{array}{c} f(x_0)\\ f(x_1)\\ f(x_2)\\ \vdots \\ f(x_{n})\\ f(x_{n+1}) \end{array}\right)
\approx h^{-2} \left( \begin{array}{c c c c c c} r_1 & d_1 & s_1 &  & & 0\\ & r_2 & d_2 & s_2 \\ & & \ddots & \ddots & s_{n-1} & 0\\ 0 &  &  & r_{n} & d_{n} & s_{n}\end{array}\right) 
\left( \begin{array}{c} u(x_0) \\ u(x_1)\\ u(x_2)\\ \vdots \\ u(x_{n}) \\ u(x_{n+1})\end{array}\right).
\]
Um Gleichungen für $u(x_0)=u(0)$ und $u(x_{n+1})=u(1)$ zu erhalten vewenden wir die Näherungen
\begin{align*}
u(-h) & \approx u(0)-hu'(0)=u(0)-\alpha h\\
u(1+h) & \approx u(1)+hu'(1)=u(1)+ \beta h.
\end{align*}
Damit ist
\begin{align*}
\left( \begin{array}{c} f(x_0)\\ f(x_1)\\ f(x_2)\\ \vdots \\ f(x_{n-1})\\ f(x_n) \end{array}\right)&\approx
h^{-2} \left( \begin{array}{c c c c c} d_0 & s_0 \\
r_1 & d_1 & s_1 &  & \\ & \ddots & \ddots & \ddots & \\  &  & r_{n} & d_{n} & s_{n}\\
  &  & & r_{n+1} & d_{n+1} 
\end{array}\right) 
\left( \begin{array}{c} u(x_0) \\ u(x_1)\\  \vdots  \\ u(x_{n+1})\end{array}\right) \\
& \quad 
 + h^{-2} \left( \begin{array}{c} r_0 (u(x_0)-\alpha h)  \\ 0 \\ \vdots \\ s_{n+1} (u(x_{n+1})+\beta h) \end{array}\right)\\
%
& = h^{-2} \left( \begin{array}{c c c c c} d_0+r_0 & s_0 \\
r_1 & d_1 & s_1 &  & \\ & \ddots & \ddots & \ddots & \\  &  & r_{n} & d_{n} & s_{n}\\
  &  & & r_{n+1} & d_{n+1}+s_{n+1} 
\end{array}\right) 
\left( \begin{array}{c} u(x_0) \\ u(x_1)\\  \vdots  \\ u(x_{n+1})\end{array}\right)\\
 & \quad + h^{-1} \left( \begin{array}{c} -  r_0 \alpha  \\ 0 \\ \vdots \\ s_{n+1} \beta  \end{array}\right)
\end{align*}
Wiederum ergibt sich ein LGS $f\approx L_h u+b_h$, und wir erwarten dass
\[
u_h:=L_h^{-1} (f-b_h)\approx u.
\] 


\subsection{Konsistenz, Stabilität und Konvergenz}

Wir betrachten in diesem Abschnitt nur das spezielle Randwertproblem
\[
L[u]:=-u''(x) + b(x)u'(x) + c(x)u(x)=f(x) \quad x\in (0,1)
\]
mit homogenen Dirichletrandbedingungen und die dazugehörige Diskretisierung
\[
L_h U_h=F
\]
aus dem letzten Abschnitt. Außerdem nehmen wir an, dass $b\in C^2[0,1]$, $c\in C[0,1]$
sowie $c>0$ gilt\footnote{Da die stetige Funktion $c$ auf dem Kompaktum $[0,1]$ ihr Minimum annimmt gilt damit sogar $c(x)\geq c_0:=\min_{x\in [0,1]} c(x)>0$.}, und dass das Randwertproblem
eine eindeutige Lösung $u\in C^4([0,1])$ besitzt. 

Zuerst charakterisieren wir, wie gut die wahren Lösungswerte
\[
U:=(u(x_1),\ldots,u(x_{n}))^T
\]
die diskretisierte Gleichung lösen.

\begin{lemma}\label{lemma:RW_Konsistenz}
Es existiert ein $C>0$, so dass 
\[
\norm{L_h U - F}_\infty \leq C h^2.
\]
Man sagt auch, das Differenzenverfahren hat \emph{Konsistenzordnung} 2.
\end{lemma}
\begin{beweis}
Der $i$-te Eintrag von  ($i=1,\ldots,n$, $x_0=0$, $x_{n+1}=0$) von  $L_h U  - F$ ist 
\[
D_h^2[U](x_i)+b(x_i)D_h[U](x_i)+c(x_i)u(x_i)-f(x_i).
\]
Da $u$ die DGL $u''(x_i)+b(x_i)u'(x_i)+c(x_i)u(x_i)-f(x_i)=0$ löst, genügt es zu zeigen, dass
\[
D_h[u](x_i)=u'(x_i)+\mathcal{O}(h^2)\quad \mbox{ und } \quad D_h^2[u](x_i)=u''(x_i)+\mathcal{O}(h^2).
\]

In der Tat erhalten wir durch Taylorentwichlung
\begin{align*}
u(x_i+h) &=u(x_i)+hu'(x_i)+\frac{1}{2}h^2u''(x_i)+\frac{1}{3!}h^3u'''(x_i)+\mathcal{O}(h^4)\\
u(x_i-h) &=u(x_i)-hu'(x_i)+\frac{1}{2}h^2u''(x_i)-\frac{1}{3!}h^3u'''(x_i)+\mathcal{O}(h^4)
\end{align*}
und damit
\begin{align*}
D_h[u](x_i)&=\frac{u(x_i+h)-u(x_i-h)}{2h}= \frac{2h u'(x_i)+\mathcal{O}(h^3)}{2h}=u'(x_i)+\mathcal{O}(h^2)\\
D^2_h[u](x_i)&= \frac{u(x_i+h)-2u(x_i)+u(x_i-h)}{h^2}=
\frac{h^2u''(x_i) + \mathcal{O}(h^4)}{h^2}\\
&=u''(x_i)+\mathcal{O}(h^2),
\end{align*}
womit die Behauptung gezeigt ist.
\end{beweis}

Aus Konsistenz (im Sinne von Lemma~\ref{lemma:RW_Konsistenz}) folgt mit 
dem folgenden einfachen Argument Konvergenz
\[
\norm{U-U_h}_\infty = \norm{L_h^{-1} L_h (U-U_h)}_\infty\leq \norm{L_h^{-1}}_\infty \norm{L_h U-F}_\infty,
\]
wenn wir zeigen können, dass $L_h$ invertierbar ist {\bf und $\norm{L_h^{-1}}_\infty$ (gleichmäßig in $h$) beschränkt ist}. Die zweite Eigenschaft heißt auch \emph{Stabilität} des Differenzenverfahrens. Um die Stabilität zu zeigen, 
konstruieren wir eine Lösung $w$ eines Randwertproblems, für den die zugehörigen Auswertungen $W$ 
\[
L_h W\geq \1
\]
erfüllen. Zusammen mit einer noch zu zeigenden Monotonieeigenschaft von $L_h^{-1}$ folgt
dann
\[
\norm{L_h^{-1}}_\infty = \norm{L_h^{-1} \1}_\infty \leq \norm{L_h^{-1} L_h W}_\infty\leq \max_{x\in [0,1]} w(x).
\]



\begin{bemerkung}\label{bem:monotonie}
Eine komponentenweise nicht-negative Matrix $M=(m_{ij})_{i,j=1}^n$ hat die Monotonieeigenschaft
\[
x\leq y \quad \Longrightarrow \quad Mx\leq My, 
\]
wobei die Ungleichheitszeichen für die Vektoren $x,y,Mx,My\in \R^n$ komponentenweise zu verstehen sind.
\end{bemerkung}


Um die Monotonieeigenschaft von unserem $L_h^{-1}$ zu zeigen, benötigen 
wir noch ein Hilfsresultat:

\begin{lemma}[Neumannsche Reihe]\label{lemma:NR}
Ist $R\in \R^{n\times n}$ und gilt $\norm{R}<1$ in einer submultiplikativen Matrixnorm,
so ist $I-R$ invertierbar und es gilt $(I-R)^{-1}=\sum_{k=0}^\infty R^k$.
\end{lemma}
\begin{beweis}
Betrachte die Folge der Partialsummen $S_N:=\sum_{k=0}^N R^k$. Da
\[
\norm{\sum_{k=0}^N R^k - \sum_{k=0}^M R^k}\leq \sum_{k=M+1}^N \norm{R}^k \quad \forall N>M
\]
und die geometrische Reihe $\sum_{k=0}^\infty \norm{R}^k$ konvergiert, folgt dass
$(S_N)_{N\in \N}$ eine Cauchy-Folge ist und damit konvergiert. 
Genauso folgt $R^k\to 0$, so dass wegen
\[
(I-R) \sum_{k=0}^N R^k= \sum_{k=0}^N R^k (I-R) = I- R^{k+1}\to I.
\]
der Grenzwert $S:=\lim_{N\to \infty}S_N=\sum_{k=0}^\infty R^k$  die Inverse von $(I-R)$ ist.
\end{beweis}




\begin{lemma}\label{lemma:wann_M}
Ist $A\in \R^{n\times n}$ eine strikt diagonaldominante Matrix mit positiven Diagonalelementen und nicht-positiven Nichtdiagonalelementen, dann ist $A$ invertierbar und $A^{-1}$ komponentenweise nicht-negativ.
\end{lemma}
\begin{beweis}
Wir zerlegen $A=D-N$ in seinen Diagonal- und Nichtdiagonalanteil. Nach Voraussetzung ist $D\geq 0$ und $R\geq 0$. Für $R=D^{-1} N$ gilt offenbar
\[
A=D (I-R), \quad R\geq 0, \quad \norm{R}_\infty=\norm{D^{-1} N}_\infty<1.
\]
Aus Lemma~\ref{lemma:NR} folgt die Invertierbarkeit von $I-R$ und damit die von $A$.
Außerdem folgt
\[
A^{-1}=(I-R)^{-1} D^{-1} =\sum_{k=0}^\infty {R^k} D^{-1}
\]
Die Einträge von $A^{-1}$ sind also Grenzwerte von Summen und Produkten nicht-negativer Zahlen und damit nicht-negativ.
\end{beweis}


\begin{lemma}\label{lemma:RW_stabil}
Es existieren $h_0>0$ und $C>0$ mit 
\[
\norm{L_h^{-1}}_\infty\leq C \quad \mbox{ für alle } 0<h<h_0.
\]
\end{lemma}
\begin{beweis}
Nach Übungsaufgabe 9.1 existiert eine eindeutige Lösung $w\in C^4[0,1]$ des Randwertproblems
\[
-w''(x) + b(x)w'(x) = 1 \quad x\in (0,1), \qquad w(0)=0=w(1).
\]

Da $w$ stetig ist, besitzt $w$ sein globales Minimum in $[0,1]$. Da in jedem inneren Minimum $w'(x)=0\leq w''(x)$
gilt und damit die DGL nicht erfüllt sein kann, muss das Minimum auf dem Rand liegen und es folgt
\[
w(x)\geq 0 \quad \forall x\in [0,1].
\]


$w$ erfüllt
\[
L[w]=-w''(x) + b(x)w'(x) + c(x)w(x)= 1+c(x)w(x).
\]
Nach Lemma~\ref{lemma:RW_Konsistenz} existiert deshalb ein $C'>0$, so dass für 
$W=(w(x_1),\ldots,w(x_{n}))^T$ 
und $G=(1+c(x_1)w(x_1),\ldots,1+c(x_n)w(x_{n}))^T$ gilt
\[
\norm{L_h W - G}_\infty \leq C' h^2,
\]
und damit insbesondere
\[
L_h W \geq G- C'h^2 \1.
\]

Da $c$ und $w$ nicht-negativ sind, ist $G\geq \1$ und es folgt
\[
L_h W \geq \1 - C' h^2\1.
\]

Für hinreichend kleine $h$ ist $1-C'h^2>\frac{1}{2}$ und die Matrix 
$L_h$ erfüllt die Voraussetzungen von Lemma~\ref{lemma:wann_M}. Mit Bemerkung~\ref{bem:monotonie}
folgt dann
\[
L_h W\geq \frac{1}{2} \1 \quad \Longrightarrow \quad W\geq \frac{1}{2}{L_h^{-1}\1}
\]
und damit 
\[
\norm{L_h^{-1}}_\infty = \norm{L_h^{-1} \1}_\infty \leq 2 \norm{W}_\infty\leq 2 \max_{x\in [0,1]} |w(x)|,
\]
womit die Behauptung gezeigt ist.
\end{beweis}

\begin{korollar}
Es existieren $h_0>0$ und $C>0$ mit 
\[
\norm{U-U_h}_\infty\leq C h^2 \quad \mbox{ für alle } 0<h<h_0.
\]
\end{korollar}
\begin{beweis}
Mit
\[
\norm{U-U_h}_\infty = \norm{L_h^{-1} L_h (U-U_h)}\leq \norm{L_h^{-1}} \norm{L_h U-F}
\]
folgt die Behauptung aus Lemma~\ref{lemma:RW_Konsistenz} und Lemma~\ref{lemma:RW_stabil}.
\end{beweis}

%%%%%%%%%%%%%%%%%

\section{Mehrdimensionale Randwertprobleme}

Mit Finite Differenzen Verfahren lassen sich auch mehrdimensionale (partielle) Differentialgleichungen
lösen. Wir betrachten dies zum Abschluss des Kapitels examplarisch an der mehrdimensionalen 
stationären Wärmeleitungsgleichung
\begin{equation}\labeq{laplace1}
-\sum \frac{\partial^2}{\partial x_j^2} u(x)=-\Delta u(x)=f(x).
\end{equation}
in einer beschränkten offenen Menge $\Omega\subseteq \R^n$. Dabei sei $f\in C(\Omega)$ eine stetige Funktion.
Ähnlich wie in der Modellierung der eindimensionalen Diffusion können wir uns $f$ als die Verteilung angelegter
Wärmequellen vorstellen und die Lösung $u$ beschreibt dann die sich im Gleichgewicht einstellende Temperatur.

Es ist anschaulich klar, dass für Gleichgewichtstemperatur auch der Rand des Gebiets
$\partial \Omega$ eine Rolle spielen wird, etwa wenn dieser Rand immer auf einer konstanten Temperatur gehalten wird.
Tatsächlich werden wir sehen, dass $u$ durch \req{laplace1} und Vorgabe von $u|_{\partial \Omega}$ eindeutig bestimmt ist.

Damit die Gleichung \req{laplace} und eventuelle Randwerte überhaupt einen Sinn ergeben,
betrachten wir als Lösungskandidaten nur Funktionen $u\in C^2(\Omega)\cap C(\overline \Omega)$ (sogenannte \emph{klassische Lösungen}). Lösungen der Laplace-Gleichung $\Delta u=0$ heißen auch \emph{harmonische} Funktionen.

\subsection{Das Maximumsprinzip}


\begin{theorem}[Maximumsprinzip]\label{satz:maxprinzip}
Es sei $f\in C(\Omega)$ punktweise nicht-positiv und die Funktion $u\in C^2(\Omega)\cap C(\overline \Omega)$ erfülle
\begin{equation}\labeq{laplace}
-\Delta u(x)=f(x)\leq 0 \quad \forall x\in \Omega.
\end{equation}
Dann nimmt $u$ sein Maximum auf dem Rand $\partial \Omega$ an (d.h. mindestens ein globales Maximum von $u$ liegt auf  $\partial \Omega$).
\end{theorem}
\begin{beweis}
\begin{enumerate}[(i)]
\item Betrachte zunächst den Fall $f(x)<0$ für alle $x\in \Omega$. Zeige, dass $u$ kein Maximum im Inneren hat.

Angenommen es gibt ein inneres Maximum $y\in \Omega$:
\[
u(y)\geq u(x) \quad \forall x\in \overline{\Omega}.
\]
Dann ist $y$ insbesondere ein Maximum in jeder Koordinatenrichtung, also
\[
\frac{\partial^2}{\partial x_j^2} u(y)\leq 0 \quad j=1,\ldots,n
\]
und damit $-\Delta u\geq 0$, was $-\Delta u=f<0$ widerspricht. $u$ kann also kein 
inneres Maximum haben. Da $u$ als stetige Funktion auf dem Kompaktum $\overline \Omega$ aber mindestens ein Maximum besitzt, muss ein Maximum auf dem Rand liegen.
%
\item Nun sei $f(x)\leq 0$ für alle $x\in \Omega$. 
Angenommen es liegt kein Maximum auf dem Rand, dann gibt es ein inneres Maximum $y\in \Omega$ mit
\[
u(y)\geq u(x) \quad \forall x\in \Omega\quad \mbox{ und } \quad
u(y)> u(x) \quad \forall x\in \partial \Omega.
\]
Mit diesem $y$ definieren wir die Funktion
\[
h(x):=\norm{x-y}^2=\sum_{j=1}^n (x_i-y_i)^2.
\]
Da $\Omega$ beschränkt ist, ist $\partial \Omega$ kompakt. 
$h$ ist auf also auf $\partial \Omega$ beschränkt und es gilt $h(y)=0$. Für hinreichend kleines $\delta>0$ nimmt deshalb 
\[
w(x):=u(x)+\delta h(x)
\]
sein Maximum nicht auf dem Rand an. Aus $\Delta h(x)=2n$ folgt aber
\[
-\Delta w(x)=f-2n\delta<0,
\]
und wir erhalten den Widerspruch aus der in Teil (i) gezeigten Aussage.
\end{enumerate}
\end{beweis}

\begin{theorem}\label{thm:MaxPrinzipFolgerungen}
Sei $f\in C(\Omega)$. 
\begin{enumerate}[(a)]
\item Ist $f\geq 0$ und $u\in C^2(\Omega)\cap C(\overline\Omega)$ eine Lösung von 
$-\Delta u=f\geq 0$ in $\Omega$, so nimmt $u$ sein Minimum auf dem
Rand $\partial \Omega$ an. (\emph{Minimumsprinzip}).
%
\item Gilt für $u,v\in C^2(\Omega)\cap C(\overline\Omega)$
\[
-\Delta u\leq -\Delta v \mbox{ in $\Omega$} \quad \mbox{ und } \quad u\leq v \mbox{ auf $\partial \Omega$}
\]
so gilt $u\leq v$ in ganz $\Omega$.
%
\item Die Nullfunktion ist die einzige Lösung $u\in C^2(\Omega)\cap C(\overline\Omega)$ von \[
-\Delta u=0, \qquad u|_{\partial \Omega}.
\]
Eine Lösung $u\in C^2(\Omega)\cap C(\overline\Omega)$ 
\[
-\Delta u=f
\]
ist also (wenn sie existiert) eindeutig durch $f$ und $u|_{\partial \Omega}$ bestimmt.
%
\item Erfüllen $u_1,u_2\in C^2(\Omega)\cap C(\overline\Omega)$ 
\[
-\Delta u_1=f= -\Delta u_2
\]
so ist 
\[
\norm{u_1-u_2}_\infty:=\max_{x\in \overline{\Omega}}|u_1(x)-u_2(x)|=\max_{x\in \partial \Omega}|u_1(x)-u_2(x)|.
\]
Die Lösung des Dirichlet-Problems hängen also (so sie denn existieren) stetig von den vorgegebenen Dirichlet-Randdaten ab.
%
\item Es existiert ein (vom Gebiet $\Omega$ abhängiges) $C>0$, so dass für alle $u\in C^2(\Omega)\cap C(\overline\Omega)$ 
\[
\norm{u}_\infty=\max_{x\in \overline\Omega} |u(x)|\leq \max_{x\in \partial \Omega} |u(x)|+C\sup_{x\in \Omega} |\Delta u|.
\]
In diesem Sinne hängt eine Lösung von $\Delta u=f$ (sofern sie existiert) also auch stetig von der rechten Seite ab, d.h. von $u\big|_{\partial \Omega}$ und $f$.
%
\item Sind $c,f\in C(\Omega)$, $c\geq 0$, $f\leq 0$ und $u\in C^2(\Omega)\cap C(\overline\Omega)$ erfüllt
\[
-\Delta u + cu =f \leq 0,
\]
so gilt
\[
\max_{x\in \Omega}{u(x)} \leq \max\{0,\max_{x\in \partial \Omega}{u(x)}\}
\]

\end{enumerate}
\end{theorem}
\begin{beweis}
\begin{enumerate}[(a)]
\item folgt aus Anwendung des Maximumprinzips auf $-u$.
\item folgt aus Anwendung des Maximumprinzips auf $u-v$.
\item folgt aus Anwendung des Maximumsprinzips und des Minimumsprinzips.
\item folgt aus Anwendung des Maximums- und Minimumprinzips auf $u-v$.
\item Für $\sup_{x\in \Omega}|\Delta u(x)|=\infty$ ist die Aussage erfüllt. Sei also $\Delta u(x)$ beschränkt.

Wähle $R>0$ so groß, dass $\Omega\subseteq B_R(0):=\{ x\in \R^n\;|\; \norm{x}=R\}$.
Für
\[
w(x):=R^2-\frac{1}{n}\norm{x}^2
\]
gilt $-\Delta w=2$ und $w(x)\geq 0$ für alle $x\in \Omega$.

Definiere außerdem
\[
v(x):=\max_{z\in \partial \Omega} |u(z)| + \frac{w(x)}{2} \sup_{z\in \Omega}|\Delta u(z)|
\]
Dann ist
\[
-\Delta v(x)=  \sup_{z\in \Omega}|\Delta u(z)|\geq -\Delta u(x) \ \forall x\in \Omega \quad \mbox{ und } \quad
v|_{\partial \Omega} \geq u|_{\partial \Omega}
\]
also nach (b) $u\leq v$ auf $\Omega$. Genauso folgt $u\geq -v$ auf $\Omega$ und damit
\begin{align*}
|u(x)|&\leq |v(x)|=v(x)\leq \max_{z\in \partial \Omega} |u(z)| + \frac{w(x)}{2} \sup_{z\in \Omega}|\Delta u(z)|\\
&\leq \max_{z\in \partial \Omega} |u(z)| + \frac{R^2}{2} \sup_{z\in \Omega}|\Delta u(z)|,
\end{align*}
also folgt die Behauptung mit $C:=\frac{R^2}{2}$.
%
\item Angenommen, es existiert ein $y\in \Omega$ mit 
\[
u(y)=\max_{x\in \overline \Omega} u(x)>\max_{x\in \partial \Omega} u(x) \quad \mbox{ und } \quad u(y)>0.
\]
Dann gilt $-\Delta u(y)=f(y)-c(y)u(y)\leq 0$ und wir erhalten den gleichen Widerspruch wie im Beweis von Satz \ref{satz:maxprinzip}.
\end{enumerate}

\end{beweis}
%(e),(f) sind schöne Übungsaufgaben
%Ü: Max.prinzip für allg. elliptische

%FD Konsistenzordnung als Ü-Aufgabe



\subsection{Finite Differenzen im Mehrdimensionalen}

Wie im Eindimensionalen betrachten wir finite Differenzen und definieren für eine Funktion $u(x)$
\begin{align*}
D_{h,i}^{+} u(x)&:=\frac{u(x+he_i)-u(x)}{h}\\
D_{h,i}^{-} u(x)&:=\frac{u(x)-u(x-he_i)}{h}\\
D_{h,i} u(x)&:=\frac{u(x+he_i)-u(x-he_i)}{2h}\\
D_{h,i}^2 u(x)&:=D_{h,i}^{+} D_{h,i}^{-}  u(x)= D_{h,i}^{-} D_{h,i}^{+}  u(x)=  \frac{u(x+he_i)-2u(x) + u(x-he_i)}{h^2}\\
\end{align*}

%Für die partielle Ableitung schreiben wir auch $D_i u=\frac{\partial}{\partial x_i} u$
Wir verwenden für mehrfache partielle Ableitungen auch die \emph{Multiindex-Notation}: Für $\alpha:=(\alpha_1,\ldots,\alpha_n)\in \N_0^n$ ist
\[
D^\alpha u=\frac{\partial^{|\alpha|}u}{\partial x_1^{\alpha_1}\cdots \partial x_n^{\alpha_n}},
\]
und $|\alpha|=\alpha_1+\ldots+\alpha_n$, $\alpha!=\alpha_1!\cdots \alpha_n!$. Für
$\alpha, \beta \in \N_0^n$, $\beta\leq \alpha$ ist außerdem ${\alpha \choose \beta}=\frac{\alpha!}{\beta!(\alpha-\beta)!}$ wobei
\[
\alpha\leq \beta \quad :\Longleftrightarrow \quad
\alpha_j\leq \beta_j \quad \mbox{ für alle } j=1,\ldots,n.
\]
Mit dieser Notation definieren wir für $u\in C^k(\overline\Omega)$ die Halbnormen
\[
|u|_{C^k(\overline\Omega)}=\max_{|\alpha|= k} \max_{x\in \overline\Omega} |D^\alpha u(x)|.
\]
und die Norm 
\[
\norm{u}_{C^k(\overline\Omega)}=\max_{|\alpha|\leq k} \max_{x\in \overline\Omega} |D^\alpha u(x)|.
\]
Man rechnet leicht nach, dass letzteres tatsächlich eine Norm ist, die $C^k(\overline\Omega)$ 
zu einem Banachraum (also einem vollständigen normierten Vektorraum) macht.

\begin{lemma}\label{lemma:FD_konsistenz1}
Sei $x\in \Omega$, $j\in \{1,\ldots,n \}$ und $h>0$ hinreichend klein, so dass 
\[
x\pm t h e_j\in \Omega \quad \mbox{ für alle } t\in [-1,1].
\]
\begin{enumerate}[(a)]
\item Für $u\in C^2(\overline\Omega)$ ist $\DS \left| D_{h,i}^{+} u(x) - \frac{\partial}{\partial x_i}u(x)\right| \leq \frac{h}{2} |u|_{C^2(\overline\Omega)}$.
\item Für $u\in C^2(\overline\Omega)$ ist $\DS \left| D_{h,i}^{-} u(x) - \frac{\partial}{\partial x_i}u(x)\right| \leq \frac{h}{2} |u|_{C^2(\overline\Omega)}$.
\item Für $u\in C^3(\overline\Omega)$ ist $\DS \left| D_{h,i} u(x) - \frac{\partial}{\partial x_i}u(x)\right| \leq \frac{h^2}{6} |u|_{C^3(\overline\Omega)}$.
\item Für $u\in C^4(\overline\Omega)$ ist $\DS \left| D_{h,i}^2 u(x) - \frac{\partial^2}{\partial x_i^2}u(x)\right| \leq \frac{h^2}{12} |u|_{C^4(\overline\Omega)}$.
\end{enumerate}
\end{lemma}
\begin{beweis}
wie im Eindimensionalen
\end{beweis}

\begin{beispiel}\label{bsp:poisson}
Wir betrachten die Gleichung
\[
-\Delta u=f \quad \mbox{ in $\Omega$} \quad \mbox{ und } \quad u|_{\partial \Omega}=0,
\]
%zu gegebenen Quelltermen und Randvorgaben $f:\Omega \to \R$ und $g:\ \partial \Omega\to \R$,
zu gegebenen Quelltermen $f:\Omega \to \R$, wobei $\Omega=(0,1)^2\subset \R^2$ ein zweidimensionales Quadrat mit Seitenlänge $1$ sei.

Wir diskretisieren $\Omega$ durch ein Punktegitter mit der Schrittweite 
 \[
h=1/(k+1),\quad k\in \N,
\]
und ordnen 
die inneren Punkte entsprechend der in der Vorlesung gemalten Skizze an
\[
x^{(i+(j-1)k)}:=(ih,jh)\in \Omega, \quad i,j=1,\ldots,k.
\]
Wir setzen noch $F=(f^{(i)})_{i=1,\ldots,k^2}\in \R^{k^2}$, $f^{(i)}=f(x^{(i)})$ und versuchen einen
Vektor von Approximationen 
\[
U_h=(u_h^{(i)})_{i=1,\ldots,k^2}\approx (u^{(i)})_{i=1,\ldots,k^2}=U \in \R^{k^2}, \quad u^{(i)}=u(x^{(i)})
\]
zu finden. Für jeden inneren Gitterpunkt $x^{(i)}\in \Omega$ erhalten wir durch die obigen Differenzenverfahren 2. Ordnung
die lineare Gleichung
\begin{align*}
f^{(i)}&=f(x^{(i)})=- \Delta u|_{x=x^{(i)}}\approx - D_{h,1}^2 u(x)|_{x=x^{(i)}} - D_{h,2}^2 u(x)|_{x=x^{(i)}}\\
&= -\frac{1}{h^2}\left( u(x^{(i)} + he_1)-2u(x^{(i)})+u(x^{(i)}-he_1) \right.\\
& \qquad \left. {} + u(x^{(i)} + he_2)-2u(x^{(i)})+u(x^{(i)}-he_2)\right)\\
&= \frac{1}{h^2} \left( 4 u^{(i)} - u^{(i-1)} - u^{(i+1)} -  u^{(i-k))} - u^{(i+k)} \right).
\end{align*}
falls alle benachbarten Punkte ebenfalls innere Punkte sind. Ist ein benachbarter Punkt ein Randpunkt, so erhalten
wir einen analogen Ausdruck, bei dem der zum Randpunkt gehörige Summand (wegen $u|_{\partial \Omega}=0$) fehlt.

Insgesamt erhalten wir so ein lineares Gleichungssystem
\[
L_h U_h = F
\]
wobei die Matrix $L_h$ die folgende Blocktridiagonalgestalt besitzt
\[
L_h=\frac{1}{h^2}\left( \begin{array}{r r r r r} C & -I\\ -I & C & -I\\ & -I & \ddots & \ddots\\ & & \ddots & \ddots & -I\\ & & & -I & C\end{array}\right)\in \R^{k^2\times k^2}
\]
mit
\[
C:=\left( \begin{array}{r r r r r} 4 & -1\\ -1 & 4 & -1\\ & -1 & \ddots & \ddots\\ & & \ddots & \ddots & -1\\ & & & -1 & 4\end{array}\right)\in \R^{k\times k},
\]
und der $k\times k$-Einheitsmatrix $I$.
\end{beispiel}

\begin{bemerkung}
Für zwei Matrizen $K=(k_{i,j})\in \R^{l \times m}$ und $L\in \R^{r \times s}$ ist das \emph{Kronecker Produkt} definiert durch
\[
K\otimes L =  \left( \begin{array}{c c c c} k_{1,1} L & k_{1,2}L & \dots & k_{1,m}L \\ k_{2,1} L & k_{2,2}L & \dots & k_{1,m}L \\ \vdots & \vdots & & \vdots\\
k_{l,1} L & k_{l,2}L & \dots & k_{l,m}L\end{array} \right) \in \R^{lr\times ms}.
\]

Damit lässt sich die Matrix $L_h$ aus \ref{bsp:poisson} schreiben als
\[
L_h=\frac{1}{h^2} \left( I \otimes T + T \otimes I \right)
\]
mit
\[
T:=\left( \begin{array}{r r r r r} 2 & -1\\ -1 & 2 & -1\\ & -1 & \ddots & \ddots\\ & & \ddots & \ddots & -1\\ & & & -1 & 2\end{array}\right)\in \R^{k\times k}.
\]
\end{bemerkung}

Inhomogene Dirichlet-Probleme
\[
-\Delta u =f, \qquad u|_{\partial \Omega}=g
\]
lassen sich analog behandeln, indem entweder (wie im Eindimensionalen vorgeführt) der Effekt der Randpunkte auf die Differenzenverfahren der randnahen Punkte  
in der rechten Seite berücksichtigt wird, oder indem die Randpunkte als Unbekannte hinzugenommen werden und für jeden Randpunkt $x^{(j)}$
die Gleichung
\[
u^{(j)}=g(x^{(j)}).
\]
aufgenommen wird.


\subsection{Ein diskretes Maximumsprinzip}

Offensichtlich lassen sich auch allgemeinere Gleichungen (mit veränderlichen Diffusionskoeeffizienten, Absorptions- und Konvektionstermen)
analog behandeln und führen wiederum auf lineare Gleichungssysteme der Form
\begin{align*}
L_h U_h =F.
\end{align*}

Die so entstehenden Diskretisierungsmatrizen $L_h$ sind üblicherweise von der Gestalt, dass die Diagonaleinträge positiv sind, die Nebendiagonaleinträge
negativ sind, und zeilenweise der Diagonaleintrag die Zeile dominiert. 
Wir werden sehen, dass solche Matrizen ein diskretes Maximumsprinzip erfüllen und benötigen dafür noch das folgende Lemma:

\begin{lemma}[Sternlemma]\label{lemma:stern}
Sei $M\in \N_0$ und $\alpha_m,x_m$, $m=0,\ldots,M$ erfüllen
\[
\alpha_m<0 \quad \forall m>0,\qquad \sum_{m=0}^M \alpha_m\geq 0, \qquad
\sum_{m=0}^M \alpha_m x_m\leq 0 \quad \mbox{ und } \quad x_0\geq 0.
\]
Ist $x_0\geq \max_{m=1,\ldots,M} x_m$, so gilt $x_0=x_1=\ldots=x_M$.
\end{lemma}
\begin{beweis}
Für $M=0$ ist die Aussage trivial. Ansonsten ist
\[
\sum_{m=1}^M \underbrace{\alpha_m}_{< 0} \underbrace{(x_m - x_0)}_{\leq 0}=\sum_{m=0}^M \alpha_m (x_m - x_0)=\underbrace{\sum_{m=0}^M \alpha_m x_m}_{\leq 0} - \underbrace{x_0\sum_{m=0}^M\alpha_m}_{\geq 0}\leq 0
\]
und es folgt $x_m=x_0$ für alle $m=1,\ldots,M$.
\end{beweis}
Offenbar kann für $\sum_{m=0}^M\alpha_m=0$ auf die Voraussetzung $x_0\geq 0$ in Lemma~\ref{lemma:stern} verzichtet werden.

\begin{theorem}\label{thm:diskretes_maxprinzip}
Sei $L_h=(a^h_{ij})_{i,j=1}^N\in \R^{N\times N}$ eine (nicht-notwendigerweise strikt) diagonaldominante Matrix mit positiven Diagonal- und negativen 
Nebendiagonaleinträgen, also
\[
a^h_{ii}\geq \sum_{i\neq j} |a^h_{ij}|  \quad \forall i=1,\ldots,N, \qquad a^h_{ij}\leq 0 \quad \forall i\neq j.
%\sum_{j=1}^N a_{ij} \geq 0 \quad \forall i=1,\ldots,N, \qquad a_{ij}\neq 0 \quad \forall i\neq j.
\]
Sei $F\in \R^{N}$ und $U_h\in \R^N$ sei eine Lösung von $L_h U_h=F$. 
Außerdem sei $F\leq 0$, also komponentenweise nicht-positiv. 

Betrachte die $i$-te Zeile des LGS $L_h U_h =F$,
\[
\sum_{j=1}^N a^h_{ij} u^{h}_j =f^h_i\leq 0.
\]
Ist $u^h_i\geq \max\{0,\max_{j:\ j\neq i, a_{ij}\neq 0} u^h_j\}$, so 
ist $u^h_i=u^h_j$ für alle $j$ mit $a_{ij}\neq 0$.
\end{theorem}
\begin{beweis}
Wir setzen $\alpha_0=a^h_{ii}$, $x_0=u^h_i$. Entsprechend seien $\alpha_l$ und $x_l$, $l=1,\ldots,k$ die anderen
von Null verschiedenen Einträge $a^h_{ij}$, $j\neq i$ und dazugehörigen $u^h_j$. Dann folgt die Behauptung aus
Lemma~\ref{lemma:stern}.
\end{beweis}



\begin{bemerkung}
\begin{enumerate}[(a)]
\item
Im Kontext unserer Finite-Differenzen-Diskretisierungen kann Theorem \ref{thm:diskretes_maxprinzip}
als \emph{diskretes Maximumsprinzip} (in Analogie zu Theorem~\ref{thm:MaxPrinzipFolgerungen}(f)) interpretiert werden.
Die diskrete Lösung $U_h$ kann nicht in einem Gitterpunkt einen nicht-negativen Wert annehmen, der strikt maximal ist unter
allen im Rahmen der Differenzenquotienten betrachten Nachbarwerten. Mehr noch: nimmt die diskrete Lösung
einen in diesem Sinne maximalen Wert an, so besitzen alle (in diesem Sinne) benachbarten Werte den gleichen maximalen Wert.
%
\item Mit dem diskreten Maximumsprinzip lässt sich oft die Lösbarkeit der diskretisierten Gleichung beweisen. Betrachten wir exemplarisch die Matrix
$L_h$ aus der Diskretisierung des Poisson-Problems auf dem Einheitsquadrat. $L_h$ ist genau dann invertierbar, 
wenn es injektiv ist,
also nur der Nullvektor das homogenen LGS $L_h U_h=0$ löst. Sei also $U_h$ eine solche Lösung. 
Dann besitzt $U_h$ einen maximalen Eintrag $u^h_j$.
O.B.d.A. sei $u_h^j\geq 0$, ansonsten betrachten wir $-U_h$. 
Da wir jeden anderen Gitterpunkt über einen Weg aus (bei den Differenzenquotienten vorkommenden)
Nachbarwerten erreichen können (das Gitter ist \emph{diskret zusammenhängend}), folgt aus dem diskreten Maximumsprinzip, dass alle Einträge von 
$u^h_j$ übereinstimmen. Aus der ersten Zeile von $L_h$ folgt dann, dass $U_h=0$ gelten muss.
\end{enumerate}
\end{bemerkung}

Die folgende Verschärfung von Lemma~\ref{lemma:wann_M}
können wir als diskretes Analogon zur 
Monotonieeigenschaft aus Theorem~\ref{thm:MaxPrinzipFolgerungen}(b) interpretieren:
\begin{theorem}
Sei $A\in \R^{N\times N}$ eine invertierbare, diagonaldominante Matrix mit positiven Diagonalelementen und nicht-positiven Nichtdiagonalelementen,
wobei
\[
a_{ii}\geq \sum_{j=1}^N |a_{ij}| \quad \forall i\in \{1,\ldots,n\}. 
\]
Dann ist $A^{-1}$ komponentenweise nicht-negativ.

Insbesondere gilt (komponentenweise)
\[
A u\leq A v \quad \Longrightarrow \quad u\leq v.
\]
\end{theorem}
\begin{beweis}
\begin{enumerate}[(a)]
\item Nach Lemma~\ref{lemma:wann_M} ist jede strikt-diagonaldominante Matrix $A\in \R^{N\times N}$
(mit positiven Diagonalelementen und nicht-positiven Nichtdiagonalelementen) invertierbar 
und $A^{-1}$ ist komponentenweise nicht-negativ.
%
\item Für (nicht notwendigerweise strikt) diagonaldominantes und invertierbares $A$ (mit positiven Diagonalelementen und nicht-positiven Nichtdiagonalelementen) erhalten wir aus Teil (a),
dass $(A+\epsilon I)$ invertierbar ist, und dass $(A+\epsilon I)^{-1}$ komponentenweise nicht-negativ ist. Da $A$ nach Voraussetzung invertierbar ist, konvergiert (für $\epsilon\to 0$) $(A+\epsilon I)^{-1}\to A^{-1}$ und es folgt die Behauptung.
\end{enumerate}
\end{beweis}

\subsection{Konsistenz, Stabilität und Konvergenz}

Sei $L_h U_h=F$ die entsprechend den letzten Abschnitten erstellte Diskretisierung des Poisson-Problems
\[
-\Delta u=f, \quad u|_{\partial \Omega}=g
\]
und $U\in \R^N$ der Vektor der Auswertungen der Funktion $u(x)$ auf den Gitterpunkten der Diskretisierung.

Wie im Eindimensionalen gilt der folgende Zusammenhang zwischen Konsistenz, Stabilität und Konvergenz:
\[
\norm{U-U_h}_\infty = \norm{L_h^{-1} L_h (U-U_h)}_\infty\leq \norm{L_h^{-1}}_\infty \norm{L_h U - F}_\infty.
\]
Erfüllt also (für $h\to 0$) die wahre Lösung (genauer: ihre Auswertungen) immer besser die diskretisierte Gleichung (Konsistenz),
d.h. $\lim_{h\to 0} \norm{L_h U - F}_\infty=0$, und bleibt $\norm{L_h^{-1}}_\infty$ beschränkt (Stabilität), so nähert die
Lösung der diskreten Gleichung die wahre Lösung immer besser an.

Die Konsistenz von finiten Differenzenverfahren erhalten wir sofort aus Abschätzungen, wie sie in Lemma~\ref{lemma:FD_konsistenz1}
vorkommen, die ihrerseits leicht aus Anwendungen der Taylor-Formel folgen. Auch im Mehrdimensionalen lassen
sich konsistente Differenzenverfahren meist sehr leicht für eine gegebene partielle Differentialgleichung konstruieren. 

Der Beweis von Stabilität ist wie im Eindimensionalen ungleich schwerer. %und erfordert üblicherweise die Ausnutzung spezieller Lösungen der betrachten PDGL.
Wir zeigen im Rahmen dieser Vorlesung die Stabilität nur für das hier exemplarisch betrachtete 
Problem $-\Delta u=f$ mit homogenen Dirichletrandwerten auf dem Einheitsquadrat.

\begin{theorem}
Sei $\Omega=(0,1)^2\subseteq \R^2$. Dann existiert ein $C>0$, so dass für die entsprechend den
letzten Abschnitten erstellte Diskretisierungsmatrix $L_h$ zum Problem 
\[
-\Delta u=f, \quad u|_{\partial \Omega}=0
\]
gilt $\norm{L_h^{-1}}_\infty < C$ für alle $h>0$. 
\end{theorem}
\begin{beweis}
Sei $R>0$ hinreichend groß, so dass $\Omega\subseteq B_{R}$ und betrachte die Funktion $w(x)=\frac{1}{4}\left( R^2 -\norm{x}^2 \right)+1$. 
Offenbar gilt $-\Delta w=1$. $w$ ist ein Polynom zweiten Grades und die verwendeten Differenzenquotienten sind dafür 
in allen nicht randnahen Gitterpunkten exakt, so dass an diesen Punkten $(L_h W)_j=1$ gilt. (Dabei bezeichnet $W$ wieder den 
Vektor der Auswertungen von $w(x)$ in den Gittepunkten.) Für die randnahen Punkte bleiben einer oder
mehrere positive Randwerte $w(x)|_{\partial \Omega}\geq 0$ 
mit einem negativen Gewicht unberücksichtigt, so dass in diesen Punkten $(L_h W)_j\geq 1$ gilt.
Insgesamt ist also 
\[
L_h W\geq 1.
\]
Damit folgt
\[
\norm{L_h^{-1}}_\infty= \norm{L_h^{-1} \1}_\infty\leq \norm{L_h^{-1} L_h W}_\infty \leq \max_{x\in \overline{B_R(0)}} |w(x)|= \frac{R^2}{4}.
\]
und damit die Behauptung.
\end{beweis}

\begin{korollar}
Falls eine Lösung des homogenen Dirichletproblems
\[
-\Delta u=f, \quad u|_{\partial \Omega}=0, \quad \Omega=(0,1)^2\subseteq \R^2
\]
existiert, so konvergieren die durch Finite Differenzen erhaltenenen Approximationen $U_h$ gegen die Lösung. 
\end{korollar}



%%%%%%%%%%%%%%%%%

\chapter{Eigenwertprobleme}

\section{Einleitung}

Wir untersuchen in diesem Kapitel, wie sich die Eigenwerte einer gegebenen Matrix numerisch bestimmen lassen.
In diesem Kapitel sei $A\in \C^{n\times n}$ stets eine quadratische Matrix mit Einträgen $a_{ij}\in \C$.
Oft werden wir uns dabei auf den Fall hermitescher $A=A^*$ (oder zumindest diagonalisierbarer) Matrizen beschränken. 
Für die Praxis reicht dies oft aus, da für allgemeine Matrizen damit die (auf den Eigenwerten von $A^*A$ beruhende)
\emph{Singulärwertzerlegung} bestimmt werden kann.

Wir erinnern zuerst an ein paar grundlegende Resultate aus der linearen Algebra.

\begin{definition}
Zu einer quadratischen Matrix $A\in \C^{n\times n}$ heißt $\lambda\in \C$ \emph{Eigenwert}, falls ein Vektor
$0\neq x\in \C^n$ existiert, so dass
\[
Ax=\lambda x.
\]
$x$ heißt \emph{Eigenvektor}. 

Die Menge aller Eigenwerte heißt \emph{Spektrum}
\[
\sigma(A):=\left\{ \lambda\in \C \dd \exists x\in \C^n\setminus\{0\} \dd Ax=\lambda x \right\}.
\]
Der Betrag des betragsgrößten Eigenwertes heißt \emph{Spektralradius}
\[
\rho(A)=\max\{|\lambda|\dd \lambda\in \sigma(A)\}.
\]
\end{definition}

\begin{bemerkung}\label{bem:EWe}
\begin{enumerate}[(a)]
\item $\lambda$ ist genau dann Eigenwert von $A$, wenn $A-\lambda I$ nicht injektiv ist. Da $A-\lambda I$ quadratisch ist, ist das äquivalent dazu, dass $A-\lambda I$ nicht surjektiv ist. $\Kern(A-\lambda I)$ ist der \emph{Eigenraum} zum Eigenwert $\lambda$. Die Dimension des Eigenraums
heißt auch \emph{geometrische Vielfachheit} des Eigenwerts. 
%
\item Eigenwerte sind genau die Nullstellen des komplexen \emph{charakteristischen Polynoms} $p(\lambda)=\det(A-\lambda I)$ vom Grad $n$.
 Aus dem Fundamentalsatz der Algebra folgt deshalb, dass jedes $A\in \C^{n\times n}$ mindestens einen und höchstens $n$ Eigenwerte
 besitzt. Die Vielfachheit des Eigenwerts als Nullstelle von $p$ heißt \emph{algebraische Vielfachheit}.
 %
 \item Eine Matrix ist genau dann \emph{diagonaliserbar}, wenn eine Basis aus Eigenvektoren besteht. Dies ist genau dann der Fall wenn für jeden Eigenwert die geometrische und algebraische Vielfachheit übereinstimmen.
 %
 \item $\norm{A}$ ist der größte Singulärwert von $A$, d.h. die Wurzel des größten Eigenwertes der Matrix $A^*A$. Es gilt also
 \[
 \norm{A}=\sqrt{\rho(A^*A)}.
 \] 
\item Für eine \emph{hermitesche} Matrix $A=A^*$ sind alle Eigenwerte reell und es existierte eine Orthogonalbasis aus Eigenvektoren. Offenbar folgt damit auch
\[
\norm{A}=\sqrt{\rho(A^2)}=\rho(A).
\]
\end{enumerate}
\end{bemerkung}



\section{Zwei Einschließungssätze}

Wir beginnen mit zwei Resultaten, mit denen sich die Lage der Eigenwerte auf recht einfache Weise grob abschätzen lässt.
Zuerst zeigen wir, dass alle Eigenwerte in der Vereinigung der sogenannten Gerschgorin-Kreise liegen müssen.

\begin{theorem}[Satz von Gerschgorin]\label{satz:gerschgorin}
Für jedes $A\in \C^{n\times n}$ gilt
\[
\sigma(A)\subset \bigcup_{i=1}^n K_i, \quad K_i:=\left\{ \zeta\in \C \dd |\zeta-a_{ii}|\leq \sum_{\substack{j=1\\ j\neq i}}^n |a_{ij}| \right\}
\]
Die $K_i$ heißen Gerschgorin-Kreise.
\end{theorem}
\begin{beweis}
Sei $\lambda\in \C$ ein Eigenwert von $A$, also $Ax=\lambda x$ mit einem $x\neq 0$. Sei $i$ ein Index eines betragsmäßig
größten Eintrags von $x$, also
\[
|x_i|\geq |x_j| \quad \forall j\neq i.
\]
Aus $\lambda x_i=(Ax)_i=\sum_{j=1}^n a_{ij}x_j$
folgt
\[
| \lambda - a_{ii}| = \left| \sum_{j=1}^n a_{ij} \frac{x_j}{x_i} - a_{ii}\right| 
= \left| \sum_{\substack{j=1\\ j\neq i}}^n a_{ij} \frac{x_j}{x_i}\right| 
\leq  \sum_{\substack{j=1\\ j\neq i}}^n |a_{ij}| \left|\frac{x_j}{x_i}\right|\leq \sum_{\substack{j=1\\ j\neq i}}^n |a_{ij}|
\]
und damit $\lambda\in K_i$.
\end{beweis}

\begin{bemerkung}\label{Bem:Transponiert}
Eine Matrix und ihre Transponierte $A^T=(a_{ji})_{i,j=1}^n$ haben dieselbe Determinante, $\det A=\det A^T$. 
Aus $\det (A-\lambda I)=\det(A^T-\lambda I)$ folgt, dass $A$ und $A^T$ dieselben Eigenwerte haben.
Genauso folgt, dass die Eigenwerte von $A^*$ die komplex konjugierten Eigenwerte von $A$ sind.

Aus Satz \ref{satz:gerschgorin} folgt deshalb auch dass 
\[
\sigma(A)=\sigma(A^T)\subset \bigcup_{i=1}^n K_i, \quad K_i:=\{ \zeta\in \C \dd |\zeta-a_{ii}|\leq \sum_{\substack{j=1\\ j\neq i}}^n |a_{ji}| \}
\]
\end{bemerkung}

\begin{beispiel}
Betrachte 
\[
A=\begin{pmatrix} 2 & 1 & -1\\ 0 & -1 & 1\\ 1 & 1 & 1\end{pmatrix}.
\]
Die Gerschgorin-Kreise für $A$ sind die (in der komplexen Ebene befindlichen) Kreise um $2$ mit Radius $2$, um $-1$ mit Radius $1$
und um $1$ mit Radius $2$. Alle Eigenwerte von $A$ liegen in diesen Kreisen.

Die Gerschgorin-Kreise für $A^T$ sind die Kreise um $2$ mit Radius $1$, um $-1$ mit Radius $2$
und um $1$ mit Radius $2$. Alle Eigenwerte von $A$ liegen auch in diesen Kreisen.
\end{beispiel}

Das zweite Einschließungsresultate verwendet das Konzept des Wertebereichs einer Matrix.
\begin{definition}
Die Menge
\[
W(A)=\left\{ \zeta=\frac{x^* A x}{x^* x} \dd 0\neq x\in \C^n \right\}=\left\{ x^* A x \dd x\in \C^n,\ \norm{x}=1\right\}\subseteq \C
\]
heißt \emph{Wertebereich} von $A$. Ausdrücke der Form $\frac{x^* A x}{x^* x}$ heißen auch \emph{Rayleigh-Quotienten}.
\end{definition}


\begin{lemma}\label{lemma:W_enthaelt_sigma}
Es gilt
\[
\sigma(A)\subset W(A).
\]
\end{lemma}
\begin{beweis}
Für einen Eigenwert $\lambda\in \C$ und zugehörigen Eigenvektor $x\in \C^n$ ist
$\frac{x^* A x}{x^*x}=\frac{x^* \lambda x}{x^*x}=\lambda$. 
\end{beweis}

\begin{lemma}\label{lemma:eigW}
\begin{enumerate}[(a)]
\item $W(A)$ ist \emph{wegzusammenhängend},
d.h. zu $\zeta_0, \zeta_1\in W(A)$ existiert stets eine stetige Abbildung
\[
\alpha:\ [0,1]\mapsto W(A),
\]
mit $\alpha(0)=\zeta_0$ und $\alpha_1=\zeta_1$.
\item Ist $A\in \C^{n\times n}$ \emph{hermitesch} (d.h. $A=A^*$), dann ist $W(A)\subset \R$ die konvexe Hülle der
Eigenwerte, d.h. das reelle Intervall $[\lambda_n,\lambda_1]$ zwischen dem größten Eigenwert $\lambda_1$ und dem kleinsten Eigenwert $\lambda_n$. 
\item Ist $A\in \C^{n\times n}$ \emph{schiefhermitesch} (d.h. $A=-A^*$), dann ist $W(A) \subset \im \R$ die konvexe Hülle der
Eigenwerte, d.h. das Intervall auf der imaginären Achse $i[a,b]$, wobei $a$ der kleinste und $b$ der größte Imaginärteil eines Eigenwertes sind.
\end{enumerate}
\end{lemma}
\begin{beweis}
\begin{enumerate}[(a)]
\item Seien $\zeta_0, \zeta_1\in W(A)$. O.B.d.A.\ $\zeta_0\neq \zeta_1$. 

Aus der Definition von $W(A)$ folgt dass
\[
\zeta_0=\frac{x_0^* A x_0}{x_0^*x_0}, \quad \zeta_1=\frac{x_1^* A x_1}{x_1^*x_1}
\]
mit $x_0\neq 0 \neq x_1$. 

Der naheliegende Kandidat für $\alpha$ ist
\[
\alpha(t):=\frac{x_t^* A x_t}{x_t^*x_t}, \quad x_t:=x_0+t(x_1-x_0)
\]
Ist $x_t\neq 0$ für alle $t\in [0,1]$, so erfüllt $\alpha$ offensichtlich das Gewünschte.
Wir müssen also nur zeigen, dass $x_t\neq 0$ für alle $t\in [0,1]$.
Angenommen dies wäre nicht der Fall, also $0=x_0+t(x_1-x_0)$. Dann wäre 
aber offenbar $t\neq 0$ und $x_1=\frac{t-1}{t} x_0$, womit $\zeta_0=\zeta_1$ und damit 
einen Widerspruch folgt.
%
\item Ist $A=A^*$, so ist für alle $x\in \C^n$
\[
\overline{\frac{x^* A x}{x^*x}}=\frac{( x^* A x )^*}{x^*x}
= \frac{ (A x)^* x}{x^*x}=\frac{ x^* A^* x}{x^*x}
=\frac{ x^* A x}{x^*x},
\]
also $W(A)\subseteq \R$.

Nach Lemma~\ref{lemma:W_enthaelt_sigma} gilt $\{\lambda_n,\lambda_1\}\subseteq W(A)$ und
zusammen mit Lemma~\ref{lemma:W_enthaelt_sigma} folgt 
\[
[\lambda_n,\lambda_1]\subseteq W(A)\subseteq \R.
\] 
 
Wir müssen also nur noch zeigen, dass für alle $\zeta\in W(A)$ gilt $\lambda_n\leq \zeta\leq \lambda_1$.
Für $\alpha>0$ hinreichend groß (z.B. $\alpha:=2\norm{A}+1$) ist $A+\alpha I$ hermitesch und 
\[
x^*(A+\alpha I)x\geq -\norm{A}\norm{x}^2 + \alpha \norm{x}^2>0 \quad \forall x\neq 0,
\]
also $A+\alpha I$ positiv definit. $A$ besitzt also eine Cholesky-Zerlegung $A=LL^*$ mit $L\in \C^{n\times n}$.
Es ist
\begin{align*}
x^*A x = x^* (A+\alpha I) x- \alpha \norm{x}^2= \norm{L^*x}^2 - \alpha \norm{x}^2\leq (\norm{L^*}^2-\alpha)\norm{x}^2
\end{align*}
und mit Bemerkung \ref{bem:EWe} folgt
\[
\frac{x^*A x}{x^* x} \leq \norm{L^*}^2-\alpha=\rho(LL^*)-\alpha=\rho(A+\alpha I)-\alpha.
\]
Da $A+\alpha I$ positiv definit ist, sind alle Eigenwerte positiv und der größte ist offenbar $\lambda_1+\alpha$.
Es gilt also $\zeta\leq \lambda_1$ für alle $\zeta=\frac{x^*A x}{x^* x}\in W(A)$. 

Der größte Eigenwert von $-A$ ist $-\lambda_n$. Mit dem gleichen Argument erhalten wir deshalb
\[
\frac{x^* (-A) x}{x^* x} \leq -\lambda_n
\]
und damit $\zeta\geq \lambda_n$ für alle $\zeta=\frac{x^*A x}{x^* x}\in W(A)$.

\item Ist $A^*=-A$, dann ist $(\im A)^*=-\im A^*=\im A$, also $\im A$ hermitesch. Da offenbar $W(\im A)=\im W(A)$ ist, folgt (c) aus (b).
\end{enumerate}
\end{beweis}

Jede Matrix $A\in \C^{n\times n}$ lässt sich in einen hermiteschen und einen schiefhermiteschen Teil zerlegen:
\[
A=\frac{A+A^*}{2}+\frac{A-A^*}{2}.
\]

Nach Lemma \ref{lemma:eigW} ist
\begin{align*}
\lefteqn{W \left(\frac{A+A^*}{2}\right)+W\left(\frac{A-A^*}{2}\right)}\\
&=\left\{ \zeta=\zeta_1+\zeta_2\in \C \dd \zeta_1\in W(\frac{A+A^*}{2}),\ \zeta_2\in W(\frac{A-A^*}{2}) \right\}\\
&=\left\{ \zeta=\xi + \im \eta\in \C \dd \xi \in W(\frac{A+A^*}{2}),\ \im \eta \in W(\frac{A-A^*}{2}) \right\}.\\
\end{align*}
ein Rechteck in der komplexen Ebene. Der folgende Satz zeigt, dass es $W(A)$ und damit insbesondere alle Eigenwerte von $A$ enthält.

\begin{theorem}[Satz von Bendixson]
Für jedes $A\in \C^{n\times n}$ gilt
\begin{align*}
W(A)& \subseteq W(\frac{A+A^*}{2})+W(\frac{A-A^*}{2})
\end{align*}
Insbesondere ist also $\sigma(A)\subset  W(\frac{A+A^*}{2})+W(\frac{A-A^*}{2})$.
\end{theorem}
\begin{beweis}
Für jedes $x\in \C^n$ mit $\norm{x}=1$ ist
\[
\quad x^* A x=x^* \left( \frac{A+A^*}{2}+\frac{A-A^*}{2}\right) x\in W(\frac{A+A^*}{2})+W(\frac{A-A^*}{2}). \quad \Box
\]
\end{beweis}

$W(\frac{A+A^*}{2})+W(\frac{A-A^*}{2})$ lässt sich mit Gerschgorin-Kreisen abschätzen.




\section{Stabilität des Eigenwertproblems}

Der \emph{naheliegender Ansatz} zur Berechnung der Eigenwerte von $A$ ist, zuerst das charakteristische Polynom aus $A$ zu berechnen und dann dessen Nullstellen zu bestimmen. In der Praxis wird man aber $A$ und damit die Koeffizienten des char. Polynoms nur näherungsweise kennen. Die Berechnung der Nullstellen eines Polynoms aus seinen Koeffizienten ist jedoch im Allgemeinen schlecht konditioniert (d.h. stark fehlerverstärkend), vgl.\ die an der Tafel gemalte Skizze.

Das Eigenwertproblem selbst ist (zumindest für normale Matrizen) nicht schlecht konditioniert, wie wir im folgenden Satz zeigen.
Zur Erinnerung: $A\in \C^{n\times n}$ heißt \emph{normal}, falls $AA^*=A^*A$. Normale Matrizen sind diagonalisierbar bzgl. einer Orthogonalbasis
aus Eigenvektoren. Es existieren also \emph{unitäre} Matrizen $X\in \C^{n\times n}$ (d.h. $X^{-1}=X^*$) mit 
\[
A=X \Lambda X^{-1}, \quad \Lambda=\begin{pmatrix} \lambda_1 & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & \lambda_n\end{pmatrix}
\]

\begin{theorem}\label{thm:stabEW}
Ist $A\in \C^{n\times n}$ normal und $E\in \C^{n\times n}$ beliebig. Ist $\tilde \lambda$ ein Eigenwert der gestörten Matrix
$A+E$, dann existiert ein $\lambda\in \sigma(A)$ mit
\[
|\lambda-\tilde \lambda| \leq \norm{E}.
\]
\end{theorem}
\begin{beweis}
Sei $\tilde \lambda$ ein Eigenwert von $A+E$ und $x\neq 0$ ein dazugehöriger Eigenvektor.
Ist $\tilde \lambda\in \sigma(A)$, dann stimmt die Behauptung. Sei also $\tilde \lambda\not\in \sigma(A)$. Dann existiert $(\tilde \lambda I-A)^{-1}$ und
aus
\[
Ex=(A+E)x-Ax=(\tilde \lambda I - A)x
\]
folgt $x=(\tilde \lambda I - A)^{-1} Ex$ und damit
\begin{align*}
1 & \leq \norm{(\tilde \lambda I - A)^{-1} E} \leq \norm{(\tilde \lambda I - A)^{-1}} \norm{E}
= \norm{(\tilde \lambda I - X \Lambda X^{-1})^{-1}} \norm{E} \\
&\leq   \norm{X} \norm{X^{-1}} \norm{(\tilde \lambda I - \Lambda )^{-1}} \norm{E}
\end{align*}
Da $X$ und $X^{-1}$ unitär sind, ist $\norm{X}=\norm{X^{-1}}=1$. Außerdem ist 
$(\tilde\lambda I -\Lambda)^{-1}$ eine
Diagonalmatrix mit den Einträgen $\frac{1}{\tilde \lambda- \lambda_j}$ wobei $\lambda_j$ die Eigenwerte von $A$ sind.
$\norm{\tilde \lambda I -\Lambda}$ ist der betragsgrößte Diagonaleintrag, d.h. es existiert ein $\lambda\in \sigma(A)$ mit
\[
\norm{(\tilde \lambda I -\Lambda)^{-1}}=\frac{1}{|\tilde \lambda-\lambda|}
\]
und damit
\[
|\tilde \lambda-\lambda|\leq \norm{E}. 
\]
\phantom{ende}
\end{beweis}

Der Beweis von \ref{thm:stabEW} liefert auch eine Abschätzung für allgemeine diagonalisierbare
(aber nicht notwendigerweise diagonalisierbare) Matrizen, siehe Übungsaufgabe ??.

Ein noch stärkeres Stabilitätsresultat ist der folgende Satz, den wir ohne Beweis angeben.
\begin{theorem}[Satz von Wielandt-Hoffman]
Seien $A,E\in \C^{n\times n}$ hermitesch. $\lambda_1\geq \ldots \geq \lambda_n$ und 
$\tilde \lambda_1\geq \ldots \geq \tilde \lambda_n$ seien die Eigenwerte von $A$ und $A+E$.

Dann gilt
\[
\sum_{i=1}^n (\lambda_i-\tilde \lambda_i)^2 \leq \norm{E}_F^2.
\]
\end{theorem}

\section{Die Potenzmethode}

Wir stellen nun die erste iterative Methode zur Berechnung von Eigenwerten vor, die \emph{Potenzmethode} (auch: \emph{von Mises-Verfahren}).
 Zur Motivation betrachten wir eine
Diagonalmatrix 
\[
A=\begin{pmatrix} \lambda_1 & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & \lambda_n\end{pmatrix}
\]
Wiederholtes Anwenden von $A$ auf einen Vektor $x=(x_i)_{i=1}^n\in \C^n$ liefert
\[
A^k x=\begin{pmatrix} \lambda_1^k x_1\\ \vdots \\ \lambda_n^k x_n\end{pmatrix} = \sum_{i=1}^n \lambda_i^k x_i e_i,
\]
wobei $e_i$ der $i$-te Einheitsvektor ist. 
Gibt es genau einen betragsgrößten Eigenwert $\lambda_j$ und ist $x_j\neq 0$, dann wird der 
dazugehörige Summand schneller wachsen (bzw. langsamer fallen für $|\lambda_j|<1$) als alle anderen Summanden. 
Er wird die Summe also immer mehr dominieren. Wir erwarten daher, dass
\[
A^k x\approx \lambda_j^k x_j e_j.
\]
Das gleiche gilt für beliebige diagonalisierbare Matrizen, wie der folgende Satz zeigt:

\begin{theorem}[Potenzmethode]\label{satz:Potenzmethode}
Sei $A\in \C^{n\times n}$ diagonalisierbar. $A$ besitze einen genau einen (aber nicht notwendigerweise einfachen) betragsgrößten Eigenwert, d.h. es sei
$\sigma(A)=\{\lambda_1,\ldots,\lambda_m\}$
\[
|\lambda_1|> |\lambda_2|\geq \ldots \geq |\lambda_m|.
\] 

Zu einem normierten Startvektor $x^{(0)}\in \C^n$ definieren wir die Folge 
\[
\tilde x^{(k)}:=Ax^{(k-1)}, \quad x^{(k)}:=\frac{\tilde x^{(k)}}{\norm{\tilde x^{(k)}}}.
\]

An $x^{(0)}$ sei ein Eigenvektor zu $\lambda_1$ beteiligt, d.h. 
es sei 
\[
x^{(0)}=\xi_1 v_1 + \sum_{j=2}^m \xi_j v_j, \quad \xi_1,\ldots,\xi_m\in \C,\ \xi_1\neq 0.
\]
wobei $v_j$ normierte Eigenvektoren zu $\lambda_j$ seien. Dann gilt:

\begin{align*}
x^{(k)}&= \frac{\lambda_1^k}{|\lambda_1|^k} \frac{\xi_1}{|\xi_1|} v_1 + O(\left| \lambda_2 / \lambda_1\right|^k),\\
(x^{(k-1)})^* \tilde x^{(k)} &= \lambda_1 + O(\left| \lambda_2 / \lambda_1\right|^{k}).
\end{align*}

$(x^{(k-1)})^* \tilde x^{(k)}$ konvergiert also gegen den betragsgrößten Eigenwert $\lambda_1$ und $x^{(k)}$ konvergiert bis auf skalare Vielfache gegen einen dazugehörigen Eigenvektor. Die Konvergenzgeschwindigkeit ist linear mit Konvergenzfaktor $|\lambda_2 / \lambda_1|$.
\end{theorem}
\begin{beweis}
Durch triviale Induktion sieht man, dass
\[
x^{(k)}=\frac{A^{k}x^{(0)}}{\norm{A^{k}x^{(0)}}}.
\]
Es ist 
\[
A^{k}x^{(0)}=\lambda_1^k \xi_1 v_1 + \sum_{j=2}^m \lambda_j^k \xi_j v_j
\]
und 
\[
\left| \norm{A^{k}x^{(0)}}- |\lambda_1^k \xi_1| \right| \leq \norm{\sum_{j=2}^m \lambda_j^k \xi_j v_j}
\leq |\lambda_2|^k \max |\xi_j|,
\]
also 
\[
\norm{A^{k}x^{(0)}}=|\lambda_1|^k |\xi_1| \left( 1 + O(\left| \lambda_2 / \lambda_1\right|^k ) \right).
\]
Damit erhalten wir
\begin{align*}
x^{(k)}&=\frac{A^{k}x^{(0)}}{\norm{A^{k}x^{(0)}}}=\frac{A^{k}x^{(0)}}{|\lambda_1|^k |\xi_1|} \frac{1}{1 + O(\left| \lambda_2 / \lambda_1\right|^k )}
=\frac{A^{k}x^{(0)}}{|\lambda_1|^k |\xi_1|} \left( 1 + O(\left| \lambda_2 / \lambda_1\right|^k )\right)\\
&= \left( \frac{\lambda_1^k}{|\lambda_1|^k} \frac{\xi_1}{|\xi_1|} v_1 + O(\left| \lambda_2 / \lambda_1\right|^k ) \right)
 \left( 1 + O(\left| \lambda_2 / \lambda_1\right|^k )\right)\\
&=\frac{\lambda_1^k}{|\lambda_1|^k} \frac{\xi_1}{|\xi_1|} v_1 + O(\left| \lambda_2 / \lambda_1\right|^k).
\end{align*}
und %(für $k\geq 1$)
\begin{align*}
(x^{(k-1)})^* \tilde x^{(k)}= (x^{(k-1)})^* A x^{(k-1)} = v_1^* A v_1 + O(\left| \lambda_2 / \lambda_1\right|^{k})
= \lambda_1 + O(\left| \lambda_2 / \lambda_1\right|^{k}).
\end{align*}
womit die Behauptung gezeigt ist.
\end{beweis}

\begin{bemerkung}
Die Konvergenz der Potenzmethode kann auch ohne die Annahme der Diagonalisierbarkeit gezeigt werden. Auf die Voraussetzung, 
dass genau ein \emph{betragsgrößter} Eigenwert existiert, kann jedoch nicht verzichtet werden.
\end{bemerkung}

\begin{alg}[Potenzmethode (von Mises-Verfahren)]
\label{algo:Potenzmethode}
\begin{algorithmic}
\State{Gegeben Matrix $A\in \C^{n\times n}$ und Startvektor $x\in \C^n$.}
\Repeat
\State{$\tilde x:=Ax$}
\State{$\lambda:=x^* \tilde x$}
\State{$x:=\tilde x / \norm{\tilde x}$}
\Until{STOP}
\State \Return $\lambda\in \C$, $x\in C^n$ approximiert betragsgrößten Eigenwert von $A$ und dazugehörigen Eigenvektor (unter den Voraussetzungen von Satz 
\ref{satz:Potenzmethode}).
\end{algorithmic}
\end{alg}


\begin{bemerkung}\label{bem:PM_andereEW}
Auch zur Bestimmung der anderer Eigenwerte kann die Potenzmethode verwendet werden, indem $A$ zuerst geignet transformiert wird.
Sei $A\in \C^{n\times n}$ diagonalisierbar.
\begin{enumerate}[(a)]
\item \emph{Inverse Iteration:} Sei $A$ invertierbar. Die betragsgrößten Eigenwerte von $A^{-1}$ sind dann  $1/\lambda_j$, wobei 
$\lambda_j$ die betragskleinsten Eigenwerte von $A$ sind. Existiert genau ein betragskleinster Eigenwert, so lässt sich dieser durch Anwendung der Potenzmethode auf $A^{-1}$ bestimmen. 
%
\item \emph{Gebrochene Iteration von Wielandt}: Ist $\mu\not\in \sigma(A)$, dann ist $A-\mu I$ invertierbar.
Die betragsgrößten Eigenwerte von $(A-\mu I)^{-1}$ sind $\frac{1}{\lambda_j-\mu}$ wobei $\lambda_j$ diejenigen Eigenwerte sind die
am nächsten an $\mu$ liegen. Gibt es davon genau einen, so lässt er sich durch Anwendung der Potenzmethode auf $(A-\mu I)^{-1}$ bestimmen.
\end{enumerate}
\end{bemerkung}

\section{Die Rayleigh-Quotient-Iteration}\label{sect:RQ}
Das in Bemerkung \ref{bem:PM_andereEW}(b) skizzierte Verfahren wird umso schneller konvergieren, umso besser $\mu$ den gesuchten Eigenwert 
approximiert. Es liegt daher nahe, in jedem Schritt $\mu$ durch die aktuelle Näherung an den Eigenwert zu ersetzen. 

\begin{alg}[Rayleigh-Quotient-Iteration]
\label{algo:RQ_Iteration}
\begin{algorithmic}
\State{Gegeben Matrix $A\in \C^{n\times n}$ und Startwerte $x\in \C^n$, $\mu\in \C$.}
\Repeat
\State{Löse $(A-\mu I) \tilde x=x$}
\State{$x:=\tilde x / \norm{\tilde x}$}
\State{$\mu:=x^* A x$}
\Until{STOP}
\State \Return $\mu\in \C$ approximiert Eigenwert, der am nächsten am Startwert liegt, $x$ approximiert dazugehörigen
Eigenvektor (vgl. Satz~\ref{thm:RQ} für die rigorose Formulierung der Konvergenzaussage).
\end{algorithmic}
\end{alg}

Für die Konvergenzuntersuchung dieses Verfahrens benötigen wir den Begriff des Betrags einer normalen Matrix.
\begin{definition}
Für eine Diagonalmatrix 
\[
\Lambda=\begin{pmatrix} \lambda_1 & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & \lambda_n\end{pmatrix}
\]
definieren wir $|\Lambda|$ durch
\[
\Lambda=\begin{pmatrix} |\lambda_1| & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & |\lambda_n| \end{pmatrix}.
\]

Sei $A \in \C^{n\times n}$ normal. Dann existiert eine Diagonalmatrix $\Lambda$ (mit den Eigenwerten auf der Diagonale)
und eine unitäre Matrix $X\in \C^{n\times n}$ so dass $A=X \Lambda X^{-1}$.
Damit definieren wir
\[
|A|=X |\Lambda| X^{-1}.
\]
Offenbar ist $|A|$ dadurch wohldefiniert.
\end{definition}

\begin{lemma}\label{lemma:betrag}
Für jedes normale $A\in \C^{n\times n}$ gilt
\begin{enumerate}[(a)]
\item $|A|$ ist hermitesch, positiv semidefinit und es gilt $|A|^2=A^* A$.
\item Für alle $x\in \C^n$ ist
\[
|x^* A x | \leq x^* |A| x.
\]
\end{enumerate}
\end{lemma}
\begin{beweis}
(a) wird in Übungsaufgabe ?? gezeigt.

Zum Beweise von (b) beachte, dass für jede Diagonalmatrix $\Lambda\in \C^{n\times n}$ und jedes
$y\in \C^n$ offenbar gilt
\[
|y^* \Lambda y|=\left| \sum_{j=1}^n \lambda_j |y_j|^2\right| \leq \sum_{j=1}^n |\lambda_j| |y_j|^2 = y^* |\Lambda| y.
\]
Damit folgt 
\[
|x^* A x | = | x^* X \Lambda X^{-1} x | = | (X^*x) \Lambda (X^* x)| \leq (X^* x) |\Lambda| (X^* x) =  x^* |A| x.
\]
\end{beweis}


\begin{theorem}\label{thm:RQ}
Sei $A\in \C^{n\times n}$ normal. $\mu_0\in \C$ und $x^{(0)}\in \C^n$ seien hinreichend gute Näherungen an einen Eigenwert $\lambda\in \C$ und
einen dazugehörigen Eigenvektor $v\in \C^n$ von $A$. $\mu_k$ und $x^{(k)}$ seien gemäß Algorithmus~\ref{algo:RQ_Iteration}
definiert, also
\begin{align*}
\tilde x^{(k)}&:=(A-\mu_{k-1} I)^{-1} x^{(k-1)}, \quad x^{(k)}:=\frac{\tilde x^{(k)}}{\norm{\tilde x^{(k)}}}, \quad 
\mu_k:=(x^{(k)})^* A x^{(k)}.
\end{align*}

Dann erreicht $\mu_k$ entweder nach endlich vielen Schritten einen Eigenwert oder es existiert eine
kubisch konvergente Folge $\epsilon_k\to 0$ mit
\[
|\lambda - \mu_{k+1} | \leq \epsilon_k \quad \forall k\in \N_0.
\]
\end{theorem}
\begin{beweis}
$\mu_k$ erreiche nicht nach endlich vielen Schritten einen Eigenwert, so dass die Rayleigh-Quotient-Iteration wohldefiniert ist.
O.B.d.A. sei außerdem $x^{(0)}$ normiert.

\begin{enumerate}[(a)]

\item Eigenraumzerlegung und Konvergenz

Jedes $x^{(k)}$ kann eindeutig in seine Eigenraumanteile zerlegt werden
\[
x^{(k)}= v^{(k)} + w^{(k)}, \quad w^{(k)}=\sum\limits_{\tilde \lambda\in \sigma(A)\setminus \{\lambda\} } w^{(k)}_{\tilde \lambda},
\]
wobei $v^{(k)}$ ein Eigenvektor zu $\lambda$ sei und $w^{(k)}_{\tilde \lambda}$ Eigenvektoren zu den anderen Eigenwerten $\tilde \lambda$ sind.
Da sie Eigenvektoren zu verschiedenen Eigenwerten sind, stehen all diese Vektoren paarweise orthogonal aufeinander.

Ähnlich wie im Beweis von Satz~\ref{satz:Potenzmethode} kann man zeigen, dass  
(wenn $\mu_0\in \C$ und $x^{(0)}\in \C^n$ hinreichend gute Näherungen an $\lambda$ und einen dazugehörigen Eigenvektor $v$ sind) $w^{(k)}\to 0$ konvergiert, also $x^{(k)}$ immer mehr zu einem Eigenvektor zum Eigenwert $\lambda$ wird.
Damit folgt auch $\mu_k=(x^{(k)})^* A x^{(k)}\to \lambda$ (siehe Übungsaufgabe ??).

\item Definition der $\epsilon_k$:

Nach Lemma \ref{lemma:betrag} gilt 
\begin{align*}
|\lambda - \mu_{k} | &= | \lambda - (x^{(k)})^* A x^{(k)} | = | (x^{(k)})^* (\lambda I - A ) (x^{(k)})^*|\\
&\leq  (x^{(k)})^* |\lambda I - A | (x^{(k)})^*=:\epsilon_k.
\end{align*}
Wir werden zeigen, dass ein $C>0$ existiert so dass (wenn $\mu_0\in \C$ und $x^{(0)}\in \C^n$ seien hinreichend gute Näherungen an $\lambda$ und $v$ sind)
\begin{align}\labeq{RQ_eps}
\epsilon_{k+1}\leq C \epsilon_{k}^3
\end{align}
Liegt $x^{(0)}$ hinreichend nahe an $v$, dann ist $\epsilon_0$ hinreichend klein, so dass aus \req{RQ_eps} auch $\epsilon_k\to 0$ folgt.

\item Wir zeigen nun, dass
\begin{align}\labeq{RQ_hilf}
%\lambda-\mu_{k+1}\leq 
\epsilon_{k+1} \leq  \frac{\epsilon_k^3}{\norm{v^{(k)}}^2} \max\limits_{ \tilde \lambda\in \sigma(A)\setminus \{\lambda\} } |\tilde\lambda-\mu_k|^{-2}
\end{align}
Da $\norm{v^{(k)}}=\norm{x^{(k)}-w^{(k)}} \to 1$ und $\mu_k\to \lambda$ folgt daraus \req{RQ_eps} und damit die Behauptung.

Zum Beweis von \req{RQ_hilf} verwenden wir die Iterationsvorschriften und erhalten %(beachte $\mu_k\in \R$)
\begin{align*}
\epsilon_{k+1}&=(x^{(k+1)})^* |\lambda I -  A| x^{(k+1)} 
= \frac{ (\tilde x^{(k+1)})^* |\lambda I -  A| \tilde x^{(k+1)}}{  \norm{\tilde x^{(k+1)}}^2 }\\
&= \frac{ (x^{(k)})^* (A-\mu_{k} I)^{-*}  | \lambda I -  A | (A-\mu_{k} I)^{-1} x^{(k)}}
{  \norm{ (A-\mu_{k} I)^{-1} x^{(k)} }^2}
\end{align*}
Wir schätzen Zähler und Nenner ab. 

\textbf{Nenner:} Wir beginnen mit dem Nenner und benutzen unsere orthogonale Zerlegung $x^{(k)}=v^{(k)} + w^{(k)}$.
Offensichtlich ist 
\[
(A-\mu_{k} I)^{-*} (A-\mu_{k} I)^{-1} v^{(k)}=\frac{1}{|\lambda-\mu_k|^2} v^{(k)}.
\]
Aus $v^{(k)}\perp w^{(k)}$ folgt deshalb
\begin{align*}
\lefteqn{\norm{ (A-\mu_{k} I)^{-1} x^{(k)} }^2}\\
&=  {(x^{(k)})^* (A-\mu_{k} I)^{-*} (A-\mu_{k} I)^{-1} x^{(k)}}\\
& = {(v^{(k)})^* | \lambda-\mu_{k} |^{-2} v^{(k)}} + {(w^{(k)})^* (A-\mu_{k} I)^{-*} (A-\mu_{k} I)^{-1} w^{(k)}}\\
& \geq {(v^{(k)})^* |\lambda-\mu_{k}|^{-2} v^{(k)}} \geq \epsilon_k^{-2} \norm{v^{(k)}}^2.
\end{align*}

\textbf{Zähler:} Nun schätzen wir den Zähler ab. Mit der Zerlegung von $w^{(k)}$ in seine Eigenraumanteile $w^{(k)}_{\tilde \lambda}$
erhalten wir aufgrund der paarweisen Orthogonalität der Eigenraumanteile
\begin{align*}
\lefteqn{(x^{(k)})^* (A-\mu_{k} I)^{-*}  | \lambda I -  A | (A-\mu_{k} I)^{-1} x^{(k)}}\\
&=(x^{(k)})^*  \sum_{\tilde \lambda\in \sigma(A)\setminus \{\lambda\} } \frac{|\lambda-\tilde \lambda|}{|\tilde\lambda-\mu_k|^2} w^{(k)}_{\tilde \lambda}
= \sum_{\tilde \lambda\in \sigma(A)\setminus \{\lambda\} } \frac{|\lambda-\tilde \lambda|}{ | \tilde\lambda-\mu_k |^2} \norm{w^{(k)}_{\tilde \lambda}}^2\\
%
&\leq \max\limits_{ \tilde \lambda\in \sigma(A)\setminus \{\lambda\} } |\tilde\lambda-\mu_k|^{-2}
 \sum_{\tilde \lambda\in \sigma(A)\setminus \{\lambda\} } |\lambda-\tilde \lambda|  \norm{w^{(k)}_{\tilde \lambda}}^2\\
%
&= \max\limits_{ \tilde \lambda\in \sigma(A)\setminus \{\lambda\} } |\tilde\lambda-\mu_k|^{-2}\ 
{(x^{(k)})^* | \lambda I -  A | x^{(k)}}
= \epsilon_k \max\limits_{ \tilde \lambda\in \sigma(A)\setminus \{\lambda\} } |\tilde\lambda-\mu_k|^{-2}.
\end{align*}
Insgesamt folgt \req{RQ_hilf}.
\end{enumerate}
\end{beweis}


\section{Das QR-Verfahren}

Das prominenteste Verfahren, um alle Eigenwerte und -vektoren einer Matrix zu bestimmen ist das \emph{QR-Verfahren}.
Wir können im Rahmen dieser Vorlesung nur die grundlegende Idee vorstellen.


\subsection{Motivation: simultane Potenzmethode}

Betrachten wir zur Motivation noch einmal die Potenzmethode. Um \emph{alle} Eigenwerte und
-vektoren einer Matrix zu bestimmen, können wir das Potenzverfahren auf $n$ Startvektoren $x_1,\ldots,x_n\in \C^n$ gleichzeitig anwenden.
In Matrixnotation beginnen wir also mit 
\[
\begin{pmatrix} x_1 & \ldots & x_n\end{pmatrix}\in \C^{n\times n}
\]
und berechnen im Wesentlichen (d.h. bis auf Normierung)
\[
A^k \begin{pmatrix} x_1 & \ldots & x_n\end{pmatrix}= \begin{pmatrix} A^k x_1 & \ldots & A^k x_n\end{pmatrix}.
\]
Im Allgemeinen wird jedoch an alle Startvektoren der Eigenvektor zum betragsgrößten Eigenwert $\lambda_1$ beteiligt sein und alle Spalten $A^k x_i$ werden gegen
einen Eigenvektor zu $\lambda_1$ konvergieren.

Um das zu verhindern, orthonormalisieren wir die Vektoren in jedem Schritt. Wir nehmen also im ersten Schritt nicht  
\[
\begin{pmatrix} A x_1 & \ldots & A x_n\end{pmatrix}
\]
sondern Vektoren
\[
\begin{pmatrix} x^{(1)}_1 & \ldots & x^{(1)}_n \end{pmatrix}
\]
mit den folgenden Eigenschaften:
\begin{itemize}
\item Für jedes $k=1,\ldots,n$ die ersten $k$ Vektoren jeweils den gleichen Raum aufspannen, also
\[
\mathrm{span} (x^{(1)}_1,\ldots,x^{(1)}_k ) = \mathrm{span} (A x_1,\ldots, A x_k)
\]
\item $x^{(1)}_1$,\ldots, $x^{(1)}_n$ orthonormiert sind, also
\[
(x^{(1)}_j)^*x^{(1)}_k=\delta_jk
\]
\end{itemize}
Im nächsten Schritt bilden wir 
\[
\begin{pmatrix} A x^{(1)}_1 & \ldots & A x^{(1)}_n \end{pmatrix}
\]
und orthonormalisieren diese zu Vektoren
\[
\begin{pmatrix} x^{(2)}_1 & \ldots & x^{(2)}_n \end{pmatrix}
\]
u.s.w.

Für den ersten Vektor entspricht dieses Verfahren gerade der Potenzmethode. Wir können also erwarten, dass er gegen einen Eigenvektor $v_1$
zum betragsgrößten Eigenwert $\lambda_1$ konvergiert. Beim zweiten Vektor wird bei diesem Verfahren die Potenzmethode angewandt und zusätzlich
durch die Orthogonalisierung der Anteil in Richtung des erste Vektors eliminiert. Wir können also erwarten, dass der zweite Vektor gegen einen Eigenvektor zum größten
Eigenwert der Matrix $A$ eingeschränkt auf den Unterraum
\[
\mathrm{span}(v_1)^\perp=\{ v\dd v_1^* v=0\}
\]
konvergiert. Dies wird (zumindest wenn die Eigenvektoren senkrecht aufeinander stehen) gerade der zweitbetragsgrößte Eigenwert sein. Enstprechend erwarten wir Konvergenz
aller $n$-Vektoren gegen Eigenvektoren zu allen $n$ Eigenwerten.
Die Eigenwerte erhalten wir dann als Diagonaleinträge von 
\[
\begin{pmatrix} x^{(k)}_1 & \ldots & x^{(k)}_n \end{pmatrix}^* A \begin{pmatrix} x^{(k)}_1 & \ldots & x^{(k)}_n \end{pmatrix}.
\]

Für die Orhogonalisierung bietet sich das aus der Linearen Algebra bekannte Gram-Schmidtsche Orthogonalisierungsverfahren an. Wir kennen jedoch bereits
eine Implementierung eines Orthogonalisierungsverfahren aus der Numerik I. Sei
\[
A=\tilde QR
\]
die QR Zerlegung von $A$. Da $\tilde Q$ unitär ist, sind die Spalten von $\tilde Q$ orthonormiert.  Da $R$ obere rechte Dreiecksgestalt hat. ergibt sich
die $k$-te Spalte von $A$ durch Kombination von $k$ Spalten von $\tilde Q$, d.h. die jeweils ersten $k$ Spalten von $A$ und $\tilde Q$ spannen den selben Raum auf.
$\tilde Q$ enthält also eine Orthonormalisierung der Spaltenvektoren von $A$.

Es erscheint natürlich, als Startvektoren die Einheitsvektoren zu wählen, also
\[
\begin{pmatrix} x^{(0)}_1 & \ldots & x^{(0)}_n \end{pmatrix}=\begin{pmatrix} 1 & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & 1\end{pmatrix}.
\]
Dann ist im ersten Schritt keine Orthonormalisierung nötig und es ergibt (durch Anwendung von $A$) 
im den ersten Schritt immer $A$, so dass wir auch gleich mit 
\[
\tilde A_0:=\begin{pmatrix} x^{(0)}_1 & \ldots & x^{(0)}_n \end{pmatrix}=A.
\]
starten können. Insgesamt erhalten wir also den folgenden Algorithmus


\begin{alg}[Simultane Potenzmethode]
\label{algo:simultan_Potenz}
\begin{algorithmic}
\State{Gegeben Matrix $A\in \C^{n\times n}$. Setze $\tilde A_0=A$.}
\For{$k=0,1,\ldots$}
\State{Berechne $QR$-Zerlegung $\tilde A_k=\tilde Q_k \tilde R_k$}
\State{$\tilde A_{k+1}:=A \tilde Q_k$}
\EndFor
\State \Return $\tilde Q_k$ approximiert spaltenweise Eigenvektoren von $A$. Die Diagonaleinträge von $\tilde Q_k^* A \tilde Q_k$ approximieren die Eigenwerte.
\end{algorithmic}
\end{alg}

\subsection{Das QR-Verfahren}

Durch Umformulierung der simultanen Potenzmethode in Algorithmus \ref{algo:simultan_Potenz} erhalten wir das QR-Verfahren in seiner einfachsten Form:

\begin{alg}[$QR$-Verfahren]
\label{algo:QR_Eigenwerte}
\begin{algorithmic}
\State{Gegeben Matrix $A\in \C^{n\times n}$. Setze $A_0=A$.}
\For{$k=0,1,\ldots$}
\State{Berechne $QR$-Zerlegung $A_k= Q_k R_k$}
\State{$A_{k+1}:=R_k Q_k$}
\EndFor
\State \Return Die Diagonaleinträge von $A_k$ approximieren die Eigenwerte.
\end{algorithmic}
\end{alg}

\begin{lemma}\label{lemma_QR_hilf}
Sei $A\in \C^{n\times n}$. % $\tilde A_k$, $\tilde Q_k$ und $\tilde R_k$ seien durch Algorithmus \ref{algo:simultan_Potenz} definiert.
$A_k$, $Q_k$ und $R_k$ seien durch Algo.~\ref{algo:QR_Eigenwerte} definiert. Dann gilt:
\begin{enumerate}[(a)]
\item Für alle $k\geq 0$ ist 
\[
A_{k+1}=Q_k^* A_k Q_k=(Q_0 \ldots Q_k)^* A (Q_0 \ldots Q_k).
\]
\item Für alle $k\geq 1 $ ist 
\[
A^k=(Q_0 \dots Q_{k-1})(R_{k-1} \dots R_0).
\]
\item Die Folgen $\tilde Q_k:=Q_0\dots Q_{k}$, $\tilde R_k:=R_k$ und $\tilde A_k:=\tilde Q_{k-1} A_k$ erfüllen
die Iterationsvorschrift aus Algorithmus \ref{algo:simultan_Potenz}
\[
\tilde A_k=\tilde Q_k \tilde R_k, \quad \tilde A_{k+1}=A \tilde Q_k \quad \forall k\geq 0.
\]
\end{enumerate}
\end{lemma}
\begin{beweis}
\begin{enumerate}[(a)]
\item ist trivial.
\item ist offenbar richtig für $k=1$. Gilt (b) für ein $k\geq 1$, dann ist
\[
A^{k+1}=A A^k = A (Q_0 \dots Q_{k-1})(R_{k-1} \dots R_0).
\]
Wegen (a) gilt $A (Q_0 \dots Q_{k-1})=(Q_0 \dots Q_{k-1}) A_k$ und zusammen mit $A_k=Q_k R_k$ folgt
\[
A^{k+1}=(Q_0 \dots Q_{k-1}) Q_k R_k (R_{k-1} \dots R_0).
\]
\item Aus der Definition von $\tilde A_k$ und $\tilde Q_k$ sowie aus $A_k=Q_kR_k$ folgt
\[
\tilde A_k=\tilde Q_{k-1} A_k= Q_0\dots Q_{k-1} Q_k R_k = \tilde Q_k \tilde R_k
\]
Außerdem folgt aus (a)
\[
\quad \tilde A_{k+1}=\tilde Q_k A_{k+1}=Q_0\dots Q_{k} (Q_0 \ldots Q_{k})^* A (Q_0 \ldots Q_{k})=A \tilde Q_k. \quad \Box
\]
\end{enumerate}
\end{beweis}

Im Rahmen dieser Vorlesung beweisen wir die Konvergenz des QR-Verfahrens nur für den (durch die Motivation durch das
simultane Potenzfahren naheliegenden) Spezialfall, dass $A$ diagonalisierbar ist
und paarweise betragsverschiedene, einfache Eigenwerte besitzt. Außerdem benötigen eine Zusatzvoraussetzung, die
sicherstellt, dass die Eigenvektoren von $A$ in geeigneter Weise Anteile in Richtung der Einheitsvektoren
besitzen.

\begin{theorem}\label{satz:QR}
$A\in \C^{n\times n}$ sei diagonalisierbar und besitze paarweise betragsverschiedene, einfache Eigenwerte, also
\[
A=X \Lambda X^{-1}, \quad \Lambda=\begin{pmatrix} \lambda_1 & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0 & \lambda_n\end{pmatrix}
\]
mit
$X\in \C^{n\times n}$ und dem Betrag nach sortierten 
\[
|\lambda_1|>\ldots>|\lambda_n| >0.
\]

Zusätzlich besitze $X^{-1}$ eine LR-Zerlegung $X^{-1}=LU$.
\footnote{
Jede invertierbare Matrix besitzt nach Zeilen- oder Spaltenvertauschungen eine LR-Zerlegung. 
Der nicht-trivale Kern unserer Zusatzvoraussetzung besteht darin, dass eine LR-Zerlegung existiert für die Matrix $X^{-1}$, in der die Eigenvektoren entsprechend der Größe der Eigenwerte sortiert sind. Zeilen-/Spaltenvertauschungen würden diese Sortierung zerstören!}
\end{theorem}

Dann konvergieren die Diagonaleinträge der durch Algorithmus~\ref{algo:QR_Eigenwerte} erzeugten 
Matrixfolge $A_k$ mit (mindestens) linearer Geschwindigkeit gegen die Eigenwerte von $A$.
\begin{beweis}

\begin{enumerate}[(a)]
%
\item Aufgrund der Existenz der LR-Zerlegung ist
\[
A^k=(X\Lambda X^{-1})^k = X \Lambda^k X^{-1}=X\Lambda^k LU = \underbrace{ X  \Lambda^k L \Lambda^{-k}}_{=:X_k} \Lambda^k  U.
\]
Die Einträge von $\Lambda^k L \Lambda^{-k}$ sind 
\[
\left( \Lambda^k L \Lambda^{-k}\right)_{ij}=\lambda_i^k l_{ij} \lambda_j^{-k}
=\left\{ \begin{array}{l l} 0 & \quad \mbox{ für $i<j$,}\\1 & \quad \mbox{ für $i=j$,}\\
l_{ij} \lambda_i^k / \lambda_j^k & \quad \mbox{ für $i>j$,}\end{array}\right.
\]

Aufgrund der Sortierung der Eigenwerte ist $|\lambda_i/\lambda_j|<1$ für alle $i>j$ und es folgt
dass 
\[
\Lambda^k L \Lambda^{-k}=I + O(q^k)
\]
wobei $I$ die $n\times n$-Einheitsmatrix ist und $q:=\max\{ |\lambda_i/\lambda_j| \dd i>j\}<1$. 

Damit folgt auch 
\begin{equation}\labeq{QRKonv_hilf1}
X_k=X\Lambda^k L \Lambda^{-k}=X+E_k \quad \mbox{ mit } E_k=O(q^k).
\end{equation}


\item Übungsaufgabe: Die Inverse einer rechten oberen Dreiecksmatrix und das Produkt rechter oberer Dreiecksmatrizen ist wieder eine rechte obere Dreiecksmatrix. Die Diagonaleinträge des Produkts sind das Produkt der Diag.einträge und die Diag.einträge der Inversen sind die Inversen der Diagonaleinträge. 

Sind $Q_1 R_1=Q_2 R_2$ zwei QR-Zerlegungen einer Matrix, dann existiert eine unitäre Diagonalmatrix $S$ mit
$Q_1=Q_2S^*$, $R_1=SR_2$.
%
\item Nach Lemma \ref{lemma_QR_hilf} ist
\[
A^k= (Q_0 \dots Q_{k-1})(R_{k-1} \dots R_0)=:\mathcal Q_{k-1} \mathcal R_{k-1}
\]
eine QR-Zerlegung von $A^k$.

Sei $X_k=P_k U_k$ eine QR-Zerlegung von $X_k$. Dann ist
\[
A^k=X_k \Lambda^k U= P_k (U_k \Lambda^k U)
\]
eine weitere QR-Zerlegung von $A^k$.

Es exisitert also eine unitäre Diagonalmatrix $S_k$ mit
\[
\mathcal Q_{k-1}=P_k S_k^* \quad \mbox{ und } \quad \mathcal R_{k-1}=S_k U_k \Lambda^k U.
\]

Nun gilt
\begin{align*}
Q_k&=(Q_0 \dots Q_{k-1})^{-1} (Q_0 \dots Q_{k})=\mathcal Q_{k-1}^{-1} \mathcal Q_{k}
= (P_k S_k^*)^{-1} P_{k+1} S_{k+1}^*\\
&= S_k P_k^{-1} P_{k+1} S_{k+1}^*.\\[+1ex]
%
R_k&= (R_k R_{k-1} \dots R_0) (R_{k-1} \dots R_0)^{-1}=\mathcal R_k \mathcal R_{k-1}^{-1}\\
&= S_{k+1} U_{k+1} \Lambda^{k+1} U  \left( S_k U_k \Lambda^k U\right)^{-1}
= S_{k+1} U_{k+1} \Lambda U_k^{-1} S_k^*.
\intertext{und damit}
A_k &= Q_k R_k = S_k P_k^{-1} P_{k+1} U_{k+1} \Lambda U_k^{-1} S_k^*\\
&= S_k \, U_k U_k^{-1}\, P_k^{-1} P_{k+1} U_{k+1} \Lambda U_k^{-1} S_k^*.
\end{align*}
Wir verwenden noch $X_k=P_k U_k$ und $X_{k+1}=P_{k+1} U_{k+1}$ und erhalten 
\begin{equation}\labeq{QRKonv_hilf2}
A_k=S_k  U_k X_k^{-1} X_{k+1} \Lambda U_k^{-1} S_k^*.
\end{equation}
%
\item Nach \req{QRKonv_hilf1} gilt
\[
X_k=X+E_k \quad \mbox{ mit } E_k=O(q^k).
\]
Damit folgt, dass 
\[
X_k^{-1}=(X+E_k)^{-1}=X^{-1} + O(q^k)
\]
und damit
\[
X_k^{-1} X_{k+1}=(X+E_k)^{-1} (X+E_{k+1})=I + F_k \quad \mbox{ mit } F_k=O(q^k).
\]

Einsetzen in \req{QRKonv_hilf2} liefert
\[
A_k=S_k  U_k \Lambda U_k^{-1} S_k^* + S_k  U_k F_k \Lambda U_k^{-1} S_k^*.
\]
Betrachte zuerst den ersten Summanden: 
$S_k  U_k \Lambda U_k^{-1} S_k^*$ ist eine rechte obere Dreiecksmatrix, deren Diagonaleinträge 
jeweils das Produkt der entsprechenden Diagonaleinträge der Faktoren sind. Die Diagonaleinträge von $S_k$
und $S_k^*=S_k^{-1}$ sowie die von $U_k$ und $U_k^{-1}$ sind jeweils zueinander invers. Die Diagonaleinträge 
der ersten Summanden sind also gerade die von $\Lambda$, also die Eigenwerte von $A$.

Wir müssen also nur noch zeigen, dass der zweite Summand gegen Null konvergiert. Es ist
\begin{align*}
\norm{S_k  U_k F_k \Lambda U_k^{-1} S_k^*}\leq \norm{S_k} \norm{U_k} \norm{F_k} \norm{\Lambda} \norm{U_k^{-1}} \norm{S_k^*}.
\end{align*}
Da $U_k=P_k^* X_k$ und $P_k$ und $S_k$ unitär sind folgt
\begin{align*}
\norm{S_k  U_k F_k \Lambda U_k^{-1} S_k^*}\leq \norm{X_k} \norm{X_k^-1} \norm{\Lambda} \norm{F_k}.
\end{align*}
Da $X_k\to X$ und $X_k^{-1}\to X^{-1}$ ist $\norm{X_k}\norm{X_k^{-1}}$ beschränkt. Es folgt
\begin{align*}
\norm{S_k  U_k F_k \Lambda U_k^{-1} S_k^*}= O(q^k)
\end{align*}
und damit die Behauptung.
\end{enumerate}
\end{beweis}

\begin{bemerkung}
\begin{enumerate}[(a)]
\item Nach Lemma \ref{lemma_QR_hilf} und Satz \ref{satz:QR} konvergiert
\[
A_{k}=(Q_0 \ldots Q_{k-1})^* A (Q_0 \ldots Q_{k-1})
\]
für große $k$ gegen eine rechte obere Dreiecksmatrix. Die Eigenvektoren von $A$ ergeben
sich aus den Eigenvektoren der Dreiecksmatrix durch die unitäre Basistransformation $Q_0 \ldots Q_{k-1}$.
\item Ähnlich wie in Abschnitt \ref{sect:RQ} lässt sich die Konvergenzgeschwindigkeit erhöhen,
indem $A$ durch $A-\mu_k I$ mit geeigneten \emph{Shifts} $\mu_k$ ersetzt wird.
%
\item Algorithmus \ref{algo:QR_Eigenwerte} benötigt in jedem Schritt eine $QR$-Zerlegung. Für eine 
effiziente Implementierung bringt man $A$ zuerst in eine spezielle Form, für die sich $QR$-Zerlegungen schnell berechnen lassen
und die unter Algorithmus \ref{algo:QR_Eigenwerte} erhalten bleibt, siehe z.B. \cite{Hanke}.
\end{enumerate}
\end{bemerkung}








\begin{appendix} 

\chapter{Hilfsmittel aus der Analysis}

\section{Der mehrdimensionale Mittelwertsatz}
Alle im Folgenden vorkommenenden Funktionen werden als stetig differenzierbar vorausgesetzt.

Für eine Funktion $f:\ \R\to \R$ und $a,b\in \R$, $a<b$ gilt der eindimensionale
Mittelwertsatz 
\[
\exists \xi\in [a,b]:\ \frac{f(b)-f(a)}{b-a}=f'(\xi)
\]
Die in der Numerik am häufigsten verwendete Folgerung daraus ist
\[
|f(b)-f(a)|\leq |b-a| \sup_{\xi \in [a,b]} |f'(\xi)|.
\]
Die Änderung von $f$ zwischen $a$ und $b$ lässt sich also durch Kenntnis der Ableitung
an allen Mittelwerten zwischen $a$ und $b$ abschätzen.

Der eigentliche Mittelwertsatz lässt sich nicht ohne weiteres ins Mehrdimensionale übertragen, die Folgerung
jedoch schon. Das folgende Lemma wird deshalb oft als \emph{Mittelwertsatz im Mehrdimensionalen}
bezeichnet.

\begin{lemma}
Für $F:\ \R^n\to \R^m$ und $x,y\in \R^n$ gilt
\[
F(x)-F(y)=\int_0^1 F'(x+t(y-x))(y-x)\dx[t]=\int_0^1 F'(x+t(y-x))\dx[t](y-x),
\]
also insbesondere
\[
\norm{F(x)-F(y)}\leq \norm{y-x} \sup_{t\in [0,1]} \norm{F'(x+t(y-x))}.
\]
\end{lemma}
\begin{beweis}
\begin{enumerate}[(a)]
\item
Wir erinnern zunächst an die Kettenregel im Mehrdimensionalen. Sind 
\[
g:\ R^s\to R^n, \quad h:\ R^n\to \R^m
\]
zwei Funktionen und ist
\[
f:\ \R^s\to \R^m,\quad f(x):=h(g(x))
\]
ihre Komposition, so gilt für die zugehörigen Jacobi Matrizen
\begin{align*}
f'(x)&=
\begin{pmatrix}
\frac{\partial f_1(x)}{\partial x_1} & \dots & \frac{\partial f_1(x)}{\partial x_s}\\
\vdots & & \vdots\\
\frac{\partial f_m(x)}{\partial x_1} & \dots & \frac{\partial f_m(x)}{\partial x_s}\\
\end{pmatrix}\in \R^{m\times s},\\
g'(x)&=
\begin{pmatrix}
\frac{\partial g_1(x)}{\partial x_1} & \dots & \frac{\partial g_1(x)}{\partial x_s}\\
\vdots & & \vdots\\
\frac{\partial g_n(x)}{\partial x_1} & \dots & \frac{\partial g_n(x)}{\partial x_s}\\
\end{pmatrix}\in \R^{n\times s}\\
h'(y)&=
\begin{pmatrix}
\frac{\partial h_1(x)}{\partial y_1} & \dots & \frac{\partial h_1(x)}{\partial y_n}\\
\vdots & & \vdots\\
\frac{\partial h_n(x)}{\partial y_1} & \dots & \frac{\partial h_m(x)}{\partial y_n}\\
\end{pmatrix}\in \R^{m\times n}
\end{align*}
die Kettenregel
\[
f'(x)=h'(g(x)) g'(x).
\]

\item Außerdem benötigen wir den Hauptsatz der Differential- und Integralrechnung. Für
$f:\ \R\to \R$ und $x,y\in \R$ gilt
\[
f(y)-f(x)=\int_x^y f'(t)\dx[t].
\]
Für eine vektorwertige Funktion 
\[
f:\ \R\to \R^m,\quad f(x)=\begin{pmatrix}f_1(x)\\ \vdots \\ f_m(x)\end{pmatrix} 
\]
gilt diese Aussage ebenfalls, da sie komponentenweise gilt:
\[
f(y)-f(x)=\begin{pmatrix}f_1(y)-f_1(x)\\ \vdots \\ f_m(y)-f_m(x)\end{pmatrix} 
=\begin{pmatrix}\int_x^y f_1'(t)\dx[t]\\ \vdots \\ \int_x^y f_m'(t)\dx[t]\end{pmatrix} 
= \int_x^y f'(t)\dx[t].
\]
\end{enumerate}
Nun können wir den Mittelwertsatz im Mehrdimensionalen beweisen. 
Sei $F:\ \R^n\to \R^m$ und $x,y\in \R^n$. Wir definieren
\[
f:\ \R\to \R^m, \quad f(t):=F(x+t(y-x))
\]
Offenbar ist $f(t)=F(g(t))$, wobei
\begin{align*}
g: \R\to \R^n, & \quad g(t):=x+t(y-x)\\
\end{align*}
und es ist
\[
g'(t)=\begin{pmatrix} 
\frac{\partial g_1}{\partial t}\\ \vdots \\ \frac{\partial g_n}{\partial t}
\end{pmatrix}
= y-x.
\]

Aus der mehrdimensionalen Kettenregel (siehe (a)) folgt 
\[
f'(t)=F'(g(t))g'(t)=F'(x+t(y-x))(y-x)
\]
und mit dem Hauptsatz der Differential- und Integralrechnung (siehe (b)) erhalten wir
\[
F(y)-F(x)=f(1)-f(0)=\int_0^1 f'(t)\dx[t]=\int_0^1 F'(x+t(y-x))(y-x)\dx[t]
\]
und damit die Behauptung.
\end{beweis}




\end{appendix}





\begin{thebibliography}{100}

\bibitem[FulfordBroadbridge]{FulfordBroadbridge}
G. R. Fulford, P. Broadbridge: \emph{Industrial Mathematics: Case Studies in the Diffusion of Heat and Matter}, 
Australian Mathematical Society Lecture Series 16, Cambridge University Press, Cambridge, 2002.

\bibitem[Hanke]{Hanke} 
M. Hanke-Bourgeois: \emph{Grundlagen der Numerischen Mathematik und des Wissenschaftlichen Rechnens}, Teubner Verlag, Wiesbaden, 2009. 

\bibitem[HairerNorsettWanner]{HairerNorsettWanner}
E Hairer, SP N{\o}rsett, G Wanner: 
\emph{Solving ordinary differential equations I. Nonstiff problems},
Springer, 1987.

%\bibitem[Num I]{NumI} 
%B. Harrach: Vorlesung \emph{Numerische Mathematik I} (WS11/12).\\ 
%{\footnotesize \verb|http://www.mathematik.uni-wuerzburg.de/~harrach/lehre/Numerik_I.pdf|}


%\bibitem[Heuser]{Heuser} 
%H. Heuser: \emph{Lehrbuch der Analysis Teil 1}, Teubner Verlag, Wiesbaden, 2009. 


%\bibitem[Forster3]{Forster3} O. Forster: \emph{Analysis 3. Integralrechnung im $\R^n$ mit Anwendungen}. 3. Auflage, Vieweg, Braunschweig, 1996.



\end{thebibliography}

\end{document}
