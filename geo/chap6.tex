\chapter{Die innere Geometrie von Flächen}


\section{Grundlagen}

Wir stellen uns „Flachländer“ (2-dim. Lebewesen) vor, die in ihrer 2-dimensionalen Welt leben und Längen und Winkel messen können, d.h. sie kennen die (abstrakte) erste Fundamentalform.

Betrachte die Länge eines Abstandskreises in einem festen Punkt mit Radius $r$:
\[
	L = \begin{cases}
		2\pi \sin r & \text{in $S^2$} \\
		2\pi r & \text{in $E^2$} \\
		2\pi \sinh r & \text{in $H^2$}
	\end{cases}
\]
Welche geometrischen Größen hängen nur von der ersten Fundamentalform ab (und können von den Flachländern erkannt werden)?
Hauptkrümmungen und mittlere Krümmung sicher nicht:
Betrachte dazu Ebene und Zylinder, beide haben erste Fundamentalform $\Matrix{1 & 0 \\ 0 & 1}$.
Erstaunlicherweise sehen wir später, dass die Gauß-Krümmung jedoch aus der ersten Fundamentalform berechnet werden kann.

Welche Größen sind hinreichend, um ein Flächenstück eindeutig (bis auf Kongruenz) festzulegen?
Kongruent impliziert isometrisch, aber isometrisch impliziert \emph{nicht} kongruent.

Richtungsableitungen von skalaren Funktionen sind stets eindeutig und \emph{innerhalb} der Fläche berechenbar, aber Ableitungen von Vektorfeldern?

\[
	D_X f|_p = X(f)|_p
	= \lim_{t\to 0} \f 1t (f(c(t)) - f(p)),
\]
wenn $c(t)$ differenzierbar, $c(0) = p, \dot c(0) = X$.
Im $\R^n$ gilt für ein Vektorfeld $Y$.
\[
	D_X Y = D_X(\sum_{i} y_i E_i)
	= \sum_{i} (D_X y_i) E_i
\]

\coursetimestamp{24}{06}{2014}

Wir verwenden die folgenden Konventionen
\[
	(u^1, \dotsc, u^n) \in U,
	(x^1, \dotsc, x^{n+1}) \in \R^{n+1}
\]
Der Grund ist die Summenkonvention
\[
	h_{ij} = \sum_{k} h_i^k g_{kj}
\]

In $\R^{n+1}$ gibt es die Richtungsableitung
\[
	D_xY|_p = DY|_p(X)
	= \lim_{t\to 0} \f 1t (Y(p+tx) - Y(p))
	= \lim_{t\to 0} \f 1t (Y(c(t)) - Y(p))
\]
für $c(0) = p, \dot c(0) = X$.
Die Begründung für die letzte Gleichung ist
\[
	\ddx[t](Y \circ c)(t) \big|_{t=0}
	= \Df[Y]\big|_{c(0)} (\ddx[t]{c}|_{t=0})
	= \Df[Y]\big|_{p}(U)
	= D_X Y|_p
\]

\begin{df}[Richtungsableitung]
	Sei $U \subset \R^n$ offen, $f: U \to \R^{n+1}$ eine Immersion, $Y: U \to \R^m$ ein differenzierbares Vektorfeld längs $f$, $p = f(u)$ ein Punkt auf der Fläche und $X \in T_u f$ ein fester Tangentialvektor in $p$.

	Dann ist die Richtungsableitung $D_X Y|_p$ an $f$ des Vektorfelds $Y$ in Richtung $X$ im Punkt $p$ definiert durch
	\[
		D_X Y|_p := \lim_{t\to  0} \f 1t \Big( Y(\underbrace{u + t(\Df)^{-1}(X)}_{\gamma(t)}) - Y(u) \Big),
	\]
	wobei $X = \Df(\xi)$ und $c(t) = f(u + t\xi)$ Kurve in der Hyperfläche ist.

	Es gilt $c(0) = p, \dot c(0) = \Df(\xi) = X$ und speziell
	\[
		D_{\f {\partial f}{\partial u^i}} Y
		= \lim_{t\to 0} \f 1t \Big(Y(u^1, \dotsc, u^i + t, \dotsc, u^n) - Y(u^1, \dotsc, u^n))
		= \f {\partial Y}{\partial u^i}.
	\]
	und
	\[
		D_{\f{\partial f}{\partial u^i}} \f{\partial f}{\partial u} = \f{\partial^2 f}{\partial u^i \partial u^j}.
	\]
	\begin{note}
		Der Ausdruck $D_X Y|_p$ ist linear in der Richtung $X$ und im Vektorfeld $Y$.
	\end{note}
\end{df}

\begin{df}[kovariante Ableitung]
	Seien $X \in T_u f, Y$ ($Y$ tangential an $f$) wie oben.
	Dann heißt
	\[
		\nabla_X Y|_p := (D_X Y|_p)^{\text{Tangentialanteil}}
		= D_X Y|_p - \<D_X|_p Y, \nu_p \> \nu_p
	\]
	die \emphdef{kovariante Ableitung} von $Y$ in Richtung $X$.
	Dann ist $\nabla_X Y |_p \in T_u f$.
	\[
		(X_p, Y) \mapsto \nabla_X Y|_p \in T_u f
	\]
	$Y$ ist definiert längs einer Kurve $c$ mit $c(0) = p, \dot c(0) = X_p$.
\end{df}

Beachte $\<D_X Y, \nu\> = - \< Y, D_x \nu\> = Ⅱ(X,Y)$, da $\< Y, \nu\> = 0$.
Also
\begin{align*}
	\nabla_X Y|_p &= D_X Y|_p - Ⅱ(X,Y) \nu_p \\
	D_x Y|_p &= \underbrace{\nabla_X Y|_p}_{\in T_u f} + \underbrace{Ⅱ(X,Y) \nu_p}_{\in \Orthspace_u f}.
\end{align*}
Es gelten folgende Rechenregeln für $D$ und $\nabla$.
\begin{itemize}
	\item
		Linearität
	\item
		Additivität
	\item
		Produktregel
	\item
		Verträglichkeit mit dem Skalarprodukt
\end{itemize}

\begin{st}
	Die kovariante Ableitung hängt nur von der ersten Fundamentalform ab (ist also eine Größe der inneren Geometrie).
	\begin{proof}
		Es gilt $X = \sum_i X^i \pddx*[u^i]{f}$, $Y = \sum_j \pddx*[u^j]{f}$ und damit
		\begin{align*}
			\nabla_X Y &= \nabla_{\sum_i X^i \pddx*[u^i]{f}} (\sum_j Y^j \pddx*[u^j]{f}) \\
			&= \sum_i X^i \nabla_{\pddx[u^i]{f}} (\sum_j Y^j \pddx*[u^j]{f}) \\
			&= \sum_{i,j} X^i \Big( \pddx*[u^i]{Y^j} \pddx*[u^j]{f} + Y^j \nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f} \Big)
		\end{align*}
		$\nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f}$ ist der Tangentialanteil von $D_{\pddx*[u^i]{f}} \pddx*[u^j]{f} = \f{\partial^2 f}{\partial u^i \partial u^j}$ und eindeutig bestimmt durch alle
		\[
			\Gamma_{ij,k} := \< \f{\partial^2 f}{\partial u^i \partial u^j}, \pddx*[u^k]{f} \>.
		\]
		$\Gamma_{ij,k}$ ist symmetrisch in $i,j$, falls $f \in C^2$.
		Es gilt
		\[
			\pddx*[u^k] \< \pddx*[u^i]{f}, \pddx*[u^j]{f} \>
		= \< \f{\partial^2 f}{\partial u^k \partial u^i}, \pddx*[u^j]{f} \>
			+ \< \pddx*[u^i]{f}, \f{\partial^2 f}{\partial u^k \partial u^j} \>
			= \Gamma_{ki,j} + \Gamma_{kj,i},
		\]
		also
		\begin{align*}
			(g_{ij})_k &= \Gamma_{ik,j} + \Gamma_{jk,i} \\
			(g_{jk})_i &= \Gamma_{ji,k} + \Gamma_{ki,j} \\
			(g_{ki})_j &= \Gamma_{kj,i} + \Gamma_{ij,k}
		\end{align*}
		und damit
		\[
			2 \Gamma_{ij,k} = - (g_{ij})_k + (g_{jk})_i + (g_{ki})_j,
		\]
		hängt also nur von der ersten Fundamentalform ab.
	\end{proof}
\end{st}

\begin{df}
	Der Ausdruck
	\[
		\Gamma_{ij,k} = \f 12 \Big( - (g_{ij})_k + (g_{jk})_i + (g_{ki})_j \Big)
	\]
	heißt \emphdef{Christoffelsymbol erster Art}.
	Die $\Gamma_{ij}^k$ mit
	\[
		\nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f}
		= \sum_l \Gamma_{ij}^l \pddx*[u^l]{f}
	\]
	heißen \emphdef{Christoffelsymbole zweiter Art}.

	Dabei gilt $\Gamma_{ij,k} = \Gamma_{ji,k}, \Gamma_{ij}^k = \Gamma_{ji}^k$, $\Gamma_{ij,k} = \sum_l \Gamma_{ij}^l g_{lk}$ und $\Gamma_{ij}^k = \sum_l \Gamma_{ij,l} g^{lk}$.

	Die kovariante Ableitung $\nabla_X Y$ mit $X = \sum_i X^i \pddx*[u^i]{f}, Y = \sum_j Y^j \pddx*[u^j]{f}$ ist
	\[
		\nabla_X Y|_p = \sum_{ij} X^i \Big( \pddx*[u^i]{Y^k} + \sum_j Y^j \Gamma_{ij}^k \Big) \pddx*[u^k]{f}
	\]
	Im euklidischen Raum sind alle $\Gamma_{ij,k} = 0$.

	Wir schreiben
	\[
		(\nabla_i Y)^k
		= \pddx*[u^i]{Y^k} + \Gamma_{ij}^k Y^j
	\]
\end{df}

\coursetimestamp{26}{06}{2014}


Die 2-dimensionalen Flachländer leiten nun wie folgt ab
\begin{itemize}
	\item
		skalare Funktion: Differentialquotient
	\item
		Vektorfelder $Y \hat = (Y^1, Y^2)$ in Komponenten einer Basis, $(1, 0), (0, 1)$ entsprechen den Basisfeldern.
		\begin{align*}
			\nabla_i (Y^1, Y^2)
			&= ((Y^1)_i, (Y^2)_i)
				+ \Big( \sum_{j} \Gamma_{ij}^1 Y^j, \sum_{j} \Gamma_{ij}^2 Y^j \Big) \\
			&= ((Y^1)_i, (Y^2)_i)
				+ (\Gamma_{i1}^1 Y^1 + \Gamma_{i2}^1 Y^2, \Gamma_{i1}^2 Y^1 + \Gamma_{i2}^2 Y^2).
		\end{align*}
		Wann ist $(Y^1, Y^2)$ „konstant“ (auch „parallel“ genannt)? 
		Wenn $\nabla_i(Y^1, Y^2) = 0$ gilt, für jedes $i$.

		Im euklidischen bedeutet ein konstantes Vektorfeld auch konstante Koeffizienten der Vektoren, hier jedoch nicht.
\end{itemize}

\begin{df}[parallel]
	\begin{enumerate}[(i)]
		\item
			Ein tangentiales Vektorfeld $Y$ längs eines (Hyper-)Flächenstücks $f$ heißt \emphdef{parallel}, wenn $\nabla_X Y|_p = 0$ für jeden Punkt $p$ und jeden Tangentialvektor $X \in T_pf$.
		\item
			$Y$ heißt \emphdef{parallel längs einer Kurve} $c = f \circ \gamma$, wenn $\nabla_{\dot c} Y = 0$ gilt für jeden Punkt der Kurve.
	\end{enumerate}
	\begin{note}
		Die Definition in (i) ist überbestimmt, d.h. im Allgemeinen gibt es keine parallelen Vektorfelder.

		(ii) ist ein System gewöhnlicher Differentialgleichungen.
	\end{note}
\end{df}

\begin{st}
	Seien $f: U \to \R^{n+1}, \gamma: \R \supset I \to U$ stetig differenzierbar, $t_0 \in I$ fest und $Y_0 \in T_{v_0} f$ fest, $c = f \circ \gamma$.

	Dann gibt es genau ein längs $c$ paralleles Vektorfeld $Y$ mit $Y(t_0) = Y_0$ (Anfangsbedingung).
	\begin{proof}
		$\gamma(t) = (u^1(t), \dotsc, u^n(t)) \in U$, $c = f \circ \gamma$.
		Es gilt
		\[
			\dot c = \ddx[t]{c}
			= X(c(t))
			= \sum_i \dot u^i(t) \pddx*[u^i]{f}
		\]
		und folglich
		\begin{align*}
			\nabla_i Y
			&= \sum_{i,k} \dot u^i \Big( \pddx[u^i]{Y^k} + \sum_j Y^i + \Gamma_{ij}^k(c(t)) \Big) \pddx[u^k]{f} \\
			&= \sum_{k} \Big( \ddx[t]{Y^k} + \sum_{i,j} \dot u^i Y^j \Gamma_{ij}^k \Big) \underbrace{\pddx[u^k]{f}}_{\text{bekannt}}
		\end{align*}
		Also ist $\gamma$ parallel genau dann, wenn $\nabla_c Y = 0$, also genau dann, wenn
		\[
			\dot Y^k + \sum_{i,j} \dot u^i Y^j \Gamma_{ij}^k = 0
		\]
		für alle $k$.
		Dies ist ein System gewöhnlicher linearer Differentialgleichungen erster Ordnung für $Y^1(t), \dotsc, Y^n(t)$.
		Die Theorie der gewöhnlichen Differentialgleichungen liefert eine eindeutige Lösung längst eines Intervalls $I$.
	\end{proof}
\end{st}

\begin{kor}
	Sei $Y$ parallel längs $c$, dann ist $\<Y, Y\>$ konstant.

	Ist $X, Y$ parallele längs $c$, dann ist $\<X, Y\>$ konstant.
	\begin{proof}
		$\nabla_i \<Y, Y\> = 2 \<\nabla_i Y, Y\> = 0$.
	\end{proof}
	\begin{note}
		Parallelverschiebungen sind Isometrien.
	\end{note}
\end{kor}

\section{Geodätische}

\begin{df}[Geodätische, geodätische Linien]
	Eine reguläre Kurve $c = f \circ \gamma$ heißt \emphdef{Geodätische}, wenn stets $\nabla_{\dot c} \dot c$ und $\dot c$ linear abhängig sind, oder äquivalent $\nabla_{c'} c' = 0$ mit Bogenlängenparameter.
	\begin{note}
		Also $(c'')^{\text{Tang}} = (D_{c'} c')^{\text{Tang}} = 0$.
	\end{note}
	\begin{proof}
		Es gilt
		\[
			\nabla_{\f{\dot c}{\|\dot c\|}} \f{\dot c}{\|\dot c\|}
			= \f 1{\|\dot c\|} \nabla_{\dot c} (\f 1{\|\dot c\|} \dot c)
			= \f 1{\|\dot c\|} \big( (\f 1{\|\dot c\|})^{\cdot} \dot c + \f 1{\|\dot c\|} \nabla_{\dot c}\dot c \big)
		\]
		also wenn $\nabla_{c'} c' = 0$, dann sind $\dot c, \nabla_{\dot c} \dot c$ linear abhängig.

		\[
			\< \dot c, \dot c\> = \f 1{\|\dot c\|} \Big( (\f 1{\|\dot c\||}) \< \dot c, \dot c \> + \f 1{\|\dot c\|} \< \nabla_{\dot c} \dot c, \dot c \> \Big)
			= 0,
		\]
		da
		\[
			(\<\dot c, \dot c\>^{-\f 12})^{\cdot}
			= - \f 1, \< \dot c, \dot c \>^{-\f 32} \cdot 2 \< \nabla_{\dot c} \dot c, \dot c\>
		\]
	\end{proof}
\end{df}

\begin{st}
	$f: U \to \R^{n+1}$ gegeben, $p_0 = f(u_0)$ sei fest.
	$Y_0$ sei fester Tangentialvektor in $p_0$ mit $\|Y_0\| = 1$.

	Dann gilt es ein $\eps > 0$ und genau eine nach Bogenlänge parametrisierte Geodätische $c = f \circ \gamma$, $\gamma: (-\eps,\eps) \to U$ mit $\gamma(0) = u_0 , c(0) = p_0, \dot c(0) = Y_0$ (Anfangsbedingung).
	\begin{proof}
		Setze $Y^i(t) = \dot u^i(t)$ in der obigen Gleichung.
		\[
			\nabla_{\dot c} \dot c = 0
			\quad\iff\quad
			\forall k : \ddot u^k + \sum_{i,j} \dot u^i \dot u^j \Gamma_{ij}^k = 0
		\]
		Dies ist ein System nicht-linearer gewöhnlicher Differentialgleichungen zweiter Ordnung (beachte: $\Gamma_{ij}^k$ hängt von $c(t)$, also von $u^i$ ab).
		Lokal existieren eindeutige Lösungen zu gegebenen Anfangsbedingungen.
		Mit $\|Y_0\| = 1 \implies \|\dot c\| = 1$ liegt eine Bogenlängenparametrisierung vor.
	\end{proof}
\end{st}

Bei nicht-regulären Kurven $c(t)$ hängt $Y$ immer von $t$ ab, nicht von $c(t)$.
Dann definiert man analog
\[
	\nabla_{\dot c} Y := (\ddx[t]{Y})^{\text{Tangentialanteil}}
\]
und schreibt auch $\f {\nabla Y(t)}{\dx[t]}$.

Sei $c = f \circ \gamma$ regulär und nach Bogenlänge parametrisiert, $\|\dot c\| = 1$.
Betrachte eine Variante der Frenet-Gleichungen mit dem Darboux-3-Bein:
\begin{align*}
	E_1 &:= c' \\
	E_2 &\orth E_1, \|E_2\| = 1, \text{ pos. orientiert}, \\ % E_2 \in T_f.
	E_3 &:= \nu
\end{align*}
Es gilt $E_1' = c'' = \kappa_g E_2 + \kappa_\nu E_3$.
Es ergibt sich
\[
	\Matrix*{E_1 & E_2 & E_3}'
	= \Matrix*{0 & \kappa_g & \kappa_\nu \\ -\kappa_g & 0 & \tau_g \\ -\kappa_\nu & - \tau_g & 0}
	\Vector*{E_1 & E_2 & E_3}
\]
mit einer geodätischen Krümmung $\kappa_g$, einer Normalkrümmung $\kappa_\nu$ und einer geodätischen Torsion $\tau_g$.

Es gilt $c'' = D_{c'} c' = \nabla_{c'} c' + \kappa_\nu E_3 = \kappa_g E_2 + \kappa_\nu E_3$, also ist $c$ Geodätische genau dann, wenn
\[
	\nabla_{c'}c' = 0,
\]
oder äquivalent
\[
	\kappa_{g} = 0,
\]
oder äquivalent $c'', \nu$ linear abhängig, oder äquivalent, wenn die $(c', c'')$-Schmiegebene die Flächennormale enthält.

\coursetimestamp{01}{07}{2014}

% fixme : C(s,t) = c'(s,t)
\begin{st}[Kürzeste Linien sind Geodätische]
	$p, q$ seien zwei feste Punkte auf $f: U \to \R^{n+1}$, $c = f \circ \gamma$ sei eine $C^\infty$-Kurve, die $p$ und $q$ verbindet, $c(0) = p$, $c(L) = q$ für die Länge $L$ von $c$.
	Falls jede andere $C^\infty$-Kurve von $p$ nach $q$ mindestens die selbe Länge hat wie $c$, dann ist $c$ eine Geodätischem
	\begin{proof}
		Betrachte eine Variation $C(s,t) \in C^\infty$ mit Kurvenparameter $s$, $c_t(s) = C(s,t)$ und Scherparametere $t$, $c(s) = C(s, 0)$.
		Es gilt $C(0,t) = c(0) = p, C(L,t) = c(L) = q$ für alle $t \in (-\eps, \eps)$.
		Man hat
		\[
			L(c_t) = \int_0^L \< \ddx[s]{c_t}, \ddx[s]{c_t} \>^{\f 12} \di[s].
		\]
		Ableiten von $L(c_t)$ bei $t = 0$ ergibt (nach Voraussetzung hat $L(c_t)$ Minimum bei $t = 0$):
		\begin{align*}
			0
			&= \ddx[t]|_{t=0} L(c_t) \\
			&= \ddx[t]|_{t=0} \int_0^t \< \ddx[s]{C}, \ddx[s]{C} \>^{\f 12} \di[s] \\
			&= \int_0^L \ddx[t]|_{t=0} \< \ddx[s]{C}, \ddx[s]{C} \>^{\f 12} \di[s] \\
			&= \int_0^1 \f 12 \dfrac{2 \< \f{\partial^2 C}{\partial l \partial s}, \ddx[s]{C} \>}{\<\ddx[s]{C}, \ddx[s]{C}\>|_{t=0}} \\
			&= \int_0^1 \< \f{\partial^2 C}{\partial l \partial s}, \ddx[s]{C} \> \di[s] \\
			&= \int_0^L \< \nabla_{\dot c} \ddx[t]{C}, \ddx[s]{C} \> \di[s] \\
			&= \int_0^L \Big( \ddx[s] \< \ddx[t]{C}, \ddx[s]{C} \> - \< \ddx[t]{C}, \nabla_{\dot c}\dot c \> \Big) \di[s] \\
			&= \< \underbrace{\ddx[t]{C}}_{= 0}, \ddx[s]{C} \> \big|_{s=0}^{s=L} - \int_0^L \< \ddx[t]{C}|_{t=0}, \nabla_{\dot c}\dot c \> \di[s]
		\end{align*}
		Es ist also notwendigerweise
		\[
			\int_0^L \< \ddx[t]{C}|_{t=0}, \nabla_{\dot c}\dot c \> \di[s] = 0
		\]
		für alle $C(s,t)$.
		Da $\ddx[t]{C}|_{t=0}$ beliebig gewählt werden kann, muss $\nabla_{\dot c} \dot c = 0$ längs $c$ sein, also ist $c$ eine Geodätische.
	\end{proof}
	\begin{note}
		Geodätische sind lokal auch kürzeste Kurven, die zwei Punkte miteinander verbinden.
		Global jedoch im Allgemeinen nicht.
	\end{note}
\end{st}

\begin{ex}
	\begin{itemize}
		\item
			In $S^2$ sind Geodätische gerade die Großkreise („sphärische Geraden“).
			Dies ergibt sich sofort daraus, dass $\ddot c \orth T_u f$.
		\item
			In $E^2$ sind die Geodätischen gerade die Geraden.
		\item
			In $H^2$ sind Geodätische gerade die „hyperbolischen Geraden“.
	\end{itemize}
\end{ex}

Welche Dinge können nun mit der inneren Geometrie beschrieben werden?
Wir haben Punkte, „Geraden“, Längen, Winkel, Abstände, Kongruenz von (geodätischen) Dreiecken, Abstandskreise.

\begin{df}
	Eine Fläche heißt \emphdef{geodätisch vollständig}, wenn jede Geodätische über ganz $\R$ nach Bogenlänge parametrisiert werden kann.
	\begin{note}
		Anschaulich heißt dies, dass Geodätische unendlich lang in beide Richtungen sind.
	\end{note}
\end{df}

\begin{ex}
	\begin{itemize}
		\item
			$S^2, E^2, H^2$ sind geodätisch vollständig.
		\item
			Die Pseudosphäre ist nicht geodätisch vollständig.
	\end{itemize}
\end{ex}

\subsection{Geodätische Polarkoordinaten um einen festen Punkt \texorpdfstring{$p$}{p}}

Sei ein Einheits-Tangentialenvektor $X$ in $p$ gegeben, sowie eine Geodätische $c_X$ mit $c_X(0) = p, \dot c_X(0) = X$.
\[
	c_X(r) \leftrightarrow (r,X) \in (0, \infty) \times S^{n-1}(1)
\]
für kleine $r > 0$.

\begin{ex}
	\begin{itemize}
		\item
			In $E^2$ haben wir
			\[
				(r, \phi) \mapsto (r \cos \phi, r \sin \phi) \in \R^2
			\]
			mit $Ⅰ=\Matrix{1 & 0 \\ 0 & r^2}$.
		\item
			In $S^2$ haben wir
			\[
				(r, \phi) \mapsto (\sin r \cos \phi, \sin r \sin \phi, \cos r) \in S^2
			\]
			mit $Ⅰ=\Matrix{1 & 0 \\ 0 & \sin^2 r}$.
		\item
			In $H^2$ haben wir
			\[
				(r, \phi) \mapsto (\sinh r \cos \phi, \sinh \cos \phi, \cosh r)
			\]
			und es ergibt sich
			\begin{align*}
				f_r &= (\cosh r \cos \phi, \cosh r \sin \phi, \sinh r) \\
				f_\phi &= (-\sinh r \sin \phi, \sinh \cos \phi, 0)
			\end{align*}
			also $\<f_r, f_r\>_1 = \cos^2 r - \sinh^2 r = 1$, $\<f_\phi, f_\phi\> = \sinh^2 r$, d.h. $Ⅰ=\Matrix{1 & 0 \\ 0 & \sinh^2 r}$.
	\end{itemize}
\end{ex}

Schon Gauß hatte erkannt:
\begin{quote}
	Die Gauß-Krümmung ist eine Größe der inneren Geometrie.
\end{quote}

Wir nutzen dazu Ableitungsgleichungen und Integrabilitätsbedingungen.

Eine notwendige Bedingung dafür, dass ein Vektorfeld $X = (X^1, x^2) \in \R^2$ ein Gradientenfeld ist, ist
\[
	\ddx[x^2]{X^1} = \ddx[x^1]{X^2},
\]
dies ergibt sich aus dem Satz von Schwartz (Vertauschen der zweiten Ableitungen).
Im $\R^n$ ist analog
\[
	\forall i,j : \ddx[x^j]{X^i} = \ddx[x^i]{X^j}
\]
eine notwendige Bedingung, auch \emphdef{Integrabilitätsbedingung} genannt.

Diese Bedingungen sind \emph{nicht} hinreichend, betrachte dazu
\[
	(X^1, X^2) = \Vector{\f{-y}{x^2 + y^2} & \f{x}{x^2 + y^2}}
\]

Lokal sind Integrabilitätsbedingungen auch hinreichend.
Betrachte dazu in $\R^2$ eine sternförmige Menge bezüglich $p \in \R^2$.
Sei ein Vektorfeld $X$ gegeben und wähle $f(p)$, setze
\[
	f(q) d= \int_p^q X
	= \int_0^1 \< X, \dot c(t) \> \di[t]
\]
mit $c(t) = (1-t)p + tq$, $\dot c = q - p$.
Es folgt dann $\ddx[x^i]{f} = X^i$.

Ableitungsgleichungen:
\begin{align*}
	\f{\partial^2 f}{\partial u^i \partial u^j} &= \sum_{l} \Gamma_{ij}^l \ddx[u^l]{f} + h_{ij} \nu, \\
	\ddx[u^i]{\nu} &= - \sum_{j} h_i^j \ddx[u^j]{f}.
\end{align*}
Jetzt sei $f$ gesucht!
Integrabilitäsbedingungen für $f$:
\begin{align*}
	\ddx[u^k] (\f{\partial^2 f}{\partial u^i \partial u^j})
	&\stack ?=
	\ddx[u^j] (\f{\partial^2 f}{\partial u^i \partial u^k}) \\
	\f{\partial^2 \nu}{\partial u^i \partial u^j} &= \f{\partial^2 \nu}{\partial u^j \partial u^i}
\end{align*}
für alle $i, j, k$.

% fixme: Gauß-Gleichung, Codazzi-Mainardi Gleichung


\begin{st}
	Die Integrabilitätsbedingungen der Ableitungsgleichungen sind die beiden folgenden Gleichungen
	\begin{enumerate}[(i)]
		\item
			Die Gauß-Gleichung
			\[
				\ddx[u^k] \Gamma_{ij}^s - \ddx[u^j] \Gamma_{ik}^s + \sum_{r} (\Gamma_{ij}^r \Gamma_{ik}^s - \Gamma_{ik}^r \Gamma_{rj}^s)
				= \sum_{m} (h_{ij} h_{km} - h_{ik} h_{jm}) g^{ms}
			\]
			für alle $i,j,k,s$.
		\item
			Die Codazzi-Mainardi-Gleichung.
	\end{enumerate}
\end{st}

Interessant ist besonders die Gauß-Gleichung, die die linke Seite nur von $(g_{ij})$ und die rechte Seite nur von $(h_{ij})$ abhängt.

\begin{kor}[Theorema Egregium, Gauß]
	Die Gauß-Krümmung $K = \f{\det Ⅱ}{\det Ⅰ}$ eines Flächenstücks $f: U \to \R^3$ der Klasse $C^3$ hängt nur von der ersten Fundamentalform ab.

	Die Gauß-Krümmung ist also eine „Größe der inneren Geometrie“.
	\begin{proof}
		Betrachte die rechte Seite der Gauß-Gleichung mit $n = 2$, $i = j = 1$, $k = 2$ und multiplizieren $g_{s2}$ und summieren über $s$:
		\[
			\sum_{s=1}^2 \sum_{m=1}^2 (h_{11} h_{2m} - h_{12} h_{1m}) \underbrace{g^{ms} g_{s2}}_{= \delta^m_{2}}
			= h_{11} h_{22} - h_{12} h_{12}
			= \det Ⅱ.
		\]
		$\det Ⅱ$ hängt also nur von der ersten Fundamentalform ab.
	\end{proof}
\end{kor}

\begin{df}
	Die linke Seite der Gauß-Gleichung heißt auch \emphdef{Krümmungstensor}:
	\[
		R_{ikj}^s
		= \pddx[u^k] \Gamma_{ij}^s - \pddx[u^j] \Gamma_{ik}^s + \sum_r ( \Gamma_{ij}^r \Gamma_{jk}^s - \Gamma_{ik}^r \Gamma_{rj}^s).
	\]
	Es gilt $R_{ikj}^s g_{sm} = R_{mikj}$.
\end{df}

\begin{ex}
	\begin{itemize}
		\item
			$g_{ij}, h_{ij}$ sind $(0,2)$-Tensoren.
		\item
			$h_i^j$ ist ein $(1,1)$-Tensor.
		\item
			$R_{ikj}^s$ ist ein $(1,3)$-Tensor.
	\end{itemize}
	Die charakteristische Eigenschaft eines Tensors ist, dass $\sum_s R_{ikj}^s \pddx[u^s]^{f}$ ein Ausdruck ist, der im festen Punkte $p$ nur von $\pddx[u^i]{f}|_p, \pddx[u^k]{f}|_p, \pddx[u^j]{f}|_p$ abhängt („tensorielles Verhalten“).

	Analog $g_{ij}|_p = Ⅰ(\pddx[u^i]{f}|_p, \pddx[u^j]{f}|_p)$.

	Ohne Beweis gilt
	\[
		\sum_s R_{ikj}^s \pddx[u^s]{f}
		= R(\pddx[u^k]{f}, \pddx[u^j]{f}) \pddx[u^i]{f}
	\]
	mit $R(X,Y)Z := \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z$ für Vektorfelder $X, Y, Z$.
	Dabei ist $[X,Y]$ die sogenannte \emphdef{Lie-Klammer} nach Sorhus Lie:
	\[
		[X, Y] := D_X Y - D_Y X.
	\]
	Es gilt stets $\nabla_{\pddx[u^i]{f}} \pddx[u^j]{f} = \nabla_{\pddx[u^j]{f}} \pddx[u^i]{f} = \f{\partial^2 f}{\partial u^i \partial u^j}$, aber im Allgemeinen \emph{nicht} $\nabla_X Y = \nabla_Y X$ für Vektorfelder $X, Y$.
	Betrachte dazu das folgende Beispiel im $\R^2 = \Span{x^1, x^2}$:
	Sei $X := x^1 e_1, Y = e_1$.
	\begin{align*}
		D_X Y &= x^1 D_{e_2} e_1 = 0 \\
		D_Y X &= D_{e_1} (x^1 e_2) = \underbrace{D_{e_1} x^1}_{\pddx[x^1]{x^1} = 1} e_2 + \underbrace{x^1 D_{e_1} e_2}_{=0} \neq 0.
	\end{align*}

	Eine Übung ist für relle Funktionen $f, g, h$
	\[
		R(fX, gX)hY|_p
		= fgh|_p R(X,Y)Z
	\]
	unabhängig von $f, g, h$.
\end{ex}


\begin{df}
	Für zwei Vektorfelder $X, Y$ in $\R^n$ heißt
	\[
		[X, Y] := D_X Y - D_Y X
	\]
	die \emphdef{Lie-Klammer} von $X \neq 0$ und $Y$.
	Falls $X, Y$ tangential an einer Hyperfläche sind, dann alternativ
	\[
		[X, Y] = \nabla_X Y - \nabla_Y X,
	\]
	weil der Normalanteil gleich $(Ⅱ(X,Y) - Ⅱ(Y,X)) \nu = 0$ ist.
\end{df}

Es gibt eine explizite Formel für $K$ in Abhängigkeit von $g_{ij}$ (für 2-dimensionale Flächen).
Theoretisch wunderbar, praktisch sehr schwierig.

\begin{st}[Gauß-Krümmung in speziellen Parametern]
	In orthogonalen Parametern eines 2-dimensionalen Flächenstücks $f(u,v)$ mit $Ⅰ = \Matrix{E & 0 \\ 0 & G}$ berechnet sich die Gauß-Krümmung als
	\[
		K = - \f 1{2\sqrt{EG}} \Big( \big(\f{E_v}{\sqrt{EG}} \big)_v + \big(\f{G_u}{\sqrt{EG}} \big)_u \Big).
	\]
	Wenn $E = G = \lambda$ (isotherme Parameter, konforme Parametrisierung), dann ist
	\[
		K = - \f 1{2\lambda} \Big( \big(\f{\lambda_v}{\lambda} \big)_v + \big(\f{\lambda_u}{\lambda} \big)_u \Big).
		= - \f 1{2\lambda} \Laplace (\log \lambda)
	\]
	\begin{proof}
		Wir haben die Christoffelsymbole
		\begin{align*}
			\Gamma_{11,1} &= \f 12 E_u, &
			\Gamma_{11}^1 &= \Gamma_{11,1} g^{11} + \Gamma_{11,2} g^{21} = \f 12 \f{E_u}{E} \\
			\Gamma_{11,2} &= -\f 12 E_v, &
			\Gamma_{11}^2 &= - \f 12 \f{E_v}{G} \\
			\Gamma_{12,1} &= \f 12 E_v, &
			\Gamma_{12}^1 &= \f 12 \f{E_v}E \\
			\Gamma_{12,2} &= \f 12 G_u, &
			\Gamma_{12}^2 &= \f 12 \f{G_u}{G} \\
			\Gamma_{22,1} &= -\f 12 G_u, &
			\Gamma_{22}^1 &= - \f 12 \f{G_u}{E} \\
			\Gamma_{22,2} &= \f 12 G_i, &
			\Gamma_{22}^2 &= \f 12 \f{G_v}{G}
		\end{align*}
		Setze nun in die Gauß-Gleichung $i=j=1, k = 2$ ein und summiere über $s$:
		\begin{align*}
			\det(h_{ij})
			&= \sum_s \bigg( (\Gamma_{11}^s)_v - (\Gamma_{12}^s)_u + \sum_{r} \Big( \gamma_11^{r} \Gamma_{r2}^s - \Gamma_{12}^r \Gamma_{r1}^s \Big) \bigg) g_{s2} \\
			&= \Big((\Gamma_{11}^2)_v - (\Gamma_{12}^2)_u + \Gamma_{11}^1 \Gamma_{12}^2 + \Gamma_{11}^2 \Gamma_{22}^2 - \Gamma_{12}^1 \Gamma_{11}^2 - \Gamma_{12}^2 \Gamma_{21}^2 \Big) G \\
			&= \f 12 \Big( - \big( \f {E_v}G \big)_v - \big(\f{G_u}{G}\big)_u +  \f{E_k}{E} \f12 \f{G_u}{G} -  \f{E_v}{G} \f 12 \f{G_v}{G} +  \f{E_v}{E} \f 12 \f {E_v}{G} -  \f{G_u}{G} \f 12 \f{G_k}{G} \Big) G
		\end{align*}
		Es gilt
		\begin{align*}
			K
			&= \f{\det h_{ij}}{EG} \\
			&= \f{G}{2EG} \Big( - \f{G E_{vv} - E_v G_v}{G^2} - \f{G_{uu}G - G_u^2}{G^2} + \f 12 \f{E_u G_u}{EG} - \f 12 \f{E_v G_v}{G^2} + \f 12 \f{E_v^2}{EG} - \f 12 \f{G_u^2}{G^2} \Big) \\
			&= \f 1{2EG} \Big( - E_{vv} - G_{uu} + \f {E_v G_v}{G} + \f{G_u^2}{G} + \f 12 \f{E_k G_k}{E} - \f 12 \f{E_v G_v}{G} + \f 12 \f {E_v^2}{E} - \f 12 \f {G_u^2}{G} \Big) \\
			&= \f 1{2EG} \Big( - E_{vv} - G_{uu} + \f 12 \f {E_v G_v}{G} + \f 12 \f{G_u^2}{G} + \f 12 \f{E_k G_k}{E} + \f 12 \f {E_v^2}{E} \Big). \\
		\end{align*}
		Andererseits gilt
		\begin{align*}
			- \f 1{2\sqrt{EG}} & \Big( \big( \f{E_v}{\sqrt{EG}} \big)_v + \big( \f{G_u}{\sqrt{EG}} \big)_u \Big) \\
			&= - \f 1{2 \sqrt{EG}} \bigg( \f{\sqrt EG E_{vv} - E_v (\sqrt{EG})_v}{EG} + \f{\sqrt{EG} G_{uu} - G_u (\sqrt{EG})_u}{EG} \bigg) \\
			&= - \f 1{2 EG} \Big( E_{vv} + G_{uu} - E_v \f 1{\sqrt{EG}} \f{E_v G + E G_v}{2 \sqrt{EG}} - G_u \f 1{\sqrt{EG}} \f {E_u G + E G_u}{2 \sqrt{EG}} \Big) \\
			&= - \f 1{2 EG} \Big( E_{vv} + G_{uu} - E_v^2 \f 1{\sqrt{2E}} - E_v G_v \f 1{2G} - G_u E_u \f 1{2E} - G_u^2 \f 1{2G} \Big)
		\end{align*}
		Dies stimmt mit oberem überein.

		Den Fall $E = G = \lambda$ überprüft man durch Einsetzen.

		Es gilt
		\[
			(\Laplace \log \lambda)
			= (\log \lambda)_{uu} + (\log \lambda)_{vv}
			= (\f{\lambda_u}{\lambda})_u + (\f{\lambda_v}{\lambda})_v.
		\]
	\end{proof}
\end{st}

\section{Konstruktion orthogonaler Koordinaten}

\begin{df}[geodätische Parallelekoordinaten]
	Die Koordinaten eines Flächenstücks $f: U \to \R^3$ heißen \emphdef{geodätischen Parallelkoordinaten}, falls die $u$-Linien stets nach der Bogenlänge parametrisierte Geodätische sind, die jede der $v$-Linien orthogonal schneiden.
	Nach Konstruktion schneiden in diesem Fall zwei $v$-Linien aus den $u$-Linien stets gleich lange Abschnitte heraus.
	\begin{note}
		Geodätische Parallelkoordinaten liegen genau dann vor, wenn in den Parametern $u,v$ die erste Fundamentalform die Gestalt
		\[
			Ⅰ= \Matrix{1 & 0 \\ 0 & G}
		\]
		hat mit einer positiven Funktion $G = G(u,v)$.
	\end{note}
\end{df}

\begin{kor}
	In geodätischen Parallelkoordinaten $\Matrix{1 & 0 \\ 0 & G}$ gilt die folgende einfache Gleichung für die Gauß-Krümmung:
	\[
		K(u,v) = - \f{(\sqrt{G})_{uu}}{\sqrt G}.
	\]
	Alternativ dazu haben wir für $Ⅰ= \Matrix{1 & 0 \\ 0 & G^2}$ den Ausdruck $K = - \f {G_{uu}}{G}$.
	\begin{proof}
		Es gilt
		\[
			K = - \f 1{2\sqrt{G}} \big( \f{G_u}{\sqrt G} \big)_u
			= - \f{(\sqrt G)_{uu}}{\sqrt{G}}.
		\]
	\end{proof}
	\begin{nt}
		Bei Drehflächen war $(g_{ij}) = \Matrix{1 & 0 \\ 0 & r^2}$ und die Gaußkrümmung $K = - \f{r''}{r}$.
	\end{nt}
\end{kor}


\coursetimestamp{08}{07}{2014}


\begin{nt}
	Hat die Länge eines Abschnittes auf $u=0$ (von $v_1$ nach $v_2$) ein Minimum im Vergleich zu den Parallelkurven, so ist $(\sqrt{G})_{uu} \ge 0$, also ist $K \le 0$.
	Analog für ein Maximum und $K \ge 0$.
\end{nt}


\begin{nt}[Geodätische Polarkoordinaten]
	Lokal kann man auf einer Fläche geodätische Polarkoordinaten anlegen.
\end{nt}

Es gibt allerdings noch „bessere“ Koordinaten, sogenannten Fermi-Koordinaten, welche in der Geodäsie eine wichtige Verwendung haben.
\begin{itemize}
	\item
		Eine Kurve $u=0$ ist eine Geodätische, nach Bogenlänge parametrisiert.
	\item
		Alle $u$-Linien sind Geodätische, nach Bogenlänge parametrisiert und senkrecht auf den $v$-Linien.
\end{itemize}
Dann gilt
\[
	\Matrix{E & F \\ F & G}
	= \Matrix{1 & 0 \\ 0 & G}
\]
mit $G(0,v) = 1$ für alle $v$ und $\pddx[u]{G}|_{u=0} = 0$ und $\Gamma_{ij}^k|_{(0,v)} = 0$ für alle $v$.
Infinitesimal sieht dies also euklidisch aus.
Wir haben also
\[
	\Matrix{E & F \\ F & G}
	= \Matrix{1 & 0 \\ 0 & 1 + \LandauO(v^2)}
\]
für festes $u$.

\begin{ex}
	\begin{itemize}
		\item
			Betrachte $S^2$ und $u = 0$, den Äquator.
			Es ergibt sich
			\[
				\Matrix{E & F \\ F & G}
				= \Matrix{1 & 0 \\ 0 & \cos^2 u}.
			\]
			Es gilt $K = - \f{(\cos u)''}{\cos u}$.
		\item
			Allgemeiner auf Drehflächen ist für $(r(t), h(t))$ nach Bogenlänge $K = - \f {r''}{r}$.
			Es gilt
			\[
				\Matrix{E & F \\ F & G}
				= \Matrix{1 & 0 \\ 0 & r^2(t)}
			\]
			wobei $r'(t_0) = 0$ und $r(t) = r(t_0) + \f{(t-t_0)^2}2 r''(t_0) + \dotsc$.
			Die $\phi$-Linie ist eine Geodätische, wenn $r' = 0$.
		\item
			Die Wulstfläche ($a^2K > 1$), oder Spindelfläche ($a^2K < 1$).
			\[
				f(t,\phi) = \Vector*{a \cos t \cos \f{\phi}a & a \cos t \sin \f{\phi}a & \int_0^t \sqrt{1 - a^2 \sin^2 x} \di[x]}.
			\]
			Wir haben
			\begin{align*}
				f_t &= \Vector{-a \sin t \cos \f{\phi}a & - a \sin t \sin \f{\phi}a & \sqrt{1 - a^2 \sin^2 t}}, &
				f_\phi &= \Vector{-\cos t \sin \f{\phi}a & \cos t \cos \f{\phi}a & 0},
			\end{align*}
			also ist
			\begin{align*}
				E &= \<f_t, f_t\> = a^2 \sin^2 t + 1 - a^2 \sin^2 t = 1, \\
				G &= \<f_\phi, f_\phi\> = \cos^2 t.
			\end{align*}
			In $t = 0$ auf dem Äquator hat man dann $K = 1$.
	\end{itemize}
\end{ex}

\begin{nt}
	$f, \tilde f$ isometrisch impliziert, dass auch $K = \tilde K$.
	Die Umkehrung gilt im Allgemeinen nicht.
\end{nt}

\begin{st}[Flächen mit gleicher konstanter Gaußkrümmung sind isometrisch]
	$f: U \to \R^3, \tilde f: \tilde U \to \R^3$ seien Flächenstücke mit der gleichen konstanten Gauß-Krümmung.
	Dann sind lokal $f$ und $\tilde f$ isometrisch zueinander.
	\begin{proof}
		$K$ sei die konstante Gauß-Krümmung.
		Wir fixieren zwei feste Punkte in $U, \tilde U$ und führen in geeigneten Umgebungen jeweils geodätische Parallelkoordinaten zu einer Geodätischen $u = 0$ ein (d.h. Fermi-Koordinaten).
		Die Parameter bezeichnen wir für beide Flächen mit dem gleichen Symbol $(u, v)$.
		Die ersten Fundamentalformen $Ⅰ, \tilde Ⅰ$ haben dann die Gestalt $\Matrix{1 & 0 \\ 0 & G(u,v)}, \Matrix{1 & 0 \\ 0 & \tilde G(u,v)}$
		mit $G(0,v) = 1 = \tilde G(0,v)$ für jedes $v$.
		Durch die notwendig bestehenden Differentialgleichungen
		\begin{align*}
			\pddx[u^2] \sqrt G &= - K \sqrt G, \\
			\pddx[u^2] \sqrt{\tilde G} &= - K \sqrt{\tilde G}
		\end{align*}
		werden dann $G$ und $\tilde G$ eindeutig bestimmt wegen der ebenfalls notwendig geltenden Anfangsbedingungen
		\[
			\pddx[u] \sqrt{G(u,v)}|_{u=0}
			= 0 =
			\pddx[u] \sqrt{\tilde G(u,v)}|_{u=0}.
		\]
		Beachte, dass dies für jedes feste (aber beliebige) $v$ eine gewöhnliche Differentialgleichung zweiter Ordnung mit Parameter $u$ ist.
		Insgesamt folgt damit in diesen Paremetern $G = \tilde G$, also $Ⅰ = \tilde Ⅰ$ und damit die (lokale) Isometrie von $f$ und $\tilde f$.
	\end{proof}
	\begin{note}
		Ist die Gauß-Krümmung nicht konstant, dann gibt es nicht-isometrische Flächenpaare mit derselben Gauß-Krümmung in gewissen Parametern!
		Das kann sich bezüglich Fermi-Koordinaten oder anderen Parametrn durchaus ändern.
		Damit kann man dieselbe Differentialgleichung wie oben nicht mehr verwenden.
	\end{note}
\end{st}

\begin{nt}[Extrinsische Interpretation der Gauß-Krümmung]
	Die Gaußkrümmung ist gegeben als $K = \det L = \det(-\Df[\nu] (\Df)^{-1})$.
	Dabei ist $\nu$ die Gauß-Abbildung.
	$K$ ist die infinitesimale Flächenverzerrung (mit Vorzeichen) der Gauß-Abbildung, bzw. der Weingartenabbildung.
	\[
		\int_{f(B)} |K| \di[A]
		= \Vol_{S^2}(\nu(B))
	\]
	für  jeden kompakten Bereich $B \subset U \xrightarrow{f} \R^2$.
	\begin{proof}
		Es gilt
		\[
			\int_{f(B)} |K| \di[A]
			= \int_{f(B)} |\det L| \di[A]
			= \int_{B} |\det L| \sqrt{\det (g_{ij})} \di[u^1]\di[u^2]
		\]
		und
		\[
			\Vol_{S^2}(\nu(B))
			= \int_{B}\sqrt{\det (e_{ij})} \di[u^1] \di[u^2]
			= \int_{B}\sqrt{(\det L)^2 \det(g_{ij})} \di[u^1]\di[u^2].
		\]
		Es gilt nämlich für eine Eigenbasis $X, Y$ von $L$
		\begin{align*}
			\det(e_{ij}) &= \det \Matrix{\<LX, LX\> & \<LX, LY\> \\ \<LY, LX\> & \<LY, LY\>} \\
			&= \det \Matrix{\lambda^2 \<X,X\> & \lambda\mu \<X, Y\> \\ \lambda\mu \<Y, X\> & \mu^2 \<Y, Y\>} \\
			&= \lambda^2 \mu^2 \det \Matrix{\<X,X\> & \<X, Y\> \\ \<Y, X\> & \<Y, Y\>} \\
			&= (\det L)^2 \det (g_{ij}).
		\end{align*}
	\end{proof}
	\begin{note}
		Damit ist $\nu$ orientierungserhaltend für $K > 0$ und orientierungsumkehrend für $K < 0$ ??
	\end{note}
\end{nt}

Wir haben
\begin{align*}
	K &= 1 : \Matrix{1 & 0 \\ 0 & \cos^2 u}, \\
	K &= -1 : \Matrix{1 & 0 \\ 0 & \cosh^2 u}, \\
	K &= 0 : \Matrix{1 & 0 \\ 0 & 1}.
\end{align*}


\coursetimestamp{10}{07}{2014}

\begin{nt}[Eine andere Schreibweise der Integrabilitätsbedingungen]
	Die Ableitungsgleichungen sind
	\begin{align*}
		D_X  Y &= \nabla_X Y + \<LX, Y\> \nu \\
		D_X \nu &= - LX.
	\end{align*}
	Mit Hilfe der Krümmungstensors $R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]} Z$, $[X,Y] = \nabla_X Y - \nabla_Y X = D_X Y - D_Y X$.
\end{nt}

\begin{nt}
	Seien $X, Y, Z$ tangentiale Vektorfelder.

	Es gilt die Gauß-Gleichung
	\[
		R(X,Y) Z = \<LX, Z\> LX - \< LX, Z\> LY \\
	\]
	und die Codazzi-Marinard-Gleichung
	\[
		\nabla_X(LY) - \nabla_Y(LX) - L([X,Y]) = 0.
	\]
	\begin{proof}
		Zerlegen der Gleichung
		\[
			D_X D_Y Z - D_Y D_X Z - D_{[X,Y]} Z = 0
		\]
		in Tangential- und Normalanteil ergibt
		\begin{align*}
			0 &= D_X D_Y Z - D_Y D_X Z \\
			&= D_X(\nabla_Y Z + \<LY, Z\> \nu) - D_Y(\nabla_X Z + \<LX, Z\> \nu)
				- \nabla_{[X,Y]}Z - \<L[X,Y], Z\> \nu \\
			&= \nabla_X \nabla_Y Z + \<LX, \nabla_Y Z\> \nu + D_X\<LY, Z\> \nu + \< LY, Z\> D_X \nu
				- \nabla_Y \nabla_X Z \\
				 &\qquad - \<LY, \nabla_X Z\> \nu - D_Y\<LX, Z\> \nu - \< LX, Z\> D_Y \nu
				- \nabla_{[X,Y]} Z - \<L[X,Y], Z\> \nu \\
			&= R(X, Y) Z - \<LY, Z\>LX + \<LX, Z\>LY + \Big( \<\nabla_X(LY), Z\> - \< \nabla_Y(LX), Z\> \\
		 	&\qquad - \<L[X,Y], Z\> \Big) \nu
		\end{align*}
		und es folgen beide Gleichungen.

		Es verbleibt $D_X D_Y Z - D_Y D_X - D_{[X,Y]} Z = 0$ zu zeigen.
		Sei $e_1, \dotsc, e_{n+1}$ die Standardbasis, $[e_i, e_j] = 0$.
		Schreibe $X = \sum_i X^i e_i, Y = \sum_i Y^i e_i, Z = \sum_i Z^i e_i$.
		Es gilt
		\begin{align*}
			D_X D_Y Z
			&= \sum_i X^i D_{e_i} \Big(\sum_j Y^j D_{e_j} Z \Big) \\
			&= \sum_{i,j} X^i Y^j D_{e_i} D_{e_j} Z + \sum_{i,j} X^i \underbrace{D_{e_i} Y^j}_{= \pddx[e^i]{Y^j}} D_{e_j} Z
		\end{align*}
		Es folgt
		\begin{align*}
			D_X D_Y Z &- D_Y D_X Z \\
			&= \sum_{i,j} X^i Y^j (\underbrace{D_{e_i} D_{e_j} Z - D_{e_j} D_{e_i} Z}_{=0}) + \sum_{i,j} (\underbrace{ X^i \pddx[x^i]{Y^j} - Y^i \pddx[x^i]{x^j} }_{\text{Komponenten von $[X,Y]$}}) D_{e_j} Z \\
			&= D_{[X,Y]} Z.
		\end{align*}
	\end{proof}
	\begin{note}
		Die Codazzi-Marinard-Gleichung lässt sich mit der „Produktregel“ \\ 
		$\nabla_X(LY) = (\nabla_X L) Y + L \nabla_X Y$ auch anders schreiben (man definiert gerade $(\nabla_X L)(Y) := \nabla_X(LY) - L(\nabla_X Y)$).
		Es gilt
		\[
			\nabla_X(LY) - \nabla_Y(LX)
			= (\nabla_X L) Y - (\nabla_Y L) X + L(\underbrace{\nabla_X Y - \nabla_Y X}_{=[X,Y]})
		\]
		und damit ist die Codazzi-Marinard-Gleichung äquivalent zu
		\[
			(\nabla_X L)(Y) - (\nabla_Y L)(X) = 0.
		\]
	\end{note}
\end{nt}

\begin{kor}
	\begin{enumerate}[1.]
		\item
			$R(X, Y) Z|_p$ hängt nur ab von $X_p, Y_p, Z_p$, weil dies für die rechte Seite der Gauß-Gleichung gilt.
		\item
			Theorema Egregium:
			\[
				K = \< R(X,Y)Y, X \>,
			\]
			wenn $X, Y$ eine ON-Basis ist.
			\begin{proof}
				\[
					\<LY, Y\>\<LX, X\> - \<LX, Y\>\<LY, X\>
					= Ⅱ(Y, Y) Ⅱ(X,X) - Ⅱ(X,Y)^2
					= \det Ⅱ
				\]
				in Basis $X, Y$.
				Also
				\[
					\<Y, Y\>\<X, X\> - \<X, Y\>^2
					= 1 = \det Ⅰ
				\]
				in Basis $X, Y$.
			\end{proof}
	\end{enumerate}
\end{kor}

\begin{st}
	$f, \tilde f: U \to \R^{n+1}$ seien zwei Hyperflächenstücke mit der gleichen ersten Fundamentalform $(g_{ij}) = (\tilde g_{ij})$.
	In einem Punkt $p = f(u)$ sei der Rang der Weingartenabbildung $L$ mindesten gleich $3$.
	Dann gilt für die zweiten Fundamentalformen in diesem Punkt
	\[
		(h_{ij}(u)) = \pm(\tilde h_{ij}(u)).
	\]
\end{st}

\begin{kor}
	Falls $U$ zusammenhängend ist und falls für $f, \tilde f: U \to \R^{n+1}$ überall $(g_{ij}) = (\tilde g_{ij})$ gilt und falls überall $\rg(L) \ge 3$ ist, dann stimmen $f(U)$ und $\tilde f(U)$ bis auf euklidische Bewegungen überein (inklusive Spiegelungen).
\end{kor}

\begin{lem}[Bewegungsinvarianz und Eindeutigkeit]
	Sei $f: U \to \R^{n+1}$ ein gegebenes Flächenstück, $B: \R^{n+1} \to \R^{n+1}$ sei eine euklidische Bewegung, d.h. $B(x) = A(x) + b$ mit einer orthogonalen Abbildung $A \in \SO(n+1)$.
	Setze $\tilde f := B \circ f$.
	Dann gilt bei geeigneter Wahl der Einheitsnormalen für die beiden Fundamentalformen $g, \tilde g, h, \tilde h$ die Gleichung
	\[
		g_{ij} = \tilde g_{ij},
		h_{ij} = \tilde h_{ij}.
	\]
	Umgekehrt: Falls für zwei gleich orientierte Flächenstücke $f, \tilde f: U \to \R^{n+1}$ die Gleichung $g_{ij} = \tilde g_{ij}, h_{ij} = \tilde h_{ij}$ gilt, dann stimmen sie überein bis auf eine euklidische Bewegung, d.h. es gilt
	\[
		\tilde f := B \circ f
	\]
	für eine gewisse euklidische Bewegung $B$.
	\begin{proof}
		Wenn $A$ und $b$ konstant sind, gilt $\pddx[u^i]{\tilde f} = A(\pddx[u^i]{f})$ und für eine geeignete Wahl der Einheitsnormalen $\nu$ gilt $\tilde \nu = A\nu$.
		Weil $A$ orthogonal ist, folgt direkt die Behauptung des ersten Teils.

		Für den zweiten Teil definieren wir für jedes $u \in U$ eine Abbildung $A(u): \R^{n+1} \to \R^{n+1}$ durch $A(u)(\pddx[u^i]{f}|_u) = \pddx[u^i]{\tilde f}|_u$ und $A(u)(\nu(u)) = \tilde \nu(u)$.
		$A(u)$ ist dann für jedes $u$ eine orthogonale Abbildung $A(u) \in \SO(n+1)$.
		Wir wollen zeigen, dass $A(u)$ nicht von $u$ abhängt.
		Durch weiteres Ableiten erhalten wir einerseits
		\begin{align*}
			\f{\partial^2 \tilde f}{\partial u^i \partial u^j}
			= \pddx[u^i] (A \pddx[u^j]{f})
			= \pddx[u^i]{A} (\pddx[u^j]{f}) + A(\f{\partial^2 f}{\partial u^i \partial u^j}), \\
			\pddx[u^i]{\tilde \nu} = \pddx[u^i]{A\nu} = \pddx[u^i]{A}(\nu) + A (\pddx[u^i]{\nu})
		\end{align*}
		Andererseits gilt $\tilde g^{ij} = g^{ij}$ und $\tilde \Gamma_{ij}^k = \Gamma_{ij}^k$.
		Damit folgt aus den Ableitungsgleichungen
		\[
			\f{\partial^2 \tilde f}{\partial u^i \partial u^j}
			= A (\f{\partial^2 f}{\partial u^i \partial u^j})
			\pddx[u^i]{\tilde \nu} = A (\pddx[u^i]{\nu})
		\]
		Dies impliziert $\pddx[u^i]{A} = 0$ für alle $i$, also ist $A$ konstant.
		Ferner ist $f - A(f)$ ebenfalls konstant, also $\tilde f - B\circ f = 0$ für eine gewisse euklidische Bewegung $B$.
	\end{proof}
\end{lem}

\section{Der Hauptsatz der lokalen Flächentheorie}

\begin{align*}
	\f{\partial^2 f}{\partial u^i \partial u^j}
		&= \sum_{k} \Gamma_{ij}^k \pddx[u^k]{f} + h_{ij} \nu \\
	\pddx[u^i]{\nu}
		&= - \sum_k h_i^k \pddx[u^k]{f}
		= - \sum_{k,j} h_{ij} g^{jk} \pddx[u^k]{f}
\end{align*}

$(g_{ij})$ und $(h_{ij})$ bestimmen lokal genau ein (Hyper-)Flächenstück (bis auf eukldisichen Bewegungen).
Wie ermitteln wir dann das Flächenstück?
Idee: Ableitungsgleichungen integrieren.
Wir erhalten Integrabilitätsbedingungen für Gauß- und Codazzi-Gleichung.

Seien $(g_{ij}), (h_{ij})$ gegeben, dann ist $(g^{kl}), \Gamma_{ij}^k, h_i^j$ bestimmt (Koeffizienten der rechten Seite der Ableitungsgleichungen).

Wir ermitteln $f$ in folgenden Schritten:
\begin{enumerate}[1.]
	\item
		Suche ein begleitendes Bein $X_1, \dotsc, X_n, \nu$, welche dem DGL-System
		\begin{align*}
			\pddx[u^i]{X_j} &= \sum_k \Gamma_{ij}^k X_k + h_{ij} \nu \\
			\pddx[u^i]{\nu} &= -\sum_k h_i^k x_k
		\end{align*}
		genügt (unter Integrabilitätsbedingung, $\f{\partial^2 X_j}{\partial u^i\partial u^m} = \f{\partial^2 X_i}{\partial u^m \partial u^j}$ ?).
	\item
		Zeige $\|\nu\| = 1$ und $\<\nu, X_i\> = 0$, $\<X_i, X_j\> = g_{ij}$ mit einem DGL-System erster Ordnung.
	\item
		Löse die DGL $\pddx[u^i]{f} = X_i$ nach $f$ mit der Integrabilitätsbedingung.
	\item
		Zeige schließlich, dass $(g_{ij}), (h_{ij})$ die Fundamentalformen vom gefundenen $f$ ist.
\end{enumerate}

\coursetimestamp{15}{07}{2014}

Betrachte die Integrabilitäsbedingung
\[
	\pddx[u^i] \pddx[u^m]{X_j} = \pddx[u^i] \ddx[u^m]{X_j} = \f{\partial^2 X_j}{\partial u^i \partial u^m}
	= \f{\partial^2 X_i}{\partial u^m \partial u^j} = \pddx[u^m] \pddx[u^i]{X_j} = \pddx[u^m] \pddx[u_j]{X_i}
\]
Dies entspricht
\[
	\f{\partial^3 f}{\partial u^i \partial u^j \partial u^m} = \f{\partial^3 f}{\partial u^m \partial u^j \partial u^i}.
\]
Dies ist äquivalent zur Integrabilitätsbedingung der Gauß, Codazzi-Mainardi Gleichungen
\[
	\f{\partial^2 \nu}{\partial u^i \partial u^j} = \f{\partial^2 \nu}{\partial u^j \partial u^i}.
\]

\begin{st}[Hauptsatz der lokalen Flächentheorie]
	Auf einer offenen Menge $U \subset \R^n$ seien symmetrische $C^2$, bzw. $C^1$ Matrizenfunktionen $g_{ij} = g_{ij}(u^1, \dotsc, u^n), h_{ij} = h_{ij}(u^1, \dotsc, u^n)$ gegeben, so dass $(g_{ij})$ überall positiv definit ist und so dass $g_{ij}, h_{ij}$ die Gleichungen von Gauß und Codazzi-Mainardi erfüllen mit den durch $(g_{ij})$ induzierten Christoffelsymbolen.
	Dann gibt es zu vorgegebenen Anfangsbedingungen
	\[
		u^{(0)} \in U, p_0 \in \R^{n+1}, X_1^{(0)}, \dotsc, X_n^{(0)} \in \R^{n+1} \isomorphic T_{p_0} \R
	\]
	mit $\<X_i^{(0)}, X_j^{(0)}\> = g_{ij}(u^{(0)})$ und zu gegebener Einheitsnormalen $\nu^{(0)}$ in $p_0$ (d.h. ein Einheitsvektor, der senkrecht auf allen $X_i^{(0)}$ steht) eine offene zusammenhängende Teilmenge $V \subset U$ mit $u^{(0)} \in V$ und genau ein (Hyper-)Flächenstück $f: V \to \R^{n+1}$ der Klasse $C^3$ mit Gauß-Abbildung $\nu$ und mit den Eigenschaften
	\begin{enumerate}[1.]
		\item
			$f(u^{(0)}) = p_0$,
		\item
			$\pddx[u^i]{f}(u^{(0)}) = X_i^{(0)}$ für $i \in \Set{1,\dotsc, n}$,
		\item
			$\nu(u^{(0)}) = \nu^{(0)}$,
		\item
			$g_{ij}, h_{ij}$ sind die erste und zweite Fundamentalform von $f$ (bezüglich $\nu$).
	\end{enumerate}
	\begin{proof}
		Wir verfahren wie oben bereits skizziert.
		\begin{enumerate}[1.]
			\item
				Lösung existiert.
			\item
				Betrachte $\pddx[u^i]\<\nu, \nu\>$, $\pddx[u^i]\<\nu, X_j\>$ und $\pddx[u^k] \<X_i, X_j\>$ zusammen mit den Ableitungsgleichungen.
				$\|v\| =1, \<\nu, X_i\> = 0, \<X_i, X_j\> = g_{ij}$ sind Lösungen davon und Eindeutigkeit folgt.
			\item
				Die Integrabilitätsbedingung $\pddx[u^j]{X_i} = \pddx[u^j]{X_j}$ ist erfüllt, wegen der Symmetrie $h_{ij} = h_{ji}, \Gamma_{ij}^k = \Gamma_{ji}^k$.
				Lokal existiert dann eien eindeutige Lösung $f$ mit der Anfangsbedingung $f(u^{(0)}) = p_0$.
			\item
				$g_{ij} = \<X_i, X_j\> = \< \pddx[u^i]{f}, \pddx[u^j]{f} \>$ ist nach Konstruktion erfüllt.
				Es gilt wegen $0 = \<\nu, X_i\> = \<\nu, \pddx[u^i]{f}\>$
				\[
					\< \f{\partial^2 f}{\partial u^i \partial u^j}, \nu\>
					= \< \sum_{k} \Gamma_{ij}^k \pddx[u^k]{f} + h_{ij} \nu, \nu \>
					= h_{ij}.
				\]
		\end{enumerate}
	\end{proof}
	\begin{note}
		\begin{align*}
			D_x Y &= \nabla_X Y + Ⅱ(X,Y) \nu \\
			D_X \nu &= -L(x)
		\end{align*}
	\end{note}
\end{st}


\section{Der Satz von Gauß-Bonnet}


Der Hopfsche Umlaufsatz besagt für eine geschlossene Randkurve $\boundary L$ eines einfach zusammenhängenden Gebiets $A \subset E^2$, dass
\[
	\int_{\boundary A} \kappa(s) \di[s] = + 2\pi,
\]
Im Fall einer Ebene ist
\[
	\int_A K \di[A] = 0,
\]
wobei $K$ die Gaußkrümmung ist.

Gauß-Bonnet besagt
\[
	\int_A K \di[A] + \int_{\boundary A} \kappa_g(s) \di[s] = 2 \pi
\]

Eine Variante von Hopf besagt ein ähnliches Resultat für stückweise differenzierbare Kurven, bei denen Knickpunkten äußere Winkel gezählt werden.

\begin{ex}
	Aus dem Satz folgen die Formeln für die Innenwinkel von Dreiecken auf Ebene, Einheitssphäre und Pseudosphäre.
	Bei Einheitssphäre und Pseudosphäre kommt es zu Exzess, bzw. Defekt, welcher dem Flächeninhalt des Dreiecks entspricht.
	Bei der Pseudesphäre sind Flächeninhalte von Dreiecken damit insbesondere beschränkt durch $\pi$.
\end{ex}

\begin{thm}[Theorema Elegantissimum, Gauß]
	Es gilt
	\[
		\beta_1 + \beta_2 + \beta_3 - \pi = \int_{\triangle} K \di[A]
	\]
	in jedem geodätischen Dreieck $\triangle$.
\end{thm}

\coursetimestamp{17}{07}{2014}

\begin{thm}[Gauß-Bonnet-Formel, erste lokale Version]
	Sei $U \subset \R^2$ eine offene Teilmenge, $B \subset U$ diffeomorph zur abgeschloossenen Kreisscheibe.
	Ferner sei $f: U \to \R^3$ ein Flächenstück und injektiv.
	Der Rand von $B$ sei durch $\gamma: I \to U$ so parametrisiert, dass das Innere von $B$ zur Linken von $\gamma$ liegt und wir setzen $c = f \circ \gamma$.

	Dann gilt
	\[
		\int_{f(B)} K \di[A] + \int_c \kappa_g \di[s] = 2\pi,
	\]
	wobei $K$ die Gauß-Krümmung von $f$ und $\kappa_g$ die geodätische Krümmung von $c$ ist.
	\begin{proof}
		Seien $X_1, X_2$ ortohonormierte Vektorfelder in $B$.
		Der Hopfsche Umlaufsatz $\oint \kappa(s) \di[s] = 2\pi$ im einfach geschlossenen Fall bleibt gültig in der jetzigen Situation:
		\begin{align*}
			e_1 &= \cos \phi X_1 + \sin \phi X_2 \\
			e_2 &= -\sin \phi X_1 + \cos \phi X_2 \\
			X_1 &= \cos \phi e_1 - \sin \phi e_2 \\
			X_2 &= \sin \phi e_1 + \cos \phi e_2.
		\end{align*}
		für $\phi: [a,b] \to \R$.
		Es gilt also
		\[
			\int_a^b \ddx[s]{\phi} \di[s] = \phi(b) - \phi(a) = 2\pi.
		\]
		Die Randkurve sei nach Bogenlänge parametrisiert, $\nabla_{e_1} e_1 = \kappa_g e_2$ mit geodätischer Krümmung $\kappa_g = \<\nabla_{e_1} e_1, e_2\>$.

		Es gilt $\<e_1, X_1\> = \cos \phi$, d.h. $\ddx[s] \<e_1, X_1\> = -\sin \phi \ddx[s]{\phi}$.
		Nach dem Hopfschen Umlaufsatz ist dann
		\begin{align*}
			2\pi
			&= \int_a^b \ddx[s]{\phi} \di[s] \\
			&= - \int_a^b \f 1{\sin \phi} \underbrace{\ddx[s]}_{\nabla e_1} \<e_1, X_1\> \di[s] \\
			&= - \int_a^b \f 1{\sin \phi} (\<\nabla_{e_1} e_1, X_1\> + \< e_1, \nabla_{e_1} X_1\>) \di[s] \\
			&= - \int_a^b \f 1{\sin \phi} (\underbrace{\<\nabla_{e_1} e_1, \cos \phi e_1\>}_{=0} - \underbrace{\< \nabla_{e_1} e_1, \sin \phi e_2\>}_{=\sin \phi \kappa_g}) \di[s] \\
			& \qquad  - \int_a^b \f 1{\sin \phi} (\underbrace{\<\cos \phi X_1, \nabla_{e_1} X_1\>}_{=0} + \< \sin \phi X_2, \nabla_{e_1} X_1) \di[s] \\
			&= \int_a^b \kappa_g(s) \di[s] - \int_a^b \underbrace{\<X_2, \nabla_{e_1} X_1\>}_{= -\<X_1, \nabla_{e_1} X_2} \di[s] \\
			&= \int_a^b \kappa_g(s) \di[s] + \int_a^b \omega_2^1(e_1) \di[s].
		\end{align*}
		Wir führen die Dualbasis $\omega^i(X_j) := \delta_j^i$ ein mit 1-Formen $\omega^1, \omega^2$.
		Definieren
		\[
			\<X_1, \nabla_{e_1} X_2\>
			= \omega^1(\nabla_{e_1} X_2)
			=: \omega_2^1(e_1),
		\]
		sogenannte Zusammenhangsformen durch
		$\omega_j^i(Y) := \omega^i(\nabla_Y X_j)$.
		Diese beschreiben vollständig die Christoffelsymbole und sind schiefsymmetrisch $\omega_j^i = - \omega_i^j$.
		Es folgt
		\begin{align*}
			\int_a^b \kappa_g(s) \di[s] + \int_a^b \omega_2^1(e_1) \di[s]
			&= \oint_{\Boundary B} \kappa_g(s) \di[s] + \oint_{\Boundary B} \omega_2^1 \\
			&\stack{\text{Stokes}}= \oint \kappa_g(s) \di[s] + \underbrace{\int_{B} \di[\omega_2^i]}_{\int_B \Omega_2^1}.
		\end{align*}
		Nun ist
		\begin{align*}
			\dx[\omega_2^1](X, Y)
			&= X(\omega_2^1 Y) - Y(\omega_2^1 X) - \omega_2^1([X,Y]) \\
			&= \nabla_X(\<\nabla_Y X_2, X_1\>) - \nabla_Y(\<\nabla_X X_2, X_1\>) - \< \nabla_{[X,Y]} X_2, X_1\> \\
			&= \< \nabla_X \nabla_Y X_2, X_1\> - \< \nabla_Y \nabla_X X_2, X_1\> \\
			&\qquad - \< \nabla_{[X,Y]} X_2, X_1\> + \< \nabla_Y X_2, \nabla_X X_1\> - \< \nabla_X X_2, \nabla_Y X_1\> \\
			&= \<R(X,Y) X_2, X_1\> + \< \nabla_Y X_2, \nabla_X X_1\> - \< \nabla_X X_2, \nabla_Y X_1\>
		\end{align*}
		Eingesetzt ergibt
		\[
			\dx[\omega_2^1](X_1, X_2) = \underbrace{\<R(X_1, X_2) X_2, X_1\>}_{=K} + \< \nabla_Y X_2, \nabla_X X_1\> - \< \nabla_X X_2, \nabla_Y X_1\>
		\]
		Es gilt
		\[
			\nabla_X X_1 = \<\nabla_X X_1, X_1\> X_1 + \< \nabla_X X_1, X_2\> X_2,
		\]
		also
		\begin{align*}
			&\< \nabla_Y X_2, X_1\>\underbrace{\<\nabla_X X_1, X_1\>}_{=0} + \<\nabla_Y X_2, X_2\> \underbrace{\<\nabla_X X_1, X_2\>}_{=0} \\
			&\quad - \< \nabla_X X_2, X_1\> \underbrace{\< \nabla_Y X_1, X_1\>}_{=0} - \< \nabla_X X_2, X_2\> \< \nabla_Y X_1, X_2\>
			= 0
		\end{align*}
		und somit
		\[
			\int_B \Omega_2^1
			= \int_B K \underbrace{\di[A]}_{=\omega^1 \wedge \omega^2}.
		\]
		Wir schreiben
		\[
			\Omega_2^1(X, Y) := \<R(X,Y) X_2, X_1\>,
		\]
		die sogenannte \emphdef{Krümmungsform}.
		Es gilt
		\[
			\Omega_2^1(X_1, X_2) = \<R(X_1, X_2) X_2, X_1\> = K
		\]
		und damit $\Omega_2^1 = K \di[A]$.
	\end{proof}
\end{thm}

\begin{thm}[Gauß-Bonnet-Formel, zweite lokale Version]
	Sei $B$ wie oben, aber nicht deffeomorph zur abgeschlossenen Kreisscheibe, sondern nur homöomorph dazu und zwar mit stückweise glattem und zusammenhängendem Rand.

	Im Bild $f(B)$ seien mit $\alpha_1, \dotsc, \alpha_n$ die orientierten äußeren Winkel an den endlich vielen Stellen (den sogenannten Ecken) bezeichnet, wo der Rand nicht glatt ist, dabei sei stets $-\pi < \alpha_i < \pi$.
	Dann gilt
	\[
		\int_{f(B)} K \di[A] + \int_{\Boundary f(B)} \kappa_g \di[s] + \sum_{i} \alpha_i = 2\pi.
	\]
\end{thm}

\begin{thm}[Gauß-Bonnet-Formel, globale Version]
	Sei $M \subset \R^3$ eine kompakte $2$-dimensionale (orientierbare) Untermannigfaltigkeit (ohne Rand).
	Dann gilt
	\[
		\int_M K \di[A] = 2\pi \chi(M) \le 4\pi,
	\]
	wobei $\chi(M) \in \Z$ die Euler-Charakteristik von $M$ ist, die invariant unter Homöomorphismen und insbesondere unabhängig von der Art der Einbettung als Untermannigfaltigkeit ist.
	\begin{proof}[Skizze]
		Zerlegung von $M$ in endlich viele $M_i$, für die die zweite lokale Version gilt
		\[
			\int_{M_i} K \di[A] + \int_{\Boundary M_i} \kappa_g(s) \di[s] + \sum_j \alpha_{ij} = 2\pi.
		\]
		Summiere nun über $i$:
		\begin{align*}
			2\pi \texp{Anzahl Flächen}
			&= 2\pi\sum_i \int_{M_i} K \di[A] + \underbrace{\sum_{i} \int_{\Boundary M_i} \kappa_s(s) \di[s]}_{=0} + \sum_{i,j} \underbrace{\alpha_{ij}}_{=\pi - \beta_{ij}} \\
			&= \int_{M} K \di[A] - 2\pi \texp{Anzahl Ecken} + 2\pi \texp{Anzahl Kanten}.
		\end{align*}
		Es folgt
		\begin{align*}
			\int_M K \di[A]
			&= 2\pi (\texp{Anzahl Ecken} - \texp{Anzahl Kanten} + \texp{Anzahl Flächen}) \\
			&= 2\pi \chi(M).
		\end{align*}
	\end{proof}
\end{thm}

\begin{nt}[Additivität von $\chi$]
	Es gilt
	\[
		\chi(A \cup B) + \chi(A \cap B) = \chi(A) + \chi(B).
	\]
\end{nt}
