\chapter{Die innere Geometrie von Flächen}


\section{Grundlagen}

Wir stellen uns „Flachländer“ (2-dim. Lebewesen), die in ihrer 2-dimensionalen Welt leben und Längen und Winkel messen können, d.h. sie kennen die (abstrakte) erste Fundamentalform.

Betrachte die Länge eines Abstandskreises in einem festen Punkt mit Radius $r$:
\[
	L = \begin{cases}
		2\pi \sin r & \text{in $S^2$} \\
		2\pi r & \text{in $E^2$} \\
		2\pi \sinh r & \text{in $H^2$}
	\end{cases}
\]
Welche geometrischen Größen hängen nur von der ersten Fundamentalform ab (und können von den Flachländern erkannt werden)?
Hauptkrümmungen und mittlere Krümmung sicher nicht:
Betrachte dazu Ebene und Zylinder, beide haben erste Fundamentalform $\Matrix{1 & 0 \\ 0 & 1}$.
Erstaunlicherweise sehen wir später, dass die Gauß-Krümmung jedoch aus der ersten Fundamentalform berechnet werden kann.

Welche Größen sind hinreichend, um ein Flächenstück eindeutig (bis auf Kongruenz) festzulegen?
Kongruent impliziert isometrisch, aber isometrisch impliziert \emph{nicht} kongruent.

Richtungsableitungen von skalaren Funktionen sind stets eindeutig und \emph{innerhalb} der Fläche berechenbar, aber Ableitungen von Vektorfeldern?

\[
	D_X f|_p = X(f)|_p
	= \lim_{t\to 0} \f 1t (f(c(t)) - f(p)),
\]
wenn $c(t)$ differenzierbar, $c(0) = p, \dot c(0) = X$.
Im $\R^n$ gilt für ein Vektorfeld $Y$.
\[
	D_X Y = D_X(\sum_{i} y_i E_i)
	= \sum_{i} (D_X y_i) E_i
\]

\coursetimestamp{24}{06}{2014}

Wir verwenden die folgenden Konventionen
\[
	(u^1, \dotsc, u^n) \in U,
	(x^1, \dotsc, x^{n+1}) \in \R^{n+1}
\]
Der Grund ist die Summenkonvention
\[
	h_{ij} = \sum_{k} h_i^k g_{kj}
\]

In $\R^{n+1}$ gibt es die Richtungsableitung
\[
	D_xY|_p = DY|_p(X)
	= \lim_{t\to 0} \f 1t (Y(p+tx) - Y(p))
	= \lim_{t\to 0} \f 1t (Y(c(t)) - Y(p))
\]
für $c(0) = p, \dot c(0) = X$.
Die Begründung für die letzte Gleichung ist
\[
	\ddx[t](Y \circ c)(t) \big|_{t=0}
	= \Df[Y]\big|_{c(0)} (\ddx[t]{c}|_{t=0})
	= \Df[Y]\big|_{p}(U)
	= D_X Y|_p
\]

\begin{df}
	Sei $f: U \to \R^{n+1}$, $Y$ sei differenzierbares Vektorfeld längs $f: U \ni u \mapsto Y(u)$, $X \in T_u f$ ein fester Tangentialvektor, $p = f(x)$.
	Dann ist die Richtungsableitung $D_x Y|_p$ definiert durch
	\[
		D_x Y|_p := \lim_{t\to  0} \f 1t \Big( Y(\underbrace{u + t(\Df)^{-1}(X)}_{\gamma(t)}) - Y(u) \Big),
	\]
	wobei $X = \Df(\xi)$ und $c(t) = f(u + t\xi)$ Kurve in der Hyperfläche ist.

	Es gilt $c(0) = p, \dot c(0) = \Df(\xi) = X$ und speziell
	\[
		D_{\f {\partial f}{\partial u^i}} Y
		= \lim_{t\to 0} \f 1t \Big(Y(u^1, \dotsc, u^i + t, \dotsc, u^n) - Y(u^1, \dotsc, u^n))
		= \f {\partial Y}{\partial u^i}.
	\]
	und
	\[
		D_{\f{\partial f}{\partial u^i}} \f{\partial f}{\partial u} = \f{\partial^2 f}{\partial u^i \partial u^j}.
	\]
\end{df}

\begin{df}[kovariante Ableitung]
	Seien $X \in T_u f, Y$ ($Y$ tangential an $f$) wie oben.
	Dann heißt
	\[
		\nabla_X Y|_p := (D_x Y|_p)^{\text{Tangentialanteil}}
		= D_X Y|_p - \<D_X|_p Y, \nu_p \> \nu_p
	\]
	die \emphdef{kovariante Ableitung} von $Y$ in Richtung $X$.
	Dann ist $\nabla_X Y |_p \in T_u f$.
	\[
		(X_p, Y) \mapsto \nabla_X Y|_p \in T_u f
	\]
	$Y$ ist definiert längs einer Kurve $c$ mit $c(0) = p, \dot c(0) = X_p$.
\end{df}

Beachte $\<D_X Y, \nu\> = - \< Y, D_x \nu\> = Ⅱ(X,Y)$, da $\< Y, \nu\> = 0$.
Also
\begin{align*}
	\nabla_X Y|_p &= D_X Y|_p - Ⅱ(X,Y) \nu_p \\
	D_x Y|_p &= \underbrace{\nabla_X Y|_p}_{\in T_u f} + \underbrace{Ⅱ(X,Y) \nu_p}_{\in \Orthspace_u f}.
\end{align*}
Es gelten folgende Rechenregeln für $D$ und $\nabla$.
\begin{itemize}
	\item
		Linearität
	\item
		Additivität
	\item
		Produktregel
	\item
		Verträglichkeit mit dem Skalarprodukt
\end{itemize}

\begin{st}
	Die kovariante Ableitung hängt nur von der ersten Fundamentalform ab (ist also eine Größe der inneren Geometrie).
	\begin{proof}
		Es gilt $X = \sum_i X^i \pddx*[u^i]{f}$, $Y = \sum_j \pddx*[u^j]{f}$ und damit
		\begin{align*}
			\nabla_X Y &= \nabla_{\sum_i X^i \pddx*[u^i]{f}} (\sum_j Y^j \pddx*[u^j]{f}) \\
			&= \sum_i X^i \nabla_{\pddx[u^i]{f}} (\sum_j Y^j \pddx*[u^j]{f}) \\
			&= \sum_{i,j} X^i \Big( \pddx*[u^i]{Y^j} \pddx*[u^j]{f} + Y^j \nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f} \Big)
		\end{align*}
		$\nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f}$ ist der Tangentialanteil von $D_{\pddx*[u^i]{f}} \pddx*[u^j]{f} = \f{\partial^2 f}{\partial u^i \partial u^j}$ und eindeutig bestimmt durch alle
		\[
			\Gamma_{ij,k} := \< \f{\partial^2 f}{\partial u^i \partial u^j}, \pddx*[u^k]{f} \>.
		\]
		$\Gamma_{ij,k}$ ist symmetrisch in $i,j$, falls $f \in C^2$.
		Es gilt
		\[
			\pddx*[u^k] \< \pddx*[u^i]{f}, \pddx*[u^j]{f} \>
		= \< \f{\partial^2 f}{\partial u^k \partial u^i}, \pddx*[u^j]{f} \>
			+ \< \pddx*[u^i]{f}, \f{\partial^2 f}{\partial u^k \partial u^j} \>
			= \Gamma_{ki,j} + \Gamma_{kj,i},
		\]
		also
		\begin{align*}
			(g_{ij})_k &= \Gamma_{ik,j} + \Gamma_{jk,i} \\
			(g_{jk})_i &= \Gamma_{ji,k} + \Gamma_{ki,j} \\
			(g_{ki})_j &= \Gamma_{kj,i} + \Gamma_{ij,k}
		\end{align*}
		und damit
		\[
			2 \Gamma_{ij,k} = - (g_{ij})_k + (g_{jk})_i + (g_{ki})_j,
		\]
		hängt also nur von der ersten Fundamentalform ab.
	\end{proof}
\end{st}

\begin{df}
	Der Ausdruck
	\[
		\Gamma_{ij,k} = \f 12 \Big( - (g_{ij})_k + (g_{jk})_i + (g_{ki})_j \Big)
	\]
	heißt \emphdef{Christoffelsymbol erster Art}.
	Die $\Gamma_{ij}^k$ mit
	\[
		\nabla_{\pddx*[u^i]{f}} \pddx*[u^j]{f}
		= \sum_l \Gamma_{ij}^l \pddx*[u^l]{f}
	\]
	heißen \emphdef{Christoffelsymbole zweiter Art}.

	Dabei gilt $\Gamma_{ij,k} = \Gamma_{ji,k}, \Gamma_{ij}^k = \Gamma_{ji}^k$, $\Gamma_{ij,k} = \sum_l \Gamma_{ij}^l g_{lk}$ und $\Gamma_{ij}^k = \sum_l \Gamma_{ij,l} g^{lk}$.

	Die kovariante Ableitung $\nabla_X Y$ mit $X = \sum_i X^i \pddx*[u^i]{f}, Y = \sum_j Y^j \pddx*[u^j]{f}$ ist
	\[
		\nabla_X Y|_p = \sum_{ij} X^i \Big( \pddx*[u^i]{Y^k} + \sum_j Y^j \Gamma_{ij}^k \Big) \pddx*[u^k]{f}
	\]
	Im euklidischen Raum sind alle $\Gamma_{ij,k} = 0$.

	Wir schreiben
	\[
		(\nabla_i Y)^k
		= \pddx*[u^i]{Y^k} + \Gamma_{ij}^k Y^j
	\]
\end{df}

\coursetimestamp{26}{06}{2014}


Die 2-dimensionalen Flachländer leiten nun wie folgt ab
\begin{itemize}
	\item
		skalare Funktion: Differentialquotient
	\item
		Vektorfelder $Y \hat = (Y^1, Y^2)$ in Komponenten einer Basis, $(1, 0), (0, 1)$ entsprechen den Basisfeldern.
		\begin{align*}
			\nabla_i (Y^1, Y^2)
			&= ((Y^1)_i, (Y^2)_i)
				+ \Big( \sum_{j} \Gamma_{ij}^1 Y^j, \sum_{j} \Gamma_{ij}^2 Y^j \Big) \\
			&= ((Y^1)_i, (Y^2)_i)
				+ (\Gamma_{i1}^1 Y^1 + \Gamma_{i2}^1 Y^2, \Gamma_{i1}^2 Y^1 + \Gamma_{i2}^2 Y^2).
		\end{align*}
		Wann ist $(Y^1, Y^2)$ „konstant“ (auch „parallel“ genannt)? 
		Wenn $\nabla_i(Y^1, Y^2) = 0$ gilt, für jedes $i$.

		Im euklidischen bedeutet ein konstantes Vektorfeld auch konstante Koeffizienten der Vektoren, hier jedoch nicht.
\end{itemize}

\begin{df}[parallel]
	\begin{enumerate}[(i)]
		\item
			Ein tangentiales Vektorfeld $Y$ längs eines (Hyper-)Flächenstücks $f$ heißt \emphdef{parallel}, wenn $\nabla_X Y|_p = 0$ für jeden Punkt $p$ und jeden Tangentialvektor $X \in T_pf$.
		\item
			$Y$ heißt \emphdef{parallel längs einer Kurve} $c = f \circ \gamma$, wenn $\nabla_{\dot c} Y = 0$ gilt für jeden Punkt der Kurve.
	\end{enumerate}
	\begin{note}
		Die Definition in (i) ist überbestimmt, d.h. im Allgemeinen gibt es keine parallelen Vektorfelder.

		(ii) ist ein System gewöhnlicher Differentialgleichungen.
	\end{note}
\end{df}

\begin{st}
	Seien $f: U \to \R^{n+1}, \gamma: \R \supset I \to U$ stetig differenzierbar, $t_0 \in I$ fest und $Y_0 \in T_{v_0} f$ fest, $c = f \circ \gamma$.

	Dann gibt es genau ein längs $c$ paralleles Vektorfeld $Y$ mit $Y(t_0) = Y_0$ (Anfangsbedingung).
	\begin{proof}
		$\gamma(t) = (u^1(t), \dotsc, u^n(t)) \in U$, $c = f \circ \gamma$.
		Es gilt
		\[
			\dot c = \ddx[t]{c}
			= X(c(t))
			= \sum_i \dot u^i(t) \pddx*[u^i]{f}
		\]
		und folglich
		\begin{align*}
			\nabla_i Y
			&= \sum_{i,k} \dot u^i \Big( \pddx[u^i]{Y^k} + \sum_j Y^i + \Gamma_{ij}^k(c(t)) \Big) \pddx[u^k]{f} \\
			&= \sum_{k} \Big( \ddx[t]{Y^k} + \sum_{i,j} \dot u^i Y^j \Gamma_{ij}^k \Big) \underbrace{\pddx[u^k]{f}}_{\text{bekannt}}
		\end{align*}
		Also ist $\gamma$ parallel genau dann, wenn $\nabla_c Y = 0$, also genau dann, wenn
		\[
			\dot Y^k + \sum_{i,j} \dot u^i Y^j \Gamma_{ij}^k = 0
		\]
		für alle $k$.
		Dies ist ein System gewöhnlicher linearer Differentialgleichungen erster Ordnung für $Y^1(t), \dotsc, Y^n(t)$.
		Die Theorie der gewöhnlichen Differentialgleichungen liefert eine eindeutige Lösung längst eines Intervalls $I$.
	\end{proof}
\end{st}

\begin{kor}
	Sei $Y$ parallel längs $c$, dann ist $\<Y, Y\>$ konstant.

	Ist $X, Y$ parallele längs $c$, dann ist $\<X, Y\>$ konstant.
	\begin{proof}
		$\nabla_i \<Y, Y\> = 2 \<\nabla_i Y, Y\> = 0$.
	\end{proof}
	\begin{note}
		Parallelverschiebungen sind Isometrien.
	\end{note}
\end{kor}

\section{Geodätische}

\begin{df}[Geodätische, geodätische Linien]
	Eine reguläre Kurve $c = f \circ \gamma$ heißt \emphdef{Geodätische}, wenn stets $\nabla_{\dot c} \dot c$ und $\dot c$ linear abhängig sind, oder äquivalent $\nabla_{c'} c' = 0$ mit Bogenlängenparameter.
	\begin{note}
		Also $(c'')^{\text{Tang}} = (D_{c'} c')^{\text{Tang}} = 0$.
	\end{note}
	\begin{proof}
		Es gilt
		\[
			\nabla_{\f{\dot c}{\|\dot c\|}} \f{\dot c}{\|\dot c\|}
			= \f 1{\|\dot c\|} \nabla_{\dot c} (\f 1{\|\dot c\|} \dot c)
			= \f 1{\|\dot c\|} \big( (\f 1{\|\dot c\|})^{\cdot} \dot c + \f 1{\|\dot c\|} \nabla_{\dot c}\dot c \big)
		\]
		also wenn $\nabla_{c'} c' = 0$, dann sind $\dot c, \nabla_{\dot c} \dot c$ linear abhängig.

		\[
			\< \dot c, \dot c\> = \f 1{\|\dot c\|} \Big( (\f 1{\|\dot c\||}) \< \dot c, \dot c \> + \f 1{\|\dot c\|} \< \nabla_{\dot c} \dot c, \dot c \> \Big)
			= 0,
		\]
		da
		\[
			(\<\dot c, \dot c\>^{-\f 12})^{\cdot}
			= - \f 1, \< \dot c, \dot c \>^{-\f 32} \cdot 2 \< \nabla_{\dot c} \dot c, \dot c\>
		\]
	\end{proof}
\end{df}

\begin{st}
	$f: U \to \R^{n+1}$ gegeben, $p_0 = f(u_0)$ sei fest.
	$Y_0$ sei fester Tangentialvektor in $p_0$ mit $\|Y_0\| = 1$.

	Dann gilt es ein $\eps > 0$ und genau eine nach Bogenlänge parametrisierte Geodätische $c = f \circ \gamma$, $\gamma: (-\eps,\eps) \to U$ mit $\gamma(0) = u_0 , c(0) = p_0, \dot c(0) = Y_0$ (Anfangsbedingung).
	\begin{proof}
		Setze $Y^i(t) = \dot u^i(t)$ in der obigen Gleichung.
		\[
			\nabla_{\dot c} \dot c = 0
			\quad\iff\quad
			\forall k : \ddot u^k + \sum_{i,j} \dot u^i \dot u^j \Gamma_{ij}^k = 0
		\]
		Dies ist ein System nicht-linearer gewöhnlicher Differentialgleichungen zweiter Ordnung (beachte: $\Gamma_{ij}^k$ hängt von $c(t)$, also von $u^i$ ab).
		Lokal existieren eindeutige Lösungen zu gegebenen Anfangsbedingungen.
		Mit $\|Y_0\| = 1 \implies \|\dot c\| = 1$ liegt eine Bogenlängenparametrisierung vor.
	\end{proof}
\end{st}

Bei nicht-regulären Kurven $c(t)$ hängt $Y$ immer von $t$ ab, nicht von $c(t)$.
Dann definiert man analog
\[
	\nabla_{\dot c} Y := (\ddx[t]{Y})^{\text{Tangentialanteil}}
\]
und schreibt auch $\f {\nabla Y(t)}{\dx[t]}$.

Sei $c = f \circ \gamma$ regulär und nach Bogenlänge parametrisiert, $\|\dot c\| = 1$.
Betrachte eine Variante der Frenet-Gleichungen mit dem Darboux-3-Bein:
\begin{align*}
	E_1 &:= c' \\
	E_2 &\orth E_1, \|E_2\| = 1, \text{ pos. orientiert}, \\ % E_2 \in T_f.
	E_3 &:= \nu
\end{align*}
Es gilt $E_1' = c'' = \kappa_g E_2 + \kappa_\nu E_3$.
Es ergibt sich
\[
	\Matrix*{E_1 & E_2 & E_3}'
	= \Matrix*{0 & \kappa_g & \kappa_\nu \\ -\kappa_g & 0 & \tau_g \\ -\kappa_\nu & - \tau_g & 0}
	\Vector*{E_1 & E_2 & E_3}
\]
mit einer geodätischen Krümmung $\kappa_g$, einer Normalkrümmung $\kappa_\nu$ und einer geodätischen Torsion $\tau_g$.

Es gilt $c'' = D_{c'} c' = \nabla_{c'} c' + \kappa_\nu E_3 = \kappa_g E_2 + \kappa_\nu E_3$, also ist $c$ Geodätische genau dann, wenn
\[
	\nabla_{c'}c' = 0,
\]
oder äquivalent
\[
	\kappa_{g} = 0,
\]
oder äquivalent $c'', \nu$ linear abhängig, oder äquivalent, wenn die $(c', c'')$-Schmiegebene die Flächennormale enthält.

\coursetimestamp{01}{07}{2014}

% fixme : C(s,t) = c'(s,t)
\begin{st}[Kürzeste Linien sind Geodätische]
	$p, q$ seien zwei feste Punkte auf $f: U \to \R^{n+1}$, $c = f \circ \gamma$ sei eine $C^\infty$-Kurve, die $p$ und $q$ verbindet, $c(0) = p$, $c(L) = q$ für die Länge $L$ von $c$.
	Falls jede andere $C^\infty$-Kurve von $p$ nach $q$ mindestens die selbe Länge hat wie $c$, dann ist $c$ eine Geodätischem
	\begin{proof}
		Betrachte eine Variation $C(s,t) \in C^\infty$ mit Kurvenparameter $s$, $c_t(s) = C(s,t)$ und Scherparametere $t$, $c(s) = C(s, 0)$.
		Es gilt $C(0,t) = c(0) = p, C(L,t) = c(L) = q$ für alle $t \in (-\eps, \eps)$.
		Man hat
		\[
			L(c_t) = \int_0^L \< \ddx[s]{c_t}, \ddx[s]{c_t} \>^{\f 12} \di[s].
		\]
		Ableiten von $L(c_t)$ bei $t = 0$ ergibt (nach Voraussetzung hat $L(c_t)$ Minimum bei $t = 0$):
		\begin{align*}
			0
			&= \ddx[t]|_{t=0} L(c_t) \\
			&= \ddx[t]|_{t=0} \int_0^t \< \ddx[s]{C}, \ddx[s]{C} \>^{\f 12} \di[s] \\
			&= \int_0^L \ddx[t]|_{t=0} \< \ddx[s]{C}, \ddx[s]{C} \>^{\f 12} \di[s] \\
			&= \int_0^1 \f 12 \dfrac{2 \< \f{\partial^2 C}{\partial l \partial s}, \ddx[s]{C} \>}{\<\ddx[s]{C}, \ddx[s]{C}\>|_{t=0}} \\
			&= \int_0^1 \< \f{\partial^2 C}{\partial l \partial s}, \ddx[s]{C} \> \di[s] \\
			&= \int_0^L \< \nabla_{\dot c} \ddx[t]{C}, \ddx[s]{C} \> \di[s] \\
			&= \int_0^L \Big( \ddx[s] \< \ddx[t]{C}, \ddx[s]{C} \> - \< \ddx[t]{C}, \nabla_{\dot c}\dot c \> \Big) \di[s] \\
			&= \< \underbrace{\ddx[t]{C}}_{= 0}, \ddx[s]{C} \> \big|_{s=0}^{s=L} - \int_0^L \< \ddx[t]{C}|_{t=0}, \nabla_{\dot c}\dot c \> \di[s]
		\end{align*}
		Es ist also notwendigerweise
		\[
			\int_0^L \< \ddx[t]{C}|_{t=0}, \nabla_{\dot c}\dot c \> \di[s] = 0
		\]
		für alle $C(s,t)$.
		Da $\ddx[t]{C}|_{t=0}$ beliebig gewählt werden kann, muss $\nabla_{\dot c} \dot c = 0$ längs $c$ sein, also ist $c$ eine Geodätische.
	\end{proof}
	\begin{note}
		Geodätische sind lokal auch kürzeste Kurven, die zwei Punkte miteinander verbinden.
		Global jedoch im Allgemeinen nicht.
	\end{note}
\end{st}

\begin{ex}
	\begin{itemize}
		\item
			In $S^2$ sind Geodätische gerade die Großkreise („sphärische Geraden“).
			Dies ergibt sich sofort daraus, dass $\ddot c \orth T_u f$.
		\item
			In $E^2$ sind die Geodätischen gerade die Geraden.
		\item
			In $H^2$ sind Geodätische gerade die „hyperbolischen Geraden“.
	\end{itemize}
\end{ex}

Welche Dinge können nun mit der inneren Geometrie beschrieben werden?
Wir haben Punkte, „Geraden“, Längen, Winkel, Abstände, Kongruenz von (geodätischen) Dreiecken, Abstandskreise.

\begin{df}
	Eine Fläche heißt \emphdef{geodätisch vollständig}, wenn jede Geodätische über ganz $\R$ nach Bogenlänge parametrisiert werden kann.
	\begin{note}
		Anschaulich heißt dies, dass Geodätische unendlich lang in beide Richtungen sind.
	\end{note}
\end{df}

\begin{ex}
	\begin{itemize}
		\item
			$S^2, E^2, H^2$ sind geodätisch vollständig.
		\item
			Die Pseudosphäre ist nicht geodätisch vollständig.
	\end{itemize}
\end{ex}

\subsection{Geodätische Polarkoordinaten um einen festen Punkt \texorpdfstring{$p$}{p}}

Sei ein Einheits-Tangentialenvektor $X$ in $p$ gegeben, sowie eine Geodätische $c_X$ mit $c_X(0) = p, \dot c_X(0) = X$.
\[
	c_X(r) \leftrightarrow (r,X) \in (0, \infty) \times S^{n-1}(1)
\]
für kleine $r > 0$.

\begin{ex}
	\begin{itemize}
		\item
			In $E^2$ haben wir
			\[
				(r, \phi) \mapsto (r \cos \phi, r \sin \phi) \in \R^2
			\]
			mit $Ⅰ=\Matrix{1 & 0 \\ 0 & r^2}$.
		\item
			In $S^2$ haben wir
			\[
				(r, \phi) \mapsto (\sin r \cos \phi, \sin r \sin \phi, \cos r) \in S^2
			\]
			mit $Ⅰ=\Matrix{1 & 0 \\ 0 & \sin^2 r}$.
		\item
			In $H^2$ haben wir
			\[
				(r, \phi) \mapsto (\sinh r \cos \phi, \sinh \cos \phi, \cosh r)
			\]
			und es ergibt sich
			\begin{align*}
				f_r &= (\cosh r \cos \phi, \cosh r \sin \phi, \sinh r) \\
				f_\phi &= (-\sinh r \sin \phi, \sinh \cos \phi, 0)
			\end{align*}
			also $\<f_r, f_r\>_1 = \cos^2 r - \sinh^2 r = 1$, $\<f_\phi, f_\phi\> = \sinh^2 r$, d.h. $Ⅰ=\Matrix{1 & 0 \\ 0 & \sinh^2 r}$.
	\end{itemize}
\end{ex}

Schon Gauß hatte erkannt:
\begin{quote}
	Die Gauß-Krümmung ist eine Größe der inneren Geometrie.
\end{quote}

Wir nutzen dazu Ableitungsgleichungen und Integrabilitätsbedingungen.

Eine notwendige Bedingung dafür, dass ein Vektorfeld $X = (X^1, x^2) \in \R^2$ ein Gradientenfeld ist, ist
\[
	\ddx[x^2]{X^1} = \ddx[x^1]{X^2},
\]
dies ergibt sich aus dem Satz von Schwartz (Vertauschen der zweiten Ableitungen).
Im $\R^n$ ist analog
\[
	\forall i,j : \ddx[x^j]{X^i} = \ddx[x^i]{X^j}
\]
eine notwendige Bedingung, auch \emphdef{Integrabilitätsbedingung} genannt.

Diese Bedingungen sind \emph{nicht} hinreichend, betrachte dazu
\[
	(X^1, X^2) = \Vector{\f{-y}{x^2 + y^2} & \f{x}{x^2 + y^2}}
\]

Lokal sind Integrabilitätsbedingungen auch hinreichend.m
Betrachte dazu in $\R^2$ eine sternförmige Menge bezüglich $p \in \R^2$.
Sei ein Vektorfeld $X$ gegeben und wähle $f(p)$, setze
\[
	f(q) d= \int_p^q X
	= \int_0^1 \< X, \dot c(t) \> \di[t]
\]
mit $c(t) = (1-t)p + tq$, $\dot c = q - p$.
Es folgt dann $\ddx[x^i]{f} = X^i$.

Ableitungsgleichungen:
\begin{align*}
	\f{\partial^2 f}{\partial u^i \partial u^j} &= \sum_{l} \Gamma_{ij}^l \ddx[u^l]{f} + h_{ij} \nu, \\
	\ddx[u^i]{\nu} &= - \sum_{j} h_i^j \ddx[u^j]{f}.
\end{align*}
Jetzt sei $f$ gesucht!
Integrabilitäsbedingungen für $f$:
\begin{align*}
	\ddx[u^k] (\f{\partial^2 f}{\partial u^i \partial u^j})
	&\stack ?=
	\ddx[u^j] (\f{\partial^2 f}{\partial u^i \partial u^k}) \\
	\f{\partial^2 \nu}{\partial u^i \partial u^j} &= \f{\partial^2 \nu}{\partial u^j \partial u^i}
\end{align*}
für alle $i, j, k$.

% fixme: Gauß-Gleichung, Codazzi-Mainardi Gleichung


\begin{st}
	Die Integrabilitätsbedingungen der Ableitungsgleichungen sind die beiden folgenden Gleichungen
	\begin{enumerate}[(i)]
		\item
			Die Gauß-Gleichung
			\[
				\ddx[u^k] \Gamma_{ij}^s - \ddx[u^j] \Gamma_{ik}^s + \sum_{r} (\Gamma_{ij}^r \Gamma_{ik}^s - \Gamma_{ik}^r \Gamma_{rj}^s)
				= \sum_{m} (h_{ij} h_{km} - h_{ik} h_{jm}) g^{ms}
			\]
			für alle $i,j,k,s$.
		\item
			Die Codazzi-Mainardi-Gleichung.
	\end{enumerate}
\end{st}

Interessant ist besonders die Gauß-Gleichung, die die linke Seite nur von $(g_{ij})$ und die rechte Seite nur von $(h_{ij})$ abhängt.

\begin{kor}[Theorema Egregium, Gauß]
	Die Gauß-Krümmung $K = \f{\det Ⅱ}{\det Ⅰ}$ eines Flächenstücks $f: U \to \R^3$ der Klasse $C^3$ hängt nur von der ersten Fundamentalform ab.

	Die Gauß-Krümmung ist also eine „Größe der inneren Geometrie“.
	\begin{proof}
		Betrachte die rechte Seite der Gauß-Gleichung mit $n = 2$, $i = j = 1$, $k = 2$ und multiplizieren $g_{s2}$ und summieren über $s$:
		\[
			\sum_{s=1}^2 \sum_{m=1}^2 (h_{11} h_{2m} - h_{12} h_{1m}) \underbrace{g^{ms} g_{s2}}_{= \delta^m_{2}}
			= h_{11} h_{22} - h_{12} h_{12}
			= \det Ⅱ.
		\]
		$\det Ⅱ$ hängt also nur von der ersten Fundamentalform ab.
	\end{proof}
\end{kor}

\begin{df}
	Die linke Seite der Gauß-Gleichung heißt auch \emphdef{Krümmungstensor}:
	\[
		R_{ikj}^s
		= \pddx[u^k] \Gamma_{ij}^s - \pddx[u^j] \Gamma_{ik}^s + \sum_r ( \Gamma_{ij}^r \Gamma_{jk}^s - \Gamma_{ik}^r \Gamma_{rj}^s).
	\]
	Es gilt $R_{ikj}^s g_{sm} = R_{mikj}$.
\end{df}

\begin{ex}
	\begin{itemize}
		\item
			$g_{ij}, h_{ij}$ sind $(0,2)$-Tensoren.
		\item
			$h_i^j$ ist ein $(1,1)$-Tensor.
		\item
			$R_{ikj}^s$ ist ein $(1,3)$-Tensor.
	\end{itemize}
	Die charakteristische Eigenschaft eines Tensors ist, dass $\sum_s R_{ikj}^s \pddx[u^s]^{f}$ ein Ausdruck ist, der im festen Punkte $p$ nur von $\pddx[u^i]{f}|_p, \pddx[u^k]{f}|_p, \pddx[u^j]{f}|_p$ abhängt („tensorielles Verhalten“).

	Analog $g_{ij}|_p = Ⅰ(\pddx[u^i]{f}|_p, \pddx[u^j]{f}|_p)$.

	Ohne Beweis gilt
	\[
		\sum_s R_{ikj}^s \pddx[u^s]{f}
		= R(\pddx[u^k]{f}, \pddx[u^j]{f}) \pddx[u^i]{f}
	\]
	mit $R(X,Y)Z := \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z$ für Vektorfelder $X, Y, Z$.
	Dabei ist $[X,Y]$ die sogenannte \emphdef{Lie-Klammer} nach Sorhus Lie:
	\[
		[X, Y] := D_X Y - D_Y X.
	\]
	Es gilt stets $\nabla_{\pddx[u^i]{f}} \pddx[u^j]{f} = \nabla_{\pddx[u^j]{f}} \pddx[u^i]{f} = \f{\partial^2 f}{\partial u^i \partial u^j}$, aber im Allgemeinen \emph{nicht} $\nabla_X Y = \nabla_Y X$ für Vektorfelder $X, Y$.
	Betrachte dazu das folgende Beispiel im $\R^2 = \Span{x^1, x^2}$:
	Sei $X := x^1 e_1, Y = e_1$.
	\begin{align*}
		D_X Y &= x^1 D_{e_2} e_1 = 0 \\
		D_Y X &= D_{e_1} (x^1 e_2) = \underbrace{D_{e_1} x^1}_{\pddx[x^1]{x^1} = 1} e_2 + \underbrace{x^1 D_{e_1} e_2}_{=0} \neq 0.
	\end{align*}

	Eine Übung ist für relle Funktionen $f, g, h$
	\[
		R(fX, gX)hY|_p
		= fgh|_p R(X,Y)Z
	\]
	unabhängig von $f, g, h$.
\end{ex}


\begin{df}
	Für zwei Vektorfelder $X, Y$ in $\R^n$ heißt
	\[
		[X, Y] := D_X Y - D_Y X
	\]
	die \emphdef{Lie-Klammer} von $X \neq 0$ und $Y$.
	Falls $X, Y$ tangential an einer Hyperfläche sind, dann alternativ
	\[
		[X, Y] = \nabla_X Y - \nabla_Y X,
	\]
	weil der Normalanteil gleich $(Ⅱ(X,Y) - Ⅱ(Y,X)) \nu = 0$ ist.
\end{df}

Es gibt eine explizite Formel für $K$ in Abhängigkeit von $g_{ij}$ (für 2-dimensionale Flächen).
Theoretisch wunderbar, praktisch sehr schwierig.

\begin{st}[Gauß-Krümmung in speziellen Parametern]
	In orthogonalen Parametern eines 2-dimensionalen Flächenstücks $f(u,v)$ mit $Ⅰ = \Matrix{E & 0 \\ 0 & G}$ berechnet sich die Gauß-Krümmung als
	\[
		K = - \f 1{2\sqrt{EG}} \Big( \big(\f{E_v}{\sqrt{EG}} \big)_v + \big(\f{G_u}{\sqrt{EG}} \big)_u \Big).
	\]
	Wenn $E = G = \lambda$ (isotherme Parameter, konforme Parametrisierung), dann ist
	\[
		K = - \f 1{2\lambda} \Big( \big(\f{\lambda_v}{\lambda} \big)_v + \big(\f{\lambda_u}{\lambda} \big)_u \Big).
		= - \f 1{2\lambda} \Laplace (\log \lambda)
	\]
	\begin{proof}
		Wir haben die Christoffelsymbole
		\begin{align*}
			\Gamma_{11,1} &= \f 12 E_u, &
			\Gamma_{11}^1 &= \Gamma_{11,1} g^{11} + \Gamma_{11,2} g^{21} = \f 12 \f{E_u}{E} \\
			\Gamma_{11,2} &= -\f 12 E_v, &
			\Gamma_{11}^2 &= - \f 12 \f{E_v}{G} \\
			\Gamma_{12,1} &= \f 12 E_v, &
			\Gamma_{12}^1 &= \f 12 \f{E_v}E \\
			\Gamma_{12,2} &= \f 12 G_u, &
			\Gamma_{12}^2 &= \f 12 \f{G_u}{G} \\
			\Gamma_{22,1} &= -\f 12 G_u, &
			\Gamma_{22}^1 &= - \f 12 \f{G_u}{E} \\
			\Gamma_{22,2} &= \f 12 G_i, &
			\Gamma_{22}^2 &= \f 12 \f{G_v}{G}
		\end{align*}
		Setze nun in die Gauß-Gleichung ein $i=j=1, k = 2$, Summiere über $s$:
		\begin{align*}
			\det(h_{ij})
			&= \sum_s \bigg( (\Gamma_{11}^s)_v - (\Gamma_{12}^s)_u + \sum_{r} \Big( \gamma_11^{r} \Gamma_{r2}^s - \Gamma_{12}^r \Gamma_{r1}^s \Big) \bigg) g_{s2} \\
			&= \Big((\Gamma_{11}^2)_v - (\Gamma_{12}^2)_u + \Gamma_{11}^1 \Gamma_{12}^2 + \Gamma_{11}^2 \Gamma_{22}^2 - \Gamma_{12}^1 \Gamma_{11}^2 - \Gamma_{12}^2 \Gamma_{21}^2 \Big) G \\
			&= \Big( -\f 12 \big( \f {E_v}G \big)_v - \f 12 \big(\f{G_u}{G}\big)_u + \f 12 \f{E_k}{E} \f12 \f{G_u}{G} - \f 12 \f{E_v}{G} \f 12 \f{G_v}{G} + \f 12 \f{E_v}{E} \f 12 \f {E_v}{G} - \f 12 \f{G_u}{G} \f 12 \f{G_k}{G} \Big) G
		\end{align*}
		Es gilt
		\begin{align*}
			K
			&= \f{\det h_{ij}}{EG} \\
			&= \f{G}{2EG} \Big( - \f{G E_{vv} - E_v G_v}{G^2} - \f{G_{uu}G - G_u^2}{G^2} + \f 12 \f{E_u G_u}{EG} - \f 12 \f{E_v G_v}{G^2} + \f 12 \f{E_v^2}{EG} - \f 12 \f{G_u^2}{G^2} \Big) \\
			&= \f 1{2EG} \Big( - E_{vv} - G_{uu} + \f {E_v G_v}{G} + \f{G_u^2}{G} + \f 12 \f{E_k G_k}{E} - \f 12 \f{E_v G_v}{G} + \f 12 \f {E_v^2}{E} - \f 12 \f {G_u^2}{G} \Big) \\
			&= \f 1{2EG} \Big( - E_{vv} - G_{uu} + \f 12 \f {E_v G_v}{G} + \f 12 \f{G_u^2}{G} + \f 12 \f{E_k G_k}{E} + \f 12 \f {E_v^2}{E} \Big). \\
		\end{align*}
		Andererseits gilt
		\begin{align*}
			- \f 1{2\sqrt{EG}} \Big( \big( \f{E_v}{\sqrt{EG}} \big)_v + \big( \f{G_u}{\sqrt{EG}} \big)_u \Big)
			= - \f 1{2 \sqrt{EG}} \bigg( \f{\sqrt EG E_{vv} - E_v (\sqrt{EG})_v}{EG} + \f{\sqrt{EG} G_{uu} - G_u (\sqrt{EG})_u}{EG} \bigg)
			= - \f 1{2 EG} \Big( E_{vv} + G_{uu} - E_v \f 1{\sqrt{EG}} \f{E_v G + E G_v}{2 \sqrt{EG}} - G_u \f 1{\sqrt{EG}} \f {E_u G + E G_u}{2 \sqrt{EG}}
			= - \f 1{2 EG} \Big( E_{vv} + G_{uu} - E_v^2 \f 1{\sqrt{2E}} - E_v G_v \f 1{2G} - G_u E_u \f 1{2E} - G_u^2 \f 1{2G}
		\end{align*}
		Dies stimmt mit oberem überein.

		Den Fall $E = G = \lambda$ überprüft man durch Einsetzen.

		Es gilt
		\[
			(\Laplace \log \lambda)
			= (\log \lambda)_{uu} + (\log \lambda)_{vv}
			= (\f{\lambda_u}{\lambda})_u + (\f{\lambda_v}{\lambda})_v.
		\]
	\end{proof}
\end{st}

\section{Konstruktion orthogonaler Koordinaten}

\begin{df}[geodätische Parallelekoordinaten]
	Die Koordinaten eines Flächenstücks $f: U \to \R^3$ heißen \emphdef{geodätischen Parallelkooridaten}, fals die $u$-Linien stets nach der Bogenlänge parametrisierte Geodätische sind, die jede der $v$-Linien orthogonnal schneiden.
	Nach Konstruktion schneiden in diesem Fall zwei $v$-Linien aus den $u$-Linien stets gleich lange Abschnitte heraus.
	\begin{note}
		Geodätische Parallelkoordinaten liegen genau dann vor, wenn in den Parametern $u,v$ die erste Fundamentalform die Gestalt
		\[
			Ⅰ= \Matrix{1 & 0 \\ 0 & G}
		\]
		hat mit einer positiven Funktion $G = G(u,v)$.
	\end{note}
\end{df}

\begin{kor}
	In geodätischen Parallelkoordinaten $\Matrix{1 & 0 \\ 0 & G}$ gilt die folgende einfache Gleichung für die Gauß-Krümmung:
	\[
		K(u,v) = - \f{(\sqrt{G})_{uu}}{\sqrt G}.
	\]
	Alternativ dazu haben wir für $Ⅰ= \Matrix{1 & 0 \\ 0 & G^2}$ den Ausdruck $K = \f -{G_{uu}}{G}$.
	\begin{proof}
		Es gilt
		\[
			K = - \f 1{2\sqrt{G}} \big( \f{G_u}{\sqrt G} \big)_u
			= - \f{(\sqrt G)_{uu}}{\sqrt{G}}.
		\]
	\end{proof}
	\begin{nt}
		Bei Drehflächen war $(g_{ij}) = \Matrix{1 & 0 \\ 0 & r^2}$ und die Gaußkrümmung $K = - \f{r''}{r}$.
	\end{nt}
\end{kor}


\coursetimestamp{08}{07}{2014}


\begin{nt}
	Hat die Länge eines Abschnittes auf $u=0$ (von $v_1$ nach $v_2$) ein Minimum im Vergleich zu den Parallelkurven, so ist $(\sqrt{G})_{uu} \ge 0$, also ist $K \le 0$.
	Analog für ein Maximum und $K \ge 0$.
\end{nt}


\begin{nt}[Geodätische Polarkoordinaten]
	Lokal kann man auf einer Fläche geodätische Polarkoordinaten anlegen.
\end{nt}

Es gibt allerdings noch „bessere“ Koordinaten, sogenannten Fermi-Koordinaten, welche in der Geodäsie eine wichtige Verwendung haben.
\begin{itemize}
	\item
		Eine Kurve $u=0$ ist eine Geodätische, nach Bogenlänge parametrisiert.
	\item
		Alle $u$-Linien sind Geodätische, nach Bogenlänge parametrisiert und senkrecht auf den $v$-Linien.
\end{itemize}
Dann gilt
\[
	\Matrix{E & F \\ F & G}
	= \Matrix{1 & 0 \\ 0 & G}
\]
mit $G(0,v) = 1$ für alle $v$ und $\pddx[u]{G}|_{u=0} = 0$ und $\Gamma_{ij}^k|_{(0,v)} = 0$ für alle $v$.
Infinitesimal sieht dies also euklidisch aus.
Wir haben also
\[
	\Matrix{E & F \\ F & G}
	= \Matrix{1 & 0 \\ 0 & 1 + \LandauO(v^2)}
\]
für festes $u$.

\begin{ex}
	\begin{itemize}
		\item
			Betrachte $S^2$ und $u = 0$, den Äquator.
			Es ergibt sich
			\[
				\Matrix{E & F \\ F & G}
				= \Matrix{1 & 0 \\ 0 & \cos^2 u}.
			\]
			Es gilt $K = - \f{(\cos u)''}{\cos u}$.
		\item
			Allgemeiner auf Drehflächen ist für $(r(t), h(t))$ nach Bogenlänge $K = - \f {r''}{r}$.
			Es gilt
			\[
				\Matrix{E & F \\ F & G}
				= \Matrix{1 & 0 \\ 0 & r^2(t)}
			\]
			wobei $r'(t_0) = 0$ und $r(t) = r(t_0) + \f{(t-t_0)^2}2 r''(t_0) + \dotsc$.
			Die $\phi$-Linie ist eine Geodätische, wenn $r' = 0$.
		\item
			Die Wulstfläche ($a^2K > 1$), oder Spindelfläche ($a^2K < 1$).
			\[
				f(t,\phi) = \Vector*{a \cos t \cos \f{\phi}a & a \cos t \sin \f{\phi}a & \int_0^t \sqrt{1 - a^2 \sin^2 x} \di[x]}.
			\]
			Wir haben
			\begin{align*}
				f_t &= \Vector{-a \sin t \cos \f{\phi}a & - a \sin t \sin \f{\phi}a & \sqrt{1 - a^2 \sin^2 t}}, &
				f_\phi &= \Vector{-\cos t \sin \f{\phi}a & \cos t \cos \f{\phi}a & 0},
			\end{align*}
			also ist
			\begin{align*}
				E &= \<f_t, f_t\> = a^2 \sin^2 t + 1 - a^2 \sin^2 t = 1, \\
				G &= \<f_\phi, f_\phi\> = \cos^2 t.
			\end{align*}
			In $t = 0$ auf dem Äquator hat man dann $K = 1$.
	\end{itemize}
\end{ex}

\begin{nt}
	$f, \tilde f$ isometrisch impliziert, dass auch $K = \tilde K$.
	Die Umkehrung gilt im Allgemeinen nicht.
\end{nt}

\begin{st}[Flächen mit gleicher konstanter Gaußkrümmung sind isometrisch]
	$f: U \to \R^3, \tilde f: \tilde U \to \R^3$ seien Flächenstücke mit der gleichen konstanten Gauß-Krümmung.
	Dann sind lokal $f$ und $\tilde f$ isometrisch zueinander.
	\begin{proof}
		$K$ ein die konstante Gauß-Krümmung.
		Wir fixieren zwei feste Punkte in $U, \tilde U$ und führen in geeigneten Ümgebungen jeweils geodätische Parallelkoordinaten zu eier Geodätischen $u = 0$ ein (d.h. Fermi-Koordinaten).
		Die Parameter bezeichnen wir für beide Flächen imt dem gleichen Symbol $(u, v)$.
		Die ersten Fundamentalformen $Ⅰ, \tilde Ⅰ$ haben dann die Gestalt $\Matrix{1 & 0 \\ 0 & G(u,v)}, \Matrix{1 & 0 \\ 0 & \tilde G(u,v)}$
		mit $G(0,v) = 1 = \tilde G(0,v)$ für jedes $v$.
		Durch die notwendig bestehenden Differentialgleicheungen
		\begin{align*}
			\pddx[u^2] \sqrt G &= - K \sqrt G,
			\pddx[u^2] \sqrt{\tilde G} &= - K \sqrt{\tilde G}
		\end{align*}
		werden dann $G$ und $\tilde G$ eindeutig bestimmt wegen der ebenfalls notwendig geltenden Anfangsbedingungen
		\[
			\pddx[u] \sqrt{G(u,v)}|_{u=0}
			= 0 =
			\pddx[u] \sqrt{\tilde G(u,v)}|_{u=0}.
		\]
		Beachte, dass dies für jedes feste (aber beliebige) $v$ eine gewöhnliche Differentialgleichung zweiter Ordnung mit Parameter $u$ ist.
		Insgesamt folgt damit in diesen Paremetern $G = \tilde G$, also $Ⅰ = \tilde Ⅰ$ und damit die (lokale) Isometrie von $f$ und $\tilde f$.
	\end{proof}
	\begin{note}
		Ist die Gauß-Krümmung nicht konstant, dann gibt es nicht-isometrische Flächenpaare mit derselben Gauß-Krümmung in gewissen Parametern!
		Das kann sich bezüglich Fermi-Koordinaten oder anderen Parametrn durchaus ändern.
		Damit kann man dieselbe Differentialgleichung wie oben nicht mehr verwenden.
	\end{note}
\end{st}

\begin{nt}[Extrinsische Interpretation der Gauß-Krümmung]
	Die Gaußkrümmung ist gegeben als $K = \det L = \det(-\Df[\nu] (\Df)^{-1})$.
	Dabei ist $\nu$ die Gauß-Abbildung.
	$K$ ist die infinitesimale Flächenverzerrung (mit Vorzeichen) der Gauß-Abbildung, bzw. der Weingartenabbildung.
	\[
		\int_{f(B)} |K| \di[A]
		= \Vol_{S^2}(\nu(B))
	\]
	für  jeden kompakten Bereich $B \subset U \xrightarrow{f} \R^2$.
	\begin{proof}
		Es gilt
		\[
			\int_{f(B)} |K| \di[A]
			= \int_{f(B)} |\det L| \di[A]
			= \int_{B} |\det L| \sqrt{\det (g_{ij})} \di[u^1]\di[u^2]
		\]
		und
		\[
			\Vol_{S^2}(\nu(B))
			= \int_{B}\sqrt{\det (e_{ij})} \di[u^1] \di[u^2]
			= \int_{B}\sqrt{(\det L)^2 \det(g_{ij})} \di[u^1]\di[u^2].
		\]
		Es gilt nämlich für eine Eigenbasis $X, Y$ von $L$
		\begin{align*}
			\det(e_{ij}) &= \det \Matrix{\<LX, LX\> & \<LX, LY\> \\ \<LY, LX\> & \<LY, LY\>} \\
			&= \det \Matrix{\lambda^2 \<X,X\> & \lambda\mu \<X, Y\> \\ \lambda\mu \<Y, X\> & \mu^2 \<Y, Y\>} \\
			&= \lambda^2 \mu^2 \det \Matrix{\<X,X\> & \<X, Y\> \\ \<Y, X\> & \<Y, Y\>} \\
			&= (\det L)^2 \det (g_{ij}).
		\end{align*}
	\end{proof}
	\begin{note}
		Damit ist $\nu$ orientierungserhaltend für $K > 0$ und orientierungsumkehrend für $K < 0$ ??
	\end{note}
\end{nt}

Wir haben
\begin{align*}
	K &= 1 : \Matrix{1 & 0 \\ 0 & \cos^2 u}, \\
	K &= -1 : \Matrix{1 & 0 \\ 0 & \cosh^2 u}, \\
	K &= 0 : \Matrix{1 & 0 \\ 0 & 1}.
\end{align*}


\coursetimestamp{10}{07}{2014}

\begin{nt}[Eine andere Schreibweise der Integrabilitätsbedingungen]
	Die Ableitungsgleichungen sind
	\begin{align*}
		D_X  Y &= \nabla_X Y + \<LX, Y\> \nu \\
		D_X \nu &= - LX.
	\end{align*}
	Mit Hilfe der Krümmungstensors $R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]} Z$, $[X,Y] = \nabla_X Y - \nabla_Y X = D_X Y - D_Y X$.
\end{nt}

\begin{nt}
	Seien $X, Y, Z$ tangentiale Vektorfelder.

	Es gilt die Gauß-Gleichung
	\[
		R(X,Y) Z = \<LX, Z\> LX - \< LX, Z\> LY \\
	\]
	und die Codazzi-Marinard-Gleichung
	\[
		\nabla_X(LY) - \nabla_Y(LX) - L([X,Y]) = 0.
	\]
	\begin{proof}
		Zerlegen der Gleichung
		\[
			D_X D_Y Z - D_Y D_X Z - D_{[X,Y]} Z = 0
		\]
		in Tangential- und Normalanteil ergibt
		\begin{align*}
			0 &= D_X D_Y Z - D_Y D_X Z \\
			&= D_X(\nabla_Y Z + \<LY, Z\> \nu) - D_Y(\nabla_X Z + \<LX, Z\> \nu)
				- \nabla_{[X,Y]}Z - \<L[X,Y], Z\> \nu \\
			&= \nabla_X \nabla_Y Z + \<LX, \nabla_Y Z\> \nu + D_X\<LY, Z\> \nu + \< LY, Z\> D_X \nu
				- \nabla_Y \nabla_X Z - \<LY, \nabla_X Z\> \nu - D_Y\<LX, Z\> \nu - \< LX, Z\> D_Y \nu
				- \nabla_{[X,Y]} Z - \<L[X,Y], Z\> \nu \\
			&= R(X, Y) Z - \<LY, Z\>LX + \<LX, Z\>LY + \Big( \<\nabla_X(LY), Z\> - \< \nabla_Y(LX), Z\> - \<L[X,Y], Z\> \Big) \nu
		\end{align*}
		und es folgen beide Gleichungen.

		Es verbleibt $D_X D_Y Z - D_Y D_X - D_{[X,Y]} Z = 0$ zu zeigen.
		Sei $e_1, \dotsc, e_{n+1}$ die Standardbasis, $[e_i, e_j] = 0$.
		Schreibe $X = \sum_i X^i e_i, Y = \sum_i Y^i e_i, Z = \sum_i Z^i e_i$.
		Es gilt
		\begin{align*}
			D_X D_Y Z
			&= \sum_i X^i D_{e_i} \Big(\sum_j Y^j D_{e_j} Z \Big) \\
			&= \sum_{i,j} X^i Y^j D_{e_i} D_{e_j} Z + \sum_{i,j} X^i \underbrace{D_{e_i} Y^j}_{= \pddx[e^i]{Y^j}} D_{e_j} Z
		\end{align*}
		Es folgt
		\begin{align*}
			D_X D_Y Z - D_Y D_X Z
			&= \sum_{i,j} X^i Y^j (\underbrace{D_{e_i} D_{e_j} Z - D_{e_j} D_{e_i} Z}_{=0}) + \sum_{i,j} (\underbrace{ X^i \pddx[x^i]{Y^j} - Y^i \pddx[x^i]{x^j} }_{\text{Komponenten von $[X,Y]$}}) D_{e_j} Z \\
			&= D_{[X,Y]} Z.
		\end{align*}
	\end{proof}
	\begin{note}
		Die Codazzi-Marinard-Gleichung lässt sich mit der „Produktregel“ $\nabla_X(LY) = (\nabla_X L) Y + L \nabla_X Y$ auch anders schreiben (man definiert gerade $(\nabla_X L)(Y) := \nabla_X(LY) - L(\nabla_X Y)$).
		Es gilt
		\[
			\nabla_X(LY) - \nabla_Y(LX)
			= (\nabla_X L) Y - (\nabla_Y L) X + L(\underbrace{\nabla_X Y - \nabla_Y X}_{=[X,Y]})
		\]
		und damit ist die Codazzi-Marinard-Gleichung äquivalent zu
		\[
			(\nabla_X L)(Y) - (\nabla_Y L)(X) = 0.
		\]
	\end{note}
\end{nt}

\begin{kor}
	\begin{enumerate}[1.]
		\item
			$R(X, Y) Z|_p$ hängt nur ab von $X_p, Y_p, Z_p$, weil dies für die rechte Seite der Gauß-Gleichung gilt.
		\item
			Theorema Egregium:
			\[
				K = \< R(X,Y)Y, X \>,
			\]
			wenn $X, Y$ eine ON-Basis ist.
			\begin{proof}
				\[
					\<LY, Y\>\<LX, X\> - \<LX, Y\>\<LY, X\>
					= Ⅱ(Y, Y) Ⅱ(X,X) - Ⅱ(X,Y)^2
					= \det Ⅱ
				\]
				in Basis $X, Y$.
				Also
				\[
					\<Y, Y\>\<X, X\> - \<X, Y\>^2
					= 1 = \det Ⅰ
				\]
				in Basis $X, Y$.
			\end{proof}
	\end{enumerate}
\end{kor}

\begin{st}
	$f, \tilde f: U \to \R^{n+1}$ seien zwei Hyperflächenstücke mit der gleichen ersten Fundamentalform $(g_{ij}) = (\tilde g_{ij})$.
	In einem Punkt $p = f(u)$ sei der Rang der Weingartenabbildung $L$ mindesten gleich $3$.
	Dann gilt für die zweiten Fundamentalformen in diesem Punkt
	\[
		(h_{ij}(u)) = \pm(\tilde h_{ij}(u)).
	\]
\end{st}

\begin{kor}
	Falls $U$ zusammenhängend ist und falls für $f, \tilde f: U \to \R^{n+1}$ überall $(g_{ij}) = (\tilde g_{ij})$ gilt und falls überall $\rg(L) \ge 3$ ist, dann stimmen $f(U)$ und $\tilde f(U)$ bis auf eukldische Bewegungen überein (inklusive Spiegelungen).
\end{kor}

\section{Der Hauptsatz der lokalen Flächentheorie}

\begin{align*}
	\f{\partial^2 f}{\partial u^i \partial u^j}
		&= \sum_{k} \Gamma_{ij}^k \pddx[u^k]{f} + h_{ij} \nu \\
	\pddx[u^i]{\nu}
		&= - \sum_k h_i^k \pddx[u^k]{f}
		= - \sum_{k,m} h_{im} g^{mk} \pddx[u^k]{f}
\end{align*}

$(g_{ij})$ und $(h_{ij})$ bestimmen lokal genau ein (Hyper-)Flächenstück (bis auf eukldisichen Bewegungen).
Wie ermitteln wir dann das Flächenstück?
Idee: Ableitungsgleichungen integrieren.
Wir erhalten Integrabilitätsbedingungen für Gauß- und Codazzi-Gleichung.

Seien $(g_{ij}), (h_{ij})$ gegeben, dann ist $(g^{kl}), \Gamma_{ij}^k, h_i^j$ bestimmte (Koeffizienten der rechten Seite der Ableitungsgleichungen).

Wir ermitteln $f$ in zwei Schritten:
\begin{enumerate}[1.]
	\item
		Suche ein begleitendes Bein $X_1, \dotsc, X_n, \nu$ mit
		\begin{align*}
			\pddx[u^i]{X_j} &= \sum_k \Gamma_{ij}^k X_k + h_{ij} \nu \\
			\pddx[u^i]{\nu} &= -\sum_k h_i^k x_k.
		\end{align*}
	\item
		$\pddx[u^i]{f} = X_i$ mit $\nu \orth X_1, \dotsc, X_n$, $\|\nu \| = 1$.
\end{enumerate}

\begin{lem}[Bewegungsinvarianz und Eindeutigkeit]
	Sei $f: U \to \R^{n+1}$ ein gegebenes Flächenstück, $B: \R^{n+1} \to \R^{n+1}$ sei eine euklidische Bewegung, d.h. $B(x) = A(x) + b$ mit einer orthogonalen Abbildung $A \in \SO(n+1)$.
	Setze $\tilde f := B \circ f$.
	Dann gilt bei geeigneter Wahl der Einheitsnormalen für die beiden Fundamentalforen $g, \tilde g, h, \tilde h$ die Gleichung
	\[
		g_{ij} = \tilde g_{ij},
		h_{ij} = \tilde h_{ij}.
	\]
	Umgegekehrt: Falls für zwei gleich orientierte Flächenstücke $f, \tilde f: U \to \R^{n+1}$ die Gleichung $g_{ij} = \tilde g_{ij}, h_{ij} = \tilde h_{ij}$ gilt, dann stimmen siee überein bis auf eine euklidische Bewegung, d.h. es gilt
	\[
		\tilde f := B \circ f
	\]
	für eine gewisse euklidische Bewegung $B$.
	\begin{proof}
		Wenn $A$ und $b$ konstant sind, gilt $\pddx[u^i]{\tilde f} = A(\pddx[u^i]{f})$ und für eine geeignete Wahl der Einheitsnormalen $\nu$ gilt $\tilde \nu = A\nu$.
		Weil $A$ orthogonal ist, folgt direkt die Behauptung des ersten Teils.

		Für den zweiten Teil definieren wir für jedes $u \in U$ eine Abbildung $A(u): \R^{n+1} \to \R^{n+1}$ durch $A(u)(\pddx[u^i]{f}|_u) = \pddx[u^i]{\tilde f}|_u$ und $A(u)(\nu(u)) = \tilde \nu(u)$.
		$A(u)$ ist dann für jedes $u$ eine orthogonale Ibbildung $A(u) \in \SO(n+1)$.
		Wir wollen zeigen, dass $A(u)$ nicht von $u$ abhängt.
		Durch weiteres Ableiten erhalten wir einerseits
		\begin{align*}
			\f{\partial^2 \tilde f}{\partial u^i \partial u^j}
			= \pddx[u^i] (A \pddx[u^j]{f})
			= \pddx[u^i]{A} (\pddx[u^j]{f}) + A(\f{\partial^2 f}{\partial u^i \partial u^j}), \\
			\pddx[u^i]{\tilde \nu} = \pddx[u^i]{A\nu} = \pddx[u^i]{A}(\nu) + A (\pddx[u^i]{\nu})
		\end{align*}
		Andererseits gilt $\tilde g^{ij} = g^{ij}$ und $\tilde \Gamma_{ij}^k = \Gamma_{ij}^k$.
		Damit folgt aus den Ableitungsgleichungen
		\[
			\f{\partial^2 \tilde f}{\partial u^i \partial u^j}
			= A (\f{\partial^2 f}{\partial u^i \partial u^j})
			\pddx[u^i]{\tilde \nu} = A (\pddx[u^i]{\nu})
		\]
		Dies impliziert $\pddx[u^i]{A} = 0$ für alle $i$, also ist $A$ konstant.
		Ferner ist $f - A(f)$ ebenfalls konstant, also $\tilde f - B\circ f = 0$ für eine gewisse euklidische Bewegung $B$.
	\end{proof}
\end{lem}




